{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c97251d1-ea7a-410a-b101-233a451e905b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "ChatPDF 简化版本\n",
    "使用 LangChain 标准组件实现 PDF 文档问答系统\n",
    "\"\"\"\n",
    "import os\n",
    "from PyPDF2 import PdfReader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.embeddings import DashScopeEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_community.llms import Tongyi\n",
    "from typing import List, Dict, Tuple\n",
    "\n",
    "# 配置参数\n",
    "CHUNK_SIZE = 1000  # 分块大小\n",
    "CHUNK_OVERLAP = 200  # 重叠\n",
    "EMBEDDING_MODEL = \"text-embedding-v1\"\n",
    "LLM_MODEL = \"qwen-turbo\"\n",
    "DASHSCOPE_API_KEY = os.getenv('DASHSCOPE_API_KEY')\n",
    "\n",
    "if not DASHSCOPE_API_KEY:\n",
    "    raise ValueError(\"请设置 DASHSCOPE_API_KEY 环境变量\")\n",
    "\n",
    "def process_pdf(pdf_path: str) -> Tuple[List[str], List[Dict]]:\n",
    "    \"\"\"\n",
    "    处理PDF文件，返回文本块和元数据\n",
    "    \"\"\"\n",
    "    # 读取PDF\n",
    "    reader = PdfReader(pdf_path)\n",
    "    \n",
    "    # 收集所有页面的文本和位置信息\n",
    "    all_text = []\n",
    "    page_positions = []  # 记录每个字符属于哪一页\n",
    "    \n",
    "    for page_num, page in enumerate(reader.pages, 1):\n",
    "        page_text = page.extract_text()\n",
    "        if not page_text:\n",
    "            continue\n",
    "            \n",
    "        # 清理文本\n",
    "        page_text = page_text.replace(\"百度文库\", \"\").replace(\"好好学习，天天向上\", \"\").strip()\n",
    "        \n",
    "        # 记录当前页面的所有字符位置\n",
    "        for _ in range(len(page_text)):\n",
    "            page_positions.append(page_num)\n",
    "            \n",
    "        all_text.append(page_text)\n",
    "    \n",
    "    # 合并所有文本\n",
    "    full_text = \"\".join(all_text)\n",
    "    \n",
    "    # 使用LangChain的文本分割器\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        separators=[\"\\n\\n\", \"\\n\", \"。\", \"！\", \"？\", \".\", \"!\", \"?\", \" \", \"\"],  # 添加中文标点\n",
    "        chunk_size=CHUNK_SIZE,\n",
    "        chunk_overlap=CHUNK_OVERLAP,\n",
    "        length_function=len,\n",
    "        is_separator_regex=False\n",
    "    )\n",
    "    \n",
    "    # 分割文本\n",
    "    chunks = text_splitter.split_text(full_text)\n",
    "    \n",
    "    # 为每个文本块创建元数据\n",
    "    chunk_metadata = []\n",
    "    for chunk in chunks:\n",
    "        # 找到这个chunk在原始文本中的位置\n",
    "        start_pos = full_text.find(chunk)\n",
    "        if start_pos == -1:\n",
    "            # 如果找不到精确匹配，使用第一个字符的位置\n",
    "            start_pos = 0\n",
    "            \n",
    "        # 获取这个chunk的起始页码\n",
    "        start_page = page_positions[start_pos] if start_pos < len(page_positions) else 1\n",
    "        \n",
    "        # 获取这个chunk的结束页码\n",
    "        end_pos = start_pos + len(chunk)\n",
    "        end_page = page_positions[min(end_pos, len(page_positions)-1)] if end_pos < len(page_positions) else start_page\n",
    "        \n",
    "        # 如果chunk跨越了多页，使用起始页码\n",
    "        chunk_metadata.append({\n",
    "            \"page\": start_page,\n",
    "            \"source\": pdf_path\n",
    "        })\n",
    "    \n",
    "    return chunks, chunk_metadata\n",
    "\n",
    "def create_vector_store(texts: List[str], metadata: List[Dict]):\n",
    "    \"\"\"\n",
    "    创建向量存储\n",
    "    \"\"\"\n",
    "    # 创建embeddings\n",
    "    embeddings = DashScopeEmbeddings(\n",
    "        model=EMBEDDING_MODEL,\n",
    "        dashscope_api_key=DASHSCOPE_API_KEY\n",
    "    )\n",
    "    \n",
    "    # 创建向量存储\n",
    "    vector_store = FAISS.from_texts(\n",
    "        texts=texts,\n",
    "        embedding=embeddings,\n",
    "        metadatas=metadata\n",
    "    )\n",
    "    # print(vector_store)\n",
    "    return vector_store\n",
    "\n",
    "def create_qa_chain(vector_store):\n",
    "    \"\"\"\n",
    "    创建问答链\n",
    "    \"\"\"\n",
    "    # 创建LLM\n",
    "    llm = Tongyi(\n",
    "        model_name=LLM_MODEL,\n",
    "        temperature=0.7,\n",
    "        dashscope_api_key=DASHSCOPE_API_KEY\n",
    "    )\n",
    "    \n",
    "    # 创建提示模板\n",
    "    template = (\n",
    "        \"\"\"你是一个专业的文档问答助手。请根据提供的上下文来回答问题。\n",
    "如果上下文中包含问题的答案，请直接回答。\n",
    "如果上下文中没有相关信息，请明确回答\"不知道\"。\n",
    "\n",
    "上下文：\n",
    "{context}\n",
    "\n",
    "问题：{question}\n",
    "\n",
    "请仔细分析上下文，确保答案准确。回答：\"\"\"\n",
    "    )\n",
    "\n",
    "    QA_PROMPT = PromptTemplate(\n",
    "        input_variables=[\"context\",\"question\"],  # 必须包含这两个变量\n",
    "        template=template\n",
    "    )\n",
    "\n",
    "    # 构建问答链\n",
    "    qa_chain = RetrievalQA.from_chain_type(\n",
    "       llm=llm,  # 控制生成稳定性\n",
    "       chain_type=\"stuff\",\n",
    "       chain_type_kwargs={\n",
    "       \"prompt\": QA_PROMPT,\n",
    "#       \"document_variable_name\": \"context\"  # 必须与模板变量名一致，context 的值是自动从检索器（retriever）获取并注入到 prompt \n",
    "        },\n",
    "       retriever=vector_store.as_retriever(\n",
    "#            search_kwargs={\"k\": 5, \"score_threshold\": 0.65}  # 如果设了score_threshold，就会出现docs返回空值\n",
    "           search_kwargs={\"k\": 5}  # 控制检索质量\n",
    "        ),\n",
    "       # input_key=\"query\",  # 显式声明输入键名\n",
    "       # document_variable_name=\"context\",  # 明确指定文档变量名\n",
    "       return_source_documents=True\n",
    "    )\n",
    "    \n",
    "    return qa_chain, vector_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a70335e9-f6a9-4b4a-9cb7-914750988c38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "处理完成，共生成 5 个文本块\n"
     ]
    }
   ],
   "source": [
    "# 处理PDF\n",
    "# pdf_path = input(\"请输入PDF文件路径：\")\n",
    "# pdf_path = './上海市数字经济发展.pdf'\n",
    "pdf_path = './浦发上海浦东发展银行西安分行个金客户经理考核办法.pdf'\n",
    "texts, metadata = process_pdf(pdf_path)\n",
    "\n",
    "print(f\"\\n处理完成，共生成 {len(texts)} 个文本块\")\n",
    "\n",
    "texts, metadata = process_pdf(pdf_path)\n",
    "# for i in range(len(texts)) :\n",
    "#     print(f\"texts[{i}]\\n{texts[i]},\\n metadata={metadata[i]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a064efcf-d81d-4226-9d6a-46f16b4eae39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RetrievalQA(verbose=False, combine_documents_chain=StuffDocumentsChain(verbose=False, llm_chain=LLMChain(verbose=False, prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template='你是一个专业的文档问答助手。请根据提供的上下文来回答问题。\\n如果上下文中包含问题的答案，请直接回答。\\n如果上下文中没有相关信息，请明确回答\"不知道\"。\\n\\n上下文：\\n{context}\\n\\n问题：{question}\\n\\n请仔细分析上下文，确保答案准确。回答：'), llm=Tongyi(client=<class 'dashscope.aigc.generation.Generation'>, model_kwargs={}), output_parser=StrOutputParser(), llm_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_variable_name='context'), return_source_documents=True, retriever=VectorStoreRetriever(tags=['FAISS', 'DashScopeEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x000002B22CF7AB40>, search_kwargs={'k': 5}))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 创建向量存储\n",
    "vector_store = create_vector_store(texts, metadata)\n",
    "\n",
    "# 创建问答链\n",
    "qa_chain, vector_store = create_qa_chain(vector_store)\n",
    "\n",
    "qa_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed71a59-b08e-4d80-afe5-9b85732c1484",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存FAISS向量数据库,已备后用\n",
    "vector_store.save_local('./faiss-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72d53bfa-2f94-4dc7-a0a5-d1d7ef13d3d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#测试score_threshold参数的作用\n",
    "retriever = vector_store.as_retriever(search_kwargs={'k': 5,'score_threshold': 0.65})  # 如果设了score_threshold，就会出现docs返回空值\n",
    "docs = retriever.invoke(\"客户经理被投诉了，投诉一次扣多少分\")  # 或 get_relevant_documents()\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65b0a37-23bf-4102-ba3e-ae29f2a3e0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#测试score_threshold参数的作用\n",
    "retriever = vector_store.as_retriever(search_kwargs={'k': 5})  # 如果设了score_threshold，就会出现docs返回空值\n",
    "docs = retriever.invoke(\"客户经理被投诉了，投诉一次扣多少分\")  # 或 get_relevant_documents()\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4b8e21-4cec-46b7-a0a0-e4f2180c181c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #比较问题和答案文档的相似性\n",
    "# from dashscope import TextEmbedding\n",
    "# import numpy as np\n",
    "# # 1. 获取 DashScope Embeddings\n",
    "# def get_embedding(text):\n",
    "#     resp = TextEmbedding.call(\n",
    "#         model = EMBEDDING_MODEL,\n",
    "#         input=text\n",
    "#     )\n",
    "#     return np.array(resp.output['embeddings'][0]['embedding'])\n",
    "\n",
    "# # 2. 计算余弦相似度\n",
    "# def cosine_similarity(a, b):\n",
    "#     return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
    "\n",
    "# # 实际使用\n",
    "# query = \"客户经理被投诉了，投诉一次扣多少分\"\n",
    "# document = docs\n",
    "\n",
    "# query_vec = get_embedding(query)\n",
    "# doc_vec = get_embedding(document)\n",
    "\n",
    "# similarity = cosine_similarity(query_vec, doc_vec)\n",
    "# print(f\"相似度: {similarity:.4f}\")  # 输出示例: 相似度: 0.83\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "94004d8e-8222-4bd4-9245-3c040685d570",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "系统已准备就绪，可以开始提问了。输入'退出'结束对话。\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "请输入问题： 客服经理的工作职责\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 问题 ===\n",
      "客服经理的工作职责\n",
      "\n",
      "=== 回答 ===\n",
      "不知道\n",
      "\n",
      "来源：\n",
      "\n",
      "未找到相关文档。\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "请输入问题： 退出\n"
     ]
    }
   ],
   "source": [
    "# 问答循环\n",
    "print(\"\\n系统已准备就绪，可以开始提问了。输入'退出'结束对话。\")\n",
    "\n",
    "\n",
    "while True:\n",
    "    question = input(\"\\n请输入问题：\")\n",
    "    if question.lower() == '退出':\n",
    "        break\n",
    "        \n",
    "    # # 直接使用检索器获取相关文档\n",
    "    #docs = vector_store.similarity_search(question, k=6)\n",
    "    # print(f\"\\n检索到的文档数量：{len(docs)}\")\n",
    "    # if docs:\n",
    "    #     # print(\"检索到的文档内容：\")\n",
    "    #     # for doc in docs:\n",
    "    #     #     print(f\"- {doc.page_content[:200]}...\")\n",
    "    \n",
    "    # 生成回答\n",
    "\n",
    "    answer = qa_chain.invoke({\"query\":question})\n",
    "    \n",
    "#    print(f'answer={answer}')\n",
    "    # 输出结果\n",
    "    print(f\"\\n=== 问题 ===\\n{question}\")\n",
    "    print(f\"\\n=== 回答 ===\\n{answer['result']}\")\n",
    "    \n",
    "    # 显示来源\n",
    "    print(\"\\n来源：\")\n",
    "    if  answer['source_documents'] :\n",
    "        for doc in answer['source_documents']:\n",
    "            print(f\"- 页码：{doc.metadata.get('page', '未知')}, 来源：{doc.metadata.get('source', '未知')}\")\n",
    "#            print(f\"  内容：{doc.page_content[:50]}...\")  # 显示文档内容的前10个字符\n",
    "    else:\n",
    "        print(\"\\n未找到相关文档。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3d6e0b-8340-4312-acc7-bb8ff1cbf7ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
