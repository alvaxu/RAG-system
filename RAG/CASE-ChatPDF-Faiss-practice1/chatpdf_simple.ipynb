{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c97251d1-ea7a-410a-b101-233a451e905b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "ChatPDF 简化版本\n",
    "使用 LangChain 标准组件实现 PDF 文档问答系统\n",
    "\"\"\"\n",
    "import os\n",
    "from PyPDF2 import PdfReader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.embeddings import DashScopeEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.chains import create_qa_with_sources_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.chains.retrieval import create_retrieval_chain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_community.llms import Tongyi\n",
    "from typing import List, Dict, Tuple\n",
    "\n",
    "# 配置参数\n",
    "CHUNK_SIZE = 1000  # 分块大小\n",
    "CHUNK_OVERLAP = 200  # 重叠\n",
    "EMBEDDING_MODEL = \"text-embedding-v1\"\n",
    "LLM_MODEL = \"qwen-turbo\"\n",
    "DASHSCOPE_API_KEY = os.getenv('DASHSCOPE_API_KEY')\n",
    "\n",
    "if not DASHSCOPE_API_KEY:\n",
    "    raise ValueError(\"请设置 DASHSCOPE_API_KEY 环境变量\")\n",
    "\n",
    "def process_pdf(pdf_path: str) -> Tuple[List[str], List[Dict]]:\n",
    "    \"\"\"\n",
    "    处理PDF文件，返回文本块和元数据\n",
    "    \"\"\"\n",
    "    # 读取PDF\n",
    "    reader = PdfReader(pdf_path)\n",
    "    \n",
    "    # 收集所有页面的文本和位置信息\n",
    "    all_text = []\n",
    "    page_positions = []  # 记录每个字符属于哪一页\n",
    "    \n",
    "    for page_num, page in enumerate(reader.pages, 1):\n",
    "        page_text = page.extract_text()\n",
    "        if not page_text:\n",
    "            continue\n",
    "            \n",
    "        # 清理文本\n",
    "        page_text = page_text.replace(\"百度文库\", \"\").replace(\"好好学习，天天向上\", \"\").strip()\n",
    "        \n",
    "        # 记录当前页面的所有字符位置\n",
    "        for _ in range(len(page_text)):\n",
    "            page_positions.append(page_num)\n",
    "            \n",
    "        all_text.append(page_text)\n",
    "    \n",
    "    # 合并所有文本\n",
    "    full_text = \"\".join(all_text)\n",
    "    \n",
    "    # 使用LangChain的文本分割器\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        separators=[\"\\n\\n\", \"\\n\", \"。\", \"！\", \"？\", \".\", \"!\", \"?\", \" \", \"\"],  # 添加中文标点\n",
    "        chunk_size=CHUNK_SIZE,\n",
    "        chunk_overlap=CHUNK_OVERLAP,\n",
    "        length_function=len,\n",
    "        is_separator_regex=False\n",
    "    )\n",
    "    \n",
    "    # 分割文本\n",
    "    chunks = text_splitter.split_text(full_text)\n",
    "    \n",
    "    # 为每个文本块创建元数据\n",
    "    chunk_metadata = []\n",
    "    for chunk in chunks:\n",
    "        # 找到这个chunk在原始文本中的位置\n",
    "        start_pos = full_text.find(chunk)\n",
    "        if start_pos == -1:\n",
    "            # 如果找不到精确匹配，使用第一个字符的位置\n",
    "            start_pos = 0\n",
    "            \n",
    "        # 获取这个chunk的起始页码\n",
    "        start_page = page_positions[start_pos] if start_pos < len(page_positions) else 1\n",
    "        \n",
    "        # 获取这个chunk的结束页码\n",
    "        end_pos = start_pos + len(chunk)\n",
    "        end_page = page_positions[min(end_pos, len(page_positions)-1)] if end_pos < len(page_positions) else start_page\n",
    "        \n",
    "        # 如果chunk跨越了多页，使用起始页码\n",
    "        chunk_metadata.append({\n",
    "            \"page\": start_page,\n",
    "            \"source\": pdf_path\n",
    "        })\n",
    "    \n",
    "    return chunks, chunk_metadata\n",
    "\n",
    "def create_vector_store(texts: List[str], metadata: List[Dict]):\n",
    "    \"\"\"\n",
    "    创建向量存储\n",
    "    \"\"\"\n",
    "    # 创建embeddings\n",
    "    embeddings = DashScopeEmbeddings(\n",
    "        model=EMBEDDING_MODEL,\n",
    "        dashscope_api_key=DASHSCOPE_API_KEY\n",
    "    )\n",
    "    \n",
    "    # 创建向量存储\n",
    "    vector_store = FAISS.from_texts(\n",
    "        texts=texts,\n",
    "        embedding=embeddings,\n",
    "        metadatas=metadata\n",
    "    )\n",
    "    # print(vector_store)\n",
    "    return vector_store\n",
    "\n",
    "def create_qa_chain(vector_store):\n",
    "    \"\"\"\n",
    "    创建问答链\n",
    "    \"\"\"\n",
    "    # 创建LLM\n",
    "    llm = Tongyi(\n",
    "        model_name=LLM_MODEL,\n",
    "        temperature=0.7,\n",
    "        dashscope_api_key=DASHSCOPE_API_KEY\n",
    "    )\n",
    "    \n",
    "    # 创建提示模板\n",
    "    prompt = PromptTemplate.from_template(\n",
    "        \"\"\"你是一个专业的文档问答助手。请根据提供的上下文来回答问题。\n",
    "如果上下文中包含问题的答案，请直接回答。\n",
    "如果上下文中没有相关信息，请明确回答\"不知道\"。\n",
    "\n",
    "上下文：\n",
    "{context}\n",
    "\n",
    "问题：{input}\n",
    "\n",
    "请仔细分析上下文，确保答案准确。回答：\"\"\"\n",
    "    )\n",
    "    \n",
    "    # 创建文档链\n",
    "    document_chain = create_stuff_documents_chain(\n",
    "        llm=llm,\n",
    "        prompt=prompt,\n",
    "        document_variable_name=\"context\"  # 明确指定文档变量名\n",
    "    )\n",
    "\n",
    "    return document_chain, vector_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a70335e9-f6a9-4b4a-9cb7-914750988c38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "处理完成，共生成 5 个文本块\n"
     ]
    }
   ],
   "source": [
    "# 处理PDF\n",
    "# pdf_path = input(\"请输入PDF文件路径：\")\n",
    "# pdf_path = './上海市数字经济发展.pdf'\n",
    "pdf_path = './浦发上海浦东发展银行西安分行个金客户经理考核办法.pdf'\n",
    "texts, metadata = process_pdf(pdf_path)\n",
    "\n",
    "print(f\"\\n处理完成，共生成 {len(texts)} 个文本块\")\n",
    "\n",
    "texts, metadata = process_pdf(pdf_path)\n",
    "# for i in range(len(texts)) :\n",
    "#     print(f\"texts[{i}]\\n{texts[i]},\\n metadata={metadata[i]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a064efcf-d81d-4226-9d6a-46f16b4eae39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.vectorstores.faiss.FAISS at 0x2215ca34e00>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 创建向量存储\n",
    "vector_store = create_vector_store(texts, metadata)\n",
    "\n",
    "# 创建问答链\n",
    "qa_chain, vector_store = create_qa_chain(vector_store)\n",
    "\n",
    "vector_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94004d8e-8222-4bd4-9245-3c040685d570",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "系统已准备就绪，可以开始提问了。输入'退出'结束对话。\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "请输入问题： 客户经理被投诉了，投诉一次扣多少分\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "检索到的文档数量：5\n",
      "\n",
      "回答：\n",
      "根据上下文，客户经理被投诉一次扣2分。具体见以下内容：\n",
      "\n",
      "\"客户服务效率低，态度生硬或不及时为客户提供维护服务，有客户投诉的, 每投诉一次扣 2分\"\n",
      "\n",
      "来源：\n",
      "- 页码：5, 来源：./浦发上海浦东发展银行西安分行个金客户经理考核办法.pdf\n",
      "  内容：-5 第五章  工作质量考核标准  \n",
      "第九条   工作质量考核实行扣分制。工作质量指个金客户经理在\n",
      "...\n",
      "- 页码：8, 来源：./浦发上海浦东发展银行西安分行个金客户经理考核办法.pdf\n",
      "  内容：准，个金客户经理即可在下一季度享受该级行员的薪资标准。下一季\n",
      "度考核时，按照已享受行员级别考核折算比...\n",
      "- 页码：1, 来源：./浦发上海浦东发展银行西安分行个金客户经理考核办法.pdf\n",
      "  内容：-   \n",
      "-1 上海浦东发展银行西安分行  \n",
      "个金客户经理管理考核暂行办法  \n",
      " \n",
      " \n",
      "第一章  总...\n",
      "- 页码：6, 来源：./浦发上海浦东发展银行西安分行个金客户经理考核办法.pdf\n",
      "  内容：调整浮动。   \n",
      "第十三条   特别聘任：  \n",
      "（一）经分行同意录用从其他单位调入的个金客户经理，由...\n",
      "- 页码：3, 来源：./浦发上海浦东发展银行西安分行个金客户经理考核办法.pdf\n",
      "  内容：-3 第三章  基础素质要求  \n",
      "第七条   个金客户经理准入条件：  \n",
      "（一）工作经历：须具备大专...\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "请输入问题： 退出\n"
     ]
    }
   ],
   "source": [
    "# 问答循环\n",
    "print(\"\\n系统已准备就绪，可以开始提问了。输入'退出'结束对话。\")\n",
    "while True:\n",
    "    question = input(\"\\n请输入问题：\")\n",
    "    if question.lower() == '退出':\n",
    "        break\n",
    "        \n",
    "    # 直接使用检索器获取相关文档\n",
    "    docs = vector_store.similarity_search(question, k=6)\n",
    "    print(f\"\\n检索到的文档数量：{len(docs)}\")\n",
    "    if docs:\n",
    "        # print(\"检索到的文档内容：\")\n",
    "        # for doc in docs:\n",
    "        #     print(f\"- {doc.page_content[:200]}...\")\n",
    "    \n",
    "        # 生成回答\n",
    "        answer = qa_chain.invoke({\n",
    "            \"input\": question,\n",
    "            \"context\": docs\n",
    "        })\n",
    "        \n",
    "        # 输出结果\n",
    "        print(\"\\n回答：\")\n",
    "        print(answer)  # 直接打印返回的字符串\n",
    "        \n",
    "        # 显示来源\n",
    "        print(\"\\n来源：\")\n",
    "        for doc in docs:\n",
    "            print(f\"- 页码：{doc.metadata.get('page', '未知')}, 来源：{doc.metadata.get('source', '未知')}\")\n",
    "            print(f\"  内容：{doc.page_content[:50]}...\")  # 显示文档内容的前10个字符\n",
    "    else:\n",
    "        print(\"\\n未找到相关文档。\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
