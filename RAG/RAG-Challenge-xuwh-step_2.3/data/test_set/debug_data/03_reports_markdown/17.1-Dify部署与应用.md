# Dify部署与应用

# 今天的学习目标

# Dify部署与应用

Dify开发平台Dify部署与使用  
Dify应用实战  
CASE：LLM联网搜索  
CASE: 搭建古诗词WorkFlow  
CASE: 智能客服ChatFlow  
CASE：智能文档分析助手(MinerU+Dify)  
·如何应用Agent APl (Coze,Dify)

# Dify开发平台

Dify是一个开源的LLM 应用开发平台。提供从Agent 构建到AIworkflow 编排、RAG 检索、模型管理等能力，轻松构建和运营生成式AI原生应用。

Dify提供五种应用类型：

·聊天助手：基于LLM构建对话式交互的助手。  
·文本生成应用：面向文本生成类任务的助手，例如撰写故事、文本分类、翻译等。  
·Agent：能够分解任务、推理思考、调用工具的对话式智能助手。  
·对话流（Chatflow）：适用于设计复杂流程的多轮对话场景，支持记忆功能并能进行动态应用编排。  
·工作流（Workflow）：适用于自动化、批处理等单轮生成类任务的场景的应用编排方式，单向生成结果。

# Dify部署

Dify 的本地化部署主要有两种方式：DockerCompose部署（推荐）和源代码部署。

Thinking: 如何使用DockerCompose 进行部署？

Docker Compose 部署是通过 Docker 容器来运行 Dify的各个组件，隔离了环境依赖，部署和管理都相对简单。

前提条件:

·安装 Docker 和 Docker Compose:https://www.docker.com 选择适合操作系统的 Docker Desktop·安装Git:用于克隆 Dify的代码仓库。

Docker:是一个开源的应用容器引擎，可以将应用及其所有依赖打包到一个可移植的容器中$\Rightarrow$ 保证了应用在任何环境中都能以相同的方式运行，简化了部署和管理。Docker Compose:是一个用于定义和运行多容器 Docker应用程序的工具。通过YAML文件配置应用服务，然后使用一条命令就能创建并启动所有服务。

# Dify部署

Step1, 克隆Dify代码仓库

打开你的终端(Terminal)或命令行工具，执行以下命令：

git clone https://github.com/langgenius/dify.git

Step2，进入Docker 目录并配置 cd dify/docker cp .env.example .env

这一步会复制一个环境变量配置文件的模板。你需要根据自己的需求修改.env文件。

关键配置项包括：

·APP_URL:你的Dify访问地址，本地部署通常是http://localhost 或http://你的iP地址。  
·数据库相关配置 (如果使用外部数据库)。默认情况下，它会使用Docker内置的数据库。  
· 模型供应商的 API Keys (例如 OpenAl,Anthropic,Qwen 等)。这里需要配置你的API密钥。

# Dify部署

Step3，启动 Dify 服务

在 dify/docker 目录下，执行以下命令来启动 Dify

docker compose up -d

参数-d表示在后台运行。

# Step4, 访问 Dify

启动成功后，等待几分钟让所有服务完全启动。然后你就可以在浏览器中访问Dify了。

管理员初始化页面:首次访问http://你的IP地址/install来设置管理员账户。

Dify主页面:初始化完成后，访问http://你的IP地址即可开始使用 Dify。

# Dify部署

Thinking: 如何更新 Dify?

在dify/docker目录下，拉取最新的代码和Docker镜像

git pull docker compose pull

Thinking: 如何重新启动服务？

docker compose up -d

# 如何使用Dify

# Thinking: 如何使用Dify

使用公司的，或者自己本地部署的Dify，或者云服务

# 嗨，近来可好

![](images/46e75714ac36789ef780b57112bfa5fe2018cfc06b67bcef83692a4cb6663619.jpg)

如果您还没有初始化账户，请前往初始化页面设置管理员账户

http://119.45.39.201:8088/signin

![](images/9d4cc295dff76618c5a9ebb225691769670a6400b74766541ec8b3b3caa025c9.jpg)

https://cloud.dify.ai/apps

Cloud.dify.ai是由Dify提供的云服务，开箱即用，支持灵活的套餐和价格。

# Chatflow与Workflow

在 Dify平台中，Chatflow和Workflow 是两种核心的应用编排工具，它们分别服务于不同类型的AI应用场景。  
·Chatflow(对话流)：专为构建交互式、多轮对话的AI应用而设计。它更侧重于模拟人类对话的模式，能够记忆上下文，并根据用户的输入进行多步骤的逻辑处理和回复。  
·Workflow(工作流)：主要面向自动化、批处理或单次任务执行的场景。它适合处理那些不需要实时对话交互，但可能涉及复杂数据处理、分析、内容生成或与其他系统集成的任务。

# Chatflow与Workflow

# Chatflow (对话流)

，对话式交互：支持多轮对话，能够理解上下文，并根据之前的交流内容进行回应。

记忆能力(Memory)：内置对话历史记录功能，使得AI应用能够“记住”用户之前的发言。

动态响应：强调在对话过程中逐步构建和输出响应，可以使用户获得更自然的交流体验。

，专属节点：拥有如"Answer"(回复)节点，用于在流程的中间步骤流式输出文本内容。

·用户交互功能：通常包含开场白、下一步问题建议、文件上传（用于对话中）、引用归属等增强用户对话体验的功能。

适用场景：智能客服、语义搜索、AI助教、需要引导用户完成特定任务的对话机器人等。

# CASE: 智能客服机器人

# Chatflow (对话流)

·对话式交互：支持多轮对话，能够理解上下文，并根据之前的交流内容进行回应。

记忆能力(Memory)：内置对话历史记录功能，使得AI应用能够“记住”用户之前的发言。

动态响应：强调在对话过程中逐步构建和输出响应，可以使用户获得更自然的交流体验。

，专属节点：拥有如"Answer"(回复)节点，用于在流程的中间步骤流式输出文本内容。

·用户交互功能：通常包含开场白、下一步问题建议、文件上传（用于对话中）、引用归属等增强用户对话体验的功能。

适用场景：智能客服、语义搜索、AI助教、需要引导用户完成特定任务的对话机器人等。

CASE：LLM联网搜索

# CASE: LLM联网搜索

TODO：LLM联网搜索

用户输入问题，AI提取关键字，使用Bing搜索，并进行总结Step1，创建工作流

![](images/671a0996b530800eb8075e489963b3f1a8b61f160e9e8175a933b7ff0cd84827.jpg)

# 获取TavilySearch APl Key

1.申请Tavily Search APl Key

https://tavily.com/

# API Keys

The keyis used to authenticate yourrequests to the ResearchAPI.To learn more,see the documentation page.

<html><body><table><tr><td>NAME</td><td>TYPE</td><td>USAGE</td><td>KEY</td><td colspan="4">OPTIONS</td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>default</td><td>dev</td><td>0</td><td></td><td>tvly-deV-*****************************:</td><td></td><td>□ 〖</td><td></td></tr></table></body></html>

# 2.在Dify中安装Tavily工具

# Tavily {

![](images/2349b913b5e9de8e42770843e42317914e04513cbdecc34ca34829348e40b7e8.jpg)

一个强大的原生AI搜索引擎和网页内容提取工具，提供高度相关的搜索结果和网页原始内容提取。

langgenius /tavily

来自MARKETPLACE 7

# 3.对TavilySearch进行授权

TavilySearchAPI是一款强大的搜索工具，支持文本和图像搜索，具备多语言、高级筛选等功能。它专为开发者设计，可快速集成到应用中

# CASE: LLM联网搜索

梳理工作流：

·开始节点：input输入你要联网搜索的主题

LLM节点:

系统提示词：对用户的问题，提取关键字，多个关键字用空格隔开

用户提示词： @开始/{x} input

![](images/eebf9a65aca51dd76cf31cd7b565c646b7010da1f2ffd1929c60ca4d9d0b9a38.jpg)

# CASE: LLM联网搜索

TavilySearch节点:

查询 String Required

查询变量：设置为前一个节点LLM输出的text

LLM/{x} text

LLM 2节点:

系统提示词：对网上搜索到的内容改进行总结整理

用户提示词：

{} Tavily Se... / {x} text

·结束节点

输出变量output设置为LLM2节点的输出text output LLM 2/ text String

# CASE： LLM联网搜索

# 黄金价格和哪些因素有关

# 总结：黄金价格的影响因素及其未来走势

# 一、黄金价格的分析框架与影响因素

# 1.历史指标失效

·历史上有效的前瞻性和同步指标在当前周期中失效或出现背离，研究者重新审视和优化了分析框架。  
·数据选取的时间段从1980年至2023年因数据长度充足且黄金市场化运作始于布雷顿森林体系崩溃后。

# 2.实际利率对金价的影响

·历史上实际利率在金价上涨周期中扮演重要角色，尤其是在降息周期和恶性通胀周期中。  
·自2022年以来，实际利率对金价的指导意义逐渐减弱，相关性有所降低。

# 3.地缘政治与宏观环境变化

·逆全球化进程和俄乌地缘争议事件促使投资者重新配置资产，推动金价脱离传统经济周期，独立走强。·央行购金量激增，从每年400-600吨跃升至1000吨以上，成为主要需求来源。

# 4.通胀与货币因素

·通胀预期是金价上涨的重要催化剂，尤其是当通胀数据韧性较强时。  
·美元与其他货币汇率变化、消费经济实力、货币政策等对金价有直接影响。

# 5.央行资产配置

·央行在资产配置时更注重汇率稳定性，黄金的低波动率和高流动性使其成为稳健配置的选择。  
·央行持续购金对金价形成托底效应，特别是在流动性宽松或通胀快速扩张时。

# 二、黄金价格的历史与未来趋势

# 1.历史复盘与趋势判断

·从1949年到2024年的金价走势显示，黄金价格与美元走势呈负相关，与通胀高度正相关。  
·2000年后全球央行停止随意出售黄金，金价逐步提升。

# 2.未来趋势预测

·预计金价未来可能突破2000美元/蛊司，甚至达到2500-3000美元/盎司。

·金价将在未来两年呈现震荡上行的趋势，回调幅度有限。  
·底部支撑位预计在2500-2600美元，上线可能达到3000美元以上。

# 3.驱动因素

·经济不确定性：全球经济下行压力、贸易摩擦和地缘政治冲突可能推高避险需求。·美联储政策：美联储的加息或降息周期对美元强弱有直接影响，进而影响黄金价格。·央行购金：央行购金行为对金价形成支撑，尤其是在经济下行或通胀加剧时。

# 三、黄金价格的主要影响因素

# 1.供需关系

·黄金供给相对稳定，需求端受通胀、地缘政治、货币宽松政策等因素影响。·科技和电子行业对黄金的需求增长也是重要边际影响因素。

# 2.美元与货币汇率

·美元走强时，黄金价格通常承压；美元疲软时，黄金价格往往上涨。

# 打卡：LLM联网搜索

搭建一个LLM联网搜索工作流

掌握插件使用  
TavilySearch网页搜索掌握大模型使用  
对关键字进行总结  
对网页搜索内容进行总结整理

CASE: 搭建古诗词工作流

# CASE: 搭建古诗词工作流

TO DO：搭建古诗词Agent

用户输入一句古诗，AI制作对应的图像

Step1，创建BOT

Step2，创建工作流

![](images/110c8f5e4d43112552b2e8220c7ebef48779d835ec8f94035ac06ccaa24fbc3e.jpg)

工作流：用于规划和实现复杂功能逻辑的工具，可以通过不同的任务节点来设计复杂的多步骤任务

# Dify中的绘图工具

Dify本身并不直接提供绘图工具，但可以通过外部工具来实现绘图功能。

AI绘图工具

·Stable Diffusion：一个开源的Al绘图模型，可以通过Dify调用生成高质量的图像。·Flux：由Black Forest Labs开发的Al绘图模型，支持通过Dify调用生成图像。·DALL-E：Dify提供的第一方工具之一，可以通过自然语言输入生成高质量图片。自定义绘图工具

SiliconFlow：通过 SiliconCloud提供的API，可以在Dify中调用Flux或 Stable Difusion绘图模型

SiliconFlow是由硅基流动提供的基于开源模型的高性价比GenAI服务，这样就可以在Dify中调用Flux和StableDifusion等绘图模型  
·申请 SiliconCloud APl Key  
·在Dify 中配置 APl Key：在 Dify 的工具页中点击"SiliconCloud $>$ 去授权"

# CASE: 搭建古诗词工作流

工作流步骤:

Step1.开始节点：input输入一句古诗词

Step2.LLM: 选择qwen-turbo

·系统提示词：用户给你古诗词，请描绘一幅画面

·用户提示词：

开始/{x} input

Step3.LLM2: 选择qwen-turbo

·系统提示词：将描述的内容翻译成英文，前面加上acientchina

·用户提示词： LLM/{x} text

![](images/4c4d0f07af72a87b1d3a2e4e20ed6c2dd9ce06940feec9d9f4f2e0470c9a5843.jpg)

# CASE: 搭建古诗词工作流

Step4.使用flux工具 （基于SiliconFlow）提示词设置为前一节点LLM2的输出text

提示词 String Required

LLM 2/{x} text

建议用英文的生成图片提示词以获得更好的生成效果

Step5.结束节点 输出变量与前序节点FLUX的输出关联

# 输出变量

<html><body><table><tr><td>text</td><td>{x} Flux/ text String</td></tr><tr><td>files</td><td>{x} Flux/files Array[File]</td></tr><tr><td> json</td><td>{} Flux/ j.. Array[Object]</td></tr></table></body></html>

# CASE: 搭建古诗词工作流

# 离离原上草

包

# 开始

68.220 ms

# LLM 2

232 tokens · 3.253 s

FLUX

10.891 s

+

LLM 128 tokens $\cdot$ 3.453 s

# 数据处理

1 {  
2 "model_mode":"chat",  
3 "prompts":[  
4 {  
5 "role":"system"  
6 "text"："用户给你古诗词，请描绘一  
幅画面",  
7 "files":[]  
8 Y

# 输出

K7

1   
2

"text"："我看到一片辽阔的草原，绿草如茵，一望无际。微风吹过，青草随风摇曳，连绵起伏，仿佛绿色的波浪在原野上翻滚。尽管季节更替，严寒酷暑，这片草地依旧生机勃勃，展现出顽强的生命力。远山如黛，近处有几株大树点缀其中，牛羊在其间悠闲地吃草，一幅宁静而充满生命力的草原风光图跃然眼前，"

1 K

# 数据处理

1 {  
2 "model_mode":"chat",  
3 "prompts":[  
4 {  
5 "role":"system"  
6 "text"："将描述的内容翻译成英文，  
前面加上 acient china",  
7 "files":[]  
8 }

# 输出

1 {   
2 "text": "acient china I see a vast grassland，with lush green grass stretching endlessly. A gentle breeze blows，and the green grass sways back and forth in rolling waves across the field.Despite seasonal changes and extreme weather this grassland remains

# 输入

1< {   
2 "prompt": "acient china I see a vast grassland，with lush green grass stretching endlessly. A gentle breeze blows，and the green grass sways back and forth in rolling waves across the field. Despite seasonal changes and extreme weather this grassland

# 输出

1 {   
2 "text": ⅡI   
3 "files":[   
4 {   
5 "dify_model_identity": '__dify__file__"   
6 "id": null,   
7 "tenant_id": "90df0h3d-e3h0-4rfd-9150-044p98

# CASE: 搭建古诗词工作流

# 离离原上草

# 举头望明月

![](images/73e81b1d024cbfb4ef4b96435b37a4bac938c5165238116ccb8c2fc3a3621df3.jpg)

![](images/23db80b99c15fb4ca9a1d83569c0479733c19d330d8eb62905765373cbbbf4ca.jpg)

# 打卡：搭建古诗词助手

搭建一个自己的文生图工具，设置工作流：

图片描述节点翻译节点text2image节点

![](images/6f34937c543bbe22960ca03c7e094a6ced6d23fca8c220203cfb9d1829727af0.jpg)

![](images/98fb01a2bd6087f150b82d20c57c6ad3a6a51ecc7ea05374e8b4b457ba9b36bc.jpg)

CASE: 智能客服ChatFlow

# CASE: 智能客服ChatFlow

TODO：智能客服ChatFlow

设置3个分类：营销专员 $^ +$ 投诉专员 $^ +$ 其他

·营销专员：配置证券知识库，实现对证券产品介绍、交易规则等高频问题的自动化解答；·投诉专员：配置了用户行为数据，用户标签，方便进一步查找关于用户行为、资产等情况，给用户提供产品使用中的问题解答

![](images/5f57fb59da3fcc822f3ba55acc98e05bd592065ad0fdcb9424b48bd370a7775e.jpg)

# CASE: 智能客服ChatFlow

Step1，添加节点 $\Rightarrow$ 问题分类器

选择模型：qwen-turbo-latest(Qwen3)

分类1：营销咨询，证券知识

分类2：投诉处理，产品使用不成功

分类3：其他问题

Step2，添加知识检索 (针对分类1，设置下游节点)配置证券知识库 (该知识库需要先进行创建，再添加)查询变量 $\mathbf { \sigma } = \mathbf { \sigma }$ 开始中的query

B ×

日

# 知识检索

![](images/ef8d574c128028a7bdc19699f91acfeaeb3da74954187ce6718608134510cdaa.jpg)

获取证券相关知识

# 查询变量\*

@开始／sys.query String

知识库 \*

召回设置+

![](images/d480bdf9e75594f5a1d17aa39dffcb3a4e172292d97bf7f08cd10844d0005b8c.jpg)

证券知识库

高质量·向量检索

# CASE: 智能客服ChatFlow

# 创建知识库：证券知识库

# 上传文本文件

![](images/8f0f22bf02f37035ceb5ff15065203aa3193274d873762044a5f37cfdfc6d014.jpg)

选择对应的文件进行上传，可以是txt,pdf,或excel等格式

# 分段设置

![](images/ecab8dda61ae7562034e06f38c4323d413a298d057222a0552f11b8432df54ee.jpg)

# 通用

通用文本分块模式，检索和召回的块是相同的

![](images/b108acc7ab7b7edf06131f9cd8757e1944dbe1c6394d00e13982be1d2033b057.jpg)

# 文本预处理规则

√

替换掉连续的空格、换行符和制表符

删除所有URL和电子邮件地址

预览块 重置

# 父子分段

使用父子模式时，子块用于检索，父块用作上下文

# 索引方式

# 高质量

![](images/0b537004ea01083267807a5397448d808f4296a314cbaa2d78887319fe3d2493.jpg)

# 经济

调用嵌入模型处理文档以实现更精确的检索，可以帮助LLM生成高质量的答案。

每个数据块使用10个关键词进行检索，不会消耗任何tokens，但会以降低检索准确性为代价。

！ 使用高质量模式进行嵌入后，无法切换回经济模式。

·分段标识：对于结构不佳的文本，上传前预设强分隔符（而非仅依赖回车），能大幅提升初始分段的语义完整性。

·长度与重叠的设置：最大长度需匹配模型处理窗口，有时小而精的分段（尤其问答型）优于大段落；重叠虽保留上下文但增加成本，常见平衡点是 $1 0 - 2 0 \%$ 。

·索引模式的思考：“高质量"模式理解复杂语义更优，适合专业内容，但模式切换成本高 (需整个知识库重索引)

# CASE: 智能客服ChatFlow

# Embedding模型

![](images/5f603bc93ce044b4f3f1491bdd5522d6f8fc4de8f0d0800577ab8cd5821d1af0.jpg)

text-embedding-v1

# 检索设置

了解更多关于检索方法，您可以随时在知识库设置中更改此设置。

![](images/1e08601fbbfc8efcf45d0a96b5ab130a0f8584593539ec636b10859e368226d2.jpg)

# 向量检索

通过生成查询嵌入并查询与其向量表示最相似的文本分段

# Rerank模型

女

gte-rerank

![](images/446c97b2649539cb7963cb0a991d5590ffbf4b9bd92e1f17a89438f2148467ce.jpg)

E

# 全文检索

索引文档中的所有词汇，从而允许用户查询任意词汇，并返回包含这些词汇的文本片段

# 混合检索

推荐

同时执行全文检索和向量检索，并应用重排序步骤，从两类查询结果中选择匹配用户问题的最佳结果，用户可以选择设置权重或配置重新排序模型。

·Embedding模型选择：选定并索引后，若想更换 Embedding模型，整个知识库需重新向量化，成本高。模型质量直接决定后续向量检索和混合检索的语义理解上限。

· Rerank 是"精炼器"而非万能药：启用 Rerank 模型（如gte-rerank）能显著提升相关性排序，但也增加检索延迟和计算成本。并非所有场景都追求极致精度，需权衡。

·Score 阀值的设定：Score的选择因所选Embedding模型而异不存在通用"最佳值"，需针对性调优。

·全文检索的作用：它能精准命中向量检索可能遗漏的特定术语、代码片段或专有名词，是语义模糊匹配的有力补充。

·混合检索的"融合艺术”：优势在于结合向量与全文，但效果好坏很大程度取决于结果的"融合与重排序"策略。Dify支持权重调整，为用户提供了个性化调优手段。

# CASE: 智能客服ChatFlow

Step3，添加LLM (知识检索下游节点)

模型： qwen-turbo-latest(Qwen3)

Sytem提示词：

使用以下上下文作为你所学习的知识，放在<context></context>XML标签内。

<context>

{#context#}}

</context>

当回答用户时：

# 添加直接回复 (LLM节点下游节点）

![](images/16f0389744e43c46604ce08f79b96fe4c3b7a22ca2c333c89028031ca4536d46.jpg)

如果你不知道，就说你不知道。如果你不确定时不知道，寻求澄清。  
避免提及你从上下文中获取的信息。  
并根据用户问题的语言进行回答。

![](images/5c746b633d800a1fc31391e1b98ef75339e54f1638984f3be342f62cafd5d2be.jpg)

针对于营销问题，直接从证券知识库中进行检索，让LLM进行推理回答

# CASE: 智能客服ChatFlow

Step4，添加LLM节点

针对投诉处理，进行关键信息提取，方便后续从用户数据中提取相关信息

System提示词：

User提示词：

你是一个智能信息提取助手你的任务是从用户提供的文本中准确地提取以下信息：

@ 开始/{x} sys.query

1.user_id:用户的唯一标识符。  
2.event_time:事件发生的时间，改成日期格式  
3.event_type:事件类型，包括：查看持仓、浏览产品、搜索、登录、委托交易、推送点击、查看行情、集合竞价、咨询客服、风险警示、查看收益、浏览广告、推送未读。

请严格按照以下格式输出你提取到的信息，即user_id: {user_id},event_time: {event_time}, event_type: {event_type}如果某个信息在用户文本中没有找到，请将对应的值设为null

# CASE: 智能客服ChatFlow

Step5，添加知识检索节点

针对提取的用户信息（user_id,event_type,  
event_time）等，从数据表中进行检索  
这里需要创建用户知识 （知识库），并添加  
上传相关的Excel:  
user_behavior_event.xlsx  
user_tag.xlsx

![](images/8a0c8615306ca152ed687204b4b54a3801ce8bb92c3872fc5ec25fe6daaff16e.jpg)

因为数据为Excel，建议采用混合检索，即语义 $^ +$ 关键词同时适当增加TopK的范围

# CASE: 智能客服ChatFlow

Step6，设置LLM  
基于前面检索出来的用户数据，进行回答  
模型

qwen-turbo-latest(Qwen3) CHAT)

上下文 $\textcircled{3}$

四知识检索／result Array[Object]

USER $\textcircled{3}$

15{x} 门 k1@ 开始/{x} sys.query

将检索出来的用户数据，放到Prompt中进行推理，因为检索出来的数据可能不仅是该用户的，所以通过LLM进行筛选

System提示词：

#角色定位：

-专业投诉处理顾问

#背景：

需通过共情语言安抚客户情绪，积极解决问题。

需核查关键信息，确保问题准确定位。

#目标:

1.回应话术：以共情安抚客户，表达积极解决态度。  
2.反馈你从数据库中查询到的情况（你需要筛选使用与该用户user_id匹配的信息，并告诉用户相关的情况，说明具体的event_detail。与该user_id无关信息不要回答)  
3.针对用户的问题给出建议  
4.回答文字简洁，通常不超过200字  
#以下是从用户数据库中检索出的信息，需要筛选对应的user_id数据{#context#}}

# CASE: 智能客服ChatFlow

Step7，设置直接回复

将LLM推理的结果，回复给用户

0

# 直接回复

B .0. ×

添加描述..

回复LLM/{x} text

24 {x} □

对于分类3，即其他问题

回复：抱歉，这些问题我无法回答。

![](images/6c7792739a759407671bcc5abcbc6bd1d4a35c7eb82b4667f6298918bb6a856b.jpg)

![](images/29af20939e2f976e1996be30dd3ea6ca460b96e07319a305b125809f260a58f3.jpg)

# CASE: 智能客服ChatFlow

# 什么是竞价盘？

# 可以在上海证券交易所挂牌交易有哪些？

![](images/9a996d57d9267adef969e34f97a7d3fd5034183a95277149e243b0e828e66d32.jpg)

竞价盘是指在证券竞价交易中，投资者提交的没有指定价格的买卖申报。这种申报会按照最终参考平衡价格进行撮合，并且在对盘时优先于竞价现价盘。未完成的竞价盘会在持续交易时段开始前自动取消。

# 引用

港股交易规则介绍.pdf +1根据相关规定，可以在上海证券交易所挂牌交易的证券包括：

(一) 股票；  
（二） 基金;  
（三) 债券;  
（四） 债券回购;  
(五) 权证;  
(六) 存托凭证;  
(七) 经证监会批准的其他交易品种。

# 引用

上海证券交易所交易规则.pdf

# CASE: 智能客服ChatFlow

我的用户id:7501690985227960354，我在5月4日登录了软件但是没有成功

您好，关于您的用户ID：  
7501690985227960354，我们查到您在5月4日10:05:00尝试通过"面容ID登录"，但系统未记录成功登录事件。建议检查设备面容ID是否正常，或尝试使用其他登录方式。如仍无法解决，请联系客服进一步协助。

引用

user_behavior_event.xlsx user_behavior_event.xlsx

#7

event time":"2025-05-04 10:05:0o";"event_type":"登录";"event_detail":"面容 ID登录";"user_id":"7501690985227960354"

107 3 d593c92 0.7

# #14

event time":"2025-05-04   
18:30:0o";"event_type":"登录";"event_detail":"密码   
登录（上次登录7天   
前）";"user_id":"7501690675818315816"   
114 $\textcircled { < }$ 25 Ae8066df 0.63

# #19

event time":"2025-05-04   
09:30:0o";"event_type":"登录";"event_detail":"通过   
手机验证码登   
录";"user id":"7501691024880730112"   
110 （204号 $\textcircled { < }$ 16 067c9da 0.62

# 打卡： 智能客服ChatFlow

使用chatFlow模式，设置意图识别

·营销咨询、证券知识：配置证券知识库，实现对证券产品介绍、交易规则等高频问题的自动化解答;  
·投诉处理、产品使用不成功：配置了用户行为数据，用户标签，方便进一步查找关于用户行为、资产等情况，给用户提供产品使用中的问题解答  
数据准备：  
·证券知识库  
·数据表:user_tag,user_behavior_event

CASE: 智能文档分析助手

# CASE: 智能文档分析助手

CASE：智能文档分析助手

用户上传一份包含复杂图表、公式和多栏排版的科研论文PDF，望针对论文中的内容进行提问。Step1.在Dify中创建应用，比如：智能文档分析助手

Step2.集成Mineru作为工具

将 Mineru封装成一个Dify可以调用的工具。即将 Mineru 的核心功能（PDF 解析和内容提取）通过API暴露出来。  
当用户上传 PDF文件时，Dify 应用会首先调用 Mineru工具。

Step3.Dify利用LLM进行回答

MinerU处理后的高质量文本被返回给Dify应用 $\Rightarrow$ 作为上下文信息，传递给LLM

用户提问：论文中的实验结果有哪些？LLM 基于Mineru提取的文本内容，更准确地在文档上下文中找到相关知识，并进行回答。

# CASE: 智能文档分析助手

Step1，设置用户上传的变量uploaded_pdf,user_question

Step2，添加MinerU插件，解析用户的uploaded_pdf $\Rightarrow$ 输出text

Step3，使用LLM进行回答

Step4，将LLM回答的结果，返回给用户

![](images/242cca5461a81fcde15f621b98d81eaec5e825f549eac67bf312781d3bb81164.jpg)

# CASE: 智能文档分析助手

Step1，设置用户上传的变量

变量名称：uploaded_pdf

显示名称：请上传PDF文件

选择单文件类型，然后选择文档类型

变量名称：user_question显示名称：请输入您的问题最大长度：100

# 编辑变量

![](images/3f788f9925cfa8693bf79952b8f488586f3bb3957ffc81302df81b2532ab873d.jpg)

# CASE: 智能文档分析助手

Step2，添加MinerU插件

这里使用MinerU官方API

Base URL: http://mineru.net/

令牌token获取 https://mineru.net/apiManage/token

![](images/7f8281516213350879dd46158f590071c7e75e58a21d671003cc63987df7e039.jpg)

Min Parse File

添加描述...

# 设置授权

×

配置凭据后，工作区中的所有成员都可以在编排应用程序时使用此工具。

MinerU服务的BaseURL \*

https://mineru.net

令牌

eyJ0eXBIljoiSldUliwiYWxnljoiSFM1MTlifQ.eyJqdGkiC

如何获取

# 服务类型\*

MinerU官方API

# CASE: 智能文档分析助手

Step3， 使用LLM进行回答

模型：qwen-turbo

SYSTEM提示词：

你是一个论文助手，下面是论文的全文，你需要基于用户的问题进行回答。

用户上传的论文： {x} Parse File/ {x} text

USER提示词：

@开始/{x}user_question

Step4， 设置结束节点 output $= L L M$ 的输出text

# 结束

1 … X

添加描述...

![](images/232a6c2e32e231b766f19ac68c7b426a32ae12cbdb3e7ac9fcafc888a241269c.jpg)

# CASE: 智能文档分析助手

使用智能文档分析助手

上传INTERNVIDEO2.5.pdf，然后提问：

论文的实验结果怎么样？

# Test Run

输入 结果 详情 追踪

# 请上传PDF文件

![](images/7e05b69d86303e227610909356211d8fd3da0f5c1b30b29d84d6b2fdabff64b6.jpg)

Test Run#1

<html><body><table><tr><td>结果</td><td>详情 追踪</td><td></td></tr><tr><td colspan="3">A 开始 34.886 ms</td></tr><tr><td>> Min</td><td>PARSE FILE</td><td>2 m 43.154 s</td></tr><tr><td>></td><td colspan="2">LLM 23.612K tokens · 11.425 s</td></tr><tr><td>></td><td></td><td>44.994 ms</td></tr><tr><td>结束</td><td colspan="2"></td></tr></table></body></html>

MinerU节点的运行时间相对较长

Min PARSEFILE

2 m 43.154 s

# 输入 □ K

1 {   
2 "file":{   
3 "dify_model_identity": __dify__file_'   
4 "id": null,   
5 "tenant_id": "90df0b3d-e3b0-4cfd-9150-044e98e98c cf",   
6 "tvne":"dnrument"

# 输出

1 {  
2 "text": "# INTERNVIDEO2.5:EMPOWERING VIDEO MLLMS WITH LONGAND RICH CONTEXT MODELING \n\nYiWang\*1，Xinhao \$\\mathbf { L i }^$\{ \ * \ 2$ 1 }\$ ，Ziang \$\\mathbf { Ya \* 1 } }\$ ，Yinan \$\\mathbfH = 1 }}\$ ，Jiashuo\$l\mathhf √}\\mathhf{ }>{

# CASE: 智能文档分析助手

结束节点的输出结果：

"output":"论文中的实验结果显示，InternVideo2.5在各种视频理解基准测试中达到了最先进的性能。具体来说，在大约7B模型规模的情况下，InternVideo2.5在多个短片和长片视频问答基准测试中几乎达到了领先地位。与基础模型InternVL2.5相比，InternVideo2.5无论是在短片还是长片预测上都有总体上的提升。特别是在处理短片时，InternVideo2.5在MVBench和Perception Test上的提升超过了3个百分点。对于长片视频的理解，虽然整体趋势仍在上升，但在不同的基准测试中变化有所不同。例如，在EgoSchema、MLVU和LVBench上的提升较为显著，而在LongVideoBench和VideoMME(无子任务)上的提升相对较小。此外，InternVideo2.5还展示了增强的视觉能力，如物体跟踪等，证明了长且丰富的上下文（LRC）在提高基本视觉任务和高层次推理方面的有效性。"

# 打卡： 智能文档分析助手

在Dify工作流中使用MinerU，对于用户上传的PDF进行精细解析

掌握MinerU插件使用  
Base URL: http://mineru.net/  
令牌token获取 https://mineru.net/apiManage/token  
·将文档内容作为上下文，进行LLM回答

如何应用Agent API(Coze, Dify)

Coze API使用

cozepy 是 Coze平台官方提供的Python SDK，用于与Coze 智能体进行API交互。它支持同步和异步调用、流式输出、分页查询等功能

# Step1. 获取 API Token

· 访问 https://www.coze.cn/open/oauth/pats  
登录账户  
·创建个人访问令牌 (Personal Access Token)  
·设置适当的权限和过期时间  
复制生成的token

<html><body><table><tr><td>OAuth应用 已授权应用 个人访问令牌</td></tr><tr><td>用于其他应用程序和平台的个人访问令牌。详细说明请查看：API使用说明 不要与他人共享您的个人访问令牌，也不要在浏览器或其他客户端代码中暴露它，以保护您账户的安全。若在公开场合发现任何泄</td></tr><tr><td>名称 创建时间 最近使用时间 过期时间</td></tr><tr><td>test1 2024-06-21 20:46:26 2025-05-20 14:34:09 永久有效</td></tr><tr><td></td></tr><tr><td>test2 2025-05-22 21:30:49 2025-06-21 Secret token 2025-05-23 11:44:12 2025-05-23 12:02:16 2025-06-22</td></tr></table></body></html>

# cozepy工具

# Step2.获取智能体ID

1.进入智能体详情页面

2.从URL中提取智能体ID   
比如   
https://www.c0ze.cn/store/agent/7507272032905199655?   
bot_id=true   
智能体ID 就是7507272032905199655

coze.cn/store/agent/7507272032905199655?bot_id=true&bid=6gbvma4fk1g0b

# cystanford

# 离离原上草

# 古诗词绘画Agent 12:17

# 开始调用工作流

“离离原上草”描绘出一幅广袤而充满生机的原野画面，以下从不同维度为你呈现其具体场景：

# 整体画面印象

在一片辽阔无垠的原野之上，视线所及之处，皆是连绵不绝的青草。它们肆意地生长着，与远处的天际线相接，形成了一幅宏大而又和谐的自然画卷。整个原野仿佛被一层绿色的绒毯所覆盖，在阳光的照耀下，闪烁着灵动的光芒，给人以生机勃勃、充满希望之感。

# 近景特写

蹲下身子靠近这些青草，能看到一株株草茎笔直而坚韧，从肥沃的土地中茁壮地挺立起来。草叶细长而翠绿，上面还挂着清晨的露珠，在阳光的折射下宛如晶莹剔透的珍珠，摇摇欲坠。微风拂过，草叶轻轻摇曳，相互摩挲，发出沙沙的声响，仿佛在低声诉说着生命的故事。每一片草叶都充满了生命力，它们努力地伸展着，向着天空汲取阳光和雨露

$\circledcirc$ 停止响应

# Step3.初始化客户端

import os   
from cozepy import Coze, TokenAuth,   
COZE_CN_BASE_URL

#配置参数 coze_api_token $\mathbf { \tau } = \mathbf { \tau }$ "your_api_token_here" coze_bot_id $\mathbf { \tau } = \mathbf { \tau }$ "your_bot_id_here" coze_api_base $\mathbf { \tau } = \mathbf { \tau }$ COZE_CN_BASE_URL

#初始化客户端  
$\mathtt { c o z e } = \mathtt { C o z e ( \xi }$ auth $\ c =$ TokenAuth(token=coze_api_token),base_url $\ c =$ coze_api_base  
）

# 普通聊天：使用‘create_and_poli可以简化非流式聊天

from cozepy import ChatStatus   
# 普通聊天示例   
chat_poll $\mathbf { \tau } = \mathbf { \tau }$ coze.chat.create_and_poll( bot_id $\ c =$ "your_bot_id", user_id="user_123", additional_messages $\ c =$ [Message.build_user_question_text("你好   
")]   
）   
if chat_poll.chat.status $\scriptstyle = =$ ChatStatus.COMPLETED: for message in chat_poll.messages: if message.role $\scriptstyle = =$ "assistant" and message.content: print(f"智能体回复: {message.content}")

# cozepy工具

# 流式聊天 (推荐)

from cozepy import Coze, TokenAuth,Message, ChatEventType, MessageContentType

#流式聊天示例   
for event in coze.chat.stream( bot_id $= ^ { 1 }$ 'your_bot_id", user_id $\ c =$ "user_123",   
additional_messages $\ c =$ [Message.build_user_question_text("   
你好，请介绍一下你自己")]   
）：

if event.event $\scriptstyle = =$ ChatEventType.CONVERSATION_MESSAGE_DELTA: if (hasattr(event.message,'content') and event.message.content and hasattr(event.message.content, 'type') and event.message.content.type $\scriptstyle = =$ MessageContentType.TEXT): print(event.message.content.text, end $\ c =$ "",flush $\ c =$ True) elif isinstance(event.message.content, str): print(event.message.content, end $\ c =$ "",flush $\mathbf { \tau } = \mathbf { \dot { \tau } }$ True)

# CASE: 古诗词绘画 (Coze API)

TO DO: 古诗词绘画Coze APl（Python客户端）基于cozepy库开发Coze 智能体Step1.在‘config.py'文件中配置Coze APl信息：

# Coze APi 配置 COZE_API_TOKEN $\mathbf { \sigma } = \mathbf { \sigma }$ "您的_Coze_API_Token" COZE_BOT_ $| \mathsf { D } = "$ 您的_智能体_ID" COZE_CN_BASE_URL $\mathbf { \tau } = \mathbf { \tau }$ "https://api.coze.cn"

# Step2.设置流式接收回复

for chunk in client.chat_stream("离离原上草"): print(chunk, end="", flush=True)

Coze智能体交互式聊天启动！输入‘quit'或‘exit'退出程序输入‘stream’切换到流式模式输入‘normal’切换到普通模式输入 'info'查看智能体信息

Coze客户端初始化成功API地址: https://api.coze.cn智能体ID: 7507272032905199655智能体名称：古诗词绘画Agent智能体描述：古诗词绘画Agent[普通]请输入您的问题：stream$\boxtimes$ 已切换到流式模式

# CASE: 古诗词绘画 (Coze API)

[流式］请输入您的问题：离离原上草用户：离离原上草

$\ast$ 智能体：开始调用工作流“离离原上草"描绘出一幅生动且富有生命力的草原画面，以下从不同角度为你详细描述：

### 整体印象

在广袤无垠的大地上，一片连绵起伏的草原映入眼帘。目之所及，皆是随风摇曳的青草，它们像是大地铺开的绿色绒毯，一直 延伸到天际，与湛蓝的天空相接，形成了一幅壮阔而和谐的自然画卷。

### 近景特写

凑近细看，每一株草都充满着勃勃生机。它们茎干细长而坚韧，从土地中挺拔而出，大约有半人多高。叶片狭长而翠绿，上面 还挂着清晨的露珠，在阳光的映照下，宛如晶莹剔透的珍珠，闪烁着细碎的光芒。微风拂过，草叶相互摩挲，发出沙沙的声响，仿佛在轻声诉说着生命的故事。

### 中景展现

视野稍微拉远一些，可以看到草原上的草一丛接着一丛，紧密而有序地生长着。它们高低错落，有的草尖微微弯曲，像是在向 大地致敬；有的则昂首挺立，尽情享受着阳光的照耀。草丛中偶尔夹杂着一些不知名的野花，红的、黄的、紫的，星星点点地 散布其中，为这片绿色的海洋增添了一抹绚丽的色彩。

### 远景概览

站在高处眺望，整个草原就像一片绿色的波涛，连绵不绝。草原的边缘与远处的山峦相连，青山与绿草相互映衬，构成了一幅 如诗如画的美景。天空中，洁白的云朵悠悠飘荡，与地上的青草相互呼应，让人心旷神怡。偶尔有一群牛羊在草原上悠闲地吃草，它们的身影点缀在这片绿色之中，更增添了一份宁静与祥和。

“离离原上草"所描绘的画面，不仅展现了大自然的壮美与生机，也让人感受到了生命的顽强与不息。Acient china "The lush grass on the plain" depicts a vivid and vibrant grassland scene.The following provides a detailed description from different perspectives:

### Overall Impression

On the vast and boundless land,a rolling grassland comes into view.As far as the eye can see， there are gr en grasses swaying in the wind.They are like a green carpet spread out by the earth，stretching all the wa y to the horizon and meeting the deep - blue sky， forming a magnificent and harmonious natural picture.

### Close - up View

Taking acloser look，each blade of grass is full of vitality. Their stems are slender and tough，standing u pright from the soil，about half a person's height.The leaves are long， narrow and emerald - green，with th e morning dew still hanging on them.In the sunlight， they are like glittering pearls， twinkling with tiny r ays of light. When the gentle breeze blows， the grass leaves rub against each other， making a rustling sound ，as if softly telling the story of life.

### Medium - distance View   
Pulling the view back a bit，one can see that the grass on the prairie grows in clusters，closely and orderl upright，fully enjoying the sunlight.Occasionally，there are some unknown wildflowers mixed among the gras   
S clusters.Red，yellow，and purple，they are scattered here and there，adding a splash of gorgeous color to this green ocean.

### Distant View

Looking out froma high place，the entire grassland is like a continuous green wave.The edge of the grassla nd is conected to the distant mountains.The green mountains and the lush grass complement each other，form ing a picturesque scenery.In the sky， white clouds float leisurely，echoing the grass on the ground，making people feel relaxed and happy.Occasionally，a group of cattle and sheep are grazing leisurely on the grass land.Their figures are dotted in this green expanse，adding more tranquility and peace.

The picture depicted by "The lush grasson the plain" not only shows the grandeur and vitality of nature but also makes people feel the tenacity and endlessness of life.![The image](https://s.coze.cn/t/lThZvuoyR_o/)

根据你提供的古诗词“离离原上草"，我已经完成绘画并展示了图像。

![](images/9b0ad278e7238c9f5e66fb9c30e96de0a3ad512ac97dfbd761e315ca2bbdad4e.jpg)

# 打卡：Coze API调用

找到你之前完成的Coze智能体，比如：古诗词绘画Agent

掌握cozepy工具使用调用Coze API

Step1.获取APIToken  
Step2.获取智能体ID  
Step3.初始化客户端  
Step4.使用普通聊天或者流式聊天进行对话  
可以在Coze智能体中，添加输出节点，增加交互的体验感

Dify API使用

# Dify API使用

API密钥(APIKey):每个应用都会生成一个或多个API密钥，用于身份验证。

APIBaseURL:每个应用都有一个基础的API访问地址。

API端点(Endpoints):Dify为不同类型的应用和操作提供了不同的 API端点。最常见的包括：

·聊天(ChatMessages):用于与对话型应用进行交互，发送消息并获取回复。

·文本补全(Completion Messages):用于与文本生成类应用进行交互，提供输入并获取生成的文本。

·工作流执行(Workflow Execution):如果应用是基于工作流构建的，可以通过APl触发工作流并获取结果。

Thinking: 如何创建Dify应用的API Key?

# API密钥

如果不想你的API被滥用，请保护好你的APIKey:)最佳实践是避免在前端代码中明文引用。

进入应用 $\Rightarrow$ 访问 $\mathsf { A P l } \Rightarrow$ 右上角API秘钥

# DifyAPI使用

F— dify_agent_client.py #主要客户端类├— dify_workflow_example.py #工作流示例F— requirements.txt #依赖包README.md #使用说明

dify_agent_client.py使用了difyapi的封装，方便用于其他项目  
dify_workflow_example.py 实现了LLM联网搜索的workflow调用，用于演示

# 客户端类 (DifyAgentClient)

class DifyAgentClient: def __init__(self, base_url: str,api_key: str): self.base_url $\mathbf { \tau } = \mathbf { \tau }$ base_url.rstrip('/") self.api_key $\mathbf { \tau } = \mathbf { \tau }$ api_key self.headers $= \{$ 'Authorization': f'Bearer {api_key}' 'Content-Type': 'application/json', 'Accept': 'application/json' }

存储Dify服务器地址和API密钥  
构建HTTP请求头，使用BearerToken认证  
统一管理API调用的基础配置

# Dify API使用

# 智能应用类型检测

def chat_completion(self, user_input: str, app_type: str $\mathbf { \tau } = \mathbf { \tau }$ "auto"): if app_type $\scriptstyle = =$ "auto":

#1.先尝试聊天端点 result $\mathbf { \tau } = \mathbf { \tau }$ self._try_chat_endpoint.(...) if "not_chat_app" in result.get("message",""):

#2.再尝试完成端点 result $\mathbf { \tau } = \mathbf { \tau }$ self._try_completion_endpoint.(...) if "app_unavailable" in result.get("message",""):

#3.最后尝试工作流端点return self._try_workflow_endpoint(..)

# 核心逻辑：

·自动检测机制：按照聊天→完成→工作流的顺序尝试·错误驱动检测：根据特定错误码判断应用类型·容错设计：一个端点失败自动尝试下一个

# Dify API端点 (聊天应用)

1.聊天应用 API (/chat-messages')   
def_try_chat_endpoint(self, user_input: str, user_id: str,   
conversation_id: Optional[str], stream: bool): url $\mathbf { \tau } = \mathbf { \tau }$ f"{self.base_url}/chat-messages" $\mathsf { p a y l o a d } = \left\{ \begin{array} { l l } { \begin{array} { r l r } \end{array} } \end{array} \right.$ "inputs": {, #空输入对象 "query": user_input, #用户消息 "response_mode": "streaming" if stream else "blocking", "user": user_id } if conversation_id: payload["conversation_id"] $\mathbf { \tau } = \mathbf { \tau }$ conversation_id #维持对记

# API特点：

·支持多轮对话（通过conversation_id）·用户输入通过\`query字段传递：支持流式和阻塞式响应

# Dify API端点 (完成应用)

2.完成应用 APl (/completion-messages")   
def_try_completion_endpoint(self, user_input: str, user_id: str,   
stream: bool): url $\mathbf { \tau } = \mathbf { \tau }$ f"{self.base_url}/completion-messages" $\mathsf { p a y l o a d } = \left\{ \begin{array} { l l } { \begin{array} { r l r } \end{array} } \end{array} \right.$ "inputs": 0, #空对象（官方文档格式） "response_mode": "streaming" if stream else "blocking", "user": user_id }

# API特点：

单次完成任务，不维持对话状态inputs通常为空对象适用于文本生成、翻译等任务

# Dify API端点 (工作流应用)

3.工作流应用 API (/workflows/run')   
def_try_workflow_endpoint(self,user_input: str, user_id: str,   
stream: bool): url $\mathbf { \tau } = \mathbf { \tau }$ f"{self.base_url}/workflows/run" $\mathsf { p a y l o a d } = \left\{ \begin{array} { l l } { \begin{array} { r l r } \end{array} } \end{array} \right.$ "inputs": {"query": user_input},#工作流输入参数 "response_mode": "streaming" if stream else "blocking", "user": user_id }

# API特点：

必须先发布工作流才能调用输入参数通过\`inputs'对象传递·支持复杂的业务逻辑处理

# Dify API端点 (工作流应用)

# 工作流调用示例：

def simple_workflow_example():#配置信息BASE_URL $\mathbf { \sigma } = \mathbf { \sigma }$ "你的Dify URL"API_KEY $\mathbf { \tau } = \mathbf { \tau }$ "你的API KEY"#创建客户端client $\mathbf { \tau } = \mathbf { \tau }$ DifyAgentClient(BASE_URL, API_KEY)

# 调用工作流  
user_input $\mathbf { \sigma } = \mathbf { \sigma }$ "黄金价格和哪些因素有关"  
result $\mathbf { \tau } = \mathbf { \tau }$ client.run_workflow(inputs $\ c =$ {"input": user_input},user_id="demo_user"  
）

# 工作流回复：### 总结整理：影响黄金价格的关键因素

####1．\*\*宏观经济因素 $^ { * * }$

：\*\*经济衰退与金融危机 $^ { * * }$ ：历史上的经济衰退（如2008年金融危机或2019年的新冠疫情）通常会导致黄金价格大幅上涨。投资者倾向于在经济危机时转向黄金以寻求避险。

- \*\*贸易战与地缘政治冲突\*\*：例如中美贸易战等政治紧张局势，往往促使投资者将资金转向黄金，以获得更稳定的资产保值

\*\*美元汇率 $^ { * * }$ ：美元是全球主要储备货币，其强弱直接影响黄金价格。美元走强时，黄金价格通常走弱；反之，美元疲软时，黄金价格趋于上涨。

#### 2，\*\*通货膨胀与利率 $^ { * * }$

－\*\*通货膨胀\*\*：通胀率较高时，持有现金的风险增大，黄金作为抗通胀工具的价值凸显，推动黄金价格上涨。

\*\*利率 $^ { * * }$ ：低利率环境下，黄金的投资吸引力增强，因为持有黄金的机会成本较低。而利率升高时，黄金的投资价值会下降，因投资者更倾向于选择收益更高的资产（如储蓄账户或债券）。

#### 3，\*\*石油价格 $^ { * * }$

－石油价格上涨通常伴随通胀压力，从而推动黄金价格上涨。石油作为重要的能源资源，其价格波动对全球经济有显著影响。

#### 4．\*\*黄金供需关系 $^ { * * }$

。\*\*供给\*\*：全球黄金产量较为稳定，约每年3500吨。矿工罢工或新技术应用等因素可能导致供给减少，从而推高金价。  
-\*\*需求 $^ { * * }$ ：黄金需求主要来自首饰、工业用途、投资和央行购金。其中，投资需求和央行购金是决定黄金需求的关键因素。

#### 5. $* *$ 避险属性与资产配置 $^ { * * }$

-\*\*避险资产 $^ { * * }$ ：黄金因其稀缺性和稳定性，常被视为避险资产。在地缘政治动荡、战争或金融危机时，黄金价格往往会上涨。

－\*\*资产配置\*\*：投资者在资产组合中加入黄金可以实现多元化，降低整体投资风险。

####6．\*\*历史与文化因素 $^ { * * }$

－\*\*文化与传统 $^ { * * }$ ：许多国家和地区（如中国）将黄金视为财富储存和身份象征，这进一步支撑了黄金的需求。  
－\*\*历史经验 $^ { * * }$ ：历史上黄金与通胀密切相关，其生产成本逐年增加，这也为金价提供了长期支撑。

#### 7．\*\*全球市场动态 $^ { * * }$

-\*\*黄金市场参与者 $^ { * * }$ ：包括银行、黄金生产企业、对冲基金、私人投资者等，他们根据市场情绪调整黄金头寸，导致价格波动。

-\*\*黄金定价中心 $^ { * * }$ ：全球三大黄金交易中心（伦敦、纽约、上海）共同影响黄金价格。伦敦市场主要提供现货价格参考，纽约市场反映期货价格，而上海黄金交易所则逐渐提升其国际影响力。

# 打卡：Dify API调用

找到你之前完成的Dify智能体，比如：LLM联网搜索

了解Dify的三种API端点类型  
聊天应用APl(/chat-messages\`)  
完成应用APl(/completion-messages\`)  
工作流应用APl (//workflows/run\`)可以对智能体应用类型进行智能检测调用Dify API

# 善

# Thank You Using data to solve problems