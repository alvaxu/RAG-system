{
  "metainfo": {
    "sha1": "Aitraining",
    "sha1_name": "Aitraining",
    "pages_amount": 68,
    "text_blocks_amount": 431,
    "tables_amount": 7,
    "pictures_amount": 0,
    "equations_amount": 0,
    "footnotes_amount": 0,
    "company_name": "AI应用开发",
    "file_name": "7-RAG高级技术与实践"
  },
  "content": {
    "chunks": [
      {
        "page": 1,
        "length_tokens": 6,
        "text": "RAG高级技术与实践",
        "id": 0,
        "type": "text"
      },
      {
        "page": 2,
        "length_tokens": 4,
        "text": "今天的学习目标",
        "id": 1,
        "type": "text"
      },
      {
        "page": 2,
        "length_tokens": 6,
        "text": "RAG高级技术与实践",
        "id": 2,
        "type": "text"
      },
      {
        "page": 2,
        "length_tokens": 40,
        "text": "RAG技术树  \nRAFT方法  \nCASE: DeepSeek $+$ Faiss搭建本地知识库检索  \nRAG高效召回方法  \nGraphRAG  \nQwen-Agent",
        "id": 3,
        "type": "text"
      },
      {
        "page": 3,
        "length_tokens": 4,
        "text": "RAG技术树",
        "id": 4,
        "type": "text"
      },
      {
        "page": 3,
        "length_tokens": 30,
        "text": "RAG研究的技术树主要涉及预训练（Pre-training）、微调（Fine-tuning）和推理（Inference）等阶段。",
        "id": 5,
        "type": "text"
      },
      {
        "page": 3,
        "length_tokens": 32,
        "text": "随着LLM的出现，RAG的研究最初侧重于利用LLMs强大的上下文学习能力，主要集中在推理阶段。",
        "id": 6,
        "type": "text"
      },
      {
        "page": 3,
        "length_tokens": 38,
        "text": "随后的研究进一步深入，逐渐与LLMs的微调阶段更加融合。研究人员也在探索通过检索增强技术来提升预训练阶段的语言模型性能。",
        "id": 7,
        "type": "text"
      },
      {
        "page": 3,
        "length_tokens": 0,
        "text": "",
        "id": 8,
        "type": "image"
      },
      {
        "page": 4,
        "length_tokens": 5,
        "text": "RAG的步骤：",
        "id": 9,
        "type": "text"
      },
      {
        "page": 4,
        "length_tokens": 15,
        "text": "Indexing $\\Rightarrow$ 如何更好地把知识存起来。",
        "id": 10,
        "type": "text"
      },
      {
        "page": 4,
        "length_tokens": 26,
        "text": "Retrieval $\\Rightarrow$ 如何在大量的知识中，找到一小部分有用的，给到模型参考。",
        "id": 11,
        "type": "text"
      },
      {
        "page": 4,
        "length_tokens": 25,
        "text": "Generation $\\Rightarrow$ 如何结合用户的提问和检索到的知识，让模型生成有用的答案。",
        "id": 12,
        "type": "text"
      },
      {
        "page": 4,
        "length_tokens": 30,
        "text": "这三个步骤虽然看似简单，但在RAG应用从构建到落地实施的整个过程中，涉及较多复杂的工作内容",
        "id": 13,
        "type": "text"
      },
      {
        "page": 4,
        "length_tokens": 61,
        "text": "Input Indexing Query User thatsa Documents ChunksVectors went through a sudden dismissal Output by the board in just three days, and then was rehired by the embeddings company,resembling a real-life versionof\"GameofThrones\"in Retrieval without RAG Relevant Documents   \n...l am unable to provide comm",
        "id": 14,
        "type": "text"
      },
      {
        "page": 4,
        "length_tokens": 71,
        "text": "levant Documents   \n...l am unable to provide comments on   \nfuture events. Currently,I do not have   \nanyinformation regarding thedismissal LLM Generation   \nand rehiring of OpenAl's CEO . Question : Chunk 1: \"Sam Altman Returns to   \nith RAGniantinena p Rpenls   \ndisagreements within OpenAl regard",
        "id": 15,
        "type": "text"
      },
      {
        "page": 4,
        "length_tokens": 80,
        "text": "ena p Rpenls   \ndisagreements within OpenAl regarding!   \n!the company's future direction and based on the following information : Chunk 2: \"The Drama Concludes? Sam Cnunk 1: AtaaUersf   \n' OpenAl... Chunk 3: \"The Personnel Turmoil at Combine Context OpenAl Comes to an End: Who Won and Who Lost?\" An",
        "id": 16,
        "type": "text"
      },
      {
        "page": 4,
        "length_tokens": 18,
        "text": " OpenAl Comes to an End: Who Won and Who Lost?\" Answer and Prompts ",
        "id": 17,
        "type": "text"
      },
      {
        "page": 5,
        "length_tokens": 2,
        "text": "RAFT方法",
        "id": 18,
        "type": "text"
      },
      {
        "page": 6,
        "length_tokens": 2,
        "text": "RAFT方法",
        "id": 19,
        "type": "text"
      },
      {
        "page": 6,
        "length_tokens": 11,
        "text": "RAFT方法（Retrieval Augmented Fine Tuning）",
        "id": 20,
        "type": "text"
      },
      {
        "page": 6,
        "length_tokens": 35,
        "text": "RAFT: Adapting Language Model to Domain Specific RAG, 2024 https://arxiv.org/pdf/2403.10131 如何最好地准备考试？ ",
        "id": 21,
        "type": "text"
      },
      {
        "page": 6,
        "length_tokens": 112,
        "text": "(a)基于微调的方法通过“学习”来实现“记忆”输入文档或回答练习题而不参考文档。  \n(b)或者，基于上下文检索的方法未能利用固定领域所提供的学习机会，相当于参加开卷考试但没有事先复习。  \n(c)相比之下，我们的方法RAFT利用了微调与问答对，并在一个模拟的不完美检索环境中参考文档一一从而有效地为开卷考试环境做准备。",
        "id": 22,
        "type": "text"
      },
      {
        "page": 6,
        "length_tokens": 0,
        "text": "",
        "id": 23,
        "type": "image"
      },
      {
        "page": 7,
        "length_tokens": 2,
        "text": "RAFT方法",
        "id": 24,
        "type": "text"
      },
      {
        "page": 7,
        "length_tokens": 13,
        "text": "RAFT方法（Retrieval Augmented Fine Tuning）: ",
        "id": 25,
        "type": "text"
      },
      {
        "page": 7,
        "length_tokens": 86,
        "text": "让LLMs从一组正面和干扰文档中读取解决方案，这与标准的RAG设置形成对比，因为在标准的RAG设置中，模型是基于检索器输出进行训练的，这包含了记忆和阅读的混合体。在测试时，所有方法都遵循标准的RAG设置，即提供上下文中排名前k的检索文档。",
        "id": 26,
        "type": "text"
      },
      {
        "page": 7,
        "length_tokens": 0,
        "text": "",
        "id": 27,
        "type": "image"
      },
      {
        "page": 8,
        "length_tokens": 2,
        "text": "RAFT方法",
        "id": 28,
        "type": "text"
      },
      {
        "page": 8,
        "length_tokens": 88,
        "text": "RAFT在所有专业领域的RAG性能上有所提升（在PubMed、HotPot、HuggingFace、Torch Hub和Tensorflow Hub等多个领域）领域特定的微调提高了基础模型的性能，RAFT无论是在有RAG的情况下还是没有RAG的情况下，都持续优于现有的领域特定微调方法。这表明了需要在上下文中训练模型。",
        "id": 29,
        "type": "text"
      },
      {
        "page": 8,
        "length_tokens": 0,
        "text": "",
        "id": 30,
        "type": "table"
      },
      {
        "page": 9,
        "length_tokens": 2,
        "text": "RAFT方法",
        "id": 31,
        "type": "text"
      },
      {
        "page": 9,
        "length_tokens": 12,
        "text": "RAFT方法（Retrieval Augmented Fine Tuning） :",
        "id": 32,
        "type": "text"
      },
      {
        "page": 9,
        "length_tokens": 132,
        "text": "·适应特定领域的LLMs对于许多新兴应用至关重要，但如何有效融入信息仍是一个开放问题。  \n·RAFT结合了检索增强生成（RAG）和监督微调（SFT），从而提高模型在特定领域内回答问题的能力。  \n·训练模型识别并忽略那些不能帮助回答问题的干扰文档，只关注和引用相关的文档。  \n·通过在训练中引入干扰文档，提高模型对干扰信息的鲁棒性，使其在测试时能更好地处理检索到的文档。",
        "id": 33,
        "type": "text"
      },
      {
        "page": 9,
        "length_tokens": 11,
        "text": "https://github.com/lumpenspace/raft ",
        "id": 34,
        "type": "text"
      },
      {
        "page": 9,
        "length_tokens": 0,
        "text": "",
        "id": 35,
        "type": "image"
      },
      {
        "page": 10,
        "length_tokens": 17,
        "text": "CASE: DeepSeek + Faiss 搭建本地知识库检索 ",
        "id": 36,
        "type": "text"
      },
      {
        "page": 11,
        "length_tokens": 16,
        "text": "CASE: DeepSeek+Faiss搭建本地知识库检索 ",
        "id": 37,
        "type": "text"
      },
      {
        "page": 11,
        "length_tokens": 11,
        "text": "百度文库－好好学习，天天向上",
        "id": 38,
        "type": "text"
      },
      {
        "page": 11,
        "length_tokens": 19,
        "text": "上海浦东发展银行西安分行个金客户经理管理考核暂行办法",
        "id": 39,
        "type": "text"
      },
      {
        "page": 11,
        "length_tokens": 4,
        "text": "第一章总则",
        "id": 40,
        "type": "text"
      },
      {
        "page": 11,
        "length_tokens": 89,
        "text": "第一条为保证我分行个金客户经理制的顺利实施，有效调动个金客户经理的积极性，促进个金业务快速、稳定地发展，根据总行《上海浦东发展银行个人金融营销体系建设方案（试行）》要求，特制定《上海浦东发展银行西安分行个金客户经理管理考核暂行办法（试行）》（以下简称本办法）。",
        "id": 41,
        "type": "text"
      },
      {
        "page": 11,
        "length_tokens": 40,
        "text": "第二条个金客户经理系指各支行（营业部）从事个人金融产品营销与市场开拓，为我行个人客户提供综合银行服务的我行市场人员。",
        "id": 42,
        "type": "text"
      },
      {
        "page": 11,
        "length_tokens": 47,
        "text": "第三条考核内容分为二大类，即个人业绩考核、工作质量考核。个人业绩包括个人资产业务、负债业务、卡业务。工作质量指个人业务的资产质量。",
        "id": 43,
        "type": "text"
      },
      {
        "page": 11,
        "length_tokens": 61,
        "text": "第四条为规范激励规则，客户经理的技术职务和薪资实行每年考核浮动。客户经理的奖金实行每季度考核浮动，即客户经理按其考核内容得分与行员等级结合，享受对应的行员等级待遇。",
        "id": 44,
        "type": "text"
      },
      {
        "page": 11,
        "length_tokens": 11,
        "text": "客户经理被投诉了，投诉一次扣多少分",
        "id": 45,
        "type": "text"
      },
      {
        "page": 11,
        "length_tokens": 17,
        "text": "根据文件内容，客户经理被投诉一次扣2分。具体规定如下：",
        "id": 46,
        "type": "text"
      },
      {
        "page": 11,
        "length_tokens": 7,
        "text": "（二） 服务质量考核：",
        "id": 47,
        "type": "text"
      },
      {
        "page": 11,
        "length_tokens": 30,
        "text": "2．客户服务效率低，态度生硬或不及时为客户提供维护服务，有客户投诉的，每投诉一次扣2分。",
        "id": 48,
        "type": "text"
      },
      {
        "page": 11,
        "length_tokens": 13,
        "text": "客户经理每年评聘申报时间是怎样的？",
        "id": 49,
        "type": "text"
      },
      {
        "page": 11,
        "length_tokens": 15,
        "text": "根据文件内容，客户经理每年评聘申报时间如下：",
        "id": 50,
        "type": "text"
      },
      {
        "page": 11,
        "length_tokens": 60,
        "text": "第十一条 每年一月份为客户经理评聘的申报时间，由分行人力资源部、个人业务部每年二月份组织统一的资格考试。考试合格者由分行颁发个金客户经理资格证书，其有效期为一年。",
        "id": 51,
        "type": "text"
      },
      {
        "page": 11,
        "length_tokens": 15,
        "text": "因此，客户经理每年评聘的申报时间是一月份。",
        "id": 52,
        "type": "text"
      },
      {
        "page": 12,
        "length_tokens": 16,
        "text": "CASE: DeepSeek+Faiss搭建本地知识库检索 ",
        "id": 53,
        "type": "text"
      },
      {
        "page": 12,
        "length_tokens": 66,
        "text": "from langchain_community.embeddings import DashScopeEmbeddings   \n# 创建嵌入模型 embeddings $\\mathbf { \\tau } = \\mathbf { \\tau }$ DashScopeEmbeddings( model $\\ c =$ \"text-embedding-v1\", dashscope_api_key $\\ c =$ DASHSCOPE_API_KEY, ） ",
        "id": 54,
        "type": "text"
      },
      {
        "page": 12,
        "length_tokens": 33,
        "text": "# 从文本块创建知识库knowledgeBase $\\mathbf { \\tau } = \\mathbf { \\tau }$ FAISS.from_texts(chunks, embeddings)",
        "id": 55,
        "type": "text"
      },
      {
        "page": 12,
        "length_tokens": 63,
        "text": "from langchain_community.llms import Tongyi Im $\\mathbf { \\tau } = \\mathbf { \\tau }$ Tongyi(model_name $\\ c =$ \"deepseek-v3\",dashscope_api_key $\\mathbf { \\tau } = \\mathbf { \\tau }$ DASHSCOPE_API_KEY) ",
        "id": 56,
        "type": "text"
      },
      {
        "page": 13,
        "length_tokens": 7,
        "text": "RAG高效召回方法",
        "id": 57,
        "type": "text"
      },
      {
        "page": 13,
        "length_tokens": 48,
        "text": "Thinking: 如果要召回更多的片段，如何设置？docs $\\mathbf { \\tau } = \\mathbf { \\tau }$ knowledgeBase.similarity_search(query, $k { = } 1 0 )$ ",
        "id": 58,
        "type": "text"
      },
      {
        "page": 14,
        "length_tokens": 7,
        "text": "RAG高效召回方法",
        "id": 59,
        "type": "text"
      },
      {
        "page": 14,
        "length_tokens": 17,
        "text": "Thinking: 都有哪些RAG召回的策略，提升召回的质量？",
        "id": 60,
        "type": "text"
      },
      {
        "page": 14,
        "length_tokens": 7,
        "text": "1．改进检索算法",
        "id": 61,
        "type": "text"
      },
      {
        "page": 14,
        "length_tokens": 31,
        "text": "知识图谱：利用知识图谱中的语义信息和实体关系，增强对查询和文档的理解，提升召回的相关性",
        "id": 62,
        "type": "text"
      },
      {
        "page": 14,
        "length_tokens": 11,
        "text": "2.引入重排序 (Reranking）",
        "id": 63,
        "type": "text"
      },
      {
        "page": 14,
        "length_tokens": 41,
        "text": "重排序模型：对召回结果进行重排，提升问题和文档的相关性。常见的重排序模型有BGE-Rerank和Cohere Rerank。",
        "id": 64,
        "type": "text"
      },
      {
        "page": 14,
        "length_tokens": 114,
        "text": "场景：用户查询“如何提高深度学习模型的训练效率？”召回结果：初步召回10篇文档，其中包含与“深度学习”、“训练效率”相关的文章。重排序：BGE-Rerank对召回的10篇文档进行重新排序，将与“训练效率”最相关的文档（如“优化深度学习训练的技巧”）排在最前面，而将相关性较低的文档（如“深度学习基础理论”）排在后面。",
        "id": 65,
        "type": "text"
      },
      {
        "page": 14,
        "length_tokens": 32,
        "text": "混合检索：结合向量检索和关键词检索的优势，通过重排序模型对结果进行归一化处理，提升召回质量",
        "id": 66,
        "type": "text"
      },
      {
        "page": 15,
        "length_tokens": 5,
        "text": "Rerank模型使用",
        "id": 67,
        "type": "text"
      },
      {
        "page": 15,
        "length_tokens": 10,
        "text": "Thinking: 什么是重排序Rerank？",
        "id": 68,
        "type": "text"
      },
      {
        "page": 15,
        "length_tokens": 74,
        "text": "重排序Rerank主要用于优化初步检索结果的排序，提高最终输出的相关性或准确性。BGE-Rerank和Cohere Rerank是两种广泛使用的重排序模型，它们在检索增强生成（RAG）系统、搜索引擎优化和问答系统中表现优异。",
        "id": 69,
        "type": "text"
      },
      {
        "page": 15,
        "length_tokens": 7,
        "text": "1.BGE-Rerank ",
        "id": 70,
        "type": "text"
      },
      {
        "page": 15,
        "length_tokens": 109,
        "text": "由北京智源人工智能研究院（BAAI）开源发布，属于FlagEmbedding项目的一部分。  \n基于Transformer的Cross-Encoder结构，直接计算查询（Query）与文档（Document）的交互相关性得分。  \n训练数据：支持多语言（中、英等），训练数据包括T2Ranking、MSMARCO、NLI等数据集。  \n提供bge-reranker-base和bge-reranker-large两个版本，后者在精度上更优。",
        "id": 71,
        "type": "text"
      },
      {
        "page": 15,
        "length_tokens": 7,
        "text": "部署方式：可本地部署",
        "id": 72,
        "type": "text"
      },
      {
        "page": 15,
        "length_tokens": 29,
        "text": "开源免费，适合本地化部署，保护数据隐私。在中文任务中表现优秀，适用于垂直领域优化",
        "id": 73,
        "type": "text"
      },
      {
        "page": 16,
        "length_tokens": 5,
        "text": "Rerank模型使用",
        "id": 74,
        "type": "text"
      },
      {
        "page": 16,
        "length_tokens": 74,
        "text": "import torch  \nfrom transformers import AutoModelForSequenceClassification, AutoTokenizer  \ntokenizer $\\mathbf { \\tau } = \\mathbf { \\tau }$ AutoTokenizer.from_pretrained('BAAl/bge-reranker-large')  \nmodel $\\mathbf { \\tau } = \\mathbf { \\tau }$ AutoModelForSequenceClassification.from_pretrained('BAAl/",
        "id": 75,
        "type": "text"
      },
      {
        "page": 16,
        "length_tokens": 84,
        "text": "elForSequenceClassification.from_pretrained('BAAl/bge-reranker-large')  \nmodel.eval()  \npairs $\\mathbf { \\tau } = \\mathbf { \\tau }$ [['what is panda?','The giant panda is a bear species endemic to China.']]  \ninputs $\\mathbf { \\tau } = \\mathbf { \\tau }$ tokenizer(pairs, padding $\\circleddash$ True, ",
        "id": 76,
        "type": "text"
      },
      {
        "page": 16,
        "length_tokens": 123,
        "text": " }$ tokenizer(pairs, padding $\\circleddash$ True, truncation $\\ c =$ True,return_tensors $u ^ { \\prime }$ pt')  \nscores $\\mathbf { \\tau } = \\mathbf { \\tau }$ model(\\*\\*inputs).logits.view(-1).float()  \nprint(scores)#输出相关性分数 4.9538  \n在BGE-Rerank模型中，相关性分数scores是一个未归一化的对数几率（logits）值，范围没有固定的上  \n限或下限（不像某",
        "id": 77,
        "type": "text"
      },
      {
        "page": 16,
        "length_tokens": 121,
        "text": "性分数scores是一个未归一化的对数几率（logits）值，范围没有固定的上  \n限或下限（不像某些模型限制在O-1）。不过BGE-Rerank的分数通常落在以下范围：  \n高相关性： $3 . 0 { \\sim } 1 0 . 0$   \n中等相关性： $0 . 0 { \\sim } 3 . 0 \\$ （204号  \n低相关性/不相关：负数（如-5.0以下）",
        "id": 78,
        "type": "text"
      },
      {
        "page": 16,
        "length_tokens": 0,
        "text": "",
        "id": 79,
        "type": "text"
      },
      {
        "page": 17,
        "length_tokens": 5,
        "text": "Rerank模型使用",
        "id": 80,
        "type": "text"
      },
      {
        "page": 17,
        "length_tokens": 8,
        "text": "2.Cohere Rerank ",
        "id": 81,
        "type": "text"
      },
      {
        "page": 17,
        "length_tokens": 11,
        "text": "由Cohere公司提供的商业API服务。",
        "id": 82,
        "type": "text"
      },
      {
        "page": 17,
        "length_tokens": 25,
        "text": "基于专有的深度学习模型，支持多语言（如rerank-multilingual-v3.0）。",
        "id": 83,
        "type": "text"
      },
      {
        "page": 17,
        "length_tokens": 33,
        "text": "川练数据：优化了语义匹配，特别适用于混合检索（如结合BM25和向量检索）后的结果优化。",
        "id": 84,
        "type": "text"
      },
      {
        "page": 17,
        "length_tokens": 24,
        "text": "使用方式：通过APi调用，集成到LangChain、Llamalndex等框架中。",
        "id": 85,
        "type": "text"
      },
      {
        "page": 17,
        "length_tokens": 2,
        "text": "优势：",
        "id": 86,
        "type": "text"
      },
      {
        "page": 17,
        "length_tokens": 15,
        "text": "·简单易用，适合快速集成到现有系统。",
        "id": 87,
        "type": "text"
      },
      {
        "page": 17,
        "length_tokens": 28,
        "text": "，在英文和多语言任务中表现优异，如提升Hit Rate（命中率）和MRR（平均倒数排名）。",
        "id": 88,
        "type": "text"
      },
      {
        "page": 18,
        "length_tokens": 5,
        "text": "Rerank模型使用",
        "id": 89,
        "type": "text"
      },
      {
        "page": 18,
        "length_tokens": 86,
        "text": "import cohere   \n$\\mathtt { c o } =$ cohere.Client(api_key=\"YOUR_API_KEY\")   \nquery $\\mathbf { \\tau } = \\mathbf { \\tau }$ \"What is the capital of France?\"   \ndocs $\\mathbf { \\tau } = \\mathbf { \\tau }$ [\"Paris is the capital of France.\", \"Berlin is the capital of Germany.\"]   \nresults $\\mathbf { \\tau",
        "id": 90,
        "type": "text"
      },
      {
        "page": 18,
        "length_tokens": 103,
        "text": "e capital of Germany.\"]   \nresults $\\mathbf { \\tau } = \\mathbf { \\tau }$ co.rerank(query $\\mathbf { \\bar { \\rho } } = \\mathbf { \\rho }$ query, documents $\\ c =$ docs,top_ $\\scriptstyle { \\mathsf { n } } = 2$ ,model $\\mathbf { \\Phi } = \\mathbf { \\Phi } ^ { \\prime }$ rerank-multilingual-v3.0') print(r",
        "id": 91,
        "type": "text"
      },
      {
        "page": 18,
        "length_tokens": 50,
        "text": "} ^ { \\prime }$ rerank-multilingual-v3.0') print(results）#Cohere Rerank的API返回的是归一化后的相关性分数（如O-1），更易解释。 ",
        "id": 92,
        "type": "text"
      },
      {
        "page": 18,
        "length_tokens": 0,
        "text": "",
        "id": 93,
        "type": "table"
      },
      {
        "page": 19,
        "length_tokens": 13,
        "text": "RAG高效召回方法 （优化查询扩展）",
        "id": 94,
        "type": "text"
      },
      {
        "page": 19,
        "length_tokens": 6,
        "text": "3.优化查询扩展",
        "id": 95,
        "type": "text"
      },
      {
        "page": 19,
        "length_tokens": 44,
        "text": "相似语义改写：使用大模型将用户查询改写成多个语义相近的查询，提升召回多样性。例如，LangChain的MultiQueryRetriever支持多查询召回。",
        "id": 96,
        "type": "text"
      },
      {
        "page": 19,
        "length_tokens": 90,
        "text": "#加载向量数据库，添加allow_dangerous_deserialization=True参数以允许反序列化   \nvectorstore $\\mathbf { \\tau } = \\mathbf { \\tau }$ FAISS.load_local(\"./faiss-1\",embeddings,allow_dangerous_deserialization=True)   \n# 创建MultiQueryRetriever   \nretriever $\\mathbf { \\tau } = \\mathbf { \\tau }$ MultiQueryRetriever.from_Ilm( retr",
        "id": 97,
        "type": "text"
      },
      {
        "page": 19,
        "length_tokens": 98,
        "text": "athbf { \\tau }$ MultiQueryRetriever.from_Ilm( retriever $\\mathbf { \\tau } = \\mathbf { \\tau }$ vectorstore.as_retriever(), Im=llm   \n）   \nquery $\\mathbf { \\sigma } = \\mathbf { \\sigma }$ \"客户经理的考核标准是什么？\"   \n#执行查询   \nresults $\\mathbf { \\tau } = \\mathbf { \\tau }$ retriever.get_relevant_documents(query) ",
        "id": 98,
        "type": "text"
      },
      {
        "page": 20,
        "length_tokens": 13,
        "text": "RAG高效召回方法 （优化查询扩展）",
        "id": 99,
        "type": "text"
      },
      {
        "page": 20,
        "length_tokens": 14,
        "text": "TO DO: 编写chatpdf-faiss-MultiQueryRetriever.py",
        "id": 100,
        "type": "text"
      },
      {
        "page": 20,
        "length_tokens": 15,
        "text": "LangChain的MultiQueryRetriever支持多查询召回，再进行回答问题",
        "id": 101,
        "type": "text"
      },
      {
        "page": 21,
        "length_tokens": 13,
        "text": "RAG高效召回方法 （双向改写）",
        "id": 102,
        "type": "text"
      },
      {
        "page": 21,
        "length_tokens": 38,
        "text": "双向改写：将查询改写成文档（Query2Doc）或为文档生成查询（Doc2Query），缓解短文本向量化效果差的问题",
        "id": 103,
        "type": "text"
      },
      {
        "page": 21,
        "length_tokens": 25,
        "text": "Query2Doc: 将查询改写成文档用户查询：“如何提高深度学习模型的训练效率？‘",
        "id": 104,
        "type": "text"
      },
      {
        "page": 21,
        "length_tokens": 0,
        "text": "",
        "id": 105,
        "type": "text"
      },
      {
        "page": 21,
        "length_tokens": 6,
        "text": "Query2Doc改写：",
        "id": 106,
        "type": "text"
      },
      {
        "page": 21,
        "length_tokens": 14,
        "text": "原始查询较短，可能无法充分表达用户意图。",
        "id": 107,
        "type": "text"
      },
      {
        "page": 21,
        "length_tokens": 13,
        "text": "通过Query2Doc 生成一段扩展文档：",
        "id": 108,
        "type": "text"
      },
      {
        "page": 21,
        "length_tokens": 16,
        "text": "提高深度学习模型的训练效率可以从以下几个方面入手：",
        "id": 109,
        "type": "text"
      },
      {
        "page": 21,
        "length_tokens": 96,
        "text": "1.使用更高效的优化算法，如AdamW或LAMB。  \n2.采用混合精度训练（Mixed Precision Training），减少显存  \n占用并加速计算。  \n3.使用分布式训练技术，如数据并行或模型并行。  \n4.对数据进行预处理和增强，减少训练时的冗余计算。  \n5.调整学习率调度策略，避免训练过程中的震荡。",
        "id": 110,
        "type": "text"
      },
      {
        "page": 21,
        "length_tokens": 11,
        "text": "Doc2Query: 为文档生成关联查询 ",
        "id": 111,
        "type": "text"
      },
      {
        "page": 21,
        "length_tokens": 4,
        "text": "文档内容：",
        "id": 112,
        "type": "text"
      },
      {
        "page": 21,
        "length_tokens": 13,
        "text": "本文介绍了深度学习模型训练中的优化技巧，包括：",
        "id": 113,
        "type": "text"
      },
      {
        "page": 21,
        "length_tokens": 56,
        "text": "1.使用AdamW优化器替代传统的SGD。2.采用混合精度训练，减少显存占用。3.使用分布式训练技术加速大规模模型的训练..通过Doc2Query生成一组可能的查询：",
        "id": 114,
        "type": "text"
      },
      {
        "page": 21,
        "length_tokens": 66,
        "text": "1.如何选择深度学习模型的优化器？  \n2.混合精度训练有哪些优势？  \n3.分布式训练技术如何加速深度学习？  \n4.如何减少深度学习训练中的显存占用？  \n5.深度学习模型训练的最佳实践是什么？",
        "id": 115,
        "type": "text"
      },
      {
        "page": 22,
        "length_tokens": 13,
        "text": "RAG高效召回方法 （索引扩展）",
        "id": 116,
        "type": "text"
      },
      {
        "page": 22,
        "length_tokens": 6,
        "text": "4.索引扩展",
        "id": 117,
        "type": "text"
      },
      {
        "page": 22,
        "length_tokens": 38,
        "text": "1）离散索引扩展：使用关键词抽取、实体识别等技术生成离散索引，与向量检索互补，提升召回准确性。",
        "id": 118,
        "type": "text"
      },
      {
        "page": 22,
        "length_tokens": 38,
        "text": "2）连续索引扩展：结合多种向量模型（如OpenAI的Ada、智源的BGE）进行多路召回，取长补短。",
        "id": 119,
        "type": "text"
      },
      {
        "page": 22,
        "length_tokens": 39,
        "text": "3）混合索引召回：将BM25等离散索引与向量索引结合，通过Ensemble Retriever实现混合召回，提升召回多样性",
        "id": 120,
        "type": "text"
      },
      {
        "page": 23,
        "length_tokens": 13,
        "text": "RAG高效召回方法 （索引扩展）",
        "id": 121,
        "type": "text"
      },
      {
        "page": 23,
        "length_tokens": 36,
        "text": "葛散索引扩展：使用关键词抽取、实体识别等技术生成离散索引，与向量检索互补，提升召回准确性。",
        "id": 122,
        "type": "text"
      },
      {
        "page": 23,
        "length_tokens": 33,
        "text": "关键词抽取：从文档中提取出重要的关键词，作为离散索引的一部分，用于补充向量检索的不足。",
        "id": 123,
        "type": "text"
      },
      {
        "page": 23,
        "length_tokens": 3,
        "text": "文档内容",
        "id": 124,
        "type": "text"
      },
      {
        "page": 23,
        "length_tokens": 13,
        "text": "本文介绍了深度学习模型训练中的优化技巧，包括：",
        "id": 125,
        "type": "text"
      },
      {
        "page": 23,
        "length_tokens": 47,
        "text": "1.使用AdamW优化器替代传统的SGD。  \n2.采用混合精度训练，减少显存占用。  \n3.使用分布式训练技术加速大规模模型的训练。",
        "id": 126,
        "type": "text"
      },
      {
        "page": 23,
        "length_tokens": 0,
        "text": "",
        "id": 127,
        "type": "image"
      },
      {
        "page": 23,
        "length_tokens": 47,
        "text": "通过关键词抽取技术（如TF-IDF、TextRank） 提取出以下关键词： [\"深度学习\",\"模型训练\",\"优化技巧\",\"AdamW\", \"混合精度训练\",\"分布式训练\"] ",
        "id": 128,
        "type": "text"
      },
      {
        "page": 23,
        "length_tokens": 29,
        "text": "当用户查询“如何优化深度学习模型训练？”时，离散索引中的关键词能够快速匹配到相关文档。",
        "id": 129,
        "type": "text"
      },
      {
        "page": 24,
        "length_tokens": 13,
        "text": "RAG高效召回方法 （索引扩展）",
        "id": 130,
        "type": "text"
      },
      {
        "page": 24,
        "length_tokens": 40,
        "text": "实体识别：从文档中识别出命名实体（如人名、地点、组织等），作为离散索引的一部分，增强检索的精确性。",
        "id": 131,
        "type": "text"
      },
      {
        "page": 24,
        "length_tokens": 0,
        "text": "",
        "id": 132,
        "type": "text"
      },
      {
        "page": 24,
        "length_tokens": 80,
        "text": "又档内谷  \n2023年诺贝尔物理学奖授予了三位科学家，以表彰他们 通过实体识别技术（如 SpaCy、BERT-based  \n在量子纠缠领域的研究成果。 NER）提取出以下实体：[\"2023年\",\"诺贝尔物理学奖\",\"量子纠缠\"]",
        "id": 133,
        "type": "text"
      },
      {
        "page": 24,
        "length_tokens": 37,
        "text": "当用户查询“2023年诺贝尔物理学奖的获奖者是谁？”时，离散索引中的实体能够快速匹配到相关文档。",
        "id": 134,
        "type": "text"
      },
      {
        "page": 25,
        "length_tokens": 13,
        "text": "RAG高效召回方法 （索引扩展）",
        "id": 135,
        "type": "text"
      },
      {
        "page": 25,
        "length_tokens": 35,
        "text": "混合索引召回：将离散索引（如关键词、实体）与向量索引结合，通过混合召回策略提升检索效果。",
        "id": 136,
        "type": "text"
      },
      {
        "page": 25,
        "length_tokens": 3,
        "text": "文档内容",
        "id": 137,
        "type": "text"
      },
      {
        "page": 25,
        "length_tokens": 12,
        "text": "本文介绍了人工智能在医疗领域的应用，包括：",
        "id": 138,
        "type": "text"
      },
      {
        "page": 25,
        "length_tokens": 1,
        "text": "二",
        "id": 139,
        "type": "text"
      },
      {
        "page": 25,
        "length_tokens": 45,
        "text": "1.使用深度学习技术进行医学影像分析。  \n2.利用自然语言处理技术提取电子病历中的关键信息。  \n3.开发智能诊断系统辅助医生决策。",
        "id": 140,
        "type": "text"
      },
      {
        "page": 25,
        "length_tokens": 64,
        "text": "当用户查询“人工智能在医疗领域的应用有哪些？”时：离散索引通过关键词和实体匹配到相关文档。向量索引通过语义相似度匹配到相关文档。综合两种召回结果，提升检索的准确性和覆盖率。",
        "id": 141,
        "type": "text"
      },
      {
        "page": 25,
        "length_tokens": 57,
        "text": "关键词抽取：[\"人工智能\",\"医疗领域\",\"深度学 习\",\"医学影像分析\",\"自然语言处理\",\"电子病历 \",\"智能诊断系统\"]   \n实体识别：[\"人工智能\",\"医疗领域\",\"深度学习\", \"自然语言处理\"] ",
        "id": 142,
        "type": "text"
      },
      {
        "page": 26,
        "length_tokens": 13,
        "text": "RAG高效召回方法 (Small-to-Big)",
        "id": 143,
        "type": "text"
      },
      {
        "page": 26,
        "length_tokens": 8,
        "text": "Small-to-Big索引策略：",
        "id": 144,
        "type": "text"
      },
      {
        "page": 26,
        "length_tokens": 89,
        "text": "一种高效的检索方法，特别适用于处理长文档或多文档场景。核心思想是通过小规模内容（如摘要、关键句或段落）建立索引，并链接到大规模内容主体中。这种策略的优势在于能够快速定位相关的小规模内容，并通过链接获取更详细的上下文信息，从而提高检索效率和答案的逻辑连贯性。",
        "id": 145,
        "type": "text"
      },
      {
        "page": 26,
        "length_tokens": 8,
        "text": "小规模内容（索引部分）：",
        "id": 146,
        "type": "text"
      },
      {
        "page": 26,
        "length_tokens": 15,
        "text": "摘要：从每篇论文中提取摘要作为索引内容。",
        "id": 147,
        "type": "text"
      },
      {
        "page": 26,
        "length_tokens": 26,
        "text": "摘要1：本文介绍了Transformer 模型在机器翻译任务中的应用，并提出了改进的注意力机制。",
        "id": 148,
        "type": "text"
      },
      {
        "page": 26,
        "length_tokens": 24,
        "text": "摘要2：本文探讨了Transformer模型在文本生成任务中的性能，并与RNN模型进行了对比。",
        "id": 149,
        "type": "text"
      },
      {
        "page": 26,
        "length_tokens": 15,
        "text": "关键句：从论文中提取与查询相关的关键句。",
        "id": 150,
        "type": "text"
      },
      {
        "page": 26,
        "length_tokens": 21,
        "text": "关键句1：Transformer 模型通过自注意力机制实现了高效的并行计算。",
        "id": 151,
        "type": "text"
      },
      {
        "page": 26,
        "length_tokens": 27,
        "text": "关键句2：BERT 是基于Transformer 的预训练模型，在多项NLP任务中取得了显著效果。",
        "id": 152,
        "type": "text"
      },
      {
        "page": 27,
        "length_tokens": 13,
        "text": "RAG高效召回方法 (Small-to-Big)",
        "id": 153,
        "type": "text"
      },
      {
        "page": 27,
        "length_tokens": 7,
        "text": "大规模内容（链接部分）：",
        "id": 154,
        "type": "text"
      },
      {
        "page": 27,
        "length_tokens": 18,
        "text": "每篇论文的完整内容作为大规模内容，通过链接与小规模内容关联。",
        "id": 155,
        "type": "text"
      },
      {
        "page": 27,
        "length_tokens": 38,
        "text": "论文1：链接到完整的PDF文档，包含详细的实验和结果。  \n论文2：链接到完整的PDF文档，包含模型架构和性能分析。",
        "id": 156,
        "type": "text"
      },
      {
        "page": 27,
        "length_tokens": 7,
        "text": "Small-to-Big机制: ",
        "id": 157,
        "type": "text"
      },
      {
        "page": 27,
        "length_tokens": 168,
        "text": "小规模内容检索：用户输入查询后，系统首先在小规模内容（如摘要、关键句或段落）中检索匹配的内容。小规模内容通常是通过摘要生成、关键句提取等技术从大规模内容中提取的，并建立索引。链接到大规模内容：当小规模内容匹配到用户的查询后，系统会通过预定义的链接（如文档ID、URL或指针）找到对应的大规模内容（如完整的文档、文章）。大规模内容包含更详细的上下文信息，为RAG提供丰富的背景知识。上下文补充：将大规模内容作为RAG 系统的上下文输入，结合用户查询和小规模内容，生成更准确和连贯的答案。",
        "id": 158,
        "type": "text"
      },
      {
        "page": 28,
        "length_tokens": 4,
        "text": "GraphRAG使用",
        "id": 159,
        "type": "text"
      },
      {
        "page": 29,
        "length_tokens": 6,
        "text": "GraphRAG过程包括：",
        "id": 160,
        "type": "text"
      },
      {
        "page": 29,
        "length_tokens": 46,
        "text": "构建社区层级(这种结构通常用来描述个体、群体及它们之间的关系，帮助理解信息如何在社区内部传播、知识如何共享以及权力和影响力如何分布)",
        "id": 161,
        "type": "text"
      },
      {
        "page": 29,
        "length_tokens": 32,
        "text": "·是一种结构化的、分层的检索增强生成（RAG）方法，而不是使用纯文本片段的语义搜索方法。",
        "id": 162,
        "type": "text"
      },
      {
        "page": 29,
        "length_tokens": 15,
        "text": "然后在执行基于RAG的任务时，会利用这些结构。",
        "id": 163,
        "type": "text"
      },
      {
        "page": 29,
        "length_tokens": 0,
        "text": "",
        "id": 164,
        "type": "image"
      },
      {
        "page": 29,
        "length_tokens": 5,
        "text": "GraphRAG: ",
        "id": 165,
        "type": "text"
      },
      {
        "page": 29,
        "length_tokens": 18,
        "text": "原始文本中提取出知识图谱为这些社区层级生成摘要。",
        "id": 166,
        "type": "text"
      },
      {
        "page": 29,
        "length_tokens": 0,
        "text": "",
        "id": 167,
        "type": "text"
      },
      {
        "page": 29,
        "length_tokens": 14,
        "text": "GraphRAG工作流，DAG（有向无环）",
        "id": 168,
        "type": "text"
      },
      {
        "page": 30,
        "length_tokens": 9,
        "text": "GraphRAG与 基线RAG:",
        "id": 169,
        "type": "text"
      },
      {
        "page": 30,
        "length_tokens": 46,
        "text": "大多数 RAG使用矢量相似性作为搜索技术，称之为 基线 RAGGraphRAG使用知识图谱来在处理复杂信息时提供问题和回答性能的显著改进。",
        "id": 170,
        "type": "text"
      },
      {
        "page": 30,
        "length_tokens": 14,
        "text": "在某些情况下，基线RAG的性能非常差：",
        "id": 171,
        "type": "text"
      },
      {
        "page": 30,
        "length_tokens": 72,
        "text": "·基线RAG难以连接各个要点。这种情况发生在回答问题需要通过共享属性遍历不同的信息片段，以提供新的综合见解。  \n·基线RAG在被要求全面理解大量的数据（跨文档）或甚至单个大文档的的语义概念时表现不佳。",
        "id": 172,
        "type": "text"
      },
      {
        "page": 30,
        "length_tokens": 42,
        "text": "RAG 在帮助LLM推理“私有数据集”方面有很大的潜力。这些数据集是LLM从未见过的，例如企业的专有研究、商业文件。",
        "id": 173,
        "type": "text"
      },
      {
        "page": 30,
        "length_tokens": 5,
        "text": "GraphRAG方法：",
        "id": 174,
        "type": "text"
      },
      {
        "page": 30,
        "length_tokens": 71,
        "text": "·使用LLMs来创建基于输入语料库的知识图谱。  \n这个知识图谱、社区层级摘要、以及知识图谱机器学习输出会  \n在用户查询时用于增强提示。  \n·GraphRAG在回答上述两类问题时可以显著改进回答能力，远超基线RAG",
        "id": 175,
        "type": "text"
      },
      {
        "page": 31,
        "length_tokens": 4,
        "text": "GraphRAG ",
        "id": 176,
        "type": "text"
      },
      {
        "page": 31,
        "length_tokens": 17,
        "text": "Query：19世纪的艺术运动是如何影响20世纪现代艺术的发展的？",
        "id": 177,
        "type": "text"
      },
      {
        "page": 31,
        "length_tokens": 46,
        "text": "LLM：19世纪的艺术运动通过鼓励对色彩、形式和主题的实验影响了20世纪的现代艺术。这些运动为抽象主义、表现主义和其他创新艺术铺平了道路。",
        "id": 178,
        "type": "text"
      },
      {
        "page": 31,
        "length_tokens": 98,
        "text": "RAG检索：1.像克劳德·莫奈这样的印象派艺术家引入了新技术，彻底改变了对光和颜色的描绘。2.印象派的技法影响了后来的艺术运动。3.巴勃罗·毕加索开创了立体主义，从根本上改变了视觉表现的方式。4.立体主义出现在20世纪初，挑战了传统的艺术观点。",
        "id": 179,
        "type": "text"
      },
      {
        "page": 31,
        "length_tokens": 52,
        "text": "RAG回答：像19世纪的克劳德·莫奈这样的印象派艺术家引入了影响后来艺术运动的新技术。巴勃罗·毕加索在20世纪初开创了立体主义相对论。",
        "id": 180,
        "type": "text"
      },
      {
        "page": 31,
        "length_tokens": 85,
        "text": "GraphRAG检索： （莫奈）-[引进 $] $ （新技术）-（新技术）-[革新] $| $ （光和颜色的描绘）（印象派技术）-[影响] $| $ （后来的艺术运动）（毕加索）-[开创 $$ （立体主义）（立体主义）-[出现] $| $ （20世纪初）",
        "id": 181,
        "type": "text"
      },
      {
        "page": 31,
        "length_tokens": 5,
        "text": "GraphRAG回答：",
        "id": 182,
        "type": "text"
      },
      {
        "page": 31,
        "length_tokens": 64,
        "text": "莫奈引进的新技术彻底改变了对光和色彩的描绘。他的印象派技巧影响了后来的艺术运动，包括20世纪初出现的毕加索的立体主义。这种影响有助于塑造毕加索对碎片化视角的创新方法。",
        "id": 183,
        "type": "text"
      },
      {
        "page": 32,
        "length_tokens": 4,
        "text": "GraphRAG ",
        "id": 184,
        "type": "text"
      },
      {
        "page": 32,
        "length_tokens": 2,
        "text": "Query ",
        "id": 185,
        "type": "text"
      },
      {
        "page": 32,
        "length_tokens": 66,
        "text": "Query Query   \nHow did the artistic movements How did the artistic movements   \nof the 19th century impact the of the 19th century impact the   \ndevelopment of modern art in development of modern art in   \nthe 20th century? the 20th century? Retriever ↓ 1. Impressionist artists like Claude Monet int",
        "id": 186,
        "type": "text"
      },
      {
        "page": 32,
        "length_tokens": 60,
        "text": "r ↓ 1. Impressionist artists like Claude Monet introduced new techniques that revolutionized the depiction of light and color. 2. The Impressionist techniques influenced later art movements. LLMs LLMs 3. Pablo Picasso pioneered Cubism, which radically transformed the approach to visual representatio",
        "id": 187,
        "type": "text"
      },
      {
        "page": 32,
        "length_tokens": 65,
        "text": "y transformed the approach to visual representation. 4. Cubism emerged in the early 20th century and challenged Response traditional perspectives on art.   \nThe artistic movements of   \nthe 19th century influenced Retrieved Text   \nmodern art in the 20th   \neptrimeyteticon with nolor, Response   \nfo",
        "id": 188,
        "type": "text"
      },
      {
        "page": 32,
        "length_tokens": 61,
        "text": "20th   \neptrimeyteticon with nolor, Response   \nform, and subject matter. Impressionist artists like Claude Monet in the 19th   \nThese movements paved century introduced new techniques that influence   \nthe way for abstraction, later art movements. Pablo Picasso pioneered   \nexpressionism, and other",
        "id": 189,
        "type": "text"
      },
      {
        "page": 32,
        "length_tokens": 73,
        "text": "ablo Picasso pioneered   \nexpressionism, and other   \ninnovative. × Cubism relativity in the early 20th century. ■=   \nHow did the artistic movements   \nof the 19th century impact the   \ndevelopment of modern art in Retriever   \nthe 20th century? 1 - (Claude Monet) - [introduced] $$ (new techniques)",
        "id": 190,
        "type": "text"
      },
      {
        "page": 32,
        "length_tokens": 93,
        "text": " (Claude Monet) - [introduced] $$ (new techniques) - (new techniques) - [revolutionized] $$ (depiction of light and color) - (Impressionist techniques) - LLMs ←[influenced] $$ (later art movements) - (Pablo Picasso) - [pioneered] $$ (Cubism) - (Cubism) -[emerged in] $$ (early 20th century) Retrieved",
        "id": 191,
        "type": "text"
      },
      {
        "page": 32,
        "length_tokens": 21,
        "text": "m) -[emerged in] $$ (early 20th century) Retrieved Triplets Response ",
        "id": 192,
        "type": "text"
      },
      {
        "page": 32,
        "length_tokens": 0,
        "text": "",
        "id": 193,
        "type": "text"
      },
      {
        "page": 32,
        "length_tokens": 51,
        "text": "Monet introduced new techniques that revolutionized the depiction of light and color. His Impressionist techniques influenced later art movements, including Picasso's Cubism， which emerged in the early 20th century. This influence helped shape Picasso's innovative approach to fragmented perspectives",
        "id": 194,
        "type": "text"
      },
      {
        "page": 32,
        "length_tokens": 9,
        "text": "o's innovative approach to fragmented perspectives. ",
        "id": 195,
        "type": "text"
      },
      {
        "page": 33,
        "length_tokens": 8,
        "text": "GraphRAG的基本步骤如下：",
        "id": 196,
        "type": "text"
      },
      {
        "page": 33,
        "length_tokens": 2,
        "text": "索引",
        "id": 197,
        "type": "text"
      },
      {
        "page": 33,
        "length_tokens": 137,
        "text": "·将输入语料库分割为一系列的文本单元（TextUnits），这些单元作为处理以下步骤的可分析单元，并在我们的输出中提供细粒度的引用。  \n·使用LLM从文本单元中提取所有实体、关系和关键声明。  \n·使用Leiden技术对知识图谱进行层次聚类。每个圆圈都是一个实体（例如人、地点或组织），大小表示实体的度，颜色表示其社区层级。  \n·自下而上地生成每个社区层级及其组成部分的摘要。这有助于对数据集的整体理解。",
        "id": 198,
        "type": "text"
      },
      {
        "page": 33,
        "length_tokens": 0,
        "text": "",
        "id": 199,
        "type": "image"
      },
      {
        "page": 34,
        "length_tokens": 4,
        "text": "GraphRAG ",
        "id": 200,
        "type": "text"
      },
      {
        "page": 34,
        "length_tokens": 2,
        "text": "查询：",
        "id": 201,
        "type": "text"
      },
      {
        "page": 34,
        "length_tokens": 67,
        "text": "·在查询时，使用这些结构为LLM上下文窗口提供材料来回答问题。主要查询模式有：全局搜索，通过社区层级摘要来推理有关语料库的整体问题。局部搜索，通过扩展到其邻居和相关概念来推理特定实体的情况。",
        "id": 202,
        "type": "text"
      },
      {
        "page": 34,
        "length_tokens": 49,
        "text": "GraphRAG方法是使用LLM构建基于图的文本索引，分两个阶段：首先从源文档中派生出实体知识图谱然后为所有密切相关的实体组预生成社区摘要。",
        "id": 203,
        "type": "text"
      },
      {
        "page": 35,
        "length_tokens": 3,
        "text": "Input Query ",
        "id": 204,
        "type": "text"
      },
      {
        "page": 35,
        "length_tokens": 25,
        "text": "bw did the artistic movements of the 19th century impactthe development of modern art in the 20th century? ",
        "id": 205,
        "type": "text"
      },
      {
        "page": 35,
        "length_tokens": 71,
        "text": "V G-Retrieval Retrieval Graph Format G-Generation Output Results Response ● 画   \nQaerygeg Reeeieir Merging Nodee Ageng Pre-Gnenemetnon Generator Pruning ：   \nDecomposition Natural Language Query Knowledge Triplets 國   \nEnhancements Enhancements O C Mid-Gncemetion Generator 1 Paths Graph Database & G",
        "id": 206,
        "type": "text"
      },
      {
        "page": 35,
        "length_tokens": 48,
        "text": "id-Gncemetion Generator 1 Paths Graph Database & G-Indexing O Syntax Tree U W Subgraphs Nod euence Post-Generation Generator Enhancements Open Knowledge Self-Constructed Graphs Graph Data Hybrid Graph Embedding ",
        "id": 207,
        "type": "text"
      },
      {
        "page": 36,
        "length_tokens": 7,
        "text": "GraphRAG索引数据流",
        "id": 208,
        "type": "text"
      },
      {
        "page": 36,
        "length_tokens": 4,
        "text": "知识模型: ",
        "id": 209,
        "type": "text"
      },
      {
        "page": 36,
        "length_tokens": 31,
        "text": "在GraphRAG的存储库中，包括实体类型如Document、TextUnit、Entity、 Relationship、 Covariate、 Community Report和Node。",
        "id": 210,
        "type": "text"
      },
      {
        "page": 36,
        "length_tokens": 20,
        "text": "默认配置工作流程：将文本文档转换为知识图谱模型，主要步骤包括：",
        "id": 211,
        "type": "text"
      },
      {
        "page": 36,
        "length_tokens": 6,
        "text": "第一阶段：组合TextUnits",
        "id": 212,
        "type": "text"
      },
      {
        "page": 36,
        "length_tokens": 30,
        "text": "将输入文档转换为TextUnits，用于知识图谱提取的文本块。  \n用户可以配置块大小和分组方式。",
        "id": 213,
        "type": "text"
      },
      {
        "page": 36,
        "length_tokens": 10,
        "text": "第二阶段： 知识图谱提取",
        "id": 214,
        "type": "text"
      },
      {
        "page": 36,
        "length_tokens": 16,
        "text": "分析每个TextUnit，用来提取实体、关系和主张。",
        "id": 215,
        "type": "text"
      },
      {
        "page": 36,
        "length_tokens": 23,
        "text": "实体和关系在entity_extract动词中提取，而主张在claim_extract动词中提取。",
        "id": 216,
        "type": "text"
      },
      {
        "page": 36,
        "length_tokens": 6,
        "text": "实体和关系提取：",
        "id": 217,
        "type": "text"
      },
      {
        "page": 36,
        "length_tokens": 14,
        "text": "使用LLM从原始文本中提取实体和关系。",
        "id": 218,
        "type": "text"
      },
      {
        "page": 36,
        "length_tokens": 20,
        "text": "合并具有相同名称和类型的实体，以及具有相同源和目标的关系。",
        "id": 219,
        "type": "text"
      },
      {
        "page": 36,
        "length_tokens": 6,
        "text": "实体和关系概述：",
        "id": 220,
        "type": "text"
      },
      {
        "page": 36,
        "length_tokens": 16,
        "text": "通过询问LLM获取每个实体和关系的简要概述",
        "id": 221,
        "type": "text"
      },
      {
        "page": 36,
        "length_tokens": 8,
        "text": "实体解析 （默认未启用）：",
        "id": 222,
        "type": "text"
      },
      {
        "page": 36,
        "length_tokens": 14,
        "text": "解析表示相同现实世界实体，但具有不同名称的实体。",
        "id": 223,
        "type": "text"
      },
      {
        "page": 36,
        "length_tokens": 8,
        "text": "主张提取和发射：",
        "id": 224,
        "type": "text"
      },
      {
        "page": 36,
        "length_tokens": 27,
        "text": "从源TextUnits中提取主张，这些主张是正面事实陈述，并作为Covariates发射。",
        "id": 225,
        "type": "text"
      },
      {
        "page": 37,
        "length_tokens": 7,
        "text": "GraphRAG索引数据流",
        "id": 226,
        "type": "text"
      },
      {
        "page": 37,
        "length_tokens": 9,
        "text": "第三阶段： 知识图谱增强",
        "id": 227,
        "type": "text"
      },
      {
        "page": 37,
        "length_tokens": 10,
        "text": "了解实体的社区结构，并增强知识图谱",
        "id": 228,
        "type": "text"
      },
      {
        "page": 37,
        "length_tokens": 24,
        "text": "使用层次Leiden算法进行社区检测，使用Node2Vec算法进行知识图谱嵌入。",
        "id": 229,
        "type": "text"
      },
      {
        "page": 37,
        "length_tokens": 6,
        "text": "第四阶段： 社区总结",
        "id": 230,
        "type": "text"
      },
      {
        "page": 37,
        "length_tokens": 32,
        "text": "生成社区报告，了解知识图谱在各个粒度级别上的高层次情况。  \n使用LLM生成每个社区的摘要。",
        "id": 231,
        "type": "text"
      },
      {
        "page": 37,
        "length_tokens": 6,
        "text": "第五阶段： 文档处理",
        "id": 232,
        "type": "text"
      },
      {
        "page": 37,
        "length_tokens": 10,
        "text": "为知识模型创建“文档”表。",
        "id": 233,
        "type": "text"
      },
      {
        "page": 37,
        "length_tokens": 22,
        "text": "如果工作流在CSV数据上运行，可以配置工作流，用于向文档输出添加其他字段。",
        "id": 234,
        "type": "text"
      },
      {
        "page": 37,
        "length_tokens": 8,
        "text": "第六阶段：网络可视化",
        "id": 235,
        "type": "text"
      },
      {
        "page": 37,
        "length_tokens": 19,
        "text": "执行UMAP降维，用于在2D空间中可视化知识图谱 ",
        "id": 236,
        "type": "text"
      },
      {
        "page": 37,
        "length_tokens": 15,
        "text": "UMAP嵌入作为“节点”表格发出。",
        "id": 237,
        "type": "text"
      },
      {
        "page": 37,
        "length_tokens": 58,
        "text": "GraphRAG工作流程是将文本数据转换为结构化的知识图谱，以便理解和分析数据。通过这个流程，用户可以提取关键信息，如实体、关系和主张，并在知识图谱中进行进一步的分析和可视化。",
        "id": 238,
        "type": "text"
      },
      {
        "page": 38,
        "length_tokens": 5,
        "text": "GraphRAG方法：",
        "id": 239,
        "type": "text"
      },
      {
        "page": 38,
        "length_tokens": 35,
        "text": "Creating virtualenv graphrag-x3i77_Wo-py3.11 in C:\\Users\\cheny\\AppData\\LocalV Installing dependencies from lock file ",
        "id": 240,
        "type": "text"
      },
      {
        "page": 38,
        "length_tokens": 16,
        "text": "Package operations: 205 installs， 1 update， 0 removals ",
        "id": 241,
        "type": "text"
      },
      {
        "page": 38,
        "length_tokens": 94,
        "text": "https://github.com/microsoft/graphrag   \nStep1，下载源代码   \ngit clone https://github.com/microsoft/graphrag.git   \ncd graphrag   \nStep2，下载依赖并初始化项目   \npip install poetry   \npoetry install   \nInstalling attrs (24.2.0)   \nInstalling rpds-py (0.20.0)   \nInstalling referencing (0.35.1)   \nInstalling six (1.1",
        "id": 242,
        "type": "text"
      },
      {
        "page": 38,
        "length_tokens": 95,
        "text": "alling referencing (0.35.1)   \nInstalling six (1.16.0)   \nInstalling jsonschema-specifications (2024.10.1)   \nInstalling platformdirs (4.3.6)   \nInstalling python-dateutil (2.9.0.post0)   \nInstalling pywin32 (307)   \nInstalling traitlets (5.14.3)   \nInstalling types-python-dateutil (2.9.0.20241003) ",
        "id": 243,
        "type": "text"
      },
      {
        "page": 38,
        "length_tokens": 102,
        "text": "Installing types-python-dateutil (2.9.0.20241003)   \nInstalling arrow (1.3.0)   \nInstalling fastjsonschema (2.20.0)   \nInstalling jsonschema (4.23.0)   \nInstalling jupyter-core (5.7.2)   \nInstalling pycparser (2.22)   \nInstalling pyzmq (26.2.0)   \nInstalling tornado (6.4.1)   \nInstalling cffi (1.17.",
        "id": 244,
        "type": "text"
      },
      {
        "page": 38,
        "length_tokens": 89,
        "text": "stalling tornado (6.4.1)   \nInstalling cffi (1.17.1)   \nInstalling fqdn (1.5.1)   \nInstalling idna (3.10)   \nInstalling isoduration (20.11.0)   \nInstalling jsonpointer (3.0.0)   \nInstalling jupyter-client (8.6.3)   \nInstalling markupsafe (3.0.1) ",
        "id": 245,
        "type": "text"
      },
      {
        "page": 38,
        "length_tokens": 0,
        "text": "",
        "id": 246,
        "type": "text"
      },
      {
        "page": 39,
        "length_tokens": 4,
        "text": "GraphRAG ",
        "id": 247,
        "type": "text"
      },
      {
        "page": 39,
        "length_tokens": 1,
        "text": "初始化",
        "id": 248,
        "type": "text"
      },
      {
        "page": 39,
        "length_tokens": 11,
        "text": "poetry run poe index --init --root . ",
        "id": 249,
        "type": "text"
      },
      {
        "page": 39,
        "length_tokens": 24,
        "text": "Poe => python -m graphrag.index --init --root   \nInitializing project at GraphRAG Indexer ",
        "id": 250,
        "type": "text"
      },
      {
        "page": 39,
        "length_tokens": 25,
        "text": "正确运行后，此处会在graphrag目录下生成output、prompts、 .env、settings.yaml文件",
        "id": 251,
        "type": "text"
      },
      {
        "page": 39,
        "length_tokens": 17,
        "text": "Step3，将待检索的文档放到./cases/input目录下 ",
        "id": 252,
        "type": "text"
      },
      {
        "page": 39,
        "length_tokens": 6,
        "text": "three_kingdoms ",
        "id": 253,
        "type": "text"
      },
      {
        "page": 39,
        "length_tokens": 12,
        "text": "Step4，修改配置文件对.env文件配置api_key",
        "id": 254,
        "type": "text"
      },
      {
        "page": 39,
        "length_tokens": 17,
        "text": "修改 settings.yaml，设置 model为 gpt-4o-mini 减少成本",
        "id": 255,
        "type": "text"
      },
      {
        "page": 39,
        "length_tokens": 102,
        "text": "2 encoding_model:cl100k_base 3 skip_workflows:[] 4 11m: 5 api_key:\\${GRAPHRAG_API_KEY} 6 type:openai_chat # or azure_openai_chat 7 model:gpt-4o-mini 8 model_supports_json:true# recommended if this is 9 # max_tokens:4000 10 # request timeout:180.0 11 #api_base:https://<instance>.openai.azure.com 12 #",
        "id": 256,
        "type": "text"
      },
      {
        "page": 39,
        "length_tokens": 94,
        "text": "#api_base:https://<instance>.openai.azure.com 12 #api_version:2024-02-15-preview 13 #organization:<organization_id> 14 #deployment_name:<azure_model_deployment_name> 15 #tokens_per_minute:150_oo0 # set a leaky bucket 16 #requests_per_minute:10_ooe # set a leaky bucket 17 # max_retries:10 18 #max_ret",
        "id": 257,
        "type": "text"
      },
      {
        "page": 39,
        "length_tokens": 87,
        "text": "set a leaky bucket 17 # max_retries:10 18 #max_retry_wait:10.0 19 #sleep_on_rate_limit_recommendation:true # wheth 20 #concurrent_requests: 25 # the number of parallel 21 #temperature:0 # temperature for sampling 22 #top_p:1 #top-p sampling 23 # n: 1 # Number of completions to generate ",
        "id": 258,
        "type": "text"
      },
      {
        "page": 40,
        "length_tokens": 4,
        "text": "GraphRAG ",
        "id": 259,
        "type": "text"
      },
      {
        "page": 40,
        "length_tokens": 22,
        "text": "Step5, 创建GraphRAG索引 （耗时较长，取决于文本的大小）",
        "id": 260,
        "type": "text"
      },
      {
        "page": 40,
        "length_tokens": 10,
        "text": "python -m graphrag.index --init ",
        "id": 261,
        "type": "text"
      },
      {
        "page": 40,
        "length_tokens": 5,
        "text": "create_base_text_units ",
        "id": 262,
        "type": "text"
      },
      {
        "page": 40,
        "length_tokens": 168,
        "text": "id n_tokens   \n。 801b6814471d697381794bb6956fd0c6 1200   \n12 e3dedbef878b93e8bf31d89efe569d2d 1200   \n7e6a07a57a5bce1b1c7062b23dbb74b7 1200   \n3 cf129ba1766b69b7320e56a265103fb6 1200   \n4 1f13f6ff579a1698e4f38c4d6f50c9e0 1200   \n185 5840b8ca61c8d142db5b0ef438d61084 1200   \n186 64748e530daca0dfe4ccb7",
        "id": 263,
        "type": "text"
      },
      {
        "page": 40,
        "length_tokens": 107,
        "text": "b5b0ef438d61084 1200   \n186 64748e530daca0dfe4ccb72b53653af6 1200   \n187 8f4a5f417780c51f68f784c98208af22 1200   \n188 de9746b3e28d9102b781bb4d5537be1b 1200   \n189 14ce6192f23892049905b4fb03431ac3 603 ",
        "id": 264,
        "type": "text"
      },
      {
        "page": 40,
        "length_tokens": 9,
        "text": "[763 rows x 5 columns] ",
        "id": 265,
        "type": "text"
      },
      {
        "page": 40,
        "length_tokens": 74,
        "text": "create_base_extracted_entities entity_graph   \n0 <graphml xmlns=\"http://graphml.graphdrawing.or. create_summarized_entities entity_graph   \n0 <graphml xmlns=\"http://graphml.graphdrawing.or. 5 create_base_entity_graph level clustered_graph   \n0 0 <graphml xmlns=\"http://graphml.graphdrawing.or.   \n1 1",
        "id": 266,
        "type": "text"
      },
      {
        "page": 40,
        "length_tokens": 49,
        "text": "phml xmlns=\"http://graphml.graphdrawing.or.   \n1 1 <graphml xmlns=\"http://graphml.graphdrawing.or...   \n2 2 <graphml xmlns=\"http://qraphml.qraphdrawing.or... ",
        "id": 267,
        "type": "text"
      },
      {
        "page": 40,
        "length_tokens": 67,
        "text": "D:\\AppData\\Local\\Programs\\Python\\Python3l1\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:59: Ful 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataF return bound(\\*args,\\*\\*kwds) ",
        "id": 268,
        "type": "text"
      },
      {
        "page": 40,
        "length_tokens": 4,
        "text": "create_final_entities ",
        "id": 269,
        "type": "text"
      },
      {
        "page": 40,
        "length_tokens": 2,
        "text": "id ",
        "id": 270,
        "type": "text"
      },
      {
        "page": 40,
        "length_tokens": 97,
        "text": "e06f3f6665aa42ac821ff4d01d98ceba 257cdee6da194ec6bbec93c2f9941c38 ad019054a71a430a8a41e0e3d91b2c5c ca823d5f25194f68b39ece117097d195 ac81cfd5ca844d7f8cff43ff78f1af4c ",
        "id": 271,
        "type": "text"
      },
      {
        "page": 40,
        "length_tokens": 137,
        "text": "[0.010473140515387058，0.022974025458097458  \n-0.0069566573947668076，0.010649037547409534  \n-0.013226160779595375, -0.0005299110780470073  \n-0.03153751790523529 -0.021626872941851616  \n[-0.020771170035004616，0.010091422125697136  \n234 25fffea45b424b3c9d1e581c6fd681b8  \n235 c1c178fa53f3483f8664633a085",
        "id": 272,
        "type": "text"
      },
      {
        "page": 40,
        "length_tokens": 149,
        "text": "9d1e581c6fd681b8  \n235 c1c178fa53f3483f8664633a085ffa18  \n236 85182bda61ef45cb9a38e49318730879  \n237 e0a0f05a3a4f47d5b156e375903748b9  \n238 f2cb3f0d39364f77924ceefe904f3eb1  \n[-0.05620903894305229 -0.010554901324212551  \n[-0.013504572212696075， -0.03294695168733597  \n[-0.021599022671580315, -0.06492",
        "id": 273,
        "type": "text"
      },
      {
        "page": 40,
        "length_tokens": 64,
        "text": "294695168733597  \n[-0.021599022671580315, -0.06492338329553604  \n-0.019512852653861046, -0.013822405599057674  \n[-0.014387020841240883 -0.03131725639104843",
        "id": 274,
        "type": "text"
      },
      {
        "page": 40,
        "length_tokens": 0,
        "text": "",
        "id": 275,
        "type": "text"
      },
      {
        "page": 40,
        "length_tokens": 0,
        "text": "",
        "id": 276,
        "type": "text"
      },
      {
        "page": 40,
        "length_tokens": 0,
        "text": "",
        "id": 277,
        "type": "table"
      },
      {
        "page": 40,
        "length_tokens": 15,
        "text": "[21558 rows x 15 columns] create_final_communities ",
        "id": 278,
        "type": "text"
      },
      {
        "page": 40,
        "length_tokens": 165,
        "text": "id text_unit_ids 0 13 [298a3982b5caca8d7469b70dfa25dde9,31b86a6ef947 12 [0520611682d791b2b24230b97e678086,34e26f0d3d0f， 2 16 [0155f78da1a3c002f786eb383427f425,2b6e6bb6274d. 3 1 [3b9ff1bfd4325c5ef3b1a04afe05d324,e3dedbef878b. 4 9 [2231c35ad19351487db2e3d6bbbc8c97,30da0f99935d. ",
        "id": 279,
        "type": "text"
      },
      {
        "page": 41,
        "length_tokens": 4,
        "text": "GraphRAG ",
        "id": 280,
        "type": "text"
      },
      {
        "page": 41,
        "length_tokens": 0,
        "text": "",
        "id": 281,
        "type": "table"
      },
      {
        "page": 41,
        "length_tokens": 10,
        "text": "[6776 rows × 10 columns] ",
        "id": 282,
        "type": "text"
      },
      {
        "page": 41,
        "length_tokens": 5,
        "text": "create_final_text_units ",
        "id": 283,
        "type": "text"
      },
      {
        "page": 41,
        "length_tokens": 163,
        "text": "id relationship_ids   \n0 801b6814471d697381794bb6956fd0c6 [9080aded4c9b4f44952bc3a02454eb92，19f6dcd5317...   \n1 e3dedbef878b93e8bf31d89efe569d2d [11792907413a46ad870b4ea6b64e8bd2，e50fbb6b703..   \n2 7e6a07a57a5bce1b1c7062b23dbb74b7 [fcec411d9ebf42709d61ff5f40645782，61cc1b4f6bd...   \n3 cf129ba1766b69b",
        "id": 284,
        "type": "text"
      },
      {
        "page": 41,
        "length_tokens": 169,
        "text": "61ff5f40645782，61cc1b4f6bd...   \n3 cf129ba1766b69b7320e56a265103fb6 [9a4db82ca62748c0896e732acf1c839a，b014e174e90..   \n4 1f13f6ff579a1698e4f38c4d6f50c9e0 [9e3bd9746ee445bbb4767a14c3fb559f，90893fd8103..   \n758 5840b8ca61c8d142db5b0ef438d61084 [3640377f34c3454a86546f88b50e746a，ca095dd8ae5..   \n759 647",
        "id": 285,
        "type": "text"
      },
      {
        "page": 41,
        "length_tokens": 178,
        "text": "f34c3454a86546f88b50e746a，ca095dd8ae5..   \n759 64748e530daca0dfe4ccb72b53653af6 [6f85ba6a3ec44575a62417e76673f0b2，2a28f93c5e6..   \n760 8f4a5f417780c51f68f784c98208af22 [9eea4da941e44a149f809a52a8fbf9f1，f6e3780d8f6..   \n761 de9746b3e28d9102b781bb4d5537be1b [b020dc312c9b49788c71fb7dca87a97c，939b0747da",
        "id": 286,
        "type": "text"
      },
      {
        "page": 41,
        "length_tokens": 81,
        "text": "7be1b [b020dc312c9b49788c71fb7dca87a97c，939b0747da3..   \n762 14ce6192f23892049905b4fb03431ac3 [a9af6efea0954150837cc6c7ff3be099，e5fc4e28e61. ",
        "id": 287,
        "type": "text"
      },
      {
        "page": 41,
        "length_tokens": 6,
        "text": "create_final_community_reports ",
        "id": 288,
        "type": "text"
      },
      {
        "page": 41,
        "length_tokens": 165,
        "text": "community id   \n0 671 f7a276e5-8706-4700-9950-688fc35106dc   \n1 672 11af1b98-4065-44e2-abec-71770b644424   \n2 628 02663567-b02e-4fd9-ada8-8cfc3c7954d4   \n3 629 9edcbda5-82ca-4eed-85fd-47fd879a4a26   \n4 630 53fdb3ea-1042-4125-b09c-d968b0dd2429   \n668 12 cacdeb2c-122a-45f4-b00b-8b26a365d99f   \n669 13 ",
        "id": 289,
        "type": "text"
      },
      {
        "page": 41,
        "length_tokens": 141,
        "text": "12 cacdeb2c-122a-45f4-b00b-8b26a365d99f   \n669 13 4b1b70ec-3d55-4b4c-af69-285d3a83bdd9   \n670 14 4a401a7b-c48d-49f0-89be-5321d444fb04   \n671 16 47cd804d-1c34-42b2-8694-8214873c92df   \n672 9 392f2225-07b2-4a3e-bbf2-9cbbf0b2640e ",
        "id": 290,
        "type": "text"
      },
      {
        "page": 41,
        "length_tokens": 9,
        "text": "[673 rows x 10 columns] ",
        "id": 291,
        "type": "text"
      },
      {
        "page": 41,
        "length_tokens": 43,
        "text": "datetime_column=pd.to_datetime(column,errors=\"ignore\" create_base_documents id title 203662678a5410290a61489e3a6b6e1f three_kingdoms.txt ",
        "id": 292,
        "type": "text"
      },
      {
        "page": 41,
        "length_tokens": 83,
        "text": "rows x 4 columns] create_final_documents id title D 203662678a5410290a61489e3a6b6e1f three_kingdoms.txt [1rowsx4columns] GraphRAG Indexer Loading Input（InputFileType.text)-1 filesloaded （0filtered) create_base_text_units create_base_extracted_entities create_summarized_entities create_base_entity_gr",
        "id": 293,
        "type": "text"
      },
      {
        "page": 41,
        "length_tokens": 49,
        "text": "s create_summarized_entities create_base_entity_graph create_final_entities create_final_nodes create_final_communities create_final_relationships create_final_text_units create_final_community_reports create_base_documents create_final_documents ALl workfLows completed successfully ",
        "id": 294,
        "type": "text"
      },
      {
        "page": 41,
        "length_tokens": 0,
        "text": "",
        "id": 295,
        "type": "text"
      },
      {
        "page": 41,
        "length_tokens": 11,
        "text": "community_reporting entity_extraction summarize_descriptions text_embedding ",
        "id": 296,
        "type": "text"
      },
      {
        "page": 41,
        "length_tokens": 26,
        "text": "创建GraphRAG索引后，会在./cache文件夹下面生成4个文件夹，方便后续进行提问",
        "id": 297,
        "type": "text"
      },
      {
        "page": 42,
        "length_tokens": 4,
        "text": "GraphRAG ",
        "id": 298,
        "type": "text"
      },
      {
        "page": 42,
        "length_tokens": 6,
        "text": "Step6，进行查询 ",
        "id": 299,
        "type": "text"
      },
      {
        "page": 42,
        "length_tokens": 19,
        "text": "python -m graphrag.query --root ./cases --method global \"和曹操 ",
        "id": 300,
        "type": "text"
      },
      {
        "page": 42,
        "length_tokens": 7,
        "text": "相关的人物都有哪些？\"",
        "id": 301,
        "type": "text"
      },
      {
        "page": 42,
        "length_tokens": 109,
        "text": "creating llm client with {'api_key': 'REDACTED,len=51'，'type': \"openai_chat\"， 'model' :'gpt-4o-mini'， 'max_tokens': 4000,'temperature': 0.0, 'top_p': 1.0,'n': 1, 'reques t_timeout': 180.0,'api_base': None，'api_version': None，'organization': None，'proxy : None，_'cognitive_services_endpoint': None,'de",
        "id": 302,
        "type": "text"
      },
      {
        "page": 42,
        "length_tokens": 80,
        "text": "xy : None，_'cognitive_services_endpoint': None,'deployment_name': None，'model_supports json':True,'tokens_per_minute': 0,'requests_per_minute': 0,'max_retries': 10,'ma X_retry_waiti: 10.0, 'sleep_on_rate_limit_recommendation': True, 'concurrent_requests' ： 25} ",
        "id": 303,
        "type": "text"
      },
      {
        "page": 42,
        "length_tokens": 13,
        "text": "SUCCESS: Global Search Response:##曹操相关人物概述",
        "id": 304,
        "type": "text"
      },
      {
        "page": 42,
        "length_tokens": 77,
        "text": "曹操是三国时期魏国的主要领导者，他与许多重要人物之间的关系复杂且深远。这些人物不仅在军事和政治上与曹操有着密切的联系，还在当时的权力斗争中扮演了关键角色。以下是与曹操相关的些重要人物及其关系的概述。",
        "id": 305,
        "type": "text"
      },
      {
        "page": 42,
        "length_tokens": 7,
        "text": "###重要盟友与将领",
        "id": 306,
        "type": "text"
      },
      {
        "page": 42,
        "length_tokens": 67,
        "text": "1．\\*\\*曹丕\\*\\*：曹操的儿子，继承了父亲的权力，并在其父去世后成为魏国的第一位皇帝。父子关系在魏国的建立和发展中起到了关键作用[Data：Reports（42，119)]。",
        "id": 307,
        "type": "text"
      },
      {
        "page": 42,
        "length_tokens": 57,
        "text": "2．\\*\\*夏侯惇\\*\\*：曹操的重要将领，以其忠诚和军事才能著称，参与了多次重要战役，支持曹操的军事策略[Data：Reports（212，79，336，+more)]。",
        "id": 308,
        "type": "text"
      },
      {
        "page": 42,
        "length_tokens": 55,
        "text": "3．\\*\\*张辽\\*\\*：另一位著名的将领，他在曹操的指挥下参与了多次重要战役，展示了曹操在军事指挥中的影响力 [Data:Reports（178，153)]。",
        "id": 309,
        "type": "text"
      },
      {
        "page": 42,
        "length_tokens": 54,
        "text": "4．\\*\\*荀或\\*\\*：作为曹操的军事顾问，荀或以其战略眼光和智谋著称，对曹操的决策产生了深远影响[Data:Reports (195，42)]。",
        "id": 310,
        "type": "text"
      },
      {
        "page": 42,
        "length_tokens": 46,
        "text": "5．\\*\\*关羽\\*\\*：虽然关羽以忠诚著称，但他与曹操的关系复杂，涉及尊重和内心冲突[Data：Reports (299，180)]。",
        "id": 311,
        "type": "text"
      },
      {
        "page": 42,
        "length_tokens": 5,
        "text": "### 主要对手",
        "id": 312,
        "type": "text"
      },
      {
        "page": 42,
        "length_tokens": 97,
        "text": "1．\\*\\*刘备\\*\\*：刘备是曹操的主要对手之一，二者之间的竞争和冲突在三国历史中占据了重要地位刘备的崛起对曹操的统治构成了威胁，双方之间的多次冲突和战略对抗影响了整个三国的政治格局[Data:Rep0rts(181，123，299，+more)]",
        "id": 313,
        "type": "text"
      },
      {
        "page": 42,
        "length_tokens": 73,
        "text": "2．\\*\\*孙权\\*\\*：作为东吴的领导者，孙权与曹操之间存在激烈的竞争关系，尤其是在赤壁之战等关键战役中，两者的对抗塑造了当时的政 治格局[Data：Reports（125，288，202，+more)]。",
        "id": 314,
        "type": "text"
      },
      {
        "page": 42,
        "length_tokens": 72,
        "text": "3．\\*\\*袁绍\\*\\*：袁绍是曹操的重要对手之一，二者在权力斗争中形成了明显的对抗关系。袁绍的失败在很大程度上为曹操的崛起铺平了道 路[Data：Reports（62，205)]。",
        "id": 315,
        "type": "text"
      },
      {
        "page": 42,
        "length_tokens": 57,
        "text": "4．\\*\\*董卓\\*\\*：董卓是曹操的敌对人物，曹操曾领导军队反对董卓的暴政，显示了他在当时政治斗争中的重要性[Data：Reports（377，165)]。",
        "id": 316,
        "type": "text"
      },
      {
        "page": 42,
        "length_tokens": 4,
        "text": "###其他相关人物",
        "id": 317,
        "type": "text"
      },
      {
        "page": 42,
        "length_tokens": 42,
        "text": "\\*\\*吕布\\*\\*：吕布曾与曹操结盟，但最终成为敌人，导致了激烈的权力斗争[Data：Reports（370  \n160)1",
        "id": 318,
        "type": "text"
      },
      {
        "page": 42,
        "length_tokens": 44,
        "text": "-\\*\\*诸葛亮\\*\\*：蜀汉的主要战略家，与曹操的对抗在三国历史中占据了重要地位[Data:Reports(240，53)]。",
        "id": 319,
        "type": "text"
      },
      {
        "page": 42,
        "length_tokens": 41,
        "text": "·\\*\\*华佗\\*\\*：著名的医师，曾为曹操治疗，显示了医疗专业在政治环境中的重要性[Data：Reports(51)]。",
        "id": 320,
        "type": "text"
      },
      {
        "page": 42,
        "length_tokens": 3,
        "text": "##结论",
        "id": 321,
        "type": "text"
      },
      {
        "page": 42,
        "length_tokens": 75,
        "text": "曹操的历史地位与他周围的众多人物密切相关。这些人物的关系和互动不仅影响了曹操的军事和政治生涯，也在三国时期的权力格局中发挥了重要作用。通过对这些人物的分析，我们可以更好地理解曹操在历史上的复杂角色及其影响力。",
        "id": 322,
        "type": "text"
      },
      {
        "page": 43,
        "length_tokens": 20,
        "text": "python -m graphrag.query --root ./cases --method local \"和曹操相 ",
        "id": 323,
        "type": "text"
      },
      {
        "page": 43,
        "length_tokens": 7,
        "text": "关的人物都有哪些？\"",
        "id": 324,
        "type": "text"
      },
      {
        "page": 43,
        "length_tokens": 112,
        "text": "creating llm client with {'api_key': 'REDACTED,len=51'，'type': \"openai_chat\",'model' :'gpt-4o-mini'， 'max_tokens': 4000，'temperature': 0.0， 'top_p': 1.0,'n': 1, 'reques t_timeout': 180.0，'api_base': None，'api_version': None，'organization': None，'proxy : None，'cognitive_services_endpoint': None，'depl",
        "id": 325,
        "type": "text"
      },
      {
        "page": 43,
        "length_tokens": 81,
        "text": "y : None，'cognitive_services_endpoint': None，'deployment_name': None，'model_supports json': True,'tokens_per_minute': 0，'requests_per_minute': 0，'max_retries': 10,'ma X_retry_wait': 10.0，'sleep_on_rate_limit_recommendation': True，'concurrent_requests' ：25} ",
        "id": 326,
        "type": "text"
      },
      {
        "page": 43,
        "length_tokens": 104,
        "text": "creating embedding llm client with {'api_key': 'REDACTED,len=51'，'type': \"openai_embe dding\"，'model': 'text-embedding-3-small'，'max_tokens': 4000，'temperature': 0, 'top_ p': 1,'n': 1， 'request_timeout': 180.0,'api_base': None,'api_version': None，'organ ization': None,'proxy': None，'cognitive_service",
        "id": 327,
        "type": "text"
      },
      {
        "page": 43,
        "length_tokens": 87,
        "text": "an ization': None,'proxy': None，'cognitive_services_endpoint': None，'deployment_name': None,'model_supports_json': None,'tokens_per_minute': 0,'requests_per_minute': 0, 'max_retries': 10, 'max_retry_waiti: 10.0, 'sleep_on_rate_iimit_recommendation': True, 'concurrent_requests': 25} ",
        "id": 328,
        "type": "text"
      },
      {
        "page": 43,
        "length_tokens": 13,
        "text": "SUCCESS:Local Search Response:##曹操相关人物概述",
        "id": 329,
        "type": "text"
      },
      {
        "page": 43,
        "length_tokens": 58,
        "text": "曹操是中国历史上著名的政治家和军事统帅，他的周围有许多重要人物，这些人物在他的军事和政治生涯中扮演了关键角色。以下是与曹操相关的一些主要人物及其简要介绍。",
        "id": 330,
        "type": "text"
      },
      {
        "page": 43,
        "length_tokens": 7,
        "text": "### 1．曹洪 ",
        "id": 331,
        "type": "text"
      },
      {
        "page": 43,
        "length_tokens": 83,
        "text": "曹洪是曹操的主要将领之一，以其在对抗袁绍的军事行动中表现出的战略才能而闻名。他在曹操的军队中担任重要职务，参与了多次关键战役，展现了对曹操的忠诚和支持[Data：Entities（291）Relationships (723，2223，2226，+more)]。",
        "id": 332,
        "type": "text"
      },
      {
        "page": 43,
        "length_tokens": 7,
        "text": "###2.许褚 ",
        "id": 333,
        "type": "text"
      },
      {
        "page": 43,
        "length_tokens": 89,
        "text": "许褚是曹操的另一位重要将领，以其勇敢和忠诚著称。他不仅在战斗中表现出色，还担任曹操的护卫，确保其安全。许褚在多次战役中与曹操并肩作战，展现了深厚的信任关系[Data：Entities530)；Relationships (735，2953，258，+more)]。",
        "id": 334,
        "type": "text"
      },
      {
        "page": 43,
        "length_tokens": 7,
        "text": "###3.荀或 ",
        "id": 335,
        "type": "text"
      },
      {
        "page": 43,
        "length_tokens": 69,
        "text": "荀或是曹操的重要谋士，以其卓越的智谋和战略眼光而闻名。他在曹操的军事和政治决策中提供了重要的建议，帮助曹操在复杂的局势中做出明智的选择[Data:Entities（903)；Relationships(未提供)]。",
        "id": 336,
        "type": "text"
      },
      {
        "page": 43,
        "length_tokens": 7,
        "text": "### 4．刘备 ",
        "id": 337,
        "type": "text"
      },
      {
        "page": 43,
        "length_tokens": 84,
        "text": "刘备是曹操的主要对手之一，最初与曹操有过合作，但后来因权力斗争而成为敌人。刘备的崛起与曹操的扩张形成鲜明对比， 二者之间的冲突深刻影响了三国时期的历史进程[Data：Entities（未提供）；Relationships(497，258，+more)]。",
        "id": 338,
        "type": "text"
      },
      {
        "page": 43,
        "length_tokens": 6,
        "text": "### 5．吕布",
        "id": 339,
        "type": "text"
      },
      {
        "page": 43,
        "length_tokens": 81,
        "text": "吕布是另一位与曹操有过直接冲突的著名武将。他以勇猛著称，但因其反复无常的性格而受到各方的忌惮。吕布与曹操之间的敌对关系在历史上留下了深刻的印记[Data：Entities（未提供）；Relationships (1789，+more)]。",
        "id": 340,
        "type": "text"
      },
      {
        "page": 43,
        "length_tokens": 2,
        "text": "##总结",
        "id": 341,
        "type": "text"
      },
      {
        "page": 43,
        "length_tokens": 94,
        "text": "曹操的周围有许多重要人物，他们在不同的历史阶段对曹操的军事和政治生涯产生了深远的影响。这些人物不仅包括他的将领和谋士，还包括他的对手，他们的互动和冲突共同塑造了三国时期的历史格局。这些关系的复杂性和多样性使得曹操的故事更加引人入胜，成为后世研究的重要课题。",
        "id": 342,
        "type": "text"
      },
      {
        "page": 44,
        "length_tokens": 5,
        "text": "GraphRAG查询模式",
        "id": 343,
        "type": "text"
      },
      {
        "page": 44,
        "length_tokens": 10,
        "text": "GraphRAG提供了两种查询模式：",
        "id": 344,
        "type": "text"
      },
      {
        "page": 44,
        "length_tokens": 14,
        "text": "GlobalQuery（全局查询）LocalQuery（本地查询）",
        "id": 345,
        "type": "text"
      },
      {
        "page": 44,
        "length_tokens": 7,
        "text": "GlobalQuery（全局查询）：",
        "id": 346,
        "type": "text"
      },
      {
        "page": 44,
        "length_tokens": 86,
        "text": "用于回答全局性的问题，例如“《三国演义》的主题是什么”它通过利用社区摘要，对整个语料库进行整体问题的推理，利用LLM生成的知识图谱来组织和聚合信息。  \n在具体实现上，GlobalQuery方法使用从社区层次结构指定层级中收集的报告作为上下文数据，以类似Map-Reduce的方式生成响应。",
        "id": 347,
        "type": "text"
      },
      {
        "page": 44,
        "length_tokens": 32,
        "text": "在Map步骤中，社区报告被分割成文本块，每个文本块用于生成中间响应，其中每个点都有一个数值评级。",
        "id": 348,
        "type": "text"
      },
      {
        "page": 44,
        "length_tokens": 55,
        "text": "在Reduce步骤中，从中间响应中挑选出最重要的点并进行聚合，最终形成用于生成最终响应的上下文。这种方法的直观理解是：越宏观的问题需要越宏观的视角和信息来回答。",
        "id": 349,
        "type": "text"
      },
      {
        "page": 44,
        "length_tokens": 26,
        "text": "这种查询方式是资源密集型的，但通常能够很好地回答那些需要对数据集整体有全面理解的问题。",
        "id": 350,
        "type": "text"
      },
      {
        "page": 45,
        "length_tokens": 5,
        "text": "GraphRAG查询模式",
        "id": 351,
        "type": "text"
      },
      {
        "page": 45,
        "length_tokens": 0,
        "text": "",
        "id": 352,
        "type": "image"
      },
      {
        "page": 46,
        "length_tokens": 5,
        "text": "GraphRAG查询模式",
        "id": 353,
        "type": "text"
      },
      {
        "page": 46,
        "length_tokens": 7,
        "text": "Local Query （本地查询）：",
        "id": 354,
        "type": "text"
      },
      {
        "page": 46,
        "length_tokens": 19,
        "text": "用于回答更加具体的问题，例如询问“洋甘菊有哪些治疗特性？”。",
        "id": 355,
        "type": "text"
      },
      {
        "page": 46,
        "length_tokens": 43,
        "text": "本地查询则基于更加微观的视角，结合知识图谱中的结构化数据与原始文档中的非结构化数据，来增强检索和生成过程中的上下文。",
        "id": 356,
        "type": "text"
      },
      {
        "page": 46,
        "length_tokens": 110,
        "text": "在具体实现上，系统将依据原始提问，从知识图谱中识别出一组与用户输入语义相关的实体。然后，利用这些实体作为查询条件，在知识图谱或相关数据库中进行检索，找到与这些实体直接相关的内容，包含：TextUnit、社区报告、实体、关系或协变量（如主张）。检索的结果经过过滤和重排序后，选择高质量的数据源，并将其整合进一个预定义大小的上下文窗口。",
        "id": 357,
        "type": "text"
      },
      {
        "page": 46,
        "length_tokens": 33,
        "text": "这种方法适用于需要理解输入文档中特定实体的问题，通过结合AI提取的知识图谱和原始文档的文本块生成答案。",
        "id": 358,
        "type": "text"
      },
      {
        "page": 46,
        "length_tokens": 34,
        "text": "GlobalQuery适合处理需要跨数据集汇总信息的宏观问题，而LocalQuery适合处理需要理解文档中特定实体的微观问题。",
        "id": 359,
        "type": "text"
      },
      {
        "page": 47,
        "length_tokens": 5,
        "text": "GraphRAG查询模式",
        "id": 360,
        "type": "text"
      },
      {
        "page": 47,
        "length_tokens": 0,
        "text": "",
        "id": 361,
        "type": "image"
      },
      {
        "page": 48,
        "length_tokens": 4,
        "text": "GraphRAG查询",
        "id": 362,
        "type": "text"
      },
      {
        "page": 48,
        "length_tokens": 26,
        "text": "python-m graphrag.query --root ./cases --method local \"关羽战胜 过哪些武将？\" ",
        "id": 363,
        "type": "text"
      },
      {
        "page": 48,
        "length_tokens": 16,
        "text": "SUCCESS:Local Search Response: ## 关羽的战斗成就 ",
        "id": 364,
        "type": "text"
      },
      {
        "page": 48,
        "length_tokens": 64,
        "text": "关羽，作为三国时期著名的将领，以其卓越的武艺和忠诚的精神而闻名。他在多场战斗中展现了非凡的战斗能力，战胜了多位敌将。以下是关羽战胜的一些重要武将：",
        "id": 365,
        "type": "text"
      },
      {
        "page": 48,
        "length_tokens": 5,
        "text": "###1.吕布",
        "id": 366,
        "type": "text"
      },
      {
        "page": 48,
        "length_tokens": 82,
        "text": "关羽在与吕布的战斗中表现出色，尽管吕布是当时公认的顶尖武将，但关羽凭借其高超的战斗技巧和勇气，成功击败了吕布。这场战斗不仅展示了关羽的武力，也突显了他在战场上的战略思维[Data: Relationships (363)]。",
        "id": 367,
        "type": "text"
      },
      {
        "page": 48,
        "length_tokens": 6,
        "text": "### 2.颜良",
        "id": 368,
        "type": "text"
      },
      {
        "page": 48,
        "length_tokens": 66,
        "text": "在著名的白马之战中，关羽面对敌将颜良，展现了他的英勇和战斗技巧。关羽在这场战斗中成功击败了颜良，进一步巩固了他在蜀汉的声望[Data：Entities（1022)]。",
        "id": 369,
        "type": "text"
      },
      {
        "page": 48,
        "length_tokens": 7,
        "text": "###3.阮籍 ",
        "id": 370,
        "type": "text"
      },
      {
        "page": 48,
        "length_tokens": 43,
        "text": "关羽在与阮籍的交战中也取得了胜利，显示了他在战斗中的灵活应变能力和战术运用[Data：Relationships (2036)]。",
        "id": 371,
        "type": "text"
      },
      {
        "page": 48,
        "length_tokens": 7,
        "text": "###4.黄承儿 ",
        "id": 372,
        "type": "text"
      },
      {
        "page": 48,
        "length_tokens": 40,
        "text": "在与黄承儿的战斗中，关羽同样表现出色，成功将其击败，进一步证明了他的战斗实力[Data：Relationships (2036)]。",
        "id": 373,
        "type": "text"
      },
      {
        "page": 48,
        "length_tokens": 6,
        "text": "###5.其他敌将",
        "id": 374,
        "type": "text"
      },
      {
        "page": 48,
        "length_tokens": 43,
        "text": "关羽在多次战斗中还战胜了其他敌将，如管亥等，展现了他在战场上的统治力和影响力[Data：Entities (32)]。",
        "id": 375,
        "type": "text"
      },
      {
        "page": 48,
        "length_tokens": 2,
        "text": "##总结",
        "id": 376,
        "type": "text"
      },
      {
        "page": 48,
        "length_tokens": 84,
        "text": "关羽的战斗成就不仅体现在他战胜的敌将上，更在于他在三国历史中的重要地位和影响力。他的忠诚、勇气和战斗技巧使他成为了三国时期最受尊敬的将领之一。关羽的传奇故事至今仍在中国文化中广为流传，成为了忠义的象征。",
        "id": 377,
        "type": "text"
      },
      {
        "page": 48,
        "length_tokens": 27,
        "text": "python -m graphrag.query --root ./cases --method global \"关羽战 胜过哪些武将？\" ",
        "id": 378,
        "type": "text"
      },
      {
        "page": 48,
        "length_tokens": 14,
        "text": "SUCCESS: Global Search Response: ##关羽的战胜记录 ",
        "id": 379,
        "type": "text"
      },
      {
        "page": 48,
        "length_tokens": 78,
        "text": "关羽，亦称为关云长，是三国时期著名的将领，以其卓越的武艺和战斗能力而闻名。他在与多位敌将的交战中取得了显著的胜利，这些胜利不仅巩固了他在蜀汉的地位，也为他赢得了传奇般的声誉",
        "id": 380,
        "type": "text"
      },
      {
        "page": 48,
        "length_tokens": 8,
        "text": "### 主要战胜的敌将",
        "id": 381,
        "type": "text"
      },
      {
        "page": 48,
        "length_tokens": 69,
        "text": "1．\\*\\*吕布\\*\\*：关羽在与吕布的战斗中取得了显著的胜利，吕布被视为当时最强的武将之一。这场胜利展示了关羽的武力和战略能力[Data：Reports（299，141，+more)]。",
        "id": 382,
        "type": "text"
      },
      {
        "page": 48,
        "length_tokens": 83,
        "text": "2.\\*\\*曹操的将领\\*\\*：关羽曾战胜曹操的多位将领，包括曹仁、颜良和文丑等。这些胜利不仅展示了他的个人实力，也在三国时期的权力斗争中产生了深远的影响[Data：Reports（132，154，277342，394，+m0re)]。",
        "id": 383,
        "type": "text"
      },
      {
        "page": 48,
        "length_tokens": 47,
        "text": "3．\\*\\*黄忠\\*\\*：关羽在与黄忠的交战中也表现出色，进一步巩固了他的声誉[Data:Reports（298，181，+more)]。",
        "id": 384,
        "type": "text"
      },
      {
        "page": 48,
        "length_tokens": 51,
        "text": "4．\\*\\*张辽\\*\\*：关羽在与张辽的战斗中取得了胜利，展示了他在战斗中的卓越才能[Data：Reports(323，255，+m0re)]。",
        "id": 385,
        "type": "text"
      },
      {
        "page": 48,
        "length_tokens": 70,
        "text": "5．\\*\\*周瑜\\*\\*：虽然与周瑜的对抗中未能完全战胜，但关羽在多次交锋中展现了强大的战斗力，给敌方造成了显著的压力[Data：Reports（79，212，249，400，+more)]。",
        "id": 386,
        "type": "text"
      },
      {
        "page": 48,
        "length_tokens": 6,
        "text": "### 战斗的影响 ",
        "id": 387,
        "type": "text"
      },
      {
        "page": 48,
        "length_tokens": 90,
        "text": "关羽的胜利不仅提升了他的个人声望，也为蜀汉的军事战略做出了重要贡献。他在战斗中展现出的勇气和智慧，使他成为三国历史上不可或缺的军事领导者。这些战斗的胜利为他赢得了“武圣”的称号，成为后世崇拜的对象[Data：Reports（323，255，+more)]。",
        "id": 388,
        "type": "text"
      },
      {
        "page": 48,
        "length_tokens": 53,
        "text": "总的来说，关羽在三国时期的战斗中战胜了多位著名武将，这些胜利不仅巩固了他在蜀汉的地位也为他在中国历史上留下了深远的影响",
        "id": 389,
        "type": "text"
      },
      {
        "page": 49,
        "length_tokens": 4,
        "text": "GraphRAG查询",
        "id": 390,
        "type": "text"
      },
      {
        "page": 49,
        "length_tokens": 0,
        "text": "",
        "id": 391,
        "type": "table"
      },
      {
        "page": 50,
        "length_tokens": 4,
        "text": "GraphRAG查询",
        "id": 392,
        "type": "text"
      },
      {
        "page": 50,
        "length_tokens": 0,
        "text": "",
        "id": 393,
        "type": "table"
      },
      {
        "page": 50,
        "length_tokens": 69,
        "text": ".ocal答案生成：针对具体问题，GraphRAG通过结合元素和元素摘要生成初步答案，这些答案来源于GraphRAG中的特定社区，Global答案生成：对于需要涵盖整个数据集的全局性问题，GraphRAG采用Map-Reduce机制，将所有社区的初步答案组合起来",
        "id": 394,
        "type": "text"
      },
      {
        "page": 51,
        "length_tokens": 9,
        "text": "搭建RAG--使用Qwen-Agent",
        "id": 395,
        "type": "text"
      },
      {
        "page": 52,
        "length_tokens": 10,
        "text": "搭建RAG (Qwen-Agent) ",
        "id": 396,
        "type": "text"
      },
      {
        "page": 52,
        "length_tokens": 7,
        "text": "Qwen-Agent开发框架：",
        "id": 397,
        "type": "text"
      },
      {
        "page": 52,
        "length_tokens": 28,
        "text": "·是一个Agent开发框架。充分利用QwenModel的指令遵循、工具使用、规划、记忆能力。",
        "id": 398,
        "type": "text"
      },
      {
        "page": 52,
        "length_tokens": 8,
        "text": "Qwen-Agent支持的模型形式：",
        "id": 399,
        "type": "text"
      },
      {
        "page": 52,
        "length_tokens": 27,
        "text": "·DashScope服务提供的Qwen模型服务·支持通过OpenAIAPI方式接入开源的Qwen模型服务。",
        "id": 400,
        "type": "text"
      },
      {
        "page": 52,
        "length_tokens": 40,
        "text": "Thinking: 现在能够原生处理数百万字输入的LLM成为了一种趋势，如何让一个上下文长度为8K的模型，能处理1M的上下文？",
        "id": 401,
        "type": "text"
      },
      {
        "page": 52,
        "length_tokens": 7,
        "text": "我们采取以下方法准备数据：",
        "id": 402,
        "type": "text"
      },
      {
        "page": 52,
        "length_tokens": 29,
        "text": "利用一个较弱的8k上下文聊天模型构建一个相对强大的智能体，能够处理1M的上下文。",
        "id": 403,
        "type": "text"
      },
      {
        "page": 52,
        "length_tokens": 20,
        "text": "随后，使用该智能体合成微调数据，并应用自动化过滤确保数据质量。",
        "id": 404,
        "type": "text"
      },
      {
        "page": 52,
        "length_tokens": 25,
        "text": "最终，使用合成数据对预训练模型进行微调，得到一个强大的1M上下文聊天模型，",
        "id": 405,
        "type": "text"
      },
      {
        "page": 53,
        "length_tokens": 10,
        "text": "搭建RAG (Qwen-Agent) ",
        "id": 406,
        "type": "text"
      },
      {
        "page": 53,
        "length_tokens": 27,
        "text": "Qwen-Agent构建的智能体包含三个复杂度级别，每一层都建立在前一层的基础上：",
        "id": 407,
        "type": "text"
      },
      {
        "page": 53,
        "length_tokens": 8,
        "text": "·级别一：检索 ",
        "id": 408,
        "type": "text"
      },
      {
        "page": 53,
        "length_tokens": 80,
        "text": "处理100万字上下文的一种朴素方法是采用RAG。RAG将上下文分割成较短的块，每块不超过512个字，然后仅保留最相关的块在8k字的上下文中。挑战在于如何精准定位最相关的块。经过多次尝试，我们提出了一种基于关键词的解决方案：",
        "id": 409,
        "type": "text"
      },
      {
        "page": 53,
        "length_tokens": 0,
        "text": "",
        "id": 410,
        "type": "image"
      },
      {
        "page": 54,
        "length_tokens": 10,
        "text": "搭建RAG (Qwen-Agent) ",
        "id": 411,
        "type": "text"
      },
      {
        "page": 54,
        "length_tokens": 54,
        "text": "步骤1: 指导聊天模型将用户查询中的指令与非指令信息分开例如，将用户查询\"回答时请用2000字详尽阐述，我的问题是，自行车是什么时候发明的？请用英文回复。“",
        "id": 412,
        "type": "text"
      },
      {
        "page": 54,
        "length_tokens": 0,
        "text": "",
        "id": 413,
        "type": "text"
      },
      {
        "page": 54,
        "length_tokens": 37,
        "text": "转化为{\"信息\":[\"自行车是什么时候发明的\"],\"指令\":[\"回答时 用2000字\",\"尽量详尽\",\"用英文回复\"]}。 ",
        "id": 414,
        "type": "text"
      },
      {
        "page": 54,
        "length_tokens": 65,
        "text": "步骤2：要求聊天模型从查询的信息部分推导出多语言关键词。 例如，短语\"自行车是什么时候发明的\"会转换为{\"关键词_英文 \":[\"bicycles\",\"invented\",\"when\"],\"关键词_中文\":[\"自行车\",\"发 明\",\"时间\"]}。 ",
        "id": 415,
        "type": "text"
      },
      {
        "page": 54,
        "length_tokens": 29,
        "text": "步骤3：运用BM25这一传统的基于关键词的检索方法，找出与提取关键词最相关的块。",
        "id": 416,
        "type": "text"
      },
      {
        "page": 54,
        "length_tokens": 0,
        "text": "",
        "id": 417,
        "type": "image"
      },
      {
        "page": 55,
        "length_tokens": 10,
        "text": "搭建RAG (Qwen-Agent) ",
        "id": 418,
        "type": "text"
      },
      {
        "page": 55,
        "length_tokens": 8,
        "text": "级别二：分块阅读 ",
        "id": 419,
        "type": "text"
      },
      {
        "page": 55,
        "length_tokens": 40,
        "text": "直接RAG检索很快，但常在相关块与用户查询关键词重叠程度不足时失效 $\\Rightarrow$ 导致这些相关的块未被检索到。",
        "id": 420,
        "type": "text"
      },
      {
        "page": 55,
        "length_tokens": 32,
        "text": "尽管理论上向量检索可以缓解这一问题，但实际上效果有限。为了解决这个局限，我们采用了一种暴力策略：",
        "id": 421,
        "type": "text"
      },
      {
        "page": 55,
        "length_tokens": 51,
        "text": "步骤1：对于每个512字块，让聊天模型评估其与用户查询的相关性，如果认为不相关则输出\"无\",如果相关则输出相关句子。这些块会被并行处理以避免长时间等待。",
        "id": 422,
        "type": "text"
      },
      {
        "page": 55,
        "length_tokens": 50,
        "text": "步骤2：取那些非\"无\"的输出（即相关句子），用它们作为搜索查询词，通过BM25检索出最相关的块（总的检索结果长度控制在8k上下文限制内）。",
        "id": 423,
        "type": "text"
      },
      {
        "page": 55,
        "length_tokens": 30,
        "text": "步骤3：最后，基于检索到的上下文生成最终答案，这一步骤的实现方式与通常的RAG相同。",
        "id": 424,
        "type": "text"
      },
      {
        "page": 55,
        "length_tokens": 0,
        "text": "",
        "id": 425,
        "type": "image"
      },
      {
        "page": 56,
        "length_tokens": 10,
        "text": "搭建RAG (Qwen-Agent) ",
        "id": 426,
        "type": "text"
      },
      {
        "page": 56,
        "length_tokens": 8,
        "text": "级别三：逐步推理",
        "id": 427,
        "type": "text"
      },
      {
        "page": 56,
        "length_tokens": 189,
        "text": "在基于文档的问题回答中，一个典型的挑战是多跳推理。  \n例如，考虑回答问题：“与第五交响曲创作于同一世纪的交通工具是什么？”  \n模型首先需要确定子问题的答案，“第五交响曲是在哪个世纪创作的？”即19世纪。然后，它才可以意识到包含“自行车于19世纪发明”的信息块实际上与原始问题相关的。  \nFunctionCall智能体或ReAct智能体是经典的解决方案，它们内置了问题分解和逐步推理的能力。因此，我们将前述级别二的智能体（Lv2-智能体）封装为一个工具，由工具调用智能体（Lv3-智能体）调用。  \n工具调用智能体进行多跳推理的流程如下：  \n向Lv3-智能体提出一个问题  \nwhile (Lv",
        "id": 428,
        "type": "text"
      },
      {
        "page": 56,
        "length_tokens": 107,
        "text": " \n工具调用智能体进行多跳推理的流程如下：  \n向Lv3-智能体提出一个问题  \nwhile (Lv3-智能体无法根据其记忆回答问题){Lv3-智能体提出一个新的子问题待解答。Lv3-智能体向Lv2-智能体提问这个子问题。将Lv2-智能体的回应添加到Lv3-智能体的记忆中，  \n（  \nLv3-智能体提供原始问题的最终答案。",
        "id": 429,
        "type": "text"
      },
      {
        "page": 56,
        "length_tokens": 0,
        "text": "",
        "id": 430,
        "type": "text"
      },
      {
        "page": 57,
        "length_tokens": 10,
        "text": "搭建RAG (Qwen-Agent) ",
        "id": 431,
        "type": "text"
      },
      {
        "page": 57,
        "length_tokens": 103,
        "text": "例如，Lv3-智能体最初向Lv2-智能体提出子问题：“贝多芬的第五交响曲是在哪个世纪创作的？”收到“19世纪”的回复后，Lv3-智能体提出新的子问题：“19世纪期间发明了什么交通工具？”通过整合Lv2-智能体的所有反馈，Lv3-智能体便能够回答原始问题：“与第五交响曲创作于同一世纪的交通工具是什么？”",
        "id": 432,
        "type": "text"
      },
      {
        "page": 57,
        "length_tokens": 73,
        "text": "Ask the 1st sub-question \"In which century was the Fifth Symphony composed\" Long Docs of Ask the 2nd sub-question \"What vehicle was invented during the 19th century?\" 1M tokens User Query: \"What vehicle was invented in Level-3 Agent Level-2 Agent the same century as the Fifth (Multi-Hop Reasoning) (",
        "id": 433,
        "type": "text"
      },
      {
        "page": 57,
        "length_tokens": 74,
        "text": " same century as the Fifth (Multi-Hop Reasoning) (Read All Chunks Parallelly) Symphony was composed?\" Answer the 1st sub-question:“The 19th century.\" Final Response: \"Bicycles were invented Give the final response Answer the 2nd sub-question: \"Bicycles.\" in the same century.\" once allsub-questions a",
        "id": 434,
        "type": "text"
      },
      {
        "page": 57,
        "length_tokens": 16,
        "text": "es.\" in the same century.\" once allsub-questions are answered. ",
        "id": 435,
        "type": "text"
      },
      {
        "page": 58,
        "length_tokens": 5,
        "text": "RAG评测结果",
        "id": 436,
        "type": "text"
      },
      {
        "page": 58,
        "length_tokens": 47,
        "text": "NeedleBench是测试模型是否能够在充满大量不相关信息的上下文中识别出最相关句子的基准测试。回答问题可能需要同时发现几个“针”并执行多跳推理。",
        "id": 437,
        "type": "text"
      },
      {
        "page": 58,
        "length_tokens": 17,
        "text": "LV-Eval是一个要求一次性理解多块证据的基准测试",
        "id": 438,
        "type": "text"
      },
      {
        "page": 58,
        "length_tokens": 44,
        "text": "·32k-Model：一个Qwen-7B聊天模型，主要在8k上下文样本上进行微调，有一些32k上下文样本，可以扩展到256k上下文。",
        "id": 439,
        "type": "text"
      },
      {
        "page": 58,
        "length_tokens": 40,
        "text": "·4k-RAG：使用与32k模型相同的模型，但应用了Lv1代理的RAG策略。它只检索和处理最相关的4k上下文。",
        "id": 440,
        "type": "text"
      },
      {
        "page": 58,
        "length_tokens": 0,
        "text": "",
        "id": 441,
        "type": "table"
      },
      {
        "page": 58,
        "length_tokens": 35,
        "text": "·4k-Agent：使用与32k模型相同的模型，遵循上述更高级的代理策略。Agent策略每次只使用4k上下文。",
        "id": 442,
        "type": "text"
      },
      {
        "page": 59,
        "length_tokens": 5,
        "text": "RAG评测结果",
        "id": 443,
        "type": "text"
      },
      {
        "page": 59,
        "length_tokens": 0,
        "text": "",
        "id": 444,
        "type": "image"
      },
      {
        "page": 60,
        "length_tokens": 4,
        "text": "Qwen-Agent使用",
        "id": 445,
        "type": "text"
      },
      {
        "page": 60,
        "length_tokens": 84,
        "text": "import pprint   \nimport urllib.parse   \nimport json5   \nfrom qwen_agent.agents import Assistant   \nfrom qwen_agent.tools.base import BaseTool, register_tool   \n#添加一个名为\\`my_image_gen\\`的自定义工具。   \n$@$ register_tool('my_image_gen')   \nclass MylmageGen(BaseTool): #description\\`用于告诉智能体该工具的功能。 description ",
        "id": 446,
        "type": "text"
      },
      {
        "page": 60,
        "length_tokens": 115,
        "text": "seTool): #description\\`用于告诉智能体该工具的功能。 description $= ^ { \\prime } \\mathsf { A l }$ 绘画（图像生成）服务，输入文本描述，返回基于文   \n本信息绘制的图像URL。' #parameters\\`告诉智能体该工具有哪些输入参数。 parameters ${ \\bf \\Xi } = [ \\{$ 'name': 'prompt', 'type': 'string', 'description':'期望的图像内容的详细描述', 'required': True ",
        "id": 447,
        "type": "text"
      },
      {
        "page": 60,
        "length_tokens": 96,
        "text": "def call(self, params: str, \\*\\*kwargs) $\\ J \\to$ str: # params'是由LLM 智能体生成的参数。 prompt $\\mathbf { \\tau } = \\mathbf { \\tau }$ json5.loads(params)['prompt'] prompt $\\mathbf { \\tau } = \\mathbf { \\tau }$ urllib.parse.quote(prompt) return json5.dumps( {'image_url': f'https://image.pollinations.ai/prompt/",
        "id": 448,
        "type": "text"
      },
      {
        "page": 60,
        "length_tokens": 73,
        "text": "mage_url': f'https://image.pollinations.ai/prompt/{prompt}'}, ensure_ascii=False) #步骤2：配置LLM。 Ilm_cfg = { 'model': 'qwen-max', 'model_server':'dashscope', 'api_key': 'sk-XX', generate_cfg': { 'top_p': 0.8 } 1 ",
        "id": 449,
        "type": "text"
      },
      {
        "page": 61,
        "length_tokens": 4,
        "text": "Qwen-Agent使用",
        "id": 450,
        "type": "text"
      },
      {
        "page": 61,
        "length_tokens": 152,
        "text": "#步骤3：创建一个智能体。这里我们以\\`Assistant'智能体为例，它能够使用工具并读取文件。  \nsystem_instruction $\\mathbf { \\sigma } = \\mathbf { \\sigma }$ \"你是一个乐于助人的AI助手。  \n在收到用户的请求后，你应该：  \n-首先绘制一幅图像，得到图像的url,  \n-然后运行代码\\`request.get\\`以下载该图像的url,  \n-最后从给定的文档中选择一个图像操作进行图像处理。  \n用‘plt.show()\\`展示图像。  \n你总是用中文回复用户。\"  \ntools $\\mathbf { \\tau } = \\ma",
        "id": 451,
        "type": "text"
      },
      {
        "page": 61,
        "length_tokens": 106,
        "text": "图像。  \n你总是用中文回复用户。\"  \ntools $\\mathbf { \\tau } = \\mathbf { \\tau }$ ['my_image_gen','code_interpreter'] #\\`code_interpreter' 是框架自带的工具，用于执行代码。  \n#files $\\mathbf { \\tau } = \\mathbf { \\tau }$ ['./examples/resource/doc.pdf'] #给智能体一个 PDF 文件阅读。files $\\mathbf { \\tau } = \\mathbf { \\tau }$ ['./examples/resource",
        "id": 452,
        "type": "text"
      },
      {
        "page": 61,
        "length_tokens": 92,
        "text": "{ \\tau } = \\mathbf { \\tau }$ ['./examples/resource/平安钟爱一生养老年金保险（分红型）.pdf']#给智能体一个 PDF 文件阅读。  \nbot $\\mathbf { \\tau } = \\mathbf { \\tau }$ Assistant(llm=lm_cfg,  \nsystem_message $\\mathbf { \\tau } =$ system_instruction,  \nfunction_list $\\ c =$ tools,  \nfiles=files)",
        "id": 453,
        "type": "text"
      },
      {
        "page": 61,
        "length_tokens": 37,
        "text": "#步骤4：作为聊天机器人运行智能体。$\\mathsf { m e s s a g e s = [ l }$ #这里储存聊天历史while True:",
        "id": 454,
        "type": "text"
      },
      {
        "page": 61,
        "length_tokens": 110,
        "text": "# 例如，输入请求\"绘制一只狗并将其旋转90 度\"  \nquery $\\mathbf { \\tau } = \\mathbf { \\tau }$ input('用户请求：\")  \n#将用户请求添加到聊天历史，  \nmessages.append({'role': 'user','content': query})  \nresponse $\\mathbf { \\varepsilon } = [ ] \\mathbf { \\varepsilon }$   \nfor response in bot.run(messages $\\ c =$ messages):#流式输出。print('机器人回应:\")p",
        "id": 455,
        "type": "text"
      },
      {
        "page": 61,
        "length_tokens": 31,
        "text": "(messages $\\ c =$ messages):#流式输出。print('机器人回应:\")pprint.pprint(response, indent $: = 2$ ）",
        "id": 456,
        "type": "text"
      },
      {
        "page": 61,
        "length_tokens": 14,
        "text": "#将机器人的回应添加到聊天历史。messages.extend(response)",
        "id": 457,
        "type": "text"
      },
      {
        "page": 62,
        "length_tokens": 10,
        "text": "用户请求：养老年金保险的特点是什么",
        "id": 458,
        "type": "text"
      },
      {
        "page": 62,
        "length_tokens": 213,
        "text": "[{‘content'：‘平安钟爱一生养老年金保险（分红型）具有以下特点：\\n'\"\\n''1．\\*\\*领至一百岁\\*\\*：退休后的生活保障，养老保险金可以领取到100岁的保单周年日。\\n''2．\\*\\*三年一增长\\*\\*：养老保险金每三年递增一次，意味着养老金水平会逐步提高。\\n''3．\\*\\*活到八十八，额外贺金庆高寿\\*\\*：如果被保险人生存至88岁的保单周年日，将额外获得一笔10万元的  \n祝寿金。\\n''4.'‘\\*\\*领取有保证\\*\\*：在开始领取养老保险金后的20年内，即使被保险人不幸身故，也会确保至少可领取20年的  \n养老保险金总额。\\n''5．\\*\\*保单可分红\\*\\*：该保",
        "id": 459,
        "type": "text"
      },
      {
        "page": 62,
        "length_tokens": 136,
        "text": "幸身故，也会确保至少可领取20年的  \n养老保险金总额。\\n''5．\\*\\*保单可分红\\*\\*：该保险产品是分红型的，意味着投保人有机会分享保险公司的经营成果，但需注意红  \n利分配是不确定的。\\n'\"\\n''这些特点旨在为投保人提供长期、稳定的养老收入来源，并且通过分红机制可能增加额外收益。不过，重要  \n的是要理解红利并非保证，实际分红情况将根据保险公司当年的实际经营状况而定。‘，'role':'assistant'}1",
        "id": 460,
        "type": "text"
      },
      {
        "page": 63,
        "length_tokens": 4,
        "text": "Qwen-Agent使用",
        "id": 461,
        "type": "text"
      },
      {
        "page": 63,
        "length_tokens": 12,
        "text": "用户请求：帮我写一个二分查找法",
        "id": 462,
        "type": "text"
      },
      {
        "page": 63,
        "length_tokens": 93,
        "text": "[{‘content'：‘二分查找法是一种在有序数组中查找特定元素的搜索算法。它的基本思想是将目标值与数组中间的元素进行比较，如果目标值等于中间元素，则查找结束；如果目标值小于或大于中间元素，则在数组的前半部分或后半部分继续查找，直到找到目标值或者搜索范围为空。\\n'",
        "id": 463,
        "type": "text"
      },
      {
        "page": 63,
        "length_tokens": 66,
        "text": "\"\\n''下面我将为您编写一个 Python‘'函数来实现二分查找法。这个函数会接收两个参数：一个是已经排序好的列表（数组），另一个是要查找的目标值。函数返回目标值在列表中的索引位置，如果未找到则返回‘",
        "id": 464,
        "type": "text"
      },
      {
        "page": 63,
        "length_tokens": 109,
        "text": "'-1。''role':'assistant'},{'content':''function_call': { 'arguments': py\\n''def binary_search(arr，target):\\n'left，right $= \\ 8$ ，len(arr) - 1\\n'■ $\\backslash \\boldsymbol { \\mathsf { n } } ^ { \\prime }$ （1 while left $< =$ right:\\n'■ mid $\\mathbf { \\sigma } = \\mathbf { \\sigma }$ (left $^ +$ right) $1 ",
        "id": 465,
        "type": "text"
      },
      {
        "page": 63,
        "length_tokens": 124,
        "text": "gma } = \\mathbf { \\sigma }$ (left $^ +$ right) $1 1 2 \\backslash { \\mathfrak { n } }$ 1if arr[mid] $\\scriptstyle = =$ target:\\n'1 return mid # 找到目标值，返回索引\\n'elif arr[mid] $\\angle \\cdot \\angle$ target:\\n'left $\\mathbf { \\Sigma } = \\mathbf { \\Sigma }$ mid $^ \\textrm { \\scriptsize + 1 }$ # 在右半部分查找\\n'els",
        "id": 466,
        "type": "text"
      },
      {
        "page": 63,
        "length_tokens": 140,
        "text": "id $^ \\textrm { \\scriptsize + 1 }$ # 在右半部分查找\\n'else:\\n'right $\\mathbf { \\sigma } = \\mathbf { \\sigma }$ mid -1 # 在左半部分查找\\n'1 \\n'1 return $^ { - 1 }$ # 未找到目标值\\n''\\n''# 示例使用\\n''sorted_list $\\mathbf { \\sigma } = \\mathbf { \\sigma }$ [1，3，5,7,9,11，13，15，'17，19]\\n''target_value $= 7 \\backslash { \\mathsf { ",
        "id": 467,
        "type": "text"
      },
      {
        "page": 63,
        "length_tokens": 71,
        "text": "7，19]\\n''target_value $= 7 \\backslash { \\mathsf { n } }$ ='index $\\mathbf { \\tau } = \\mathbf { \\tau }$ binary_search(sorted_list,'target_value)\\n''print(f\"目标值{target_value} 的索引是：‘'{index}\")\\n'",
        "id": 468,
        "type": "text"
      },
      {
        "page": 63,
        "length_tokens": 43,
        "text": "{'content':'二分查找法已经实现，并且我们用一个示例来测试了这个函数。对于排序好的列表‘[1,3,5,7,9,11,13,'",
        "id": 469,
        "type": "text"
      },
      {
        "page": 63,
        "length_tokens": 27,
        "text": "'15,17,19]\\`，目标值7'在列表中的索引是\\`3\\`。\\n'",
        "id": 470,
        "type": "text"
      },
      {
        "page": 63,
        "length_tokens": 3,
        "text": "\\n' ",
        "id": 471,
        "type": "text"
      },
      {
        "page": 63,
        "length_tokens": 25,
        "text": "如果您有特定的列表或目标值想要测试，请告诉我，我可以为您运行该算法。‘",
        "id": 472,
        "type": "text"
      },
      {
        "page": 63,
        "length_tokens": 8,
        "text": "'role': 'assistant'}] ",
        "id": 473,
        "type": "text"
      },
      {
        "page": 64,
        "length_tokens": 4,
        "text": "Qwen-Agent使用",
        "id": 474,
        "type": "text"
      },
      {
        "page": 64,
        "length_tokens": 20,
        "text": "用户请求：[1,2,3,4,5,6]中查找5 ",
        "id": 475,
        "type": "text"
      },
      {
        "page": 64,
        "length_tokens": 103,
        "text": "{'content':''function_call': { 'arguments':' \\` py\\n''# 使用之前定义的binary_search函数来查找5\\n''sorted_list $\\mathbf { \\sigma } = \\mathbf { \\sigma }$ [1,2,3,4,5,6]\\n''target_value $\\mathbf { \\sigma } = \\mathbf { \\sigma }$ 5\\n''index $\\mathbf { \\sigma } = \\mathbf { \\sigma }$ binary_search(sorted_list，''target_",
        "id": 476,
        "type": "text"
      },
      {
        "page": 64,
        "length_tokens": 131,
        "text": "bf { \\sigma }$ binary_search(sorted_list，''target_value)\\n''print(f\"目标值{target_value} 的索引是：''{index}\")\\n''name': 'code_interpreter'},'role':'assistant'},  \n{'content'：'stdout:\\n\\n\\`\\`\\n目标值 5 的索引是：4\\n\\n\\`'name':'code_interpreter''role': 'function'},  \n{‘content'：‘在排序列表‘[1，2，3，4，5，6]’中，目标值‘5’的索引是‘4\\`。",
        "id": 477,
        "type": "text"
      },
      {
        "page": 64,
        "length_tokens": 99,
        "text": "\n{‘content'：‘在排序列表‘[1，2，3，4，5，6]’中，目标值‘5’的索引是‘4\\`。这意味着‘5’位于列表中的第‘'5 个位置（因为索引是从 开始计数的）。\\n'\"\\n''如果您还有其他数值需要查找或有其他问题，请告诉我！‘,'role': 'assistant'}]",
        "id": 478,
        "type": "text"
      },
      {
        "page": 65,
        "length_tokens": 10,
        "text": "Qwen-Agent使用 (多文件提问)",
        "id": 479,
        "type": "text"
      },
      {
        "page": 65,
        "length_tokens": 108,
        "text": "import os  \n# 获取文件夹下所有文件  \nfile_dir $\\mathbf { \\tau } = \\mathbf { \\tau }$ os.path.join('./','平安团体险')  \n$\\mathsf { f i l e s } = \\left[ \\mathsf { l } \\right]$   \nif os.path.exists(file_dir):#遍历目录下的所有文件for file in os.listdir(file_dir):file_path $\\mathbf { \\tau } = \\mathbf { \\tau }$ os.path.join(file_d",
        "id": 480,
        "type": "text"
      },
      {
        "page": 65,
        "length_tokens": 65,
        "text": "f { \\tau } = \\mathbf { \\tau }$ os.path.join(file_dir, file)if os.path.isfile(file_path):#确保是文件而不是目录files.append(file_path)  \nprint('files $\\mathbf { \\partial } = \\mathbf { \\vec { \\tau } }$ , files)",
        "id": 481,
        "type": "text"
      },
      {
        "page": 65,
        "length_tokens": 213,
        "text": "files=['./平安团体险\\\\1-平安商业综合责任保险（亚马逊）.txt',/平安团体险\\\\2-雇主责任险.txt',./平安团体险\\3-平安企业团体综合意外险.txt','./平安团体险\\\\4-雇主安心保.txt','./平安团体险\\\\5-施工保.txt','./平安团体险\\\\6-财产一切险.txt','./平安团体险\\/\\7-平安装修保.txt','./平安团体险/平安产险交通出行意外伤害保险（互联网版）产品说明.pdf,'./平安团体险\\平安产险交通工具意外伤害保险（互联网版）条款.pdf，'./平安团体险\\平安企业团体综合意外险(互联网版)适用条款.pdf，'./平安团体险/平安商",
        "id": 482,
        "type": "text"
      },
      {
        "page": 65,
        "length_tokens": 91,
        "text": "df，'./平安团体险\\平安企业团体综合意外险(互联网版)适用条款.pdf，'./平安团体险/平安商业综合责任保险（亚马逊）.pdf,'/平安团体险\\平安境内紧急医疗救援服务条款.pdf,'./平安团体险\\/平安附加疾病身故保险条款.pdf]",
        "id": 483,
        "type": "text"
      },
      {
        "page": 66,
        "length_tokens": 10,
        "text": "Qwen-Agent使用 (多文件提问)",
        "id": 484,
        "type": "text"
      },
      {
        "page": 66,
        "length_tokens": 8,
        "text": "介绍下雇主责任险 ",
        "id": 485,
        "type": "text"
      },
      {
        "page": 66,
        "length_tokens": 43,
        "text": "雇主责任险是一种为企业提供保障的保险产品，主要针对企业在雇佣员工过程中可能面临的法律责任风险。以下是雇主责任险的详细介绍：",
        "id": 486,
        "type": "text"
      },
      {
        "page": 66,
        "length_tokens": 11,
        "text": "###1.\\*\\*保障范围\\*\\* ",
        "id": 487,
        "type": "text"
      },
      {
        "page": 66,
        "length_tokens": 10,
        "text": "雇主责任险的保障范围包括：",
        "id": 488,
        "type": "text"
      },
      {
        "page": 66,
        "length_tokens": 31,
        "text": "-\\*\\*死亡赔偿金\\*\\*：员工因工作原因导致死亡，保险公司将赔付相应的死亡赔偿金。",
        "id": 489,
        "type": "text"
      },
      {
        "page": 66,
        "length_tokens": 36,
        "text": "-\\*\\*伤残赔偿金\\*\\*：员工因工作原因导致伤残，保险公司将根据伤残等级赔付相应的赔偿金。",
        "id": 490,
        "type": "text"
      },
      {
        "page": 66,
        "length_tokens": 30,
        "text": "-\\*\\*医疗费用\\*\\*：员工因工作原因受伤或患病，保险公司将赔付相应的医疗费用。",
        "id": 491,
        "type": "text"
      },
      {
        "page": 66,
        "length_tokens": 35,
        "text": "-\\*\\*误工费用\\*\\*：员工因工作原因受伤或患病导致无法工作，保险公司将赔付相应的误工费用。",
        "id": 492,
        "type": "text"
      },
      {
        "page": 66,
        "length_tokens": 45,
        "text": "-\\*\\*法律诉讼费用\\*\\*：员工因工作原因受伤或患病，企业因此面临法律诉讼，保险公司将赔付相应的法律诉讼费用。",
        "id": 493,
        "type": "text"
      },
      {
        "page": 66,
        "length_tokens": 12,
        "text": "###2.\\*\\*产品亮点\\*\\* ",
        "id": 494,
        "type": "text"
      },
      {
        "page": 66,
        "length_tokens": 48,
        "text": "-\\*\\*雇主责任转嫁给保险公司\\*\\*：企业通过购买雇主责任险，将员工在工作中可能面临的风险责任转嫁给保险公司，降低企业的用工风险。",
        "id": 495,
        "type": "text"
      },
      {
        "page": 66,
        "length_tokens": 2,
        "text": "0 ",
        "id": 496,
        "type": "text"
      },
      {
        "page": 66,
        "length_tokens": 14,
        "text": "当内容超过LLM上下文长度的时候，需要采用召回策略",
        "id": 497,
        "type": "text"
      },
      {
        "page": 67,
        "length_tokens": 10,
        "text": "Thinking: 多种RAG技术如何使用？",
        "id": 498,
        "type": "text"
      },
      {
        "page": 67,
        "length_tokens": 44,
        "text": "·单文件互动：DeepSeek直接提问·多文件互动：Qwen-Agent，DeepSeek $^ +$ FaissQwen-Agent内置多种召回方式，提升召回的可能性",
        "id": 499,
        "type": "text"
      },
      {
        "page": 68,
        "length_tokens": 8,
        "text": "Thank You Using data to solve problems ",
        "id": 500,
        "type": "text"
      }
    ]
  }
}