{
  "metainfo": {
    "sha1": "Aitraining",
    "sha1_name": "Aitraining",
    "pages_amount": 6,
    "text_blocks_amount": 29,
    "tables_amount": 1,
    "pictures_amount": 0,
    "equations_amount": 0,
    "footnotes_amount": 0,
    "company_name": "AI应用开发",
    "file_name": "17.2-DeepSeek-R1-0528"
  },
  "content": {
    "chunks": [
      {
        "page": 1,
        "length_tokens": 8,
        "text": "DeepSeek-R1-0528 ",
        "id": 0,
        "type": "text"
      },
      {
        "page": 2,
        "length_tokens": 8,
        "text": "DeepSeek-R1-0528 ",
        "id": 1,
        "type": "text"
      },
      {
        "page": 2,
        "length_tokens": 9,
        "text": "DeepSeek-R1-0528: ",
        "id": 2,
        "type": "text"
      },
      {
        "page": 2,
        "length_tokens": 26,
        "text": "于2025年5月28日发布，基于DeepSeek-V3-0324训练参数量达660B。",
        "id": 3,
        "type": "text"
      },
      {
        "page": 2,
        "length_tokens": 48,
        "text": "模型在编程、推理、长文本处理等方面表现卓越，甚至在某些任务上超越Claude 4Sonnet和Gemini 2.5Pro，接近 OpenAl o3-high 水平",
        "id": 4,
        "type": "text"
      },
      {
        "page": 2,
        "length_tokens": 0,
        "text": "",
        "id": 5,
        "type": "table"
      },
      {
        "page": 2,
        "length_tokens": 12,
        "text": "https://livecodebench.github.io/leaderboard.html ",
        "id": 6,
        "type": "text"
      },
      {
        "page": 3,
        "length_tokens": 8,
        "text": "DeepSeek-R1-0528 ",
        "id": 7,
        "type": "text"
      },
      {
        "page": 3,
        "length_tokens": 4,
        "text": "核心亮点：",
        "id": 8,
        "type": "text"
      },
      {
        "page": 3,
        "length_tokens": 5,
        "text": "超强编程能力",
        "id": 9,
        "type": "text"
      },
      {
        "page": 3,
        "length_tokens": 92,
        "text": "在 LiveCodeBench 测试中，性能接近 OpenAl o3-high，甚至超越 Gemini 2.5 Flash 和 Claude 4 Sonnet。  \n能一次性生成 超千行无Bug代码，在 前端开发（HTML/CSS/JS）、物理模拟、算法优化 等任务中表现优异。  \n开发者实测发现，其代码生成质量高，首次运行即可完美执行，无需调试。",
        "id": 10,
        "type": "text"
      },
      {
        "page": 3,
        "length_tokens": 10,
        "text": "长文本处理 ( $\\cdot$ tokens)",
        "id": 11,
        "type": "text"
      },
      {
        "page": 3,
        "length_tokens": 55,
        "text": "支持20,480字的长上下文推理，适合法律、科研、复杂文档分析等场景。  \n在32Ktokens内的文本召回表现优秀，但 $6 0 \\mathsf { K } +$ 时性能下降。",
        "id": 12,
        "type": "text"
      },
      {
        "page": 3,
        "length_tokens": 10,
        "text": "·深度推理与长时间思考",
        "id": 13,
        "type": "text"
      },
      {
        "page": 3,
        "length_tokens": 53,
        "text": "单任务处理时间可达30-60分钟，适合复杂逻辑推理（如数学证明、多步骤问题）。  \n能正确处理“9.9-9.11\"等易错计算问题，推理过程更缜密。",
        "id": 14,
        "type": "text"
      },
      {
        "page": 4,
        "length_tokens": 8,
        "text": "DeepSeek-R1-0528 ",
        "id": 15,
        "type": "text"
      },
      {
        "page": 4,
        "length_tokens": 4,
        "text": "，文本生成优化",
        "id": 16,
        "type": "text"
      },
      {
        "page": 4,
        "length_tokens": 41,
        "text": "输出更自然、格式规范，减少冗余信息（如不再频繁提及“量子力学”）。  \n适用于写作、翻译、商业报告等任务。",
        "id": 17,
        "type": "text"
      },
      {
        "page": 4,
        "length_tokens": 6,
        "text": "·开源与低成本",
        "id": 18,
        "type": "text"
      },
      {
        "page": 4,
        "length_tokens": 32,
        "text": "模型权重已开源至HuggingFace，采用MIT许可证，可商用。  \n推理成本低，每百万tokens价格为16元。",
        "id": 19,
        "type": "text"
      },
      {
        "page": 5,
        "length_tokens": 8,
        "text": "DeepSeek-R1-0528 ",
        "id": 20,
        "type": "text"
      },
      {
        "page": 5,
        "length_tokens": 12,
        "text": "8已深度思考（用时8秒）",
        "id": 21,
        "type": "text"
      },
      {
        "page": 5,
        "length_tokens": 45,
        "text": "嗯，用户问了一个很直接的问题——“你是什么版本？”。看来ta想确认我的身份和能力范围。可能刚接触我，或者在其他平台遇到过不同版本的AI助手。",
        "id": 22,
        "type": "text"
      },
      {
        "page": 5,
        "length_tokens": 54,
        "text": "用户语气简洁，没有多余修饰，大概率是实用主义者。回答时需要明确版本号和关键参数，但避免堆砌技术术语。可以顺便提一下知识截止日期一一很多人会关心这个。",
        "id": 23,
        "type": "text"
      },
      {
        "page": 5,
        "length_tokens": 60,
        "text": "啊，提到\"深度求索公司\"时要自然，既表明身份又不显得打广告。最后主动延伸提供帮助，给用户一个开口的机会。毕竟单纯问版本的人，往往接下来就要问具体问题了。",
        "id": 24,
        "type": "text"
      },
      {
        "page": 5,
        "length_tokens": 54,
        "text": "对了，结尾加个表情符号调节气氛，毕竟冷冰冰报版本号显得太机械。用比 $\\hat { \\mathbf { \\Omega } }$ 更合适，后者太跳脱了。",
        "id": 25,
        "type": "text"
      },
      {
        "page": 5,
        "length_tokens": 65,
        "text": "我是DeepSeek-R1版本，由深度求索（DeepSeek）公司研发。我的知识截止到2024年7月，支持中文和英文等多种语言，上下文记忆长度可达128Ktokens，能处理超长文本，比如整本书、长报告或复杂代码库。",
        "id": 26,
        "type": "text"
      },
      {
        "page": 5,
        "length_tokens": 42,
        "text": "我目前是纯文本助手，不支持识图或语音功能，但你可以上传文本类文件（如PDF、Word、Excel等），我可以从中读取文字内容并帮你处理。",
        "id": 27,
        "type": "text"
      },
      {
        "page": 5,
        "length_tokens": 35,
        "text": "如果你对我的功能、使用方式或背后技术感兴趣，欢迎随时问我！ $\\circledcirc$ 需要我帮你做些什么吗？",
        "id": 28,
        "type": "text"
      },
      {
        "page": 6,
        "length_tokens": 8,
        "text": "Thank You Using data to solve problems ",
        "id": 29,
        "type": "text"
      }
    ]
  }
}