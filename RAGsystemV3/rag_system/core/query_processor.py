"""
æŸ¥è¯¢å¤„ç†å™¨æ¨¡å— - é‡æ„ç‰ˆ

RAGç³»ç»Ÿçš„æŸ¥è¯¢å¤„ç†å™¨ï¼Œä¸¥æ ¼æŒ‰ç…§33.V3_RAGæŸ¥è¯¢å¤„ç†æ¨¡å—è¯¦ç»†è®¾è®¡æ–‡æ¡£é‡æ„
é‡‡ç”¨æ–°çš„æ¶æ„è®¾è®¡ï¼šæŸ¥è¯¢è·¯ç”±å™¨ + ç»Ÿä¸€æœåŠ¡æ¥å£ + æ™ºèƒ½å¤„ç†å™¨
"""

import logging
import time
from typing import Dict, List, Optional, Any

from .config_integration import ConfigIntegration
from .query_router import SimpleQueryRouter
from .common_models import QueryOptions, QueryResult, QueryType
from .exceptions import (
    ServiceInitializationError,
    QueryProcessingError,
    ConfigurationError
)

logger = logging.getLogger(__name__)


class QueryProcessor:
    """æŸ¥è¯¢å¤„ç†å™¨ - é‡æ„ç‰ˆï¼Œä¸¥æ ¼æŒ‰ç…§è®¾è®¡æ–‡æ¡£å®ç°"""
    
    def __init__(self, config_integration: ConfigIntegration, 
                 retrieval_engine=None, llm_caller=None, 
                 reranking_service=None, attribution_service=None, 
                 display_service=None, metadata_manager=None, memory_manager=None):
        """
        åˆå§‹åŒ–æŸ¥è¯¢å¤„ç†å™¨
        
        :param config_integration: é…ç½®é›†æˆç®¡ç†å™¨å®ä¾‹
        :param retrieval_engine: å¬å›å¼•æ“å®ä¾‹ï¼ˆå¯é€‰ï¼‰
        :param llm_caller: LLMè°ƒç”¨å™¨å®ä¾‹ï¼ˆå¯é€‰ï¼‰
        :param reranking_service: é‡æ’åºæœåŠ¡å®ä¾‹ï¼ˆå¯é€‰ï¼‰
        :param attribution_service: æº¯æºæœåŠ¡å®ä¾‹ï¼ˆå¯é€‰ï¼‰
        :param display_service: å±•ç¤ºæœåŠ¡å®ä¾‹ï¼ˆå¯é€‰ï¼‰
        :param metadata_manager: å…ƒæ•°æ®ç®¡ç†å™¨å®ä¾‹ï¼ˆå¯é€‰ï¼‰
        :param memory_manager: è®°å¿†ç®¡ç†å™¨å®ä¾‹ï¼ˆå¯é€‰ï¼‰
        """
        self.config = config_integration
        
        # å­˜å‚¨ä¼ å…¥çš„æœåŠ¡å®ä¾‹ï¼ˆå¦‚æœæä¾›ï¼‰
        self.retrieval_engine = retrieval_engine
        self.llm_caller = llm_caller
        self.reranking_service = reranking_service
        self.attribution_service = attribution_service
        self.display_service = display_service
        self.metadata_manager = metadata_manager
        self.memory_manager = memory_manager
        
        try:
            # åˆå§‹åŒ–æŸ¥è¯¢è·¯ç”±å™¨
            self.query_router = SimpleQueryRouter(config_integration)
            
            logger.info("æŸ¥è¯¢å¤„ç†å™¨é‡æ„ç‰ˆåˆå§‹åŒ–å®Œæˆ")
            
        except (ServiceInitializationError, ConfigurationError) as e:
            logger.error(f"æŸ¥è¯¢å¤„ç†å™¨é‡æ„ç‰ˆåˆå§‹åŒ–å¤±è´¥: {e}")
            raise ServiceInitializationError(f"æŸ¥è¯¢å¤„ç†å™¨é‡æ„ç‰ˆåˆå§‹åŒ–å¤±è´¥: {e}") from e
        except Exception as e:
            logger.error(f"æŸ¥è¯¢å¤„ç†å™¨é‡æ„ç‰ˆåˆå§‹åŒ–å¤±è´¥ï¼ˆæœªçŸ¥é”™è¯¯ï¼‰: {e}")
            raise ServiceInitializationError(f"æŸ¥è¯¢å¤„ç†å™¨é‡æ„ç‰ˆåˆå§‹åŒ–å¤±è´¥: {e}") from e
    
    def get_service_instance(self, service_name: str):
        """
        è·å–æŒ‡å®šçš„æœåŠ¡å®ä¾‹
        
        :param service_name: æœåŠ¡åç§°
        :return: æœåŠ¡å®ä¾‹æˆ–None
        """
        service_map = {
            'retrieval_engine': self.retrieval_engine,
            'llm_caller': self.llm_caller,
            'reranking_service': self.reranking_service,
            'attribution_service': self.attribution_service,
            'display_service': self.display_service,
            'metadata_manager': self.metadata_manager
        }
        return service_map.get(service_name)
    
    def has_service(self, service_name: str) -> bool:
        """
        æ£€æŸ¥æ˜¯å¦æä¾›äº†æŒ‡å®šçš„æœåŠ¡
        
        :param service_name: æœåŠ¡åç§°
        :return: æ˜¯å¦å¯ç”¨
        """
        return self.get_service_instance(service_name) is not None
    
    def get_service_status(self) -> Dict[str, Any]:
        """
        è·å–æœåŠ¡çŠ¶æ€ä¿¡æ¯
        
        :return: æœåŠ¡çŠ¶æ€å­—å…¸
        """
        return {
            'status': 'ready',
            'service_type': 'QueryProcessor',
            'config_integration': self.config is not None,
            'query_router': self.query_router is not None,
            'services': {
                'retrieval_engine': self.has_service('retrieval_engine'),
                'llm_caller': self.has_service('llm_caller'),
                'reranking_service': self.has_service('reranking_service'),
                'attribution_service': self.has_service('attribution_service'),
                'display_service': self.has_service('display_service'),
                'metadata_manager': self.has_service('metadata_manager')
            },
            'features': [
                'query_routing',
                'smart_processing',
                'hybrid_processing',
                'service_integration'
            ]
        }
    
    async def process_query(self, query: str, query_type: str = "auto", 
                          options: Dict[str, Any] = None) -> QueryResult:
        """
        æŸ¥è¯¢å¤„ç†ä¸»å…¥å£ - é‡æ„ç‰ˆï¼Œä¸¥æ ¼æŒ‰ç…§è®¾è®¡æ–‡æ¡£å®ç°
        
        :param query: æŸ¥è¯¢æ–‡æœ¬
        :param query_type: æŸ¥è¯¢ç±»å‹ï¼Œé»˜è®¤ä¸º"auto"è‡ªåŠ¨æ£€æµ‹
        :param options: æŸ¥è¯¢é€‰é¡¹
        :return: æŸ¥è¯¢ç»“æœ
        """
        start_time = time.time()
        
        try:
            logger.info(f"å¼€å§‹æŸ¥è¯¢å¤„ç†: {query[:50]}...ï¼Œç±»å‹: {query_type}")
            
            # 1. æ£€ç´¢ç›¸å…³å†å²è®°å¿†ï¼ˆå¦‚æœå¯ç”¨ï¼‰
            context_memories = []
            logger.info(f"ğŸ” è®°å¿†æ£€ç´¢æ¡ä»¶æ£€æŸ¥:")
            logger.info(f"  - memory_managerå­˜åœ¨: {self.memory_manager is not None}")
            logger.info(f"  - optionså­˜åœ¨: {options is not None}")
            logger.info(f"  - session_id: {options.get('session_id') if options else None}")
            logger.info(f"  - user_id: {options.get('user_id') if options else None}")
            logger.info(f"  - å®Œæ•´options: {options}")
            
            # å¦‚æœæ²¡æœ‰session_idä½†æœ‰user_idï¼Œå…ˆåˆ›å»ºä¼šè¯
            if self.memory_manager and options and not options.get('session_id') and options.get('user_id'):
                try:
                    logger.info(f"ğŸ†• ä¸ºè®°å¿†æ£€ç´¢åˆ›å»ºä¼šè¯: user_id={options.get('user_id')}")
                    session = self.memory_manager.create_session(user_id=options.get('user_id'))
                    options['session_id'] = session.session_id
                    logger.info(f"âœ… åˆ›å»ºä¼šè¯æˆåŠŸ: {session.session_id}")
                except Exception as e:
                    logger.warning(f"âŒ åˆ›å»ºä¼šè¯å¤±è´¥: {e}")
            
            if self.memory_manager and options and options.get('session_id'):
                try:
                    logger.info(f"ğŸ” å¼€å§‹æ£€ç´¢å†å²è®°å¿†:")
                    logger.info(f"  - å½“å‰æŸ¥è¯¢: '{query}'")
                    logger.info(f"  - ä¼šè¯ID: {options.get('session_id')}")
                    logger.info(f"  - ç”¨æˆ·ID: {options.get('user_id')}")
                    context_memories = await self._retrieve_context_memories(query, options)
                    if context_memories:
                        logger.info(f"âœ… æ£€ç´¢åˆ° {len(context_memories)} æ¡ç›¸å…³å†å²è®°å¿†")
                        for i, memory in enumerate(context_memories[:3]):
                            logger.info(f"  - è®°å¿†{i+1}: {memory.get('content', '')[:100]}...")
                    else:
                        logger.info("âŒ æœªæ‰¾åˆ°ç›¸å…³å†å²è®°å¿†")
                except Exception as e:
                    logger.warning(f"âŒ æ£€ç´¢å†å²è®°å¿†å¤±è´¥: {e}")
                    import traceback
                    logger.warning(f"âŒ é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")
            else:
                logger.info(f"â­ï¸ è·³è¿‡å†å²è®°å¿†æ£€ç´¢:")
                logger.info(f"  - memory_managerå­˜åœ¨: {self.memory_manager is not None}")
                logger.info(f"  - optionså­˜åœ¨: {options is not None}")
                logger.info(f"  - session_idå­˜åœ¨: {options.get('session_id') if options else None}")
                logger.info(f"  - æ¡ä»¶ä¸æ»¡è¶³ï¼Œè·³è¿‡è®°å¿†æ£€ç´¢")
            
            # 2. æ„å»ºæŸ¥è¯¢é€‰é¡¹ï¼ˆåŒ…å«å†å²è®°å¿†ï¼‰
            query_options = self._build_query_options(options, context_memories)
            
            # 3. é€šè¿‡æŸ¥è¯¢è·¯ç”±å™¨å¤„ç†æŸ¥è¯¢
            result = await self.query_router.route_query(query, query_type, query_options)
            
            # 4. å¦‚æœæœ‰å†å²è®°å¿†ï¼Œæ›´æ–°ç»“æœä¸­çš„ä¸Šä¸‹æ–‡ä¿¡æ¯
            if context_memories:
                result.processing_metadata = result.processing_metadata or {}
                result.processing_metadata['context_memories_count'] = len(context_memories)
                result.processing_metadata['memory_enhanced'] = True
                logger.info(f"è®¾ç½®è®°å¿†å¢å¼º: {len(context_memories)} æ¡å†å²è®°å¿†")
            
            # 3. æ›´æ–°å¤„ç†å…ƒæ•°æ®
            processing_time = time.time() - start_time
            if result.processing_metadata is None:
                result.processing_metadata = {}
            
            result.processing_metadata.update({
                'total_processing_time': processing_time,
                'query_processor_version': 'refactored_v2',
                'query_router_used': True
            })
            
            # 4. è®°å½•å¯¹è¯åˆ°è®°å¿†æ¨¡å—ï¼ˆå¦‚æœå¯ç”¨ï¼‰
            if self.memory_manager and result.success:
                try:
                    logger.info(f"å¼€å§‹è®°å½•å¯¹è¯åˆ°è®°å¿†æ¨¡å—: query={query[:50]}..., success={result.success}")
                    await self._record_conversation_to_memory(query, result, options)
                    logger.info("å¯¹è¯è®°å½•åˆ°è®°å¿†æ¨¡å—æˆåŠŸ")
                except Exception as e:
                    logger.error(f"è®°å½•å¯¹è¯åˆ°è®°å¿†æ¨¡å—å¤±è´¥: {e}", exc_info=True)
            else:
                logger.warning(f"è·³è¿‡è®°å¿†è®°å½•: memory_manager={self.memory_manager is not None}, result.success={result.success}")
            
            logger.info(f"æŸ¥è¯¢å¤„ç†å®Œæˆï¼Œç±»å‹: {query_type}ï¼Œç»“æœçŠ¶æ€: {result.success}ï¼Œè€—æ—¶: {processing_time:.2f}ç§’")
            
            return result
            
        except (QueryProcessingError, ServiceInitializationError) as e:
            processing_time = time.time() - start_time
            error_msg = f"æŸ¥è¯¢å¤„ç†å¤±è´¥: {str(e)}"
            logger.error(error_msg)
            
            result = QueryResult()
            result.success = False
            result.error_message = error_msg
            result.processing_metadata = {
                'total_processing_time': processing_time,
                'error': str(e),
                'query_processor_version': 'refactored_v2'
            }
            return result
        except Exception as e:
            processing_time = time.time() - start_time
            error_msg = f"æŸ¥è¯¢å¤„ç†å¤±è´¥ï¼ˆæœªçŸ¥é”™è¯¯ï¼‰: {str(e)}"
            logger.error(error_msg)
            
            result = QueryResult()
            result.success = False
            result.error_message = error_msg
            result.processing_metadata = {
                'total_processing_time': processing_time,
                'error': str(e),
                'query_processor_version': 'refactored_v2'
            }
            return result
    
    def _build_query_options(self, options: Dict[str, Any] = None, context_memories: List[Dict[str, Any]] = None) -> QueryOptions:
        """
        æ„å»ºæŸ¥è¯¢é€‰é¡¹
        
        :param options: åŸå§‹é€‰é¡¹å­—å…¸
        :return: æŸ¥è¯¢é€‰é¡¹å¯¹è±¡
        """
        try:
            if options is None:
                options = {}
            
            # ä»é…ç½®è·å–é»˜è®¤å€¼
            default_max_results = self.config.get_rag_config('query_processing.max_results', 10)
            default_relevance_threshold = self.config.get_rag_config('query_processing.relevance_threshold', 0.5)
            default_context_length_limit = self.config.get_rag_config('query_processing.max_context_length', 4000)
            default_enable_streaming = self.config.get_rag_config('query_processing.enable_streaming', True)
            
            # æ„å»ºæŸ¥è¯¢é€‰é¡¹
            context_memories = context_memories or []
            logger.info(f"ğŸ”§ æ„å»ºQueryOptions:")
            logger.info(f"  - context_memoriesæ•°é‡: {len(context_memories)}")
            if context_memories:
                logger.info(f"  - å†å²è®°å¿†å†…å®¹é¢„è§ˆ:")
                for i, memory in enumerate(context_memories[:3]):
                    logger.info(f"    {i+1}. {memory.get('content', '')[:50]}...")
            else:
                logger.info(f"  - æ²¡æœ‰å†å²è®°å¿†")
            
            query_options = QueryOptions(
                max_results=options.get('max_results', default_max_results),
                relevance_threshold=options.get('relevance_threshold', default_relevance_threshold),
                context_length_limit=options.get('context_length_limit', default_context_length_limit),
                enable_streaming=options.get('enable_streaming', default_enable_streaming),
                context_memories=context_memories
            )
            
            logger.info(f"âœ… QueryOptionsæ„å»ºå®Œæˆï¼Œcontext_memories={len(query_options.context_memories)}æ¡")
            
            return query_options
            
        except Exception as e:
            logger.warning(f"æ„å»ºæŸ¥è¯¢é€‰é¡¹å¤±è´¥: {e}ï¼Œä½¿ç”¨é»˜è®¤é€‰é¡¹")
            return QueryOptions()
    
    def get_processing_statistics(self) -> Dict[str, Any]:
        """è·å–å¤„ç†ç»Ÿè®¡ä¿¡æ¯"""
        try:
            return {
                'processor_type': 'QueryProcessor_Refactored',
                'architecture': 'router_based',
                'components': {
                    'query_router': 'SimpleQueryRouter',
                    'smart_processor': 'SimpleSmartProcessor',
                    'hybrid_processor': 'SimpleHybridProcessor',
                    'unified_services': 'UnifiedServices'
                },
                'processing_flow': [
                    'query_input',
                    'router_dispatch',
                    'type_detection',
                    'content_retrieval',
                    'reranking',
                    'llm_generation',
                    'result_integration'
                ]
            }
            
        except Exception as e:
            logger.error(f"è·å–å¤„ç†ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {e}")
            return {
                'processor_type': 'QueryProcessor_Refactored',
                'error': str(e)
            }
    
    async def _record_conversation_to_memory(self, query: str, result: QueryResult, options: Dict[str, Any] = None):
        """
        è®°å½•å¯¹è¯åˆ°è®°å¿†æ¨¡å—
        
        :param query: ç”¨æˆ·æŸ¥è¯¢
        :param result: æŸ¥è¯¢ç»“æœ
        :param options: æŸ¥è¯¢é€‰é¡¹
        """
        try:
            if not self.memory_manager:
                logger.warning("è®°å¿†ç®¡ç†å™¨ä¸å¯ç”¨ï¼Œè·³è¿‡è®°å¿†è®°å½•")
                return
            
            # è·å–ä¼šè¯IDï¼Œå¦‚æœæ²¡æœ‰åˆ™åˆ›å»ºé»˜è®¤ä¼šè¯
            session_id = options.get('session_id') if options else None
            user_id = options.get('user_id', 'web_user') if options else 'web_user'
            
            logger.info(f"è®°å¿†è®°å½•å‚æ•°: session_id={session_id}, user_id={user_id}")
            
            if not session_id:
                # åˆ›å»ºé»˜è®¤ä¼šè¯
                logger.info(f"åˆ›å»ºæ–°ä¼šè¯ï¼Œuser_id={user_id}")
                session = self.memory_manager.create_session(user_id=user_id)
                session_id = session.session_id
                logger.info(f"ä¸ºè®°å¿†æ¨¡å—åˆ›å»ºæ–°ä¼šè¯: {session_id}")
                # æ›´æ–°optionsä¸­çš„session_idï¼Œè¿™æ ·APIå“åº”ä¸­ä¼šåŒ…å«å®ƒ
                if options:
                    options['session_id'] = session_id
            
            # æ„å»ºè®°å¿†å†…å®¹
            memory_content = f"ç”¨æˆ·è¯¢é—®: {query}"
            if result.answer:
                memory_content += f"\nç³»ç»Ÿå›ç­”: {result.answer}"
            
            logger.info(f"è®°å¿†å†…å®¹é•¿åº¦: {len(memory_content)}")
            
            # è®¡ç®—ç›¸å…³æ€§å’Œé‡è¦æ€§åˆ†æ•°
            relevance_score = 0.8  # é»˜è®¤ç›¸å…³æ€§
            importance_score = 0.7  # é»˜è®¤é‡è¦æ€§
            
            # å¦‚æœæœ‰æ£€ç´¢ç»“æœï¼Œæ ¹æ®ç»“æœæ•°é‡è°ƒæ•´é‡è¦æ€§
            if result.results:
                importance_score = min(0.9, 0.5 + len(result.results) * 0.1)
            
            # æ·»åŠ è®°å¿†
            memory_chunk = self.memory_manager.add_memory(
                session_id=session_id,
                content=memory_content,
                content_type="text",
                relevance_score=relevance_score,
                importance_score=importance_score,
                metadata={
                    'query_type': options.get('query_type', 'auto') if options else 'auto',
                    'processing_time': result.processing_metadata.get('total_processing_time', 0) if result.processing_metadata else 0,
                    'retrieved_chunks_count': len(result.results) if result.results else 0,
                    'source': 'rag_query'
                }
            )
            
            logger.info(f"å¯¹è¯å·²è®°å½•åˆ°è®°å¿†æ¨¡å—: ä¼šè¯={session_id}, è®°å¿†ID={memory_chunk.chunk_id}")
            
        except Exception as e:
            logger.error(f"è®°å½•å¯¹è¯åˆ°è®°å¿†æ¨¡å—å¤±è´¥: {e}")
            raise
    
    async def _retrieve_context_memories(self, query: str, options: Dict[str, Any]) -> List[Dict[str, Any]]:
        """
        æ£€ç´¢ç›¸å…³å†å²è®°å¿†ç”¨äºä¸Šä¸‹æ–‡å¢å¼º
        
        :param query: å½“å‰æŸ¥è¯¢
        :param options: æŸ¥è¯¢é€‰é¡¹
        :return: ç›¸å…³è®°å¿†åˆ—è¡¨
        """
        try:
            session_id = options.get('session_id')
            if not session_id:
                return []
            
            # æ„å»ºè®°å¿†æŸ¥è¯¢
            from .memory.models import MemoryQuery
            memory_query = MemoryQuery(
                query_text=query,
                session_id=session_id,
                max_results=5,  # è·å–å¤šæ¡å†å²è®°å½•
                similarity_threshold=0.1,  # æœ€ä½ç›¸ä¼¼åº¦é˜ˆå€¼
                content_types=["text"]  # åªæ£€ç´¢æ–‡æœ¬è®°å¿†
            )
            
            logger.info(f"ğŸ” è®°å¿†æŸ¥è¯¢å‚æ•°:")
            logger.info(f"  - query_text: '{query}'")
            logger.info(f"  - session_id: '{session_id}'")
            logger.info(f"  - max_results: 5")
            logger.info(f"  - similarity_threshold: 0.1")
            logger.info(f"  - content_types: ['text']")
            
            # æ£€ç´¢ç›¸å…³è®°å¿†
            logger.info(f"ğŸ” è°ƒç”¨memory_manager.retrieve_memories...")
            memories = self.memory_manager.retrieve_memories(memory_query)
            logger.info(f"ğŸ“Š è®°å¿†æ£€ç´¢ç»“æœ: æ‰¾åˆ° {len(memories)} æ¡è®°å¿†")
            
            # è¯¦ç»†è®°å½•æ£€ç´¢åˆ°çš„è®°å¿†
            for i, memory in enumerate(memories):
                logger.info(f"  - è®°å¿†{i+1}: ID={memory.chunk_id}, å†…å®¹={memory.content[:100]}...")
            
            # è½¬æ¢ä¸ºå­—å…¸æ ¼å¼ï¼Œä¾¿äºåç»­å¤„ç†
            context_memories = []
            for memory in memories:
                context_memory = {
                    'content': memory.content,
                    'chunk_id': memory.chunk_id,
                    'content_type': memory.content_type,
                    'relevance_score': memory.relevance_score,
                    'importance_score': memory.importance_score,
                    'created_at': memory.created_at.isoformat() if memory.created_at else '',
                    'metadata': memory.metadata
                }
                context_memories.append(context_memory)
            
            logger.info(f"æ£€ç´¢åˆ° {len(context_memories)} æ¡ç›¸å…³å†å²è®°å¿†")
            return context_memories
            
        except Exception as e:
            logger.error(f"æ£€ç´¢å†å²è®°å¿†å¤±è´¥: {e}")
            return []
