"""
æŸ¥è¯¢å¤„ç†å™¨æ¨¡å— - é‡æ„ç‰ˆ

RAGç³»ç»Ÿçš„æŸ¥è¯¢å¤„ç†å™¨ï¼Œä¸¥æ ¼æŒ‰ç…§33.V3_RAGæŸ¥è¯¢å¤„ç†æ¨¡å—è¯¦ç»†è®¾è®¡æ–‡æ¡£é‡æ„
é‡‡ç”¨æ–°çš„æ¶æ„è®¾è®¡ï¼šæŸ¥è¯¢è·¯ç”±å™¨ + ç»Ÿä¸€æœåŠ¡æ¥å£ + æ™ºèƒ½å¤„ç†å™¨
"""

import logging
import time
from typing import Dict, List, Optional, Any

from .config_integration import ConfigIntegration
from .query_router import SimpleQueryRouter
from .common_models import QueryOptions, QueryResult, QueryType
from .spacy_query_rewriter import get_query_rewriter
from .exceptions import (
    ServiceInitializationError,
    QueryProcessingError,
    ConfigurationError
)

logger = logging.getLogger(__name__)


class QueryProcessor:
    """æŸ¥è¯¢å¤„ç†å™¨ - é‡æ„ç‰ˆï¼Œä¸¥æ ¼æŒ‰ç…§è®¾è®¡æ–‡æ¡£å®ç°"""
    
    def __init__(self, config_integration: ConfigIntegration, 
                 retrieval_engine=None, llm_caller=None, 
                 reranking_service=None, attribution_service=None, 
                 display_service=None, metadata_manager=None, memory_manager=None):
        """
        åˆå§‹åŒ–æŸ¥è¯¢å¤„ç†å™¨
        
        :param config_integration: é…ç½®é›†æˆç®¡ç†å™¨å®ä¾‹
        :param retrieval_engine: å¬å›å¼•æ“å®ä¾‹ï¼ˆå¯é€‰ï¼‰
        :param llm_caller: LLMè°ƒç”¨å™¨å®ä¾‹ï¼ˆå¯é€‰ï¼‰
        :param reranking_service: é‡æ’åºæœåŠ¡å®ä¾‹ï¼ˆå¯é€‰ï¼‰
        :param attribution_service: æº¯æºæœåŠ¡å®ä¾‹ï¼ˆå¯é€‰ï¼‰
        :param display_service: å±•ç¤ºæœåŠ¡å®ä¾‹ï¼ˆå¯é€‰ï¼‰
        :param metadata_manager: å…ƒæ•°æ®ç®¡ç†å™¨å®ä¾‹ï¼ˆå¯é€‰ï¼‰
        :param memory_manager: è®°å¿†ç®¡ç†å™¨å®ä¾‹ï¼ˆå¯é€‰ï¼‰
        """
        self.config = config_integration
        
        # å­˜å‚¨ä¼ å…¥çš„æœåŠ¡å®ä¾‹ï¼ˆå¦‚æœæä¾›ï¼‰
        self.retrieval_engine = retrieval_engine
        self.llm_caller = llm_caller
        self.reranking_service = reranking_service
        self.attribution_service = attribution_service
        self.display_service = display_service
        self.metadata_manager = metadata_manager
        self.memory_manager = memory_manager
        
        try:
            # åˆå§‹åŒ–æŸ¥è¯¢è·¯ç”±å™¨
            self.query_router = SimpleQueryRouter(config_integration)
            
            logger.info("æŸ¥è¯¢å¤„ç†å™¨é‡æ„ç‰ˆåˆå§‹åŒ–å®Œæˆ")
            
        except (ServiceInitializationError, ConfigurationError) as e:
            logger.error(f"æŸ¥è¯¢å¤„ç†å™¨é‡æ„ç‰ˆåˆå§‹åŒ–å¤±è´¥: {e}")
            raise ServiceInitializationError(f"æŸ¥è¯¢å¤„ç†å™¨é‡æ„ç‰ˆåˆå§‹åŒ–å¤±è´¥: {e}") from e
        except Exception as e:
            logger.error(f"æŸ¥è¯¢å¤„ç†å™¨é‡æ„ç‰ˆåˆå§‹åŒ–å¤±è´¥ï¼ˆæœªçŸ¥é”™è¯¯ï¼‰: {e}")
            raise ServiceInitializationError(f"æŸ¥è¯¢å¤„ç†å™¨é‡æ„ç‰ˆåˆå§‹åŒ–å¤±è´¥: {e}") from e
    
    def get_service_instance(self, service_name: str):
        """
        è·å–æŒ‡å®šçš„æœåŠ¡å®ä¾‹
        
        :param service_name: æœåŠ¡åç§°
        :return: æœåŠ¡å®ä¾‹æˆ–None
        """
        service_map = {
            'retrieval_engine': self.retrieval_engine,
            'llm_caller': self.llm_caller,
            'reranking_service': self.reranking_service,
            'attribution_service': self.attribution_service,
            'display_service': self.display_service,
            'metadata_manager': self.metadata_manager
        }
        return service_map.get(service_name)
    
    def has_service(self, service_name: str) -> bool:
        """
        æ£€æŸ¥æ˜¯å¦æä¾›äº†æŒ‡å®šçš„æœåŠ¡
        
        :param service_name: æœåŠ¡åç§°
        :return: æ˜¯å¦å¯ç”¨
        """
        return self.get_service_instance(service_name) is not None
    
    def get_service_status(self) -> Dict[str, Any]:
        """
        è·å–æœåŠ¡çŠ¶æ€ä¿¡æ¯
        
        :return: æœåŠ¡çŠ¶æ€å­—å…¸
        """
        return {
            'status': 'ready',
            'service_type': 'QueryProcessor',
            'config_integration': self.config is not None,
            'query_router': self.query_router is not None,
            'services': {
                'retrieval_engine': self.has_service('retrieval_engine'),
                'llm_caller': self.has_service('llm_caller'),
                'reranking_service': self.has_service('reranking_service'),
                'attribution_service': self.has_service('attribution_service'),
                'display_service': self.has_service('display_service'),
                'metadata_manager': self.has_service('metadata_manager')
            },
            'features': [
                'query_routing',
                'smart_processing',
                'hybrid_processing',
                'service_integration'
            ]
        }
    
    async def process_query(self, query: str, query_type: str = "auto", 
                          options: Dict[str, Any] = None) -> QueryResult:
        """
        æŸ¥è¯¢å¤„ç†ä¸»å…¥å£ - é‡æ„ç‰ˆï¼Œä¸¥æ ¼æŒ‰ç…§è®¾è®¡æ–‡æ¡£å®ç°
        
        :param query: æŸ¥è¯¢æ–‡æœ¬
        :param query_type: æŸ¥è¯¢ç±»å‹ï¼Œé»˜è®¤ä¸º"auto"è‡ªåŠ¨æ£€æµ‹
        :param options: æŸ¥è¯¢é€‰é¡¹
        :return: æŸ¥è¯¢ç»“æœ
        """
        start_time = time.time()
        
        try:
            logger.info(f"å¼€å§‹æŸ¥è¯¢å¤„ç†: {query[:50]}...ï¼Œç±»å‹: {query_type}")
            
            # 1. æ£€ç´¢ç›¸å…³å†å²è®°å¿†ï¼ˆå¦‚æœå¯ç”¨ï¼‰
            context_memories = []
            logger.info(f"ğŸ” è®°å¿†æ£€ç´¢æ¡ä»¶æ£€æŸ¥:")
            logger.info(f"  - memory_managerå­˜åœ¨: {self.memory_manager is not None}")
            logger.info(f"  - optionså­˜åœ¨: {options is not None}")
            logger.info(f"  - session_id: {options.get('session_id') if options else None}")
            logger.info(f"  - user_id: {options.get('user_id') if options else None}")
            logger.info(f"  - å®Œæ•´options: {options}")
            
            # å¦‚æœæ²¡æœ‰session_idä½†æœ‰user_idï¼Œå…ˆåˆ›å»ºä¼šè¯
            if self.memory_manager and options and not options.get('session_id') and options.get('user_id'):
                try:
                    logger.info(f"ğŸ†• ä¸ºè®°å¿†æ£€ç´¢åˆ›å»ºä¼šè¯: user_id={options.get('user_id')}")
                    session = self.memory_manager.create_session(user_id=options.get('user_id'))
                    options['session_id'] = session.session_id
                    logger.info(f"âœ… åˆ›å»ºä¼šè¯æˆåŠŸ: {session.session_id}")
                except Exception as e:
                    logger.warning(f"âŒ åˆ›å»ºä¼šè¯å¤±è´¥: {e}")
            
            # 2. æŸ¥è¯¢é‡å†™ï¼šå…ˆè¿›è¡ŒæŸ¥è¯¢é‡å†™ï¼Œå†æ£€ç´¢å†å²è®°å¿†
            rewritten_query = query
            context_memories = []
            
            if self.memory_manager and options and options.get('session_id'):
                try:
                    # 2.1 å…ˆå¿«é€Ÿæ£€ç´¢å°‘é‡å†å²è®°å¿†ç”¨äºæŸ¥è¯¢é‡å†™
                    logger.info(f"ğŸ” å¼€å§‹å¿«é€Ÿæ£€ç´¢å†å²è®°å¿†ç”¨äºæŸ¥è¯¢é‡å†™:")
                    logger.info(f"  - å½“å‰æŸ¥è¯¢: '{query}'")
                    logger.info(f"  - ä¼šè¯ID: {options.get('session_id')}")
                    logger.info(f"  - ç”¨æˆ·ID: {options.get('user_id')}")
                    
                    temp_memories = await self._retrieve_context_memories_for_rewrite(query, options)
                    if temp_memories:
                        logger.info(f"âœ… æ£€ç´¢åˆ° {len(temp_memories)} æ¡å†å²è®°å¿†ç”¨äºæŸ¥è¯¢é‡å†™")
                        
                        # 2.2 åŸºäºå†å²è®°å¿†è¿›è¡ŒæŸ¥è¯¢é‡å†™
                        try:
                            logger.info(f"ğŸ”„ å¼€å§‹æŸ¥è¯¢é‡å†™: åŸå§‹æŸ¥è¯¢='{query}'")
                            rewritten_query = self._rewrite_query_with_context(query, temp_memories)
                            if rewritten_query != query:
                                logger.info(f"âœ… æŸ¥è¯¢é‡å†™æˆåŠŸ: '{query}' -> '{rewritten_query}'")
                                # ä¿å­˜é‡å†™ä¿¡æ¯åˆ°optionsä¸­
                                if options:
                                    options['original_query'] = query
                                    options['rewritten_query'] = rewritten_query
                                    options['query_rewritten'] = True
                            else:
                                logger.info(f"â­ï¸ æŸ¥è¯¢æ— éœ€é‡å†™: '{query}'")
                        except Exception as e:
                            logger.warning(f"âŒ æŸ¥è¯¢é‡å†™å¤±è´¥: {e}")
                            import traceback
                            logger.warning(f"âŒ é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")
                    
                    # 2.3 ä½¿ç”¨é‡å†™åçš„æŸ¥è¯¢æ£€ç´¢ç›¸å…³å†å²è®°å¿†
                    logger.info(f"ğŸ” ä½¿ç”¨é‡å†™åçš„æŸ¥è¯¢æ£€ç´¢å†å²è®°å¿†: '{rewritten_query}'")
                    context_memories = await self._retrieve_context_memories(rewritten_query, options)
                    if context_memories:
                        logger.info(f"âœ… æ£€ç´¢åˆ° {len(context_memories)} æ¡ç›¸å…³å†å²è®°å¿†")
                        for i, memory in enumerate(context_memories[:3]):
                            logger.info(f"  - è®°å¿†{i+1}: {memory.get('content', '')[:100]}...")
                    else:
                        logger.info("âŒ æœªæ‰¾åˆ°ç›¸å…³å†å²è®°å¿†")
                        
                except Exception as e:
                    logger.warning(f"âŒ å†å²è®°å¿†å¤„ç†å¤±è´¥: {e}")
                    import traceback
                    logger.warning(f"âŒ é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")
            else:
                logger.info(f"â­ï¸ è·³è¿‡å†å²è®°å¿†å¤„ç†:")
                logger.info(f"  - memory_managerå­˜åœ¨: {self.memory_manager is not None}")
                logger.info(f"  - optionså­˜åœ¨: {options is not None}")
                logger.info(f"  - session_idå­˜åœ¨: {options.get('session_id') if options else None}")
                logger.info(f"  - æ¡ä»¶ä¸æ»¡è¶³ï¼Œè·³è¿‡è®°å¿†å¤„ç†")
            
            # 3. æ„å»ºæŸ¥è¯¢é€‰é¡¹ï¼ˆåŒ…å«å†å²è®°å¿†å’Œé‡å†™åçš„æŸ¥è¯¢ï¼‰
            query_options = self._build_query_options(options, context_memories, rewritten_query)
            
            # 4. é€šè¿‡æŸ¥è¯¢è·¯ç”±å™¨å¤„ç†æŸ¥è¯¢ï¼ˆä½¿ç”¨é‡å†™åçš„æŸ¥è¯¢ï¼‰
            result = await self.query_router.route_query(rewritten_query, query_type, query_options)
            
            # 4.1. å°†æŸ¥è¯¢é€‰é¡¹çš„å…ƒæ•°æ®å¤åˆ¶åˆ°ç»“æœä¸­
            if hasattr(query_options, 'metadata') and query_options.metadata:
                result.metadata = query_options.metadata.copy()
                logger.info(f"å¤åˆ¶æŸ¥è¯¢é‡å†™å…ƒæ•°æ®åˆ°ç»“æœ: {result.metadata}")
            
            # 4. å¦‚æœæœ‰å†å²è®°å¿†ï¼Œæ›´æ–°ç»“æœä¸­çš„ä¸Šä¸‹æ–‡ä¿¡æ¯
            if context_memories:
                result.processing_metadata = result.processing_metadata or {}
                result.processing_metadata['context_memories_count'] = len(context_memories)
                result.processing_metadata['memory_enhanced'] = True
                logger.info(f"è®¾ç½®è®°å¿†å¢å¼º: {len(context_memories)} æ¡å†å²è®°å¿†")
            
            # 3. æ›´æ–°å¤„ç†å…ƒæ•°æ®
            processing_time = time.time() - start_time
            if result.processing_metadata is None:
                result.processing_metadata = {}
            
            result.processing_metadata.update({
                'total_processing_time': processing_time,
                'query_processor_version': 'refactored_v2',
                'query_router_used': True
            })
            
            # 4. è®°å½•å¯¹è¯åˆ°è®°å¿†æ¨¡å—ï¼ˆå¦‚æœå¯ç”¨ï¼‰
            if self.memory_manager and result.success:
                try:
                    logger.info(f"å¼€å§‹è®°å½•å¯¹è¯åˆ°è®°å¿†æ¨¡å—: query={query[:50]}..., success={result.success}")
                    await self._record_conversation_to_memory(query, result, options)
                    logger.info("å¯¹è¯è®°å½•åˆ°è®°å¿†æ¨¡å—æˆåŠŸ")
                except Exception as e:
                    logger.error(f"è®°å½•å¯¹è¯åˆ°è®°å¿†æ¨¡å—å¤±è´¥: {e}", exc_info=True)
            else:
                logger.warning(f"è·³è¿‡è®°å¿†è®°å½•: memory_manager={self.memory_manager is not None}, result.success={result.success}")
            
            logger.info(f"æŸ¥è¯¢å¤„ç†å®Œæˆï¼Œç±»å‹: {query_type}ï¼Œç»“æœçŠ¶æ€: {result.success}ï¼Œè€—æ—¶: {processing_time:.2f}ç§’")
            
            return result
            
        except (QueryProcessingError, ServiceInitializationError) as e:
            processing_time = time.time() - start_time
            error_msg = f"æŸ¥è¯¢å¤„ç†å¤±è´¥: {str(e)}"
            logger.error(error_msg)
            
            result = QueryResult()
            result.success = False
            result.error_message = error_msg
            result.processing_metadata = {
                'total_processing_time': processing_time,
                'error': str(e),
                'query_processor_version': 'refactored_v2'
            }
            return result
        except Exception as e:
            processing_time = time.time() - start_time
            error_msg = f"æŸ¥è¯¢å¤„ç†å¤±è´¥ï¼ˆæœªçŸ¥é”™è¯¯ï¼‰: {str(e)}"
            logger.error(error_msg)
            
            result = QueryResult()
            result.success = False
            result.error_message = error_msg
            result.processing_metadata = {
                'total_processing_time': processing_time,
                'error': str(e),
                'query_processor_version': 'refactored_v2'
            }
            return result
    
    def _build_query_options(self, options: Dict[str, Any] = None, context_memories: List[Dict[str, Any]] = None, rewritten_query: str = None) -> QueryOptions:
        """
        æ„å»ºæŸ¥è¯¢é€‰é¡¹
        
        :param options: åŸå§‹é€‰é¡¹å­—å…¸
        :return: æŸ¥è¯¢é€‰é¡¹å¯¹è±¡
        """
        try:
            if options is None:
                options = {}
            
            # ä»é…ç½®è·å–é»˜è®¤å€¼
            default_max_results = self.config.get_rag_config('query_processing.max_results', 10)
            default_relevance_threshold = self.config.get_rag_config('query_processing.relevance_threshold', 0.5)
            default_context_length_limit = self.config.get_rag_config('query_processing.max_context_length', 4000)
            default_enable_streaming = self.config.get_rag_config('query_processing.enable_streaming', True)
            
            # æ„å»ºæŸ¥è¯¢é€‰é¡¹
            context_memories = context_memories or []
            logger.info(f"ğŸ”§ æ„å»ºQueryOptions:")
            logger.info(f"  - context_memoriesæ•°é‡: {len(context_memories)}")
            logger.info(f"  - rewritten_query: '{rewritten_query}'")
            if context_memories:
                logger.info(f"  - å†å²è®°å¿†å†…å®¹é¢„è§ˆ:")
                for i, memory in enumerate(context_memories[:3]):
                    logger.info(f"    {i+1}. {memory.get('content', '')[:50]}...")
            else:
                logger.info(f"  - æ²¡æœ‰å†å²è®°å¿†")
            
            # å‡†å¤‡metadata
            metadata = {}
            if rewritten_query and rewritten_query != options.get('original_query', ''):
                metadata['original_query'] = options.get('original_query', '')
                metadata['rewritten_query'] = rewritten_query
                metadata['query_rewritten'] = True
            
            query_options = QueryOptions(
                max_results=options.get('max_results', default_max_results),
                relevance_threshold=options.get('relevance_threshold', default_relevance_threshold),
                context_length_limit=options.get('context_length_limit', default_context_length_limit),
                enable_streaming=options.get('enable_streaming', default_enable_streaming),
                context_memories=context_memories,
                metadata=metadata
            )
            
            
            logger.info(f"âœ… QueryOptionsæ„å»ºå®Œæˆï¼Œcontext_memories={len(query_options.context_memories)}æ¡")
            
            return query_options
            
        except Exception as e:
            logger.warning(f"æ„å»ºæŸ¥è¯¢é€‰é¡¹å¤±è´¥: {e}ï¼Œä½¿ç”¨é»˜è®¤é€‰é¡¹")
            return QueryOptions()
    
    def get_processing_statistics(self) -> Dict[str, Any]:
        """è·å–å¤„ç†ç»Ÿè®¡ä¿¡æ¯"""
        try:
            return {
                'processor_type': 'QueryProcessor_Refactored',
                'architecture': 'router_based',
                'components': {
                    'query_router': 'SimpleQueryRouter',
                    'smart_processor': 'SimpleSmartProcessor',
                    'hybrid_processor': 'SimpleHybridProcessor',
                    'unified_services': 'UnifiedServices'
                },
                'processing_flow': [
                    'query_input',
                    'router_dispatch',
                    'type_detection',
                    'content_retrieval',
                    'reranking',
                    'llm_generation',
                    'result_integration'
                ]
            }
            
        except Exception as e:
            logger.error(f"è·å–å¤„ç†ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {e}")
            return {
                'processor_type': 'QueryProcessor_Refactored',
                'error': str(e)
            }
    
    async def _record_conversation_to_memory(self, query: str, result: QueryResult, options: Dict[str, Any] = None):
        """
        è®°å½•å¯¹è¯åˆ°è®°å¿†æ¨¡å—
        
        :param query: ç”¨æˆ·æŸ¥è¯¢
        :param result: æŸ¥è¯¢ç»“æœ
        :param options: æŸ¥è¯¢é€‰é¡¹
        """
        try:
            if not self.memory_manager:
                logger.warning("è®°å¿†ç®¡ç†å™¨ä¸å¯ç”¨ï¼Œè·³è¿‡è®°å¿†è®°å½•")
                return
            
            # è·å–ä¼šè¯IDï¼Œå¦‚æœæ²¡æœ‰åˆ™åˆ›å»ºé»˜è®¤ä¼šè¯
            session_id = options.get('session_id') if options else None
            user_id = options.get('user_id', 'web_user') if options else 'web_user'
            
            logger.info(f"è®°å¿†è®°å½•å‚æ•°: session_id={session_id}, user_id={user_id}")
            
            if not session_id:
                # åˆ›å»ºé»˜è®¤ä¼šè¯
                logger.info(f"åˆ›å»ºæ–°ä¼šè¯ï¼Œuser_id={user_id}")
                session = self.memory_manager.create_session(user_id=user_id)
                session_id = session.session_id
                logger.info(f"ä¸ºè®°å¿†æ¨¡å—åˆ›å»ºæ–°ä¼šè¯: {session_id}")
                # æ›´æ–°optionsä¸­çš„session_idï¼Œè¿™æ ·APIå“åº”ä¸­ä¼šåŒ…å«å®ƒ
                if options:
                    options['session_id'] = session_id
            
            # æ„å»ºè®°å¿†å†…å®¹
            memory_content = f"ç”¨æˆ·è¯¢é—®: {query}"
            if result.answer:
                memory_content += f"\nç³»ç»Ÿå›ç­”: {result.answer}"
            
            logger.info(f"è®°å¿†å†…å®¹é•¿åº¦: {len(memory_content)}")
            
            # è®¡ç®—ç›¸å…³æ€§å’Œé‡è¦æ€§åˆ†æ•°
            relevance_score = 0.8  # é»˜è®¤ç›¸å…³æ€§
            importance_score = 0.7  # é»˜è®¤é‡è¦æ€§
            
            # å¦‚æœæœ‰æ£€ç´¢ç»“æœï¼Œæ ¹æ®ç»“æœæ•°é‡è°ƒæ•´é‡è¦æ€§
            if result.results:
                importance_score = min(0.9, 0.5 + len(result.results) * 0.1)
            
            # æ·»åŠ è®°å¿†
            memory_chunk = self.memory_manager.add_memory(
                session_id=session_id,
                content=memory_content,
                content_type="text",
                relevance_score=relevance_score,
                importance_score=importance_score,
                metadata={
                    'query_type': options.get('query_type', 'auto') if options else 'auto',
                    'processing_time': result.processing_metadata.get('total_processing_time', 0) if result.processing_metadata else 0,
                    'retrieved_chunks_count': len(result.results) if result.results else 0,
                    'source': 'rag_query',
                    'user_query': query  # æ·»åŠ ç”¨æˆ·æŸ¥è¯¢å­—æ®µ
                }
            )
            
            logger.info(f"å¯¹è¯å·²è®°å½•åˆ°è®°å¿†æ¨¡å—: ä¼šè¯={session_id}, è®°å¿†ID={memory_chunk.chunk_id}")
            
        except Exception as e:
            logger.error(f"è®°å½•å¯¹è¯åˆ°è®°å¿†æ¨¡å—å¤±è´¥: {e}")
            raise
    
    async def _retrieve_context_memories(self, query: str, options: Dict[str, Any]) -> List[Dict[str, Any]]:
        """
        æ£€ç´¢ç›¸å…³å†å²è®°å¿†ç”¨äºä¸Šä¸‹æ–‡å¢å¼º
        
        :param query: å½“å‰æŸ¥è¯¢
        :param options: æŸ¥è¯¢é€‰é¡¹
        :return: ç›¸å…³è®°å¿†åˆ—è¡¨
        """
        try:
            session_id = options.get('session_id')
            if not session_id:
                return []
            
            # æ„å»ºè®°å¿†æŸ¥è¯¢
            from .memory.models import MemoryQuery
            memory_query = MemoryQuery(
                query_text=query,
                session_id=session_id,
                max_results=5,  # è·å–å¤šæ¡å†å²è®°å½•
                similarity_threshold=0.1,  # æœ€ä½ç›¸ä¼¼åº¦é˜ˆå€¼
                content_types=["text"]  # åªæ£€ç´¢æ–‡æœ¬è®°å¿†
            )
            
            logger.info(f"ğŸ” è®°å¿†æŸ¥è¯¢å‚æ•°:")
            logger.info(f"  - query_text: '{query}'")
            logger.info(f"  - session_id: '{session_id}'")
            logger.info(f"  - max_results: 5")
            logger.info(f"  - similarity_threshold: 0.1")
            logger.info(f"  - content_types: ['text']")
            
            # æ£€ç´¢ç›¸å…³è®°å¿†
            logger.info(f"ğŸ” è°ƒç”¨memory_manager.retrieve_memories...")
            memories = self.memory_manager.retrieve_memories(memory_query)
            logger.info(f"ğŸ“Š è®°å¿†æ£€ç´¢ç»“æœ: æ‰¾åˆ° {len(memories)} æ¡è®°å¿†")
            
            # è¯¦ç»†è®°å½•æ£€ç´¢åˆ°çš„è®°å¿†
            for i, memory in enumerate(memories):
                logger.info(f"  - è®°å¿†{i+1}: ID={memory.chunk_id}, å†…å®¹={memory.content[:100]}...")
            
            # è½¬æ¢ä¸ºå­—å…¸æ ¼å¼ï¼Œä¾¿äºåç»­å¤„ç†
            context_memories = []
            for memory in memories:
                context_memory = {
                    'content': memory.content,
                    'chunk_id': memory.chunk_id,
                    'content_type': memory.content_type,
                    'relevance_score': memory.relevance_score,
                    'importance_score': memory.importance_score,
                    'created_at': memory.created_at.isoformat() if memory.created_at else '',
                    'metadata': memory.metadata,
                    'user_query': memory.metadata.get('user_query') if memory.metadata else None  # æ·»åŠ ç”¨æˆ·æŸ¥è¯¢å­—æ®µ
                }
                context_memories.append(context_memory)
            
            # ä½¿ç”¨spaCyå¢å¼ºè®°å¿†æ’åº
            enhanced_memories = self._enhance_memory_ranking_with_spacy(query, context_memories)
            
            logger.info(f"æ£€ç´¢åˆ° {len(enhanced_memories)} æ¡ç›¸å…³å†å²è®°å¿†ï¼ˆspaCyå¢å¼ºåï¼‰")
            return enhanced_memories
            
        except Exception as e:
            logger.error(f"æ£€ç´¢å†å²è®°å¿†å¤±è´¥: {e}")
            return []
    
    async def _retrieve_context_memories_for_rewrite(self, query: str, options: Dict[str, Any]) -> List[Dict[str, Any]]:
        """
        å¿«é€Ÿæ£€ç´¢å†å²è®°å¿†ç”¨äºæŸ¥è¯¢é‡å†™ï¼ˆåªæ£€ç´¢å°‘é‡è®°å¿†ï¼‰
        
        :param query: å½“å‰æŸ¥è¯¢
        :param options: æŸ¥è¯¢é€‰é¡¹
        :return: ç›¸å…³è®°å¿†åˆ—è¡¨
        """
        try:
            session_id = options.get('session_id')
            if not session_id:
                return []
            
            # æ„å»ºè®°å¿†æŸ¥è¯¢ï¼ˆåªè·å–å°‘é‡è®°å¿†ç”¨äºé‡å†™ï¼‰
            from .memory.models import MemoryQuery
            memory_query = MemoryQuery(
                query_text=query,
                session_id=session_id,
                max_results=3,  # åªè·å–3æ¡è®°å¿†ç”¨äºé‡å†™
                similarity_threshold=0.1,
                content_types=["text"]
            )
            
            # æ£€ç´¢ç›¸å…³è®°å¿†
            memories = self.memory_manager.retrieve_memories(memory_query)
            
            # è½¬æ¢ä¸ºå­—å…¸æ ¼å¼
            context_memories = []
            for memory in memories:
                context_memory = {
                    'content': memory.content,
                    'chunk_id': memory.chunk_id,
                    'content_type': memory.content_type,
                    'relevance_score': memory.relevance_score,
                    'importance_score': memory.importance_score,
                    'created_at': memory.created_at.isoformat() if memory.created_at else '',
                    'metadata': memory.metadata,
                    'user_query': memory.metadata.get('user_query') if memory.metadata else None
                }
                context_memories.append(context_memory)
            
            logger.info(f"å¿«é€Ÿæ£€ç´¢åˆ° {len(context_memories)} æ¡å†å²è®°å¿†ç”¨äºæŸ¥è¯¢é‡å†™")
            return context_memories
            
        except Exception as e:
            logger.error(f"å¿«é€Ÿæ£€ç´¢å†å²è®°å¿†å¤±è´¥: {e}")
            return []
    
    def _enhance_memory_ranking_with_spacy(self, query: str, memories: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """
        ä½¿ç”¨spaCyå¢å¼ºè®°å¿†æ’åº
        
        :param query: å½“å‰æŸ¥è¯¢
        :param memories: è®°å¿†åˆ—è¡¨
        :return: å¢å¼ºæ’åºåçš„è®°å¿†åˆ—è¡¨
        """
        try:
            # è·å–spaCyæŸ¥è¯¢é‡å†™å™¨
            from .spacy_query_rewriter import get_query_rewriter
            rewriter = get_query_rewriter(self.config)
            
            if not rewriter.nlp or not rewriter.spacy_available:
                logger.info("spaCyä¸å¯ç”¨ï¼Œä½¿ç”¨åŸå§‹è®°å¿†æ’åº")
                return memories
            
            enhanced_memories = []
            
            for memory in memories:
                # åŸºç¡€TF-IDFç›¸ä¼¼åº¦ï¼ˆç°æœ‰ï¼‰
                tfidf_score = memory.get('relevance_score', 0.0)
                
                # spaCyè¯­ä¹‰ç›¸ä¼¼åº¦ï¼ˆæ–°å¢ï¼‰
                semantic_score = self._calculate_semantic_similarity(query, memory['content'], rewriter.nlp)
                
                # å®ä½“åŒ¹é…åº¦ï¼ˆæ–°å¢ï¼‰
                entity_score = self._calculate_entity_similarity(query, memory['content'], rewriter.nlp)
                
                # æ—¶é—´è¡°å‡ï¼ˆä¿æŒç°æœ‰é€»è¾‘ï¼‰
                time_decay = self._calculate_time_decay(memory.get('created_at'))
                
                # ç»¼åˆè¯„åˆ†
                final_score = (
                    0.4 * tfidf_score +      # ä¿æŒç°æœ‰TF-IDFæƒé‡
                    0.3 * semantic_score +   # æ–°å¢è¯­ä¹‰ç›¸ä¼¼åº¦
                    0.2 * entity_score +     # æ–°å¢å®ä½“åŒ¹é…åº¦
                    0.1 * time_decay         # æ—¶é—´è¡°å‡
                )
                
                # æ·»åŠ å¢å¼ºè¯„åˆ†åˆ°è®°å¿†æ•°æ®
                enhanced_memory = memory.copy()
                enhanced_memory['enhanced_score'] = final_score
                enhanced_memory['tfidf_score'] = tfidf_score
                enhanced_memory['semantic_score'] = semantic_score
                enhanced_memory['entity_score'] = entity_score
                enhanced_memory['time_decay'] = time_decay
                
                enhanced_memories.append(enhanced_memory)
            
            # æŒ‰ç»¼åˆè¯„åˆ†æ’åº
            enhanced_memories.sort(key=lambda x: x['enhanced_score'], reverse=True)
            
            # é€‰æ‹©æœ€ä½³è®°å¿†ï¼ˆç¡®ä¿æœ€ä½åˆ†æ•°é˜ˆå€¼ï¼‰
            selected_memories = []
            for memory in enhanced_memories:
                if memory['enhanced_score'] >= 0.3:  # æœ€ä½ç›¸ä¼¼åº¦é˜ˆå€¼
                    selected_memories.append(memory)
            
            logger.info(f"spaCyå¢å¼ºæ’åº: åŸå§‹{len(memories)}æ¡ -> å¢å¼º{len(selected_memories)}æ¡")
            return selected_memories
            
        except Exception as e:
            logger.error(f"spaCyå¢å¼ºè®°å¿†æ’åºå¤±è´¥: {e}")
            return memories
    
    def _calculate_semantic_similarity(self, query: str, memory_content: str, nlp) -> float:
        """è®¡ç®—spaCyè¯­ä¹‰ç›¸ä¼¼åº¦"""
        try:
            query_doc = nlp(query)
            memory_doc = nlp(memory_content)
            return query_doc.similarity(memory_doc)
        except Exception as e:
            logger.warning(f"spaCyè¯­ä¹‰ç›¸ä¼¼åº¦è®¡ç®—å¤±è´¥: {e}")
            return 0.0
    
    def _calculate_entity_similarity(self, query: str, memory_content: str, nlp) -> float:
        """è®¡ç®—å®ä½“åŒ¹é…åº¦"""
        try:
            query_doc = nlp(query)
            memory_doc = nlp(memory_content)
            
            # æå–å®ä½“
            query_entities = [ent.text for ent in query_doc.ents]
            memory_entities = [ent.text for ent in memory_doc.ents]
            
            # è®¡ç®—å®ä½“é‡å åº¦
            if not query_entities or not memory_entities:
                return 0.0
            
            overlap = len(set(query_entities) & set(memory_entities))
            total = len(set(query_entities) | set(memory_entities))
            
            return overlap / total if total > 0 else 0.0
        except Exception as e:
            logger.warning(f"å®ä½“ç›¸ä¼¼åº¦è®¡ç®—å¤±è´¥: {e}")
            return 0.0
    
    def _calculate_time_decay(self, created_at_str: str) -> float:
        """è®¡ç®—æ—¶é—´è¡°å‡"""
        try:
            if not created_at_str:
                return 0.5  # é»˜è®¤å€¼
            
            from datetime import datetime, timezone
            created_at = datetime.fromisoformat(created_at_str.replace('Z', '+00:00'))
            now = datetime.now(timezone.utc)
            
            # è®¡ç®—æ—¶é—´å·®ï¼ˆå°æ—¶ï¼‰
            time_diff = (now - created_at).total_seconds() / 3600
            
            # æŒ‡æ•°è¡°å‡ï¼šè¶Šæ–°æƒé‡è¶Šé«˜
            decay_factor = 0.1
            return max(0.1, 1.0 / (1.0 + decay_factor * time_diff))
        except Exception as e:
            logger.warning(f"æ—¶é—´è¡°å‡è®¡ç®—å¤±è´¥: {e}")
            return 0.5
    
    def _rewrite_query_with_context(self, query: str, context_memories: List[Dict[str, Any]]) -> str:
        """
        åŸºäºå†å²è®°å¿†é‡å†™æŸ¥è¯¢ï¼Œè§£æä»£è¯æŒ‡ä»£ï¼ˆä½¿ç”¨spaCyï¼‰
        
        :param query: åŸå§‹æŸ¥è¯¢
        :param context_memories: å†å²è®°å¿†åˆ—è¡¨
        :return: é‡å†™åçš„æŸ¥è¯¢
        """
        try:
            logger.info(f"ğŸ”„ å¼€å§‹spaCyæŸ¥è¯¢é‡å†™åˆ†æ: '{query}'")
            
            # ä½¿ç”¨spaCyæŸ¥è¯¢é‡å†™å™¨
            query_rewriter = get_query_rewriter(self.config)
            rewritten_query = query_rewriter.rewrite_query_with_context(query, context_memories)
            
            if rewritten_query != query:
                logger.info(f"âœ… spaCyæŸ¥è¯¢é‡å†™æˆåŠŸ: '{query}' -> '{rewritten_query}'")
            else:
                logger.info(f"â­ï¸ æŸ¥è¯¢æ— éœ€é‡å†™: '{query}'")
            
            return rewritten_query
            
        except Exception as e:
            logger.error(f"spaCyæŸ¥è¯¢é‡å†™å¤±è´¥: {e}")
            # å¦‚æœspaCyå¤±è´¥ï¼Œå›é€€åˆ°ç®€å•ç‰ˆæœ¬
            return self._simple_rewrite_query_with_context(query, context_memories)
    
    def _simple_rewrite_query_with_context(self, query: str, context_memories: List[Dict[str, Any]]) -> str:
        """
        ç®€å•ç‰ˆæœ¬çš„æŸ¥è¯¢é‡å†™ï¼ˆspaCyä¸å¯ç”¨æ—¶çš„å¤‡é€‰æ–¹æ¡ˆï¼‰
        
        :param query: åŸå§‹æŸ¥è¯¢
        :param context_memories: å†å²è®°å¿†åˆ—è¡¨
        :return: é‡å†™åçš„æŸ¥è¯¢
        """
        try:
            logger.info(f"ğŸ”„ å¼€å§‹ç®€å•æŸ¥è¯¢é‡å†™åˆ†æ: '{query}'")
            
            # æ£€æŸ¥æ˜¯å¦åŒ…å«ä»£è¯
            pronouns = ['å®ƒ', 'ä»–', 'å¥¹', 'è¿™', 'é‚£', 'è¿™å®¶', 'é‚£å®¶', 'è¿™ä¸ª', 'é‚£ä¸ª', 'è¿™äº›', 'é‚£äº›']
            has_pronoun = any(pronoun in query for pronoun in pronouns)
            
            if not has_pronoun:
                logger.info(f"â­ï¸ æŸ¥è¯¢ä¸åŒ…å«ä»£è¯ï¼Œæ— éœ€é‡å†™: '{query}'")
                return query
            
            logger.info(f"ğŸ” æ£€æµ‹åˆ°ä»£è¯ï¼Œå¼€å§‹å®ä½“æå–: {[p for p in pronouns if p in query]}")
            
            # ä»å†å²è®°å¿†ä¸­æå–å®ä½“
            entities = self._extract_entities_from_memories(context_memories)
            logger.info(f"ğŸ“Š ä»å†å²è®°å¿†ä¸­æå–åˆ°å®ä½“: {entities}")
            
            if not entities:
                logger.info(f"âŒ æœªæ‰¾åˆ°ç›¸å…³å®ä½“ï¼Œä¿æŒåŸå§‹æŸ¥è¯¢: '{query}'")
                return query
            
            # é‡å†™æŸ¥è¯¢
            rewritten_query = self._replace_pronouns_with_entities(query, entities)
            logger.info(f"âœ… ç®€å•æŸ¥è¯¢é‡å†™å®Œæˆ: '{query}' -> '{rewritten_query}'")
            
            return rewritten_query
            
        except Exception as e:
            logger.error(f"ç®€å•æŸ¥è¯¢é‡å†™å¤±è´¥: {e}")
            return query
    
    def _extract_entities_from_memories(self, context_memories: List[Dict[str, Any]]) -> List[str]:
        """
        ä»å†å²è®°å¿†ä¸­æå–å®ä½“
        
        :param context_memories: å†å²è®°å¿†åˆ—è¡¨
        :return: å®ä½“åˆ—è¡¨
        """
        try:
            entities = []
            
            for memory in context_memories:
                content = memory.get('content', '')
                if not content:
                    continue
                
                # ç®€å•çš„å®ä½“æå–è§„åˆ™
                # 1. æå–å…¬å¸åç§°ï¼ˆåŒ…å«"å…¬å¸"ã€"é›†å›¢"ã€"ä¼ä¸š"ç­‰ï¼‰
                import re
                company_patterns = [
                    r'([^ï¼Œã€‚ï¼ï¼Ÿ\s]{2,10}(?:å…¬å¸|é›†å›¢|ä¼ä¸š|ç§‘æŠ€|è‚¡ä»½|æœ‰é™|æ§è‚¡))',
                    r'([^ï¼Œã€‚ï¼ï¼Ÿ\s]{2,10}(?:å›½é™…|é“¶è¡Œ|ä¿é™©|åŸºé‡‘|è¯åˆ¸))',
                ]
                
                for pattern in company_patterns:
                    matches = re.findall(pattern, content)
                    entities.extend(matches)
                
                # 2. æå–äººåï¼ˆç®€å•è§„åˆ™ï¼‰
                name_patterns = [
                    r'([^ï¼Œã€‚ï¼ï¼Ÿ\s]{2,4}(?:å…ˆç”Ÿ|å¥³å£«|åšå£«|æ•™æˆ|è€å¸ˆ))',
                ]
                
                for pattern in name_patterns:
                    matches = re.findall(pattern, content)
                    entities.extend(matches)
                
                # 3. æå–äº§å“åç§°ï¼ˆåŒ…å«"äº§å“"ã€"æœåŠ¡"ç­‰ï¼‰
                product_patterns = [
                    r'([^ï¼Œã€‚ï¼ï¼Ÿ\s]{2,10}(?:äº§å“|æœåŠ¡|æŠ€æœ¯|ç³»ç»Ÿ|å¹³å°))',
                ]
                
                for pattern in product_patterns:
                    matches = re.findall(pattern, content)
                    entities.extend(matches)
            
            # å»é‡å¹¶æ’åº
            entities = list(set(entities))
            entities.sort(key=len, reverse=True)  # æŒ‰é•¿åº¦æ’åºï¼Œä¼˜å…ˆåŒ¹é…é•¿å®ä½“
            
            logger.info(f"ğŸ“Š æå–åˆ°å®ä½“: {entities}")
            return entities
            
        except Exception as e:
            logger.error(f"å®ä½“æå–å¤±è´¥: {e}")
            return []
    
    def _replace_pronouns_with_entities(self, query: str, entities: List[str]) -> str:
        """
        å°†æŸ¥è¯¢ä¸­çš„ä»£è¯æ›¿æ¢ä¸ºå®ä½“
        
        :param query: åŸå§‹æŸ¥è¯¢
        :param entities: å®ä½“åˆ—è¡¨
        :return: æ›¿æ¢åçš„æŸ¥è¯¢
        """
        try:
            if not entities:
                return query
            
            rewritten_query = query
            
            # ä»£è¯æ›¿æ¢è§„åˆ™
            pronoun_replacements = {
                'å®ƒ': entities[0],  # ä½¿ç”¨ç¬¬ä¸€ä¸ªï¼ˆæœ€ç›¸å…³çš„ï¼‰å®ä½“
                'ä»–': entities[0],
                'å¥¹': entities[0],
                'è¿™': entities[0],
                'é‚£': entities[0],
                'è¿™å®¶': entities[0],
                'é‚£å®¶': entities[0],
                'è¿™ä¸ª': entities[0],
                'é‚£ä¸ª': entities[0],
                'è¿™äº›': entities[0],
                'é‚£äº›': entities[0],
            }
            
            # æ‰§è¡Œæ›¿æ¢
            for pronoun, entity in pronoun_replacements.items():
                if pronoun in rewritten_query:
                    rewritten_query = rewritten_query.replace(pronoun, entity)
                    logger.info(f"ğŸ”„ ä»£è¯æ›¿æ¢: '{pronoun}' -> '{entity}'")
            
            return rewritten_query
            
        except Exception as e:
            logger.error(f"ä»£è¯æ›¿æ¢å¤±è´¥: {e}")
            return query
