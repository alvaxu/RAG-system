"""
æ™ºèƒ½æŸ¥è¯¢å¤„ç†å™¨æ¨¡å—

RAGç³»ç»Ÿçš„æ™ºèƒ½æŸ¥è¯¢å¤„ç†å™¨ï¼Œè´Ÿè´£æ™ºèƒ½æŸ¥è¯¢ç±»å‹æ£€æµ‹å’Œå•ç±»å‹æŸ¥è¯¢å¤„ç†
ä¸¥æ ¼æŒ‰ç…§33.V3_RAGæŸ¥è¯¢å¤„ç†æ¨¡å—è¯¦ç»†è®¾è®¡æ–‡æ¡£å®ç°
"""

import logging
import time
from typing import Dict, List, Optional, Any

from .config_integration import ConfigIntegration
from .unified_services import UnifiedServices
from .common_models import QueryOptions, QueryResult
from .exceptions import (
    ServiceInitializationError,
    QueryProcessingError,
    ContentProcessingError,
    ConfigurationError
)

logger = logging.getLogger(__name__)


class SimpleSmartProcessor:
    """æ™ºèƒ½æŸ¥è¯¢å¤„ç†å™¨ - ä¸¥æ ¼æŒ‰ç…§è®¾è®¡æ–‡æ¡£å®ç°"""
    
    def __init__(self, config_integration: ConfigIntegration):
        """
        åˆå§‹åŒ–æ™ºèƒ½æŸ¥è¯¢å¤„ç†å™¨
        
        :param config_integration: é…ç½®é›†æˆç®¡ç†å™¨å®ä¾‹
        """
        self.config = config_integration
        
        try:
            # åˆå§‹åŒ–ç»Ÿä¸€æœåŠ¡æ¥å£
            self.unified_services = UnifiedServices(config_integration)
            
            logger.info("æ™ºèƒ½æŸ¥è¯¢å¤„ç†å™¨åˆå§‹åŒ–å®Œæˆ")
            
        except (ServiceInitializationError, ConfigurationError) as e:
            logger.error(f"æ™ºèƒ½æŸ¥è¯¢å¤„ç†å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
            raise ServiceInitializationError(f"æ™ºèƒ½æŸ¥è¯¢å¤„ç†å™¨åˆå§‹åŒ–å¤±è´¥: {e}") from e
        except Exception as e:
            logger.error(f"æ™ºèƒ½æŸ¥è¯¢å¤„ç†å™¨åˆå§‹åŒ–å¤±è´¥ï¼ˆæœªçŸ¥é”™è¯¯ï¼‰: {e}")
            raise ServiceInitializationError(f"æ™ºèƒ½æŸ¥è¯¢å¤„ç†å™¨åˆå§‹åŒ–å¤±è´¥: {e}") from e
    
    async def process_smart_query(self, query: str, options: QueryOptions) -> QueryResult:
        """
        æ™ºèƒ½æŸ¥è¯¢å¤„ç† - ä¸¥æ ¼æŒ‰ç…§è®¾è®¡æ–‡æ¡£å®ç°
        
        :param query: æŸ¥è¯¢æ–‡æœ¬
        :param options: æŸ¥è¯¢é€‰é¡¹
        :return: æ™ºèƒ½æŸ¥è¯¢ç»“æœ
        """
        start_time = time.time()
        
        try:
            logger.info(f"å¼€å§‹æ™ºèƒ½æŸ¥è¯¢å¤„ç†: {query[:50]}...")
            
            result = QueryResult()
            
            # 1. æ™ºèƒ½æŸ¥è¯¢ç±»å‹æ£€æµ‹
            detected_type, confidence = self._detect_type(query)
            result.query_type = detected_type
            
            # 2. æ ¹æ®æ£€æµ‹ç»“æœé€‰æ‹©å¤„ç†ç­–ç•¥
            if confidence >= 0.7:  # é«˜ç½®ä¿¡åº¦ï¼Œä½¿ç”¨å•ç±»å‹å¤„ç†
                result = await self._process_single_type(query, detected_type, options)
            else:  # ä½ç½®ä¿¡åº¦ï¼Œå›é€€åˆ°æ··åˆæŸ¥è¯¢
                logger.info(f"æ£€æµ‹ç½®ä¿¡åº¦è¾ƒä½({confidence:.2f})ï¼Œä½¿ç”¨æ··åˆæŸ¥è¯¢")
                result = await self._process_hybrid_query(query, options)
            
            # 3. æ›´æ–°å¤„ç†å…ƒæ•°æ®
            processing_time = time.time() - start_time
            result.processing_metadata = {
                'processing_time': processing_time,
                'detection_confidence': confidence,
                'detected_type': detected_type,
                'processing_strategy': 'smart_query'
            }
            
            result.success = True
            logger.info(f"æ™ºèƒ½æŸ¥è¯¢å¤„ç†å®Œæˆï¼Œè€—æ—¶: {processing_time:.2f}ç§’")
            
            return result
            
        except (QueryProcessingError, ContentProcessingError) as e:
            processing_time = time.time() - start_time
            error_msg = f"æ™ºèƒ½æŸ¥è¯¢å¤„ç†å¤±è´¥: {str(e)}"
            logger.error(error_msg)
            
            result = QueryResult()
            result.success = False
            result.error_message = error_msg
            result.processing_metadata = {
                'processing_time': processing_time,
                'error': str(e)
            }
            return result
        except Exception as e:
            processing_time = time.time() - start_time
            error_msg = f"æ™ºèƒ½æŸ¥è¯¢å¤„ç†å¤±è´¥ï¼ˆæœªçŸ¥é”™è¯¯ï¼‰: {str(e)}"
            logger.error(error_msg)
            
            result = QueryResult()
            result.success = False
            result.error_message = error_msg
            result.processing_metadata = {
                'processing_time': processing_time,
                'error': str(e)
            }
            return result
    
    async def process_single_type_query(self, query: str, content_type: str, 
                                      options: QueryOptions) -> QueryResult:
        """
        å•ç±»å‹æŸ¥è¯¢å¤„ç†
        
        :param query: æŸ¥è¯¢æ–‡æœ¬
        :param content_type: å†…å®¹ç±»å‹
        :param options: æŸ¥è¯¢é€‰é¡¹
        :return: æŸ¥è¯¢ç»“æœ
        """
        start_time = time.time()
        
        try:
            logger.info(f"å¼€å§‹å•ç±»å‹æŸ¥è¯¢å¤„ç†: {query[:50]}...ï¼Œç±»å‹: {content_type}")
            
            result = QueryResult()
            result.query_type = content_type
            
            # 1. è°ƒç”¨å¯¹åº”ç±»å‹æ£€ç´¢
            logger.info(f"å¼€å§‹{content_type}ç±»å‹å†…å®¹æ£€ç´¢ï¼Œæœ€å¤§ç»“æœ: {options.max_results}ï¼Œé˜ˆå€¼: {options.relevance_threshold}")
            content_types = [content_type]
            retrieval_results = await self.unified_services.retrieve(query, content_types, {
                'max_results': options.max_results,
                'relevance_threshold': options.relevance_threshold
            })
            
            logger.info(f"{content_type}ç±»å‹æ£€ç´¢å®Œæˆï¼Œè¿”å› {len(retrieval_results)} ä¸ªç»“æœ")
            
            if not retrieval_results:
                result.success = False
                result.error_message = "æ²¡æœ‰æ‰¾åˆ°ç›¸å…³çš„å†…å®¹"
                return result
            
            # 2. é‡æ’åº
            logger.info("å¼€å§‹é‡æ’åºå¤„ç†")
            reranked_results = await self.unified_services.rerank(query, retrieval_results)
            logger.info(f"é‡æ’åºå®Œæˆï¼Œè¿”å› {len(reranked_results)} ä¸ªç»“æœ")
            
            # 3. LLMé—®ç­”
            logger.info("ğŸ¤– å¼€å§‹LLMé—®ç­”ç”Ÿæˆ")
            context_memories = options.context_memories if hasattr(options, 'context_memories') else None
            logger.info(f"ğŸ“Š SimpleSmartProcessoræ”¶åˆ°context_memories:")
            logger.info(f"  - æ•°é‡: {len(context_memories) if context_memories else 0}")
            if context_memories:
                logger.info(f"  - å†å²è®°å¿†å†…å®¹:")
                for i, memory in enumerate(context_memories[:3]):
                    logger.info(f"    {i+1}. {memory.get('content', '')[:50]}...")
            else:
                logger.info(f"  - æ²¡æœ‰å†å²è®°å¿†")
            answer = await self.unified_services.generate_answer(query, reranked_results, context_memories)
            logger.info("âœ… LLMé—®ç­”ç”Ÿæˆå®Œæˆ")
            
            # 4. å­è¡¨åˆå¹¶ï¼ˆåœ¨è¾“å‡ºç»™å‰ç«¯å‰ï¼‰
            if content_type == 'table' and self.config.get('rag_system.table_merge.enabled', True):
                try:
                    logger.info(f"ğŸ”„ å¼€å§‹è¡¨æ ¼å­è¡¨åˆå¹¶ï¼Œè¾“å…¥ç»“æœæ•°é‡: {len(reranked_results)}")
                    
                    # è·å–å‘é‡æ•°æ®åº“é›†æˆå®ä¾‹
                    vector_db = self.unified_services.vector_db_integration
                    if vector_db:
                        # è®°å½•åˆå¹¶å‰çš„è¡¨æ ¼ç»“æœ
                        table_results_before = [r for r in reranked_results if r.get('chunk_type') == 'table']
                        logger.info(f"ğŸ”„ åˆå¹¶å‰è¡¨æ ¼ç»“æœæ•°é‡: {len(table_results_before)}")
                        for i, table_result in enumerate(table_results_before):
                            logger.info(f"  è¡¨æ ¼ {i+1}: chunk_id={table_result.get('chunk_id')}, is_subtable={table_result.get('metadata', {}).get('is_subtable', False)}")
                        
                        merged_results = vector_db.format_search_results_with_merge(reranked_results)
                        
                        # è®°å½•åˆå¹¶åçš„è¡¨æ ¼ç»“æœ
                        table_results_after = [r for r in merged_results if r.get('chunk_type') == 'table']
                        logger.info(f"ğŸ”„ åˆå¹¶åè¡¨æ ¼ç»“æœæ•°é‡: {len(table_results_after)}")
                        for i, table_result in enumerate(table_results_after):
                            logger.info(f"  è¡¨æ ¼ {i+1}: chunk_id={table_result.get('chunk_id')}, table_htmlé•¿åº¦={len(table_result.get('table_html', ''))}")
                        
                        logger.info(f"âœ… è¡¨æ ¼å­è¡¨åˆå¹¶å®Œæˆï¼ŒåŸå§‹ç»“æœ: {len(reranked_results)}ï¼Œåˆå¹¶åç»“æœ: {len(merged_results)}")
                        reranked_results = merged_results
                    else:
                        logger.warning("âš ï¸ æ— æ³•è·å–å‘é‡æ•°æ®åº“é›†æˆå®ä¾‹")
                except Exception as e:
                    logger.warning(f"âŒ è¡¨æ ¼å­è¡¨åˆå¹¶å¤±è´¥ï¼Œä½¿ç”¨åŸå§‹ç»“æœ: {e}")
            else:
                logger.info(f"â„¹ï¸ è·³è¿‡å­è¡¨åˆå¹¶ï¼Œcontent_type={content_type}, enabled={self.config.get('rag_system.table_merge.enabled', True)}")
            
            # 5. æ•´åˆç»“æœ
            result.success = True
            result.answer = answer
            result.results = reranked_results
            
            # 6. æ›´æ–°å¤„ç†å…ƒæ•°æ®
            processing_time = time.time() - start_time
            result.processing_metadata = {
                'processing_time': processing_time,
                'content_type': content_type,
                'results_count': len(reranked_results),
                'processing_strategy': 'single_type'
            }
            
            logger.info(f"å•ç±»å‹æŸ¥è¯¢å¤„ç†å®Œæˆï¼Œç±»å‹: {content_type}ï¼Œç»“æœæ•°é‡: {len(reranked_results)}")
            return result
            
        except Exception as e:
            processing_time = time.time() - start_time
            error_msg = f"å•ç±»å‹æŸ¥è¯¢å¤„ç†å¤±è´¥: {str(e)}"
            logger.error(error_msg)
            
            result = QueryResult()
            result.success = False
            result.error_message = error_msg
            result.processing_metadata = {
                'processing_time': processing_time,
                'content_type': content_type,
                'error': str(e)
            }
            return result
    
    async def _process_hybrid_query(self, query: str, options: QueryOptions) -> QueryResult:
        """
        å¤„ç†æ··åˆæŸ¥è¯¢ï¼ˆå½“æ™ºèƒ½æ£€æµ‹ä¸æ˜ç¡®æ—¶ï¼‰
        
        :param query: æŸ¥è¯¢æ–‡æœ¬
        :param options: æŸ¥è¯¢é€‰é¡¹
        :return: æŸ¥è¯¢ç»“æœ
        """
        try:
            logger.info(f"å¼€å§‹æ··åˆæŸ¥è¯¢å¤„ç†: {query[:50]}...")
            
            result = QueryResult()
            result.query_type = 'hybrid'
            
            # 1. å¹¶è¡Œæ£€ç´¢æ‰€æœ‰ç±»å‹
            logger.info(f"å¼€å§‹æ··åˆå†…å®¹æ£€ç´¢ï¼Œæœ€å¤§ç»“æœ: {options.max_results}ï¼Œé˜ˆå€¼: {options.relevance_threshold}")
            retrieval_results = await self.unified_services.retrieve(query, None, {
                'max_results': options.max_results,
                'relevance_threshold': options.relevance_threshold
            })
            
            logger.info(f"æ··åˆå†…å®¹æ£€ç´¢å®Œæˆï¼Œè¿”å› {len(retrieval_results)} ä¸ªç»“æœ")
            
            if not retrieval_results:
                result.success = False
                result.error_message = "æ²¡æœ‰æ‰¾åˆ°ç›¸å…³çš„å†…å®¹"
                return result
            
            # 2. é‡æ’åº
            logger.info("å¼€å§‹é‡æ’åºå¤„ç†")
            reranked_results = await self.unified_services.rerank(query, retrieval_results)
            logger.info(f"é‡æ’åºå®Œæˆï¼Œè¿”å› {len(reranked_results)} ä¸ªç»“æœ")
            
            # 3. LLMé—®ç­”
            logger.info("ğŸ¤– å¼€å§‹LLMé—®ç­”ç”Ÿæˆ")
            context_memories = options.context_memories if hasattr(options, 'context_memories') else None
            logger.info(f"ğŸ“Š SimpleSmartProcessoræ”¶åˆ°context_memories:")
            logger.info(f"  - æ•°é‡: {len(context_memories) if context_memories else 0}")
            if context_memories:
                logger.info(f"  - å†å²è®°å¿†å†…å®¹:")
                for i, memory in enumerate(context_memories[:3]):
                    logger.info(f"    {i+1}. {memory.get('content', '')[:50]}...")
            else:
                logger.info(f"  - æ²¡æœ‰å†å²è®°å¿†")
            answer = await self.unified_services.generate_answer(query, reranked_results, context_memories)
            logger.info("âœ… LLMé—®ç­”ç”Ÿæˆå®Œæˆ")
            
            # 4. å­è¡¨åˆå¹¶ï¼ˆåœ¨è¾“å‡ºç»™å‰ç«¯å‰ï¼‰
            if self.config.get('rag_system.table_merge.enabled', True):
                try:
                    # è·å–å‘é‡æ•°æ®åº“é›†æˆå®ä¾‹
                    vector_db = self.unified_services.vector_db_integration
                    if vector_db:
                        merged_results = vector_db.format_search_results_with_merge(reranked_results)
                        logger.info(f"è¡¨æ ¼å­è¡¨åˆå¹¶å®Œæˆï¼ŒåŸå§‹ç»“æœ: {len(reranked_results)}ï¼Œåˆå¹¶åç»“æœ: {len(merged_results)}")
                        reranked_results = merged_results
                except Exception as e:
                    logger.warning(f"è¡¨æ ¼å­è¡¨åˆå¹¶å¤±è´¥ï¼Œä½¿ç”¨åŸå§‹ç»“æœ: {e}")
            
            # 5. æ•´åˆç»“æœ
            result.success = True
            result.answer = answer
            result.results = reranked_results
            
            logger.info(f"æ··åˆæŸ¥è¯¢å¤„ç†å®Œæˆï¼Œæœ€ç»ˆç»“æœæ•°é‡: {len(reranked_results)}")
            return result
            
        except Exception as e:
            error_msg = f"æ··åˆæŸ¥è¯¢å¤„ç†å¤±è´¥: {str(e)}"
            logger.error(error_msg)
            
            result = QueryResult()
            result.success = False
            result.error_message = error_msg
            return result
    
    def _detect_type(self, query: str) -> tuple[str, float]:
        """
        æŸ¥è¯¢ç±»å‹æ£€æµ‹ - ä¸¥æ ¼æŒ‰ç…§è®¾è®¡æ–‡æ¡£å®ç°
        
        :param query: æŸ¥è¯¢æ–‡æœ¬
        :return: (æ£€æµ‹ç±»å‹, ç½®ä¿¡åº¦)
        """
        try:
            # å›¾ç‰‡ç›¸å…³å…³é”®è¯æ£€æµ‹
            image_keywords = ['å›¾ç‰‡', 'å›¾åƒ', 'ç…§ç‰‡', 'å›¾è¡¨', 'æˆªå›¾', 'ç•Œé¢', 'æ˜¾ç¤º', 'å±•ç¤º', 'å›¾æ ‡', 'logo']
            image_matches = sum(1 for keyword in image_keywords if keyword in query)
            
            # è¡¨æ ¼ç›¸å…³å…³é”®è¯æ£€æµ‹
            table_keywords = ['è¡¨æ ¼', 'æ•°æ®', 'ç»Ÿè®¡', 'æ•°å­—', 'é‡‘é¢', 'æ•°é‡', 'æ¯”ä¾‹', 'ç™¾åˆ†æ¯”', 'æ’å', 'å¯¹æ¯”', 
                            'è¥æ”¶', 'æ”¶å…¥', 'åˆ©æ¶¦', 'è´¢åŠ¡', 'ä¸šç»©', 'æŠ¥å‘Š', 'å¹´æŠ¥', 'åŠå¹´æŠ¥', 'å­£åº¦', 'é¢„æµ‹', 
                            'è¶‹åŠ¿', 'å˜åŒ–', 'å¢é•¿', 'ä¸‹é™', 'ä¸Šå‡', 'ä¸‹è·Œ', 'åˆ†æ', 'æŒ‡æ ‡', 'æ¯”ç‡']
            table_matches = sum(1 for keyword in table_keywords if keyword in query)
            
            # æ–‡æœ¬ç›¸å…³ç‰¹å¾
            text_features = len(query) > 20  # é•¿æ–‡æœ¬å€¾å‘äºæ–‡æœ¬æŸ¥è¯¢
            
            # è®¡ç®—å„ç±»å‹çš„åŒ¹é…åˆ†æ•°
            image_score = image_matches / len(image_keywords) if image_keywords else 0
            table_score = table_matches / len(table_keywords) if table_keywords else 0
            text_score = 0.5 if text_features else 0.3
            
            # ç¡®å®šç±»å‹å’Œç½®ä¿¡åº¦
            if image_score > 0.3 and table_score > 0.3:
                # æ··åˆç±»å‹
                return 'hybrid', min(max(image_score, table_score), 0.8)
            elif image_score > 0.3:
                # å›¾ç‰‡ç±»å‹
                confidence = min(image_score + 0.2, 0.9)
                return 'image', confidence
            elif table_score > 0.1:
                # è¡¨æ ¼ç±»å‹
                confidence = min(table_score + 0.2, 0.9)
                return 'table', confidence
            elif text_score > 0.4:
                # æ–‡æœ¬ç±»å‹
                confidence = min(text_score + 0.1, 0.8)
                return 'text', confidence
            else:
                # é»˜è®¤æ–‡æœ¬ç±»å‹ï¼Œç½®ä¿¡åº¦è¾ƒä½
                return 'text', 0.5
                
        except Exception as e:
            logger.warning(f"æŸ¥è¯¢ç±»å‹æ£€æµ‹å¤±è´¥: {e}ï¼Œä½¿ç”¨é»˜è®¤æ–‡æœ¬ç±»å‹")
            return 'text', 0.3
    
    def get_service_status(self) -> Dict[str, Any]:
        """è·å–æœåŠ¡çŠ¶æ€ä¿¡æ¯"""
        return {
            'status': 'ready',
            'service_type': 'SimpleSmartProcessor',
            'unified_services': self.unified_services is not None,
            'features': [
                'type_detection',
                'single_type_processing',
                'hybrid_fallback',
                'confidence_based_routing'
            ]
        }
