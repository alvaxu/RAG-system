"""
æ··åˆæœç´¢ç­–ç•¥ä¼˜åŒ–åŠŸèƒ½æµ‹è¯•

æµ‹è¯•å¬å›å¼•æ“çš„æ··åˆæœç´¢ç­–ç•¥ä¼˜åŒ–åŠŸèƒ½ï¼ŒåŒ…æ‹¬è·¨ç±»å‹å†…å®¹ç›¸å…³æ€§è®¡ç®—å’Œæ™ºèƒ½èåˆæœç´¢ç»“æœ
"""

import unittest
from unittest.mock import Mock, MagicMock
import sys
import os

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from core.retrieval import RetrievalEngine


class MockConfigIntegration:
    """æ¨¡æ‹Ÿé…ç½®é›†æˆç®¡ç†å™¨"""
    
    def __init__(self):
        self.config_data = {
            'rag_system.engines.hybrid_engine': {
                'enabled': True,
                'max_results': 25,
                'weights': {'image': 0.3, 'text': 0.4, 'table': 0.3},
                'cross_type_boost': 0.2
            },
            'rag_system.engines.text_engine': {
                'enabled': True,
                'max_results': 30,
                'similarity_threshold': 0.7,
                'use_keyword_search': True,
                'use_expansion_search': True
            },
            'rag_system.engines.image_engine': {
                'enabled': True,
                'max_results': 20,
                'similarity_threshold': 0.3,
                'use_keyword_search': True,
                'use_expansion_search': True
            },
            'rag_system.engines.table_engine': {
                'enabled': True,
                'max_results': 15,
                'similarity_threshold': 0.65,
                'use_semantic_search': True,
                'use_keyword_search': True,
                'use_expansion_search': True
            }
        }
    
    def get(self, key, default=None):
        """è·å–é…ç½®å€¼"""
        keys = key.split('.')
        value = self.config_data
        for k in keys:
            if isinstance(value, dict) and k in value:
                value = value[k]
            else:
                return default
        return value


class MockVectorDBIntegration:
    """æ¨¡æ‹Ÿå‘é‡æ•°æ®åº“é›†æˆç®¡ç†å™¨"""
    
    def __init__(self):
        # æ¨¡æ‹Ÿæ–‡æœ¬æ•°æ®
        self.mock_texts = [
            {
                'chunk_id': 'text_001',
                'content': 'äººå·¥æ™ºèƒ½æŠ€æœ¯åœ¨åŒ»ç–—é¢†åŸŸçš„åº”ç”¨ç ”ç©¶',
                'content_type': 'text',
                'similarity_score': 0.85,
                'metadata': {
                    'title': 'AIåŒ»ç–—åº”ç”¨ç ”ç©¶',
                    'description': 'æ¢è®¨AIåœ¨åŒ»ç–—è¯Šæ–­å’Œæ²»ç–—ä¸­çš„åº”ç”¨',
                    'keywords': ['äººå·¥æ™ºèƒ½', 'åŒ»ç–—', 'è¯Šæ–­', 'æ²»ç–—'],
                    'category': 'technology'
                }
            },
            {
                'chunk_id': 'text_002',
                'content': 'æœºå™¨å­¦ä¹ ç®—æ³•åœ¨é‡‘èé£æ§ä¸­çš„åº”ç”¨',
                'content_type': 'text',
                'similarity_score': 0.78,
                'metadata': {
                    'title': 'MLé‡‘èé£æ§åº”ç”¨',
                    'description': 'æœºå™¨å­¦ä¹ åœ¨é‡‘èé£é™©æ§åˆ¶ä¸­çš„åº”ç”¨æ¡ˆä¾‹',
                    'keywords': ['æœºå™¨å­¦ä¹ ', 'é‡‘è', 'é£æ§', 'ç®—æ³•'],
                    'category': 'finance'
                }
            }
        ]
        
        # æ¨¡æ‹Ÿå›¾ç‰‡æ•°æ® - å¢åŠ æ›´å¤šåŒ¹é…å…³é”®è¯
        self.mock_images = [
            {
                'chunk_id': 'img_001',
                'content': 'åŒ»ç–—AIè¯Šæ–­ç³»ç»Ÿç•Œé¢æˆªå›¾',
                'content_type': 'image',
                'similarity_score': 0.82,
                'metadata': {
                    'title': 'AIè¯Šæ–­ç³»ç»Ÿç•Œé¢',
                    'description': 'åŒ»ç–—AIè¯Šæ–­ç³»ç»Ÿçš„ç”¨æˆ·ç•Œé¢æˆªå›¾',
                    'keywords': ['AIè¯Šæ–­', 'åŒ»ç–—', 'ç•Œé¢', 'ç³»ç»Ÿ', 'äººå·¥æ™ºèƒ½', 'è¯Šæ–­', 'æ²»ç–—'],
                    'category': 'medical'
                }
            },
            {
                'chunk_id': 'img_002',
                'content': 'é‡‘èæ•°æ®åˆ†æå›¾è¡¨',
                'content_type': 'image',
                'similarity_score': 0.75,
                'metadata': {
                    'title': 'é‡‘èæ•°æ®åˆ†æå›¾',
                    'description': 'é‡‘èé£é™©åˆ†æçš„æ•°æ®å¯è§†åŒ–å›¾è¡¨',
                    'keywords': ['é‡‘è', 'æ•°æ®åˆ†æ', 'å›¾è¡¨', 'é£æ§', 'æœºå™¨å­¦ä¹ ', 'ç®—æ³•'],
                    'category': 'finance'
                }
            },
            {
                'chunk_id': 'img_003',
                'content': 'AIæŠ€æœ¯åº”ç”¨åœºæ™¯å›¾',
                'content_type': 'image',
                'similarity_score': 0.88,
                'metadata': {
                    'title': 'AIæŠ€æœ¯åº”ç”¨',
                    'description': 'äººå·¥æ™ºèƒ½æŠ€æœ¯åœ¨å„é¢†åŸŸçš„åº”ç”¨åœºæ™¯',
                    'keywords': ['äººå·¥æ™ºèƒ½', 'AI', 'æŠ€æœ¯', 'åº”ç”¨', 'åœºæ™¯', 'åˆ›æ–°'],
                    'category': 'technology'
                }
            }
        ]
        
        # æ¨¡æ‹Ÿè¡¨æ ¼æ•°æ®
        self.mock_tables = [
            {
                'chunk_id': 'table_001',
                'content': 'AIåŒ»ç–—è¯Šæ–­å‡†ç¡®ç‡ç»Ÿè®¡è¡¨',
                'content_type': 'table',
                'similarity_score': 0.80,
                'metadata': {
                    'title': 'AIè¯Šæ–­å‡†ç¡®ç‡ç»Ÿè®¡',
                    'description': 'ä¸åŒAIæ¨¡å‹åœ¨åŒ»ç–—è¯Šæ–­ä¸­çš„å‡†ç¡®ç‡å¯¹æ¯”',
                    'keywords': ['AIè¯Šæ–­', 'å‡†ç¡®ç‡', 'åŒ»ç–—', 'ç»Ÿè®¡', 'äººå·¥æ™ºèƒ½', 'è¯Šæ–­'],
                    'category': 'medical'
                }
            }
        ]
    
    def search_texts(self, query, max_results, threshold):
        """æ¨¡æ‹Ÿæ–‡æœ¬æœç´¢"""
        results = []
        query_lower = query.lower()
        for text in self.mock_texts:
            # æ£€æŸ¥æ ‡é¢˜ã€æè¿°ã€å…³é”®è¯æ˜¯å¦åŒ¹é…
            if (any(keyword.lower() in query_lower for keyword in text['metadata']['keywords']) or
                text['metadata']['title'].lower() in query_lower or
                text['metadata']['description'].lower() in query_lower):
                results.append(text)
        return results[:max_results]
    
    def search_images(self, query, max_results, threshold):
        """æ¨¡æ‹Ÿå›¾ç‰‡æœç´¢ - æ”¹è¿›åŒ¹é…é€»è¾‘"""
        results = []
        query_lower = query.lower()
        
        for image in self.mock_images:
            # æ£€æŸ¥æ ‡é¢˜ã€æè¿°ã€å…³é”®è¯æ˜¯å¦åŒ¹é…
            if (any(keyword.lower() in query_lower for keyword in image['metadata']['keywords']) or
                image['metadata']['title'].lower() in query_lower or
                image['metadata']['description'].lower() in query_lower):
                results.append(image)
        
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°åŒ¹é…çš„å›¾ç‰‡ï¼Œè¿”å›ä¸€äº›ç›¸å…³çš„å›¾ç‰‡ï¼ˆé¿å…é™çº§ï¼‰
        if not results and 'AI' in query or 'äººå·¥æ™ºèƒ½' in query:
            results = [self.mock_images[0]]  # è¿”å›AIç›¸å…³çš„å›¾ç‰‡
        elif not results and 'åŒ»ç–—' in query:
            results = [self.mock_images[0]]  # è¿”å›åŒ»ç–—ç›¸å…³çš„å›¾ç‰‡
        elif not results and 'é‡‘è' in query:
            results = [self.mock_images[1]]  # è¿”å›é‡‘èç›¸å…³çš„å›¾ç‰‡
        
        return results[:max_results]
    
    def search_tables(self, query, max_results, threshold):
        """æ¨¡æ‹Ÿè¡¨æ ¼æœç´¢"""
        results = []
        query_lower = query.lower()
        for table in self.mock_tables:
            if (any(keyword.lower() in query_lower for keyword in table['metadata']['keywords']) or
                table['metadata']['title'].lower() in query_lower or
                table['metadata']['description'].lower() in query_lower):
                results.append(table)
        return results[:max_results]


def create_test_retrieval_engine():
    """åˆ›å»ºæµ‹è¯•ç”¨çš„å¬å›å¼•æ“å®ä¾‹"""
    mock_config = MockConfigIntegration()
    mock_vector_db = MockVectorDBIntegration()
    return RetrievalEngine(mock_config, mock_vector_db)


class TestHybridSearch(unittest.TestCase):
    """æ··åˆæœç´¢ç­–ç•¥ä¼˜åŒ–æµ‹è¯•ç±»"""
    
    def setUp(self):
        """æµ‹è¯•å‰å‡†å¤‡"""
        self.engine = create_test_retrieval_engine()
    
    def test_cross_type_relevance_calculation(self):
        """æµ‹è¯•è·¨ç±»å‹ç›¸å…³æ€§è®¡ç®—"""
        # åˆ›å»ºæµ‹è¯•æ•°æ®
        text_result = {
            'content': 'äººå·¥æ™ºèƒ½åœ¨åŒ»ç–—é¢†åŸŸçš„åº”ç”¨',
            'metadata': {'title': 'AIåŒ»ç–—åº”ç”¨', 'keywords': ['AI', 'åŒ»ç–—']}
        }
        
        image_result = {
            'content': 'åŒ»ç–—AIç³»ç»Ÿç•Œé¢',
            'metadata': {'title': 'AIç³»ç»Ÿç•Œé¢', 'keywords': ['AI', 'åŒ»ç–—', 'ç•Œé¢']}
        }
        
        # æµ‹è¯•è·¨ç±»å‹ç›¸å…³æ€§è®¡ç®—
        cross_score = self.engine._calculate_cross_type_relevance(
            text_result, [image_result], "AIåŒ»ç–—åº”ç”¨"
        )
        
        self.assertIsInstance(cross_score, float)
        self.assertGreaterEqual(cross_score, 0.0)
        self.assertLessEqual(cross_score, 1.0)
    
    def test_cross_content_similarity(self):
        """æµ‹è¯•è·¨å†…å®¹ç›¸ä¼¼åº¦è®¡ç®—"""
        content1 = "äººå·¥æ™ºèƒ½åœ¨åŒ»ç–—è¯Šæ–­ä¸­çš„åº”ç”¨"
        content2 = "AIåŒ»ç–—è¯Šæ–­ç³»ç»Ÿç•Œé¢"
        metadata1 = {'title': 'AIåŒ»ç–—åº”ç”¨', 'keywords': ['AI', 'åŒ»ç–—', 'è¯Šæ–­']}
        metadata2 = {'title': 'AIè¯Šæ–­ç³»ç»Ÿ', 'keywords': ['AI', 'åŒ»ç–—', 'è¯Šæ–­', 'ç³»ç»Ÿ']}
        
        similarity = self.engine._calculate_cross_content_similarity(
            content1, content2, metadata1, metadata2
        )
        
        self.assertIsInstance(similarity, float)
        self.assertGreaterEqual(similarity, 0.0)
        self.assertLessEqual(similarity, 1.0)
    
    def test_metadata_similarity(self):
        """æµ‹è¯•å…ƒæ•°æ®ç›¸ä¼¼åº¦è®¡ç®—"""
        metadata1 = {
            'title': 'AIåŒ»ç–—åº”ç”¨ç ”ç©¶',
            'description': 'äººå·¥æ™ºèƒ½åœ¨åŒ»ç–—é¢†åŸŸçš„åº”ç”¨',
            'keywords': ['AI', 'åŒ»ç–—', 'åº”ç”¨']
        }
        
        metadata2 = {
            'title': 'åŒ»ç–—AIç³»ç»Ÿç ”ç©¶',
            'description': 'åŒ»ç–—é¢†åŸŸçš„äººå·¥æ™ºèƒ½ç³»ç»Ÿ',
            'keywords': ['åŒ»ç–—', 'AI', 'ç³»ç»Ÿ']
        }
        
        similarity = self.engine._calculate_metadata_similarity(metadata1, metadata2)
        
        self.assertIsInstance(similarity, float)
        self.assertGreaterEqual(similarity, 0.0)
        self.assertLessEqual(similarity, 1.0)
    
    def test_keyword_extraction(self):
        """æµ‹è¯•å…³é”®è¯æå–"""
        content = "äººå·¥æ™ºèƒ½æŠ€æœ¯åœ¨åŒ»ç–—è¯Šæ–­å’Œæ²»ç–—ä¸­çš„åº”ç”¨ç ”ç©¶ï¼ŒåŒ…æ‹¬æœºå™¨å­¦ä¹ ç®—æ³•å’Œæ·±åº¦å­¦ä¹ æ¨¡å‹"
        
        keywords = self.engine._extract_keywords_from_content(content)
        
        self.assertIsInstance(keywords, list)
        self.assertTrue(len(keywords) > 0)
        # æ£€æŸ¥æ˜¯å¦åŒ…å«é¢„æœŸå…³é”®è¯
        expected_keywords = ['äººå·¥æ™ºèƒ½', 'åŒ»ç–—', 'è¯Šæ–­', 'æ²»ç–—', 'æœºå™¨å­¦ä¹ ', 'æ·±åº¦å­¦ä¹ ']
        found_keywords = [kw for kw in expected_keywords if kw in keywords]
        self.assertTrue(len(found_keywords) > 0)
    
    def test_keyword_set_similarity(self):
        """æµ‹è¯•å…³é”®è¯é›†åˆç›¸ä¼¼åº¦"""
        keywords1 = ['AI', 'åŒ»ç–—', 'è¯Šæ–­', 'æ²»ç–—']
        keywords2 = ['AI', 'åŒ»ç–—', 'è¯Šæ–­', 'ç³»ç»Ÿ']
        
        similarity = self.engine._calculate_keyword_set_similarity(keywords1, keywords2)
        
        self.assertIsInstance(similarity, float)
        self.assertGreaterEqual(similarity, 0.0)
        self.assertLessEqual(similarity, 1.0)
        # åº”è¯¥æœ‰3ä¸ªå…±åŒå…³é”®è¯ï¼Œæ€»å…±5ä¸ªä¸åŒå…³é”®è¯ï¼Œç›¸ä¼¼åº¦åº”è¯¥æ˜¯3/5=0.6
        self.assertAlmostEqual(similarity, 0.6, places=1)
    
    def test_diversity_strategy(self):
        """æµ‹è¯•å¤šæ ·æ€§ç­–ç•¥"""
        # åˆ›å»ºæµ‹è¯•ç»“æœ
        test_results = [
            {'content_type': 'text', 'content': 'AIåŒ»ç–—åº”ç”¨', 'final_score': 0.9},
            {'content_type': 'image', 'content': 'åŒ»ç–—ç•Œé¢', 'final_score': 0.8},
            {'content_type': 'table', 'content': 'åŒ»ç–—æ•°æ®', 'final_score': 0.7},
            {'content_type': 'text', 'content': 'å¦ä¸€ä¸ªAIåº”ç”¨', 'final_score': 0.6}
        ]
        
        diverse_results = self.engine._apply_diversity_strategy(test_results, 3)
        
        self.assertIsInstance(diverse_results, list)
        self.assertLessEqual(len(diverse_results), 3)
        
        # æ£€æŸ¥å†…å®¹ç±»å‹å¤šæ ·æ€§
        content_types = [r['content_type'] for r in diverse_results]
        unique_types = set(content_types)
        self.assertGreaterEqual(len(unique_types), 2)  # è‡³å°‘åº”è¯¥æœ‰2ç§ä¸åŒç±»å‹
    
    def test_content_type_balance(self):
        """æµ‹è¯•å†…å®¹ç±»å‹å¹³è¡¡ç­–ç•¥"""
        # åˆ›å»ºæµ‹è¯•ç»“æœ - ç¡®ä¿æœ‰è¶³å¤Ÿçš„ä¸åŒç±»å‹
        test_results = [
            {'content_type': 'text', 'content': 'å†…å®¹1', 'final_score': 0.9},
            {'content_type': 'image', 'content': 'å›¾ç‰‡1', 'final_score': 0.8},
            {'content_type': 'table', 'content': 'è¡¨æ ¼1', 'final_score': 0.7},
            {'content_type': 'text', 'content': 'å†…å®¹2', 'final_score': 0.6},
            {'content_type': 'image', 'content': 'å›¾ç‰‡2', 'final_score': 0.5}
        ]
        
        # æµ‹è¯•ä¸åŒçš„max_resultså€¼
        balanced_results_3 = self.engine._apply_content_type_balance(test_results, 3)
        balanced_results_5 = self.engine._apply_content_type_balance(test_results, 5)
        
        # æ£€æŸ¥3ä¸ªç»“æœçš„æƒ…å†µ
        self.assertIsInstance(balanced_results_3, list)
        self.assertLessEqual(len(balanced_results_3), 3)
        
        # æ£€æŸ¥5ä¸ªç»“æœçš„æƒ…å†µ
        self.assertIsInstance(balanced_results_5, list)
        self.assertLessEqual(len(balanced_results_5), 5)
        
        # æ£€æŸ¥ç±»å‹åˆ†å¸ƒ - åº”è¯¥åŒ…å«å¤šç§ç±»å‹
        if len(balanced_results_3) >= 2:
            content_types_3 = [r['content_type'] for r in balanced_results_3]
            unique_types_3 = set(content_types_3)
            self.assertGreaterEqual(len(unique_types_3), 1)  # è‡³å°‘1ç§ç±»å‹
        
        if len(balanced_results_5) >= 2:
            content_types_5 = [r['content_type'] for r in balanced_results_5]
            unique_types_5 = set(content_types_5)
            self.assertGreaterEqual(len(unique_types_5), 2)  # è‡³å°‘2ç§ç±»å‹
    
    def test_hybrid_retrieval_integration(self):
        """æµ‹è¯•æ··åˆå¬å›é›†æˆåŠŸèƒ½"""
        query = "AIåŒ»ç–—åº”ç”¨"
        results = self.engine.retrieve_hybrid(query, max_results=10)
        
        self.assertIsInstance(results, list)
        self.assertLessEqual(len(results), 10)
        
        # æ£€æŸ¥ç»“æœç»“æ„
        if results:
            result = results[0]
            self.assertIn('final_score', result)
            self.assertIn('cross_type_score', result)
    
    def test_edge_cases(self):
        """æµ‹è¯•è¾¹ç•Œæƒ…å†µ"""
        # æµ‹è¯•ç©ºæŸ¥è¯¢
        empty_results = self.engine.retrieve_hybrid("", max_results=5)
        self.assertIsInstance(empty_results, list)
        
        # æµ‹è¯•æ— ç»“æœæŸ¥è¯¢
        no_results = self.engine.retrieve_hybrid("ä¸å­˜åœ¨çš„æŸ¥è¯¢", max_results=5)
        self.assertIsInstance(no_results, list)
        
        # æµ‹è¯•é›¶é˜ˆå€¼
        zero_threshold_results = self.engine._calculate_cross_type_relevance(
            {}, [], ""
        )
        self.assertEqual(zero_threshold_results, 0.0)


def run_hybrid_search_tests():
    """è¿è¡Œæ··åˆæœç´¢ç­–ç•¥ä¼˜åŒ–æµ‹è¯•"""
    print("ğŸ§ª å¼€å§‹æ··åˆæœç´¢ç­–ç•¥ä¼˜åŒ–åŠŸèƒ½æµ‹è¯•...")
    
    # åˆ›å»ºæµ‹è¯•å¥—ä»¶
    test_suite = unittest.TestLoader().loadTestsFromTestCase(TestHybridSearch)
    
    # è¿è¡Œæµ‹è¯•
    runner = unittest.TextTestRunner(verbosity=2)
    result = runner.run(test_suite)
    
    # è¾“å‡ºæµ‹è¯•ç»“æœ
    if result.wasSuccessful():
        print("âœ… æ··åˆæœç´¢ç­–ç•¥ä¼˜åŒ–åŠŸèƒ½æµ‹è¯•å…¨éƒ¨é€šè¿‡")
        print(f"ğŸ“Š æµ‹è¯•ç»“æœ: {result.testsRun} ä¸ªæµ‹è¯•é€šè¿‡")
    else:
        print("âŒ æ··åˆæœç´¢ç­–ç•¥ä¼˜åŒ–åŠŸèƒ½æµ‹è¯•å­˜åœ¨å¤±è´¥")
        print(f"ğŸ“Š æµ‹è¯•ç»“æœ: {result.testsRun} ä¸ªæµ‹è¯•ï¼Œ{len(result.failures)} ä¸ªå¤±è´¥ï¼Œ{len(result.errors)} ä¸ªé”™è¯¯")
    
    return result.wasSuccessful()


if __name__ == '__main__':
    run_hybrid_search_tests()
