"""
é…ç½®éªŒè¯æµ‹è¯•è„šæœ¬

æµ‹è¯•é…ç½®éªŒè¯å™¨çš„å„é¡¹åŠŸèƒ½ï¼Œç¡®ä¿ç¬¦åˆæŠ€æœ¯è§„èŒƒè¦æ±‚
"""

import json
import logging
from core.config_validator import ConfigValidator
from core.exceptions import ConfigurationError, ValidationError

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)

logger = logging.getLogger(__name__)


def test_valid_config():
    """æµ‹è¯•æœ‰æ•ˆé…ç½®"""
    print("\nğŸ§ª æµ‹è¯•æœ‰æ•ˆé…ç½®...")
    
    valid_config = {
        "enabled": True,
        "version": "3.0.0",
        "models": {
            "llm": {
                "model_name": "qwen-turbo",
                "max_tokens": 2048,
                "temperature": 0.7
            },
            "reranking": {
                "model_name": "gte-rerank-v2",
                "batch_size": 32,
                "similarity_threshold": 0.7
            }
        },
        "query_processing": {
            "max_context_length": 4000,
            "max_results": 10,
            "relevance_threshold": 0.5
        },
        "engines": {
            "text_engine": {
                "enabled": True,
                "max_results": 10,
                "similarity_threshold": 0.7
            },
            "image_engine": {
                "enabled": True,
                "max_results": 20,
                "similarity_threshold": 0.3
            },
            "table_engine": {
                "enabled": True,
                "max_results": 15,
                "similarity_threshold": 0.65
            }
        },
        "performance": {
            "max_concurrent_queries": 10,
            "query_timeout": 60,
            "enable_monitoring": True
        }
    }
    
    try:
        validator = ConfigValidator()
        result = validator.validate_config(valid_config)
        print(f"âœ… æœ‰æ•ˆé…ç½®éªŒè¯é€šè¿‡: {result}")
        return True
    except Exception as e:
        print(f"âŒ æœ‰æ•ˆé…ç½®éªŒè¯å¤±è´¥: {e}")
        return False


def test_invalid_config():
    """æµ‹è¯•æ— æ•ˆé…ç½®"""
    print("\nğŸ§ª æµ‹è¯•æ— æ•ˆé…ç½®...")
    
    invalid_configs = [
        {
            "name": "ç¼ºå°‘å¿…éœ€å­—æ®µ",
            "config": {
                "enabled": True
                # ç¼ºå°‘å…¶ä»–å¿…éœ€å­—æ®µ
            }
        },
        {
            "name": "å­—æ®µç±»å‹é”™è¯¯",
            "config": {
                "enabled": "not_a_boolean",  # åº”è¯¥æ˜¯å¸ƒå°”å€¼
                "version": "3.0.0",
                "models": {},
                "query_processing": {},
                "engines": {},
                "performance": {}
            }
        },
        {
            "name": "å€¼è¶…å‡ºèŒƒå›´",
            "config": {
                "enabled": True,
                "version": "3.0.0",
                "models": {},
                "query_processing": {
                    "max_context_length": 500,  # ä½äºæœ€å°å€¼1000
                    "max_results": 150,         # è¶…å‡ºæœ€å¤§å€¼100
                    "relevance_threshold": 1.5  # è¶…å‡ºèŒƒå›´[0.0, 1.0]
                },
                "engines": {},
                "performance": {}
            }
        }
    ]
    
    validator = ConfigValidator()
    all_tests_passed = True
    
    for test_case in invalid_configs:
        print(f"\n  æµ‹è¯•: {test_case['name']}")
        try:
            validator.validate_config(test_case['config'])
            print(f"    âŒ åº”è¯¥å¤±è´¥ä½†é€šè¿‡äº†éªŒè¯")
            all_tests_passed = False
        except (ConfigurationError, ValidationError) as e:
            print(f"    âœ… æ­£ç¡®æ•è·åˆ°é”™è¯¯: {type(e).__name__}: {e}")
        except Exception as e:
            print(f"    âš ï¸ æ•è·åˆ°æœªçŸ¥é”™è¯¯: {type(e).__name__}: {e}")
            all_tests_passed = False
    
    return all_tests_passed


def test_config_issues():
    """æµ‹è¯•é…ç½®é—®é¢˜æ£€æµ‹"""
    print("\nğŸ§ª æµ‹è¯•é…ç½®é—®é¢˜æ£€æµ‹...")
    
    config_with_issues = {
        "enabled": True,
        "version": "3.0.0",
        "models": {},
        "query_processing": {
            "max_context_length": 500,  # é—®é¢˜ï¼šä½äºæœ€å°å€¼
            "max_results": 150,         # é—®é¢˜ï¼šè¶…å‡ºæœ€å¤§å€¼
            "relevance_threshold": 1.5  # é—®é¢˜ï¼šè¶…å‡ºèŒƒå›´
        },
        "engines": {},
        "performance": {}
    }
    
    try:
        validator = ConfigValidator()
        
        # è·å–é…ç½®é—®é¢˜
        issues = validator.get_config_issues(config_with_issues)
        print(f"âœ… æ£€æµ‹åˆ°é…ç½®é—®é¢˜: {len(issues)} ä¸ª")
        for i, issue in enumerate(issues, 1):
            print(f"  {i}. {issue}")
        
        # è·å–ä¿®å¤å»ºè®®
        suggestions = validator.suggest_config_fixes(config_with_issues)
        print(f"\nğŸ”§ ä¿®å¤å»ºè®®: {len(suggestions)} ä¸ª")
        for field, suggestion in suggestions.items():
            print(f"  {field}: {suggestion}")
        
        return True
    except Exception as e:
        print(f"âŒ é…ç½®é—®é¢˜æ£€æµ‹å¤±è´¥: {e}")
        return False


def test_rag_config_validation():
    """æµ‹è¯•RAGé…ç½®éªŒè¯"""
    print("\nğŸ§ª æµ‹è¯•RAGé…ç½®éªŒè¯...")
    
    rag_config = {
        "rag_system": {
            "enabled": True,
            "version": "3.0.0",
            "models": {
                "llm": {"model_name": "qwen-turbo"},
                "reranking": {"model_name": "gte-rerank-v2"}
            },
            "query_processing": {
                "max_context_length": 4000,
                "max_results": 10,
                "relevance_threshold": 0.5
            },
            "engines": {
                "text_engine": {"enabled": True, "similarity_threshold": 0.7},
                "image_engine": {"enabled": True, "similarity_threshold": 0.3},
                "table_engine": {"enabled": True, "similarity_threshold": 0.65}
            },
            "performance": {"max_concurrent_queries": 10}
        }
    }
    
    try:
        validator = ConfigValidator()
        result = validator.validate_rag_config(rag_config)
        print(f"âœ… RAGé…ç½®éªŒè¯é€šè¿‡: {result}")
        return True
    except Exception as e:
        print(f"âŒ RAGé…ç½®éªŒè¯å¤±è´¥: {e}")
        return False


def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("=" * 60)
    print("ğŸ§ª RAGç³»ç»Ÿé…ç½®éªŒè¯æµ‹è¯•")
    print("=" * 60)
    
    # è¿è¡Œå„é¡¹æµ‹è¯•
    tests = [
        ("æœ‰æ•ˆé…ç½®éªŒè¯", test_valid_config),
        ("æ— æ•ˆé…ç½®éªŒè¯", test_invalid_config),
        ("é…ç½®é—®é¢˜æ£€æµ‹", test_config_issues),
        ("RAGé…ç½®éªŒè¯", test_rag_config_validation)
    ]
    
    results = []
    for test_name, test_func in tests:
        try:
            result = test_func()
            results.append((test_name, result))
        except Exception as e:
            print(f"âŒ {test_name} æµ‹è¯•å¼‚å¸¸: {e}")
            results.append((test_name, False))
    
    # è¾“å‡ºæµ‹è¯•ç»“æœ
    print("\n" + "=" * 60)
    print("ğŸ“Š æµ‹è¯•ç»“æœæ±‡æ€»")
    print("=" * 60)
    
    passed = 0
    total = len(results)
    
    for test_name, result in results:
        status = "âœ… é€šè¿‡" if result else "âŒ å¤±è´¥"
        print(f"{test_name}: {status}")
        if result:
            passed += 1
    
    print(f"\næ€»ä½“ç»“æœ: {passed}/{total} æµ‹è¯•é€šè¿‡")
    
    if passed == total:
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼é…ç½®éªŒè¯å™¨å·¥ä½œæ­£å¸¸ã€‚")
    else:
        print("âš ï¸ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œéœ€è¦æ£€æŸ¥é—®é¢˜ã€‚")
    
    print("=" * 60)


if __name__ == "__main__":
    main()
