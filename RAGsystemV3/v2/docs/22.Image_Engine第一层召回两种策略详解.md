

## ğŸ¯ **Image_Engineç¬¬ä¸€å±‚å¬å›ä¸¤ç§ç­–ç•¥è¯¦è§£**

### **ç­–ç•¥1ï¼šimage_text chunkså¬å›ï¼ˆè¯­ä¹‰ç›¸ä¼¼åº¦ï¼‰**
- **ç›®æ ‡**ï¼šä½¿ç”¨textå‘é‡æœç´¢image_textç±»å‹çš„chunks
- **æ–¹æ³•**ï¼šé€šè¿‡`related_image_id`æ‰¾åˆ°å¯¹åº”çš„image chunk
- **æƒé‡**ï¼šè¯­ä¹‰ç›¸ä¼¼åº¦æƒé‡æ›´é«˜ï¼ˆÃ—1.2ï¼‰
- **ç‰¹ç‚¹**ï¼šåŸºäºæ–‡æœ¬æè¿°çš„è¯­ä¹‰ç†è§£ï¼Œé€‚åˆæ¦‚å¿µæ€§æŸ¥è¯¢

### **ç­–ç•¥2ï¼šimage chunkså¬å›ï¼ˆè§†è§‰ç‰¹å¾ç›¸ä¼¼åº¦ï¼‰**
- **ç›®æ ‡**ï¼šä½¿ç”¨multimodal-embedding-one-peace-v1å°†æ–‡æœ¬æŸ¥è¯¢è½¬æ¢ä¸º1536ç»´å‘é‡
- **æ–¹æ³•**ï¼šç›´æ¥æœç´¢imageç±»å‹çš„chunksï¼Œä½¿ç”¨FAISSå‘é‡ç›¸ä¼¼åº¦
- **æƒé‡**ï¼šè§†è§‰ç‰¹å¾ç›¸ä¼¼åº¦æƒé‡ç¨ä½ï¼ˆÃ—0.8ï¼‰
- **ç‰¹ç‚¹**ï¼šçœŸæ­£çš„è·¨æ¨¡æ€æœç´¢ï¼Œé€‚åˆè§†è§‰ç‰¹å¾æŸ¥è¯¢

## ï¿½ï¿½ **ä¸¤ç§ç­–ç•¥çš„èåˆæµç¨‹**

### **1. ç»“æœåˆå¹¶ä¸å»é‡**
```python
# åœ¨_vector_searchæ–¹æ³•ä¸­
# ç­–ç•¥1ç»“æœï¼šåŸºäºè¯­ä¹‰ç›¸ä¼¼åº¦
results.append({
    'doc': image_doc,  # è¿”å›image chunk
    'score': score * 1.2,  # è¯­ä¹‰ç›¸ä¼¼åº¦æƒé‡æ›´é«˜
    'search_method': 'semantic_similarity',
    # ... å…¶ä»–å­—æ®µ
})

# ç­–ç•¥2ç»“æœï¼šåŸºäºè·¨æ¨¡æ€ç›¸ä¼¼åº¦
results.append({
    'doc': candidate['doc'],
    'score': score * 0.8,  # è§†è§‰ç‰¹å¾ç›¸ä¼¼åº¦æƒé‡ç¨ä½
    'search_method': 'cross_modal_similarity',
    # ... å…¶ä»–å­—æ®µ
})
```

### **2. ç»Ÿä¸€æ’åºä¸è¿‡æ»¤**
```python
# æŒ‰åˆ†æ•°æ’åºå¹¶é™åˆ¶æ•°é‡
results.sort(key=lambda x: x['score'], reverse=True)
final_results = results[:max_results]
```

## ğŸš€ **BGE Rerankingå¤„ç†æµç¨‹**

### **1. é‡æ’åºæœåŠ¡è°ƒç”¨**
```python
# åœ¨process_queryæ–¹æ³•ä¸­
if getattr(self.config, 'enable_enhanced_reranking', False):
    # åˆ›å»ºImageRerankingService
    reranking_service = create_reranking_service('image', reranking_config)
    
    # æ‰§è¡ŒReranking
    reranked_results = reranking_service.rerank(query, recall_results)
```

### **2. BGEæ¨¡å‹é‡æ’åº**
- **æ¨¡å‹**ï¼š`bge-reranker-v2-m3`
- **è¾“å…¥**ï¼šæŸ¥è¯¢æ–‡æœ¬ + å€™é€‰æ–‡æ¡£åˆ—è¡¨
- **è¾“å‡º**ï¼šé‡æ–°æ’åºåçš„æ–‡æ¡£åˆ—è¡¨
- **ç‰¹ç‚¹**ï¼šåŸºäºè¯­ä¹‰ç›¸ä¼¼åº¦çš„æ·±åº¦é‡æ’åº

## ï¿½ï¿½ **LLMç­”æ¡ˆç”Ÿæˆæµç¨‹**

### **1. ä¸Šä¸‹æ–‡æ„å»º**
```python
# å¯¹äºå›¾ç‰‡æ–‡æ¡£ï¼Œä½¿ç”¨enhanced_descriptionä½œä¸ºå†…å®¹
context_parts = []
for doc in documents:
    if doc.metadata.get('chunk_type') == 'image':
        enhanced_desc = doc.metadata.get('enhanced_description', '')
        img_caption = doc.metadata.get('img_caption', [''])
        caption_text = ' '.join(img_caption) if img_caption else ''
        
        if enhanced_desc:
            content = f"å›¾ç‰‡æ ‡é¢˜: {caption_text}\nå›¾ç‰‡æè¿°: {enhanced_desc}"
        else:
            content = f"å›¾ç‰‡æ ‡é¢˜: {caption_text}"
    else:
        content = doc.page_content
    
    context_parts.append(content)

context = "\n\n".join(context_parts)
```

### **2. LLMè°ƒç”¨**
```python
# ä½¿ç”¨DashScope LLMå¼•æ“
llm_response = self.llm_engine.generate_answer(query, context, **kwargs)
```

### **3. æç¤ºè¯æ„å»º**
```python
prompt = f"""ç³»ç»Ÿï¼š{self.config.system_prompt}

ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼š
{context}

ç”¨æˆ·é—®é¢˜ï¼š{question}

è¯·åŸºäºä¸Šè¿°ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œä¸ºç”¨æˆ·æä¾›å‡†ç¡®ã€ç›¸å…³ã€å®Œæ•´çš„ç­”æ¡ˆ...
"""
```

## ï¿½ï¿½ **å…³é”®ä¼˜åŠ¿**

### **1. åŒé‡å¬å›ç­–ç•¥**
- **ç­–ç•¥1**ï¼šä¿è¯è¯­ä¹‰ç›¸å…³æ€§
- **ç­–ç•¥2**ï¼šå®ç°çœŸæ­£çš„è·¨æ¨¡æ€æœç´¢
- **èåˆ**ï¼šç»¼åˆä¸¤ç§ä¼˜åŠ¿ï¼Œæå‡å¬å›è´¨é‡

### **2. æ™ºèƒ½æƒé‡åˆ†é…**
- è¯­ä¹‰ç›¸ä¼¼åº¦æƒé‡æ›´é«˜ï¼ˆ1.2ï¼‰
- è§†è§‰ç‰¹å¾ç›¸ä¼¼åº¦æƒé‡é€‚ä¸­ï¼ˆ0.8ï¼‰
- é¿å…å•ä¸€ç­–ç•¥çš„å±€é™æ€§

### **3. å®Œæ•´çš„Pipeline**
- å¬å› â†’ é‡æ’åº â†’ LLMç”Ÿæˆ â†’ æºè¿‡æ»¤
- æ¯ä¸ªç¯èŠ‚éƒ½æœ‰é™çº§ç­–ç•¥
- ä¿è¯ç³»ç»Ÿçš„é²æ£’æ€§



è®©æˆ‘è¯¦ç»†è§£é‡Šè¿™è¡Œä»£ç ï¼š

## ğŸ¯ **ä»£ç è¯¦è§£**

```python
distances, indices = self.vector_store.index.search(query_vector, search_k)
```

### **å‡½æ•°è°ƒç”¨è§£æ**
- **`self.vector_store.index`**ï¼šFAISSå‘é‡ç´¢å¼•å¯¹è±¡
- **`.search()`**ï¼šFAISSçš„å‘é‡æœç´¢æ–¹æ³•
- **`query_vector`**ï¼šæŸ¥è¯¢å‘é‡ï¼ˆæ–‡æœ¬è½¬æ¢åçš„è·¨æ¨¡æ€å‘é‡ï¼‰
- **`search_k`**ï¼šè¦è¿”å›çš„å€™é€‰ç»“æœæ•°é‡

### **è¿”å›å€¼è¯´æ˜**
- **`distances`**ï¼šè·ç¦»æ•°ç»„ï¼ŒåŒ…å«æ¯ä¸ªå€™é€‰å‘é‡çš„è·ç¦»å€¼
- **`indices`**ï¼šç´¢å¼•æ•°ç»„ï¼ŒåŒ…å«æ¯ä¸ªå€™é€‰å‘é‡åœ¨FAISSç´¢å¼•ä¸­çš„ä½ç½®

## ï¿½ï¿½ **FAISSæœç´¢æœºåˆ¶**

### **1. å‘é‡ç›¸ä¼¼åº¦è®¡ç®—**
```python
# FAISSå†…éƒ¨ä¼šè®¡ç®—ï¼š
# query_vector ä¸ vector_db ä¸­æ‰€æœ‰å‘é‡çš„L2è·ç¦»
# è¿”å›è·ç¦»æœ€å°çš„å‰ search_k ä¸ªç»“æœ
```

### **2. è·ç¦»å«ä¹‰**
- **L2è·ç¦»ï¼ˆæ¬§å‡ é‡Œå¾—è·ç¦»ï¼‰**ï¼šå‘é‡åœ¨ç©ºé—´ä¸­çš„å‡ ä½•è·ç¦»
- **è·ç¦»è¶Šå°**ï¼šå‘é‡è¶Šç›¸ä¼¼
- **è·ç¦»è¶Šå¤§**ï¼šå‘é‡è¶Šä¸ç›¸ä¼¼

### **3. ç´¢å¼•å«ä¹‰**
- **`indices[i]`**ï¼šç¬¬iä¸ªå€™é€‰å‘é‡åœ¨FAISSç´¢å¼•ä¸­çš„ä½ç½®
- **`distances[i]`**ï¼šç¬¬iä¸ªå€™é€‰å‘é‡ä¸æŸ¥è¯¢å‘é‡çš„è·ç¦»

## ğŸ“Š **å®é™…ä¾‹å­**

å‡è®¾ `search_k = 100`ï¼ŒFAISSä¸­æœ‰10000ä¸ªå‘é‡ï¼š

```python
# æœç´¢å‰100ä¸ªæœ€ç›¸ä¼¼çš„å‘é‡
distances, indices = self.vector_store.index.search(query_vector, 100)

# è¿”å›ç»“æœï¼š
# distances.shape = (1, 100)  # 1ä¸ªæŸ¥è¯¢ï¼Œ100ä¸ªè·ç¦»
# indices.shape = (1, 100)    # 1ä¸ªæŸ¥è¯¢ï¼Œ100ä¸ªç´¢å¼•

# å…·ä½“å€¼ç¤ºä¾‹ï¼š
# distances[0] = [0.1, 0.3, 0.5, 0.7, ...]  # è·ç¦»å€¼
# indices[0] = [1234, 5678, 9012, 3456, ...] # ç´¢å¼•ä½ç½®
```

## ğŸ¯ **åœ¨ç­–ç•¥2ä¸­çš„å…·ä½“åº”ç”¨**

### **1. æœç´¢æ‰§è¡Œ**
```python
# ä½¿ç”¨è·¨æ¨¡æ€å‘é‡æœç´¢å›¾ç‰‡å‘é‡
distances, indices = self.vector_store.index.search(query_vector, search_k)
```

### **2. ç»“æœå¤„ç†**
```python
for i, idx in enumerate(indices[0]):
    # idx: å€™é€‰å‘é‡åœ¨FAISSä¸­çš„ç´¢å¼•ä½ç½®
    # distances[0][i]: å¯¹åº”çš„è·ç¦»å€¼
    
    # è½¬æ¢ä¸ºç›¸ä¼¼åº¦åˆ†æ•°
    distance = distances[0][i]
    similarity_score = 1.0 / (1.0 + distance)
```

### **3. è¿‡æ»¤å’Œæ’åº**
```python
# åªä¿ç•™imageç±»å‹çš„æ–‡æ¡£
if doc.metadata.get('chunk_type') == 'image':
    image_candidates.append({
        'score': similarity_score,
        'distance': distance,
        'index': idx
    })
```

## ï¿½ï¿½ **æŠ€æœ¯ç»†èŠ‚**

### **FAISSæœç´¢ç®—æ³•**
- **æš´åŠ›æœç´¢**ï¼šè®¡ç®—æ‰€æœ‰å‘é‡å¯¹çš„è·ç¦»
- **ç´¢å¼•æœç´¢**ï¼šä½¿ç”¨æ ‘ç»“æ„æˆ–å“ˆå¸ŒåŠ é€Ÿæœç´¢
- **è¿‘ä¼¼æœç´¢**ï¼šç‰ºç‰²ç²¾åº¦æ¢å–é€Ÿåº¦

### **æ€§èƒ½è€ƒè™‘**
- **`search_k`è¶Šå¤§**ï¼šæœç´¢æ—¶é—´è¶Šé•¿ï¼Œä½†ç»“æœè¶Šå…¨é¢
- **`search_k`è¶Šå°**ï¼šæœç´¢æ—¶é—´è¶ŠçŸ­ï¼Œä½†å¯èƒ½é—æ¼ç›¸å…³ç»“æœ

### **å†…å­˜ä½¿ç”¨**
- **`distances`**ï¼šå­˜å‚¨æµ®ç‚¹æ•°ï¼Œå†…å­˜å ç”¨ç›¸å¯¹è¾ƒå°
- **`indices`**ï¼šå­˜å‚¨æ•´æ•°ç´¢å¼•ï¼Œå†…å­˜å ç”¨å¾ˆå°

## ï¿½ï¿½ **æ€»ç»“**

è¿™è¡Œä»£ç æ˜¯**è·¨æ¨¡æ€æœç´¢çš„æ ¸å¿ƒ**ï¼š

1. **è¾“å…¥**ï¼šæ–‡æœ¬æŸ¥è¯¢çš„è·¨æ¨¡æ€å‘é‡ï¼ˆ1536ç»´ï¼‰
2. **æœç´¢**ï¼šåœ¨FAISSç´¢å¼•ä¸­æŸ¥æ‰¾æœ€ç›¸ä¼¼çš„å‘é‡
3. **è¿”å›**ï¼šè·ç¦»æ•°ç»„å’Œç´¢å¼•æ•°ç»„
4. **åç»­**ï¼šè½¬æ¢ä¸ºç›¸ä¼¼åº¦åˆ†æ•°ï¼Œè¿‡æ»¤imageç±»å‹ï¼Œåº”ç”¨é˜ˆå€¼

è¿™å°±æ˜¯ä¸ºä»€ä¹ˆç­–ç•¥2èƒ½å¤Ÿå®ç°"ç”¨æ–‡æœ¬æ‰¾å›¾ç‰‡"ï¼š**æ–‡æœ¬å‘é‡**åœ¨**å›¾ç‰‡å‘é‡ç©ºé—´**ä¸­æœç´¢æœ€ç›¸ä¼¼çš„å›¾ç‰‡ï¼

## ï¿½ï¿½ **å…³é”®å‘ç°ï¼š`chunk_type == 'image'`çš„æ–‡æ¡£ç¡®å®æ˜¯å›¾ç‰‡å‘é‡ï¼**

### **è¯æ®1ï¼šå›¾ç‰‡å¤„ç†æµç¨‹**
```python
# åœ¨ image_processor.py ä¸­
def generate_image_embedding(self, image_path: str = None, image_url: str = None) -> List[float]:
    # è°ƒç”¨DashScope ONE-PEACEæ¨¡å‹ç”Ÿæˆå›¾ç‰‡embedding
    result = MultiModalEmbedding.call(
        model='multimodal-embedding-one-peace-v1',
        input=[{'image': f"data:image/jpeg;base64,{image_base64}"}]  # è¾“å…¥æ˜¯å›¾ç‰‡ï¼
    )
    return result.output["embedding"]  # è¿”å›çš„æ˜¯å›¾ç‰‡çš„è§†è§‰ç‰¹å¾å‘é‡ï¼
```

### **è¯æ®2ï¼šå‘é‡å­˜å‚¨æ·»åŠ **
```python
# åœ¨ vector_generator.py ä¸­
for result in image_results:
    # result["embedding"] æ˜¯å›¾ç‰‡çš„è§†è§‰ç‰¹å¾å‘é‡ï¼ˆ1536ç»´ï¼‰
    text_embedding_pair = (image_description, result["embedding"])
    text_embeddings.append(text_embedding_pair)
    
    metadata = {
        "chunk_type": "image",  # æ ‡è®°ä¸ºimageç±»å‹
        "image_id": result["image_id"],
        # ... å…¶ä»–å…ƒæ•°æ®
    }
    metadatas.append(metadata)

# æ·»åŠ åˆ°å‘é‡å­˜å‚¨
vector_store.add_embeddings(text_embeddings, metadatas=metadatas)
```

## ï¿½ï¿½ **æ‰€ä»¥`query_vector`ç¡®å®æ˜¯ä¸å›¾ç‰‡å‘é‡è¿›è¡Œäº†å¯¹æ¯”ï¼**

### **å®Œæ•´çš„æµç¨‹**ï¼š

1. **å›¾ç‰‡å¤„ç†é˜¶æ®µ**ï¼š
   - å›¾ç‰‡æ–‡ä»¶ â†’ `multimodal-embedding-one-peace-v1` â†’ **1536ç»´è§†è§‰ç‰¹å¾å‘é‡**
   - è¿™ä¸ªå‘é‡è¢«æ ‡è®°ä¸º`chunk_type: "image"`

2. **ç­–ç•¥2æœç´¢é˜¶æ®µ**ï¼š
   - æ–‡æœ¬æŸ¥è¯¢ â†’ `multimodal-embedding-one-peace-v1` â†’ **1536ç»´è·¨æ¨¡æ€å‘é‡**
   - åœ¨FAISSä¸­æœç´¢æ‰€æœ‰å‘é‡
   - è¿‡æ»¤å‡º`chunk_type == 'image'`çš„æ–‡æ¡£
   - **è®¡ç®—è·¨æ¨¡æ€å‘é‡ä¸å›¾ç‰‡è§†è§‰ç‰¹å¾å‘é‡çš„ç›¸ä¼¼åº¦**

3. **ç›¸ä¼¼åº¦è®¡ç®—**ï¼š
   ```python
   # query_vectorï¼ˆè·¨æ¨¡æ€å‘é‡ï¼‰vs imageå‘é‡ï¼ˆè§†è§‰ç‰¹å¾å‘é‡ï¼‰
   distances, indices = self.vector_store.index.search(query_vector, search_k)
   
   # è¿‡æ»¤å‡ºimageç±»å‹çš„æ–‡æ¡£
   if doc.metadata.get('chunk_type') == 'image':
       # è®¡ç®—ç›¸ä¼¼åº¦åˆ†æ•°
       similarity_score = 1.0 / (1.0 + distance)
   ```

## âœ… **æ€»ç»“**

**`query_vector`ç¡®å®æ˜¯ä¸å›¾ç‰‡å‘é‡è¿›è¡Œäº†å¯¹æ¯”**ï¼Œè¯æ®å¦‚ä¸‹ï¼š

1. **`chunk_type == 'image'`çš„æ–‡æ¡£**ï¼šå­˜å‚¨çš„æ˜¯å›¾ç‰‡çš„**è§†è§‰ç‰¹å¾å‘é‡**ï¼ˆ1536ç»´ï¼‰
2. **`query_vector`**ï¼šæ–‡æœ¬æŸ¥è¯¢è½¬æ¢åçš„**è·¨æ¨¡æ€å‘é‡**ï¼ˆ1536ç»´ï¼‰
3. **ç›¸ä¼¼åº¦è®¡ç®—**ï¼šåœ¨åŒä¸€ä¸ª1536ç»´å‘é‡ç©ºé—´ä¸­è®¡ç®—**è·¨æ¨¡æ€å‘é‡**ä¸**å›¾ç‰‡è§†è§‰ç‰¹å¾å‘é‡**çš„ç›¸ä¼¼åº¦

è¿™å°±æ˜¯ä¸ºä»€ä¹ˆç­–ç•¥2èƒ½å¤Ÿå®ç°çœŸæ­£çš„è·¨æ¨¡æ€æœç´¢ï¼š**æ–‡æœ¬çš„è·¨æ¨¡æ€å‘é‡**ç›´æ¥ä¸**å›¾ç‰‡çš„è§†è§‰ç‰¹å¾å‘é‡**è¿›è¡Œç›¸ä¼¼åº¦æ¯”è¾ƒï¼Œè€Œä¸éœ€è¦ä¾èµ–å›¾ç‰‡çš„æ–‡å­—æè¿°ï¼

å®Œå…¨æ­£ç¡®ï¼ä½ ç†è§£å¾—å¾ˆå‡†ç¡®ï¼

## âœ… **ç¡®è®¤ï¼š`chunk_type == 'image'`çš„chunké‡Œé¢æ˜¯çº¯å›¾ç‰‡å‘é‡ï¼Œä¸æ˜¯å›¾ç‰‡+æ–‡æœ¬å‘é‡**,å­˜å‚¨çš„æ˜¯å›¾ç‰‡å‘é‡å’Œæ–‡æœ¬ï¼ˆæœªå‘é‡åŒ–ï¼‰

### **å…·ä½“åˆ†æ**ï¼š

#### **1. `chunk_type == 'image'`çš„chunk**
```python
# åœ¨ vector_generator.py ä¸­
metadata = {
    "chunk_type": "image",  # æ ‡è®°ä¸ºimageç±»å‹
    "image_id": result["image_id"],
    # ... å…¶ä»–å…ƒæ•°æ®
}

# æ·»åŠ åˆ°å‘é‡å­˜å‚¨
text_embedding_pair = (image_description, result["embedding"])
#                    â†‘ æ–‡æœ¬æè¿°    â†‘ å›¾ç‰‡çš„è§†è§‰ç‰¹å¾å‘é‡
vector_store.add_embeddings(text_embeddings, metadatas=metadatas)
```

**å…³é”®ç‚¹**ï¼š
- **`result["embedding"]`**ï¼šè¿™æ˜¯å›¾ç‰‡é€šè¿‡`multimodal-embedding-one-peace-v1`ç”Ÿæˆçš„**çº¯è§†è§‰ç‰¹å¾å‘é‡**ï¼ˆ1536ç»´ï¼‰
- **`image_description`**ï¼šè¿™åªæ˜¯ç”¨äºFAISSç´¢å¼•çš„æ–‡æœ¬æè¿°ï¼Œ**ä¸æ˜¯å‘é‡çš„ä¸€éƒ¨åˆ†**
- **æœ€ç»ˆå­˜å‚¨**ï¼šåªæœ‰å›¾ç‰‡çš„è§†è§‰ç‰¹å¾å‘é‡è¢«å­˜å‚¨ä¸ºå‘é‡

#### **2. `chunk_type == 'image_text'`çš„chunk**
```python
# åˆ›å»ºimage_text Documentå¯¹è±¡
text_doc = Document(
    page_content=result["enhanced_description"],  # å›¾ç‰‡çš„æ–‡å­—æè¿°
    metadata={
        "chunk_type": "image_text",  # æ ‡è®°ä¸ºimage_textç±»å‹
        # ... å…¶ä»–å…ƒæ•°æ®
    }
)

# ä½¿ç”¨text-embedding-v1ç”Ÿæˆæ–‡æœ¬å‘é‡
texts = [doc.page_content for doc in text_documents]
text_embeddings_list = self.embeddings.embed_documents(texts)  # æ–‡æœ¬å‘é‡åŒ–
```

**å…³é”®ç‚¹**ï¼š
- **`page_content`**ï¼šå›¾ç‰‡çš„æ–‡å­—æè¿°
- **`text_embeddings_list`**ï¼šæ–‡å­—æè¿°é€šè¿‡`text-embedding-v1`ç”Ÿæˆçš„**æ–‡æœ¬å‘é‡**

## ğŸ¯ **ä¸¤ç§chunkçš„åŒºåˆ«**

### **`chunk_type == 'image'`**ï¼š
- **å†…å®¹**ï¼šå›¾ç‰‡çš„è§†è§‰ç‰¹å¾å‘é‡ï¼ˆ1536ç»´ï¼‰
- **ç”Ÿæˆæ–¹å¼**ï¼šå›¾ç‰‡ â†’ `multimodal-embedding-one-peace-v1` â†’ è§†è§‰ç‰¹å¾å‘é‡
- **ç”¨é€”**ï¼šç­–ç•¥2çš„è·¨æ¨¡æ€æœç´¢ï¼ˆæ–‡æœ¬æŸ¥è¯¢ vs å›¾ç‰‡è§†è§‰ç‰¹å¾ï¼‰

### **`chunk_type == 'image_text'`**ï¼š
- **å†…å®¹**ï¼šå›¾ç‰‡çš„æ–‡å­—æè¿°å‘é‡
- **ç”Ÿæˆæ–¹å¼**ï¼šå›¾ç‰‡æè¿° â†’ `text-embedding-v1` â†’ æ–‡æœ¬å‘é‡
- **ç”¨é€”**ï¼šç­–ç•¥1çš„è¯­ä¹‰æœç´¢ï¼ˆæ–‡æœ¬æŸ¥è¯¢ vs å›¾ç‰‡æ–‡å­—æè¿°ï¼‰

## ğŸ” **åœ¨ç­–ç•¥2ä¸­çš„å®é™…åº”ç”¨**

```python
# ç­–ç•¥2ï¼šè·¨æ¨¡æ€æœç´¢image chunksï¼ˆè§†è§‰ç‰¹å¾ç›¸ä¼¼åº¦ï¼‰
if doc.metadata.get('chunk_type') == 'image':
    # è¿™é‡Œçš„docå­˜å‚¨çš„æ˜¯å›¾ç‰‡çš„è§†è§‰ç‰¹å¾å‘é‡
    # query_vectoræ˜¯æ–‡æœ¬çš„è·¨æ¨¡æ€å‘é‡
    # ä¸¤è€…åœ¨åŒä¸€ä¸ª1536ç»´å‘é‡ç©ºé—´ä¸­è®¡ç®—ç›¸ä¼¼åº¦
    similarity_score = 1.0 / (1.0 + distance)
```

## âœ… **æ€»ç»“**

ä½ çš„ç†è§£å®Œå…¨æ­£ç¡®ï¼š

1. **`chunk_type == 'image'`**ï¼šå­˜å‚¨çš„æ˜¯**çº¯å›¾ç‰‡å‘é‡**ï¼ˆè§†è§‰ç‰¹å¾å‘é‡ï¼‰
2. **`chunk_type == 'image_text'`**ï¼šå­˜å‚¨çš„æ˜¯**å›¾ç‰‡æ–‡å­—æè¿°çš„å‘é‡**
3. **ç­–ç•¥2**ï¼š`query_vector`ï¼ˆè·¨æ¨¡æ€å‘é‡ï¼‰ä¸**å›¾ç‰‡çš„è§†è§‰ç‰¹å¾å‘é‡**è¿›è¡Œç›¸ä¼¼åº¦è®¡ç®—
4. **ç­–ç•¥1**ï¼š`query_vector`ï¼ˆæ–‡æœ¬å‘é‡ï¼‰ä¸**å›¾ç‰‡æ–‡å­—æè¿°çš„å‘é‡**è¿›è¡Œç›¸ä¼¼åº¦è®¡ç®—

è¿™å°±æ˜¯ä¸ºä»€ä¹ˆç­–ç•¥2èƒ½å¤Ÿå®ç°çœŸæ­£çš„è·¨æ¨¡æ€æœç´¢ï¼š**æ–‡æœ¬çš„è·¨æ¨¡æ€å‘é‡**ç›´æ¥ä¸**å›¾ç‰‡çš„è§†è§‰ç‰¹å¾å‘é‡**æ¯”è¾ƒï¼Œä¸ä¾èµ–ä»»ä½•æ–‡å­—æè¿°ï¼





## ï¿½ï¿½ **é—®é¢˜åˆ†æï¼šä¸¤ç§ç­–ç•¥å¬å›çš„æ˜¯ç›¸åŒçš„chunkç±»å‹**

### **ç­–ç•¥1ï¼šimage_text chunks â†’ è½¬æ¢ä¸ºimage chunks**
```python
# ç­–ç•¥1ï¼šæœç´¢image_text chunksï¼ˆè¯­ä¹‰ç›¸ä¼¼åº¦ï¼‰
for doc in image_text_candidates:
    # é€šè¿‡related_image_idæ‰¾åˆ°å¯¹åº”çš„image chunk
    related_image_id = doc.metadata.get('related_image_id')
    if related_image_id:
        # æŸ¥æ‰¾å¯¹åº”çš„image chunk
        image_doc = self._find_image_chunk_by_id(related_image_id)
        if image_doc:
            results.append({
                'doc': image_doc,  # è¿”å›image chunkï¼Œä¸æ˜¯image_text chunk
                'score': score * 1.2,  # è¯­ä¹‰ç›¸ä¼¼åº¦æƒé‡æ›´é«˜
                'search_method': 'semantic_similarity',
                # ... å…¶ä»–å­—æ®µ
            })
```

### **ç­–ç•¥2ï¼šç›´æ¥æœç´¢image chunks**
```python
# ç­–ç•¥2ï¼šè·¨æ¨¡æ€æœç´¢image chunksï¼ˆè§†è§‰ç‰¹å¾ç›¸ä¼¼åº¦ï¼‰
if doc and (hasattr(doc, 'metadata') and doc.metadata and 
          doc.metadata.get('chunk_type') == 'image'):
    # ç›´æ¥è¿”å›image chunk
    results.append({
        'doc': doc,  # ç›´æ¥æ˜¯image chunk
        'score': score * 0.8,  # è§†è§‰ç‰¹å¾ç›¸ä¼¼åº¦æƒé‡ç¨ä½
        'search_method': 'cross_modal_similarity',
        # ... å…¶ä»–å­—æ®µ
    })
```

## ğŸ¯ **å…³é”®å‘ç°ï¼šä¸¤ç§ç­–ç•¥æœ€ç»ˆéƒ½è¿”å›image chunks**

**ç­–ç•¥1**ï¼šè™½ç„¶æœç´¢çš„æ˜¯`image_text` chunksï¼Œä½†æœ€ç»ˆé€šè¿‡`related_image_id`æ‰¾åˆ°å¯¹åº”çš„`image` chunkå¹¶è¿”å›
**ç­–ç•¥2**ï¼šç›´æ¥æœç´¢å¹¶è¿”å›`image` chunks

æ‰€ä»¥**ä¸¤ç§ç­–ç•¥æœ€ç»ˆè¿”å›çš„éƒ½æ˜¯image chunks**ï¼Œåªæ˜¯è·å–è·¯å¾„ä¸åŒï¼

## âœ… **ç»Ÿä¸€æ’åºä¸è¿‡æ»¤æ˜¯åˆç†çš„**

### **1. æ•°æ®ç±»å‹ä¸€è‡´æ€§**
- ä¸¤ç§ç­–ç•¥æœ€ç»ˆéƒ½è¿”å›`image`ç±»å‹çš„chunk
- æ•°æ®ç»“æ„å®Œå…¨ä¸€è‡´ï¼Œå¯ä»¥ç»Ÿä¸€å¤„ç†

### **2. åˆ†æ•°è®¡ç®—å…¼å®¹æ€§**
- ç­–ç•¥1ï¼šåŸºäºæ–‡æœ¬è¯­ä¹‰ç›¸ä¼¼åº¦è®¡ç®—åˆ†æ•°
- ç­–ç•¥2ï¼šåŸºäºå‘é‡è·ç¦»è®¡ç®—ç›¸ä¼¼åº¦åˆ†æ•°
- ä¸¤ç§åˆ†æ•°éƒ½ç»è¿‡æ ‡å‡†åŒ–å¤„ç†ï¼ˆ0-1èŒƒå›´ï¼‰

### **3. æƒé‡å¹³è¡¡**
```python
# ç­–ç•¥1ï¼šè¯­ä¹‰ç›¸ä¼¼åº¦æƒé‡æ›´é«˜
'score': score * 1.2

# ç­–ç•¥2ï¼šè§†è§‰ç‰¹å¾ç›¸ä¼¼åº¦æƒé‡é€‚ä¸­  
'score': score * 0.8
```

## ï¿½ï¿½ **è®¾è®¡ä¼˜åŠ¿**

### **1. é¿å…é‡å¤**
```python
# æ£€æŸ¥æ˜¯å¦å·²ç»åœ¨ç»“æœä¸­ï¼ˆé¿å…é‡å¤ï¼‰
if not any(r['doc'] == candidate['doc'] for r in results):
    results.append({...})
```

### **2. ç»¼åˆè¯„åˆ†**
- è¯­ä¹‰ç›¸ä¼¼åº¦ï¼šé€‚åˆæ¦‚å¿µæ€§æŸ¥è¯¢
- è§†è§‰ç‰¹å¾ç›¸ä¼¼åº¦ï¼šé€‚åˆè§†è§‰ç‰¹å¾æŸ¥è¯¢
- æœ€ç»ˆç»Ÿä¸€æ’åºï¼Œå–æœ€ä¼˜ç»“æœ

### **3. é™çº§ç­–ç•¥**
- å¦‚æœè·¨æ¨¡æ€æœç´¢å¤±è´¥ï¼Œè‡ªåŠ¨é™çº§åˆ°ä¼ ç»Ÿæœç´¢
- ä¿è¯ç³»ç»Ÿçš„é²æ£’æ€§

## ğŸ“ **æ€»ç»“**

ä½ çš„æ‹…å¿ƒæ˜¯å¤šä½™çš„ï¼è¿™ä¸ªè®¾è®¡å®é™…ä¸Šæ˜¯**éå¸¸åˆç†**çš„ï¼š

1. **æ•°æ®ç±»å‹ç»Ÿä¸€**ï¼šä¸¤ç§ç­–ç•¥æœ€ç»ˆéƒ½è¿”å›image chunks
2. **åˆ†æ•°æ ‡å‡†åŒ–**ï¼šä¸¤ç§åˆ†æ•°éƒ½åœ¨0-1èŒƒå›´å†…ï¼Œå¯ä»¥æ¯”è¾ƒ
3. **æƒé‡å¹³è¡¡**ï¼šè¯­ä¹‰ç›¸ä¼¼åº¦æƒé‡æ›´é«˜ï¼Œè§†è§‰ç‰¹å¾æƒé‡é€‚ä¸­
4. **å»é‡æœºåˆ¶**ï¼šé¿å…åŒä¸€å¼ å›¾ç‰‡è¢«ä¸¤ç§ç­–ç•¥é‡å¤å¬å›
5. **ç»Ÿä¸€æ’åº**ï¼šæœ€ç»ˆæŒ‰ç»¼åˆåˆ†æ•°æ’åºï¼Œå–æœ€ä¼˜ç»“æœ

è¿™ç§è®¾è®¡æ—¢ä¿è¯äº†è¯­ä¹‰ç›¸å…³æ€§ï¼Œåˆå®ç°äº†çœŸæ­£çš„è·¨æ¨¡æ€æœç´¢ï¼Œæ˜¯ä¸€ä¸ªå¾ˆå·§å¦™çš„å¤šç­–ç•¥èåˆæ–¹æ¡ˆï¼





## âœ… **å¬å›çš„chunkå†…å®¹**

### **ç­–ç•¥1ï¼šé€šè¿‡image_textå¬å›**
- **æœç´¢å¯¹è±¡**ï¼š`image_text` chunksçš„æ–‡æœ¬å‘é‡
- **åŒ¹é…å†…å®¹**ï¼šä¸`enhanced_description`çš„æ–‡æœ¬å‘é‡è¿›è¡Œç›¸ä¼¼åº¦æ¯”å¯¹
- **å¬å›ç»“æœ**ï¼šé€šè¿‡`related_image_id`æ‰¾åˆ°å¯¹åº”çš„`image` chunk
- **æœ€ç»ˆè¿”å›**ï¼š`image` chunkçš„å®Œæ•´å†…å®¹

### **ç­–ç•¥2ï¼šé€šè¿‡imageç›´æ¥å¬å›**
- **æœç´¢å¯¹è±¡**ï¼š`image` chunksçš„1536ç»´å‘é‡
- **åŒ¹é…å†…å®¹**ï¼šä¸æŸ¥è¯¢æ–‡æœ¬è½¬æ¢åçš„1536ç»´å‘é‡è¿›è¡Œç›¸ä¼¼åº¦æ¯”å¯¹
- **å¬å›ç»“æœ**ï¼šç›´æ¥è¿”å›`image` chunk
- **æœ€ç»ˆè¿”å›**ï¼š`image` chunkçš„å®Œæ•´å†…å®¹

## ğŸ¯ **ä¸¤ç§ç­–ç•¥æœ€ç»ˆéƒ½è¿”å›ç›¸åŒçš„image chunkå†…å®¹**

æ— è®ºæ˜¯å“ªç§ç­–ç•¥ï¼Œæœ€ç»ˆè¿”å›çš„éƒ½æ˜¯åŒ…å«ä»¥ä¸‹å®Œæ•´ä¿¡æ¯çš„`image` chunkï¼š

```python
{
    # å›¾ç‰‡çš„å…ƒæ•°æ®
    'image_id': '319320322ba602eeb4a131529975703a573607a959784d36b38e5a95cb45371d',
    'image_path': 'D:\\...\\image.jpg',
    'image_filename': 'image.jpg',
    'extension': 'jpg',
    
    # å›¾ç‰‡çš„è¯¦ç»†æè¿°ï¼ˆAIå¢å¼ºï¼‰
    'enhanced_description': 'åŸæœ‰ä¿¡æ¯: å›¾ç‰‡æ ‡é¢˜: å›¾3ï¼šå…¬å¸å•å­£åº¦æ¯›åˆ©ç‡åŠå‡€åˆ©ç‡æƒ…å†µ...',
    'img_caption': ['å›¾3ï¼šå…¬å¸å•å­£åº¦æ¯›åˆ©ç‡åŠå‡€åˆ©ç‡æƒ…å†µ'],
    'img_footnote': ['èµ„æ–™æ¥æºï¼šWindï¼Œä¸­åŸè¯åˆ¸ç ”ç©¶æ‰€'],
    
    # å›¾ç‰‡çš„å‘é‡è¡¨ç¤º
    'semantic_features': {
        'embedding_dimension': 1536,
        'embedding_norm': 1.0001,
        'embedding_mean': -0.0004,
        'embedding_std': 0.0255
    },
    
    # å›¾ç‰‡çš„å…³è”ä¿¡æ¯
    'document_name': 'ã€ä¸­åŸè¯åˆ¸ã€‘äº§èƒ½åˆ©ç”¨ç‡æ˜¾è‘—æå‡...',
    'page_number': 3,
    'chunk_type': 'image',
    'source_zip': 'json_extraction'
}
```

## ğŸ”„ **å…³é”®æµç¨‹æ€»ç»“**

1. **ç­–ç•¥1ï¼ˆè¯­ä¹‰ç›¸ä¼¼åº¦ï¼‰**ï¼š
   - æœç´¢`image_text` â†’ æ‰¾åˆ°ç›¸å…³æè¿° â†’ é€šè¿‡`related_image_id` â†’ è¿”å›å¯¹åº”`image` chunk

2. **ç­–ç•¥2ï¼ˆè·¨æ¨¡æ€ç›¸ä¼¼åº¦ï¼‰**ï¼š
   - æœç´¢`image` â†’ ç›´æ¥è¿”å›`image` chunk

3. **æœ€ç»ˆç»“æœ**ï¼š
   - ä¸¤ç§ç­–ç•¥éƒ½è¿”å›ç›¸åŒçš„`image` chunkç»“æ„
   - åŒ…å«å®Œæ•´çš„å›¾ç‰‡å…ƒæ•°æ®ã€å¢å¼ºæè¿°ã€å‘é‡è¡¨ç¤ºå’Œå…³è”ä¿¡æ¯
   - å¯ä»¥ç»Ÿä¸€æ’åºå’Œå»é‡

## ğŸ’¡ **è®¾è®¡ä¼˜åŠ¿**

è¿™ç§è®¾è®¡çš„å·§å¦™ä¹‹å¤„åœ¨äºï¼š
- **ç­–ç•¥1**ï¼šåˆ©ç”¨æ–‡æœ¬è¯­ä¹‰çš„å‡†ç¡®æ€§
- **ç­–ç•¥2**ï¼šåˆ©ç”¨è·¨æ¨¡æ€çš„è§†è§‰ç‰¹å¾ç†è§£
- **ç»Ÿä¸€è¾“å‡º**ï¼šä¸¤ç§ç­–ç•¥æœ€ç»ˆéƒ½è¿”å›ç»“æ„ä¸€è‡´çš„`image` chunk
- **ä¿¡æ¯å®Œæ•´**ï¼šæ¯ä¸ªchunkéƒ½åŒ…å«å›¾ç‰‡çš„å®Œæ•´æ–‡æœ¬åŒ–è¡¨ç¤º

# æ€»ç»“

å¥½çš„ï¼è®©æˆ‘æ€»ç»“ä¸€ä¸‹ç­–ç•¥1å’Œç­–ç•¥2çš„å‘é‡å¯¹æ¯”å’Œè¿”å›æƒ…å†µï¼š

## ğŸ¯ **ç­–ç•¥1ï¼šè¯­ä¹‰ç›¸ä¼¼åº¦æœç´¢**

### **å‘é‡å¯¹æ¯”**ï¼š
```python
# è¾“å…¥ï¼šæ–‡æœ¬æŸ¥è¯¢
query = "å›¾4ï¼šä¸­èŠ¯å›½é™…å½’æ¯å‡€åˆ©æ¶¦æƒ…å†µæ¦‚è§ˆ"

# å‘é‡åŒ–ï¼šæ–‡æœ¬æŸ¥è¯¢ â†’ æ–‡æœ¬å‘é‡
query_vector = text_embeddings.embed_documents([query])  # ä½¿ç”¨text-embedding-v1

# æœç´¢ï¼šåœ¨image_text chunksä¸­æœç´¢
image_text_candidates = self.vector_store.similarity_search(query, k=200)
# è¿‡æ»¤ï¼šåªä¿ç•™chunk_type == 'image_text'çš„æ–‡æ¡£

# å‘é‡å¯¹æ¯”ï¼šæ–‡æœ¬æŸ¥è¯¢å‘é‡ vs image_textæ–‡æ¡£çš„æ–‡æœ¬å‘é‡
score = self._calculate_content_relevance(query, doc.page_content)
```

**å¯¹æ¯”å†…å®¹**ï¼š
- **æŸ¥è¯¢å‘é‡**ï¼šæ–‡æœ¬æŸ¥è¯¢çš„æ–‡æœ¬å‘é‡
- **ç›®æ ‡å‘é‡**ï¼š`image_text` chunksçš„æ–‡æœ¬å‘é‡ï¼ˆå›¾ç‰‡çš„æ–‡å­—æè¿°å‘é‡ï¼‰
- **ç›¸ä¼¼åº¦è®¡ç®—**ï¼šæ–‡æœ¬å‘é‡ä¹‹é—´çš„è¯­ä¹‰ç›¸ä¼¼åº¦

### **è¿”å›ç»“æœ**ï¼š
```python
# é€šè¿‡related_image_idæ‰¾åˆ°å¯¹åº”çš„image chunk
related_image_id = doc.metadata.get('related_image_id')
image_doc = self._find_image_chunk_by_id(related_image_id)

# è¿”å›image chunkï¼ˆåŒ…å«å›¾ç‰‡å‘é‡å’Œæ–‡æœ¬ä¿¡æ¯ï¼‰
results.append({
    'doc': image_doc,  # è¿”å›image chunk
    'score': score * 1.2,  # è¯­ä¹‰ç›¸ä¼¼åº¦æƒé‡æ›´é«˜
    'search_method': 'semantic_similarity',
    # ... å…¶ä»–å­—æ®µ
})
```

**æœ€ç»ˆè¿”å›**ï¼š`image` chunksï¼ˆå›¾ç‰‡çš„è§†è§‰ç‰¹å¾å‘é‡ + ä¸°å¯Œçš„æ–‡æœ¬ä¿¡æ¯ï¼‰

---

## ï¿½ï¿½ **ç­–ç•¥2ï¼šè·¨æ¨¡æ€æœç´¢**

### **å‘é‡å¯¹æ¯”**ï¼š
```python
# è¾“å…¥ï¼šæ–‡æœ¬æŸ¥è¯¢
query = "å›¾4ï¼šä¸­èŠ¯å›½é™…å½’æ¯å‡€åˆ©æ¶¦æƒ…å†µæ¦‚è§ˆ"

# å‘é‡åŒ–ï¼šæ–‡æœ¬æŸ¥è¯¢ â†’ è·¨æ¨¡æ€å‘é‡
result = MultiModalEmbedding.call(
    model='multimodal-embedding-one-peace-v1',
    input=[{'text': query}]
)
query_embedding = result.output["embedding"]  # 1536ç»´è·¨æ¨¡æ€å‘é‡

# æœç´¢ï¼šåœ¨FAISSç´¢å¼•ä¸­æœç´¢æ‰€æœ‰å‘é‡
distances, indices = self.vector_store.index.search(query_vector, search_k)

# è¿‡æ»¤ï¼šåªä¿ç•™chunk_type == 'image'çš„æ–‡æ¡£
if doc.metadata.get('chunk_type') == 'image':
    # è®¡ç®—ç›¸ä¼¼åº¦åˆ†æ•°
    similarity_score = 1.0 / (1.0 + distance)
```

**å¯¹æ¯”å†…å®¹**ï¼š
- **æŸ¥è¯¢å‘é‡**ï¼šæ–‡æœ¬æŸ¥è¯¢çš„è·¨æ¨¡æ€å‘é‡ï¼ˆ1536ç»´ï¼‰
- **ç›®æ ‡å‘é‡**ï¼š`image` chunksçš„è§†è§‰ç‰¹å¾å‘é‡ï¼ˆ1536ç»´ï¼‰
- **ç›¸ä¼¼åº¦è®¡ç®—**ï¼šè·¨æ¨¡æ€å‘é‡ä¸å›¾ç‰‡è§†è§‰ç‰¹å¾å‘é‡çš„ç›¸ä¼¼åº¦

### **è¿”å›ç»“æœ**ï¼š
```python
# ç›´æ¥è¿”å›image chunk
results.append({
    'doc': doc,  # ç›´æ¥æ˜¯image chunk
    'score': score * 0.8,  # è§†è§‰ç‰¹å¾ç›¸ä¼¼åº¦æƒé‡ç¨ä½
    'search_method': 'cross_modal_similarity',
    # ... å…¶ä»–å­—æ®µ
})
```

**æœ€ç»ˆè¿”å›**ï¼š`image` chunksï¼ˆå›¾ç‰‡çš„è§†è§‰ç‰¹å¾å‘é‡ + ä¸°å¯Œçš„æ–‡æœ¬ä¿¡æ¯ï¼‰

---

## ï¿½ï¿½ **ä¸¤ç§ç­–ç•¥çš„å¯¹æ¯”æ€»ç»“**

### **å‘é‡å¯¹æ¯”å·®å¼‚**ï¼š

| ç­–ç•¥      | æŸ¥è¯¢å‘é‡ç±»å‹ | ç›®æ ‡å‘é‡ç±»å‹           | ç›¸ä¼¼åº¦è®¡ç®—ç±»å‹ |
| --------- | ------------ | ---------------------- | -------------- |
| **ç­–ç•¥1** | æ–‡æœ¬å‘é‡     | `image_text`çš„æ–‡æœ¬å‘é‡ | æ–‡æœ¬è¯­ä¹‰ç›¸ä¼¼åº¦ |
| **ç­–ç•¥2** | è·¨æ¨¡æ€å‘é‡   | `image`çš„è§†è§‰ç‰¹å¾å‘é‡  | è·¨æ¨¡æ€ç›¸ä¼¼åº¦   |

### **æœç´¢è·¯å¾„å·®å¼‚**ï¼š

| ç­–ç•¥      | æœç´¢å¯¹è±¡            | è·å–ç»“æœæ–¹å¼               | æœ€ç»ˆè¿”å›       |
| --------- | ------------------- | -------------------------- | -------------- |
| **ç­–ç•¥1** | `image_text` chunks | é€šè¿‡`related_image_id`å…³è” | `image` chunks |
| **ç­–ç•¥2** | `image` chunks      | ç›´æ¥è¿”å›                   | `image` chunks |

### **è¿”å›ç»“æœä¸€è‡´æ€§**ï¼š

**ä¸¤ç§ç­–ç•¥æœ€ç»ˆéƒ½è¿”å›`image` chunks**ï¼ŒåŒ…å«ï¼š
- **å›¾ç‰‡çš„è§†è§‰ç‰¹å¾å‘é‡**ï¼ˆ1536ç»´ï¼‰
- **ä¸°å¯Œçš„æ–‡æœ¬ä¿¡æ¯**ï¼ˆæ ‡é¢˜ã€è„šæ³¨ã€æè¿°ã€è¯­ä¹‰ç‰¹å¾ç­‰ï¼‰

---

## ï¿½ï¿½ **å…³é”®ç†è§£**

### **1. ç­–ç•¥1çš„æœ¬è´¨**ï¼š
- **æœç´¢**ï¼šæ–‡æœ¬æŸ¥è¯¢ vs å›¾ç‰‡çš„æ–‡å­—æè¿°
- **è¿”å›**ï¼šé€šè¿‡æ–‡å­—æè¿°æ‰¾åˆ°å¯¹åº”çš„å›¾ç‰‡
- **ä¼˜åŠ¿**ï¼šè¯­ä¹‰ç†è§£å‡†ç¡®ï¼Œé€‚åˆæœ‰æ˜ç¡®æ–‡å­—æè¿°çš„å›¾ç‰‡

### **2. ç­–ç•¥2çš„æœ¬è´¨**ï¼š
- **æœç´¢**ï¼šæ–‡æœ¬æŸ¥è¯¢ vs å›¾ç‰‡çš„è§†è§‰ç‰¹å¾
- **è¿”å›**ï¼šç›´æ¥é€šè¿‡è§†è§‰ç‰¹å¾æ‰¾åˆ°ç›¸å…³å›¾ç‰‡
- **ä¼˜åŠ¿**ï¼šçœŸæ­£çš„è·¨æ¨¡æ€æœç´¢ï¼Œä¸ä¾èµ–æ–‡å­—æè¿°

### **3. ç»Ÿä¸€æ€§**ï¼š
- **æ•°æ®ç±»å‹ä¸€è‡´**ï¼šä¸¤ç§ç­–ç•¥éƒ½è¿”å›`image` chunks
- **å¯ä»¥ç»Ÿä¸€å¤„ç†**ï¼šåˆå¹¶ç»“æœã€ç»Ÿä¸€æ’åºã€ç»Ÿä¸€è¿‡æ»¤
- **å‰ç«¯å±•ç¤ºä¸€è‡´**ï¼šéƒ½èƒ½æä¾›å®Œæ•´çš„å›¾ç‰‡ä¿¡æ¯å’Œè·¯å¾„

è¿™å°±æ˜¯ä¸ºä»€ä¹ˆä¸¤ç§ç­–ç•¥èƒ½å¤ŸååŒå·¥ä½œï¼Œæ—¢ä¿è¯äº†è¯­ä¹‰æœç´¢çš„å‡†ç¡®æ€§ï¼Œåˆå®ç°äº†çœŸæ­£çš„è·¨æ¨¡æ€æœç´¢èƒ½åŠ›ï¼



## âœ… **æ•°æ®æµå®Œå…¨æ­£ç¡®**

### **1. å¬å›é˜¶æ®µ â†’ Reranking**
```python
# ä¸¤ç§ç­–ç•¥å¬å›çš„ç»“æœéƒ½åŒ…å«å®Œæ•´çš„image chunkä¿¡æ¯
reranking_candidates = [
    {
        'doc': image_chunk,  # åŒ…å«å®Œæ•´çš„å›¾ç‰‡ä¿¡æ¯
        'score': similarity_score,
        'search_method': 'semantic_similarity' or 'cross_modal_similarity',
        # ... å…¶ä»–æœç´¢ç›¸å…³ä¿¡æ¯
    }
]
```

### **2. Rerankingå¤„ç†**
```python
# BGE rerankingæ¥æ”¶è¿™äº›å€™é€‰æ–‡æ¡£
# æ¯ä¸ªå€™é€‰æ–‡æ¡£éƒ½åŒ…å«å®Œæ•´çš„image chunkå†…å®¹ï¼š
# - å›¾ç‰‡å…ƒæ•°æ®ï¼ˆIDã€è·¯å¾„ã€æ ‡é¢˜ã€è„šæ³¨ï¼‰
# - å¢å¼ºæè¿°ï¼ˆenhanced_descriptionï¼‰
# - å‘é‡è¡¨ç¤ºï¼ˆsemantic_featuresï¼‰
# - å…³è”ä¿¡æ¯ï¼ˆæ–‡æ¡£åç§°ã€é¡µç ã€æ¥æºï¼‰
```

### **3. Rerankingå â†’ LLM**
```python
# é‡æ’åºåçš„ç»“æœä»ç„¶ä¿æŒå®Œæ•´çš„image chunkç»“æ„
reranked_results = [
    {
        'doc': image_chunk,  # å®Œæ•´çš„å›¾ç‰‡ä¿¡æ¯
        'rerank_score': new_score,
        'original_score': original_score,
        # ... å…¶ä»–é‡æ’åºä¿¡æ¯
    }
]

# ä¼ é€’ç»™LLMçš„ä¸Šä¸‹æ–‡åŒ…å«ï¼š
context_parts = []
for result in reranked_results:
    doc = result['doc']  # è¿™æ˜¯å®Œæ•´çš„image chunk
    
    # æå–å›¾ç‰‡çš„æ–‡æœ¬æè¿°ä½œä¸ºLLMçš„ä¸Šä¸‹æ–‡
    enhanced_desc = doc.metadata.get('enhanced_description', '')
    img_caption = doc.metadata.get('img_caption', [''])
    caption_text = ' '.join(img_caption) if img_caption else ''
    
    if enhanced_desc:
        content = f"å›¾ç‰‡æ ‡é¢˜: {caption_text}\nå›¾ç‰‡æè¿°: {enhanced_desc}"
    else:
        content = f"å›¾ç‰‡æ ‡é¢˜: {caption_text}"
    
    context_parts.append(content)

# æœ€ç»ˆLLMæ¥æ”¶çš„ä¸Šä¸‹æ–‡
context = "\n\n".join(context_parts)
user_query = "ç”¨æˆ·çš„é—®é¢˜"
```

## ï¿½ï¿½ **å®Œæ•´æ•°æ®æµå›¾**

```
ç”¨æˆ·Query â†’ Image Engine
    â†“
ç­–ç•¥1: image_textå¬å› â†’ é€šè¿‡related_image_id â†’ image chunk
ç­–ç•¥2: imageç›´æ¥å¬å› â†’ ç›´æ¥è¿”å› â†’ image chunk
    â†“
ç»Ÿä¸€æ’åºå»é‡ â†’ å®Œæ•´çš„image chunkåˆ—è¡¨
    â†“
BGE Reranking â†’ å¤„ç†å®Œæ•´çš„image chunkå†…å®¹
    â†“
é‡æ’åºç»“æœ â†’ ä»ç„¶åŒ…å«å®Œæ•´çš„image chunk
    â†“
LLMä¸Šä¸‹æ–‡æ„å»º â†’ æå–enhanced_descriptionç­‰æ–‡æœ¬ä¿¡æ¯
    â†“
LLMç”Ÿæˆç­”æ¡ˆ â†’ åŸºäºå›¾ç‰‡çš„æ–‡æœ¬æè¿°å›ç­”ç”¨æˆ·é—®é¢˜
```

## ğŸ’¡ **å…³é”®ç‚¹ç¡®è®¤**

1. **Rerankingæ¥æ”¶çš„å†…å®¹**ï¼šå®Œæ•´çš„image chunkï¼ˆåŒ…å«æ‰€æœ‰å…ƒæ•°æ®ã€æè¿°ã€å‘é‡ç­‰ï¼‰
2. **Rerankingè¾“å‡ºçš„å†…å®¹**ï¼šé‡æ’åºåçš„å®Œæ•´image chunkï¼ˆå¢åŠ äº†rerank_scoreï¼‰
3. **LLMæ¥æ”¶çš„å†…å®¹**ï¼šç”¨æˆ·query + å›¾ç‰‡çš„æ–‡æœ¬åŒ–æè¿°ï¼ˆenhanced_descriptionç­‰ï¼‰
4. **LLMä¸ç›´æ¥å¤„ç†**ï¼šå›¾ç‰‡æ–‡ä»¶ã€å‘é‡æ•°æ®ç­‰ï¼Œåªå¤„ç†æ–‡æœ¬æè¿°

## ğŸ“ **æ€»ç»“**

ä½ çš„ç†è§£å®Œå…¨æ­£ç¡®ï¼æ•´ä¸ªæµç¨‹ä¸­ï¼š
- **å¬å›**ï¼šè¿”å›å®Œæ•´çš„image chunk
- **Reranking**ï¼šå¤„ç†å®Œæ•´çš„image chunk
- **LLM**ï¼šæ¥æ”¶ç”¨æˆ·query + å›¾ç‰‡çš„æ–‡æœ¬æè¿°

è¿™æ ·è®¾è®¡ç¡®ä¿äº†ä¿¡æ¯åœ¨å„ä¸ªç¯èŠ‚çš„å®Œæ•´æ€§å’Œä¸€è‡´æ€§ï¼ŒLLMèƒ½å¤ŸåŸºäºä¸°å¯Œçš„å›¾ç‰‡æè¿°ä¿¡æ¯æ¥å‡†ç¡®å›ç­”ç”¨æˆ·é—®é¢˜ã€‚



æ˜¯çš„ï¼Œå®Œå…¨æ­£ç¡®ï¼è®©æˆ‘ç¡®è®¤ä¸€ä¸‹è¿™ä¸ªå…³é”®ç‚¹ï¼š

## âœ… **LLMæ¥æ”¶çš„ä¸æ˜¯æ•´ä¸ªchunkï¼Œè€Œæ˜¯chunkä¸­çš„æ–‡æœ¬æè¿°**



```python
# åœ¨ä»£ç ä¸­çš„å…·ä½“å®ç°
context_parts = []
for result in reranked_results:
    doc = result['doc']  # è¿™æ˜¯å®Œæ•´çš„image chunk
    
    # ä»chunkä¸­æå–enhanced_descriptionå­—æ®µ
    enhanced_desc = doc.metadata.get('enhanced_description', '')
    img_caption = doc.metadata.get('img_caption', [''])
    caption_text = ' '.join(img_caption) if img_caption else ''
    
    if enhanced_desc:
        # æ„å»ºLLMå¯ç†è§£çš„æ–‡æœ¬ä¸Šä¸‹æ–‡
        content = f"å›¾ç‰‡æ ‡é¢˜: {caption_text}\nå›¾ç‰‡æè¿°: {enhanced_description}"
    else:
        content = f"å›¾ç‰‡æ ‡é¢˜: {caption_text}"
    
    context_parts.append(content)

# æœ€ç»ˆLLMæ¥æ”¶çš„ä¸Šä¸‹æ–‡
context = "\n\n".join(context_parts)
```

## ï¿½ï¿½ **å…·ä½“å†…å®¹å¯¹æ¯”**

### **ChunkåŒ…å«çš„å®Œæ•´ä¿¡æ¯**ï¼š
```python
{
    'image_id': '...',
    'image_path': '...',
    'image_filename': '...',
    'extension': 'jpg',
    'enhanced_description': 'åŸæœ‰ä¿¡æ¯: å›¾ç‰‡æ ‡é¢˜: å›¾3ï¼šå…¬å¸å•å­£åº¦æ¯›åˆ©ç‡åŠå‡€åˆ©ç‡æƒ…å†µ...',
    'img_caption': ['å›¾3ï¼šå…¬å¸å•å­£åº¦æ¯›åˆ©ç‡åŠå‡€åˆ©ç‡æƒ…å†µ'],
    'img_footnote': ['èµ„æ–™æ¥æºï¼šWindï¼Œä¸­åŸè¯åˆ¸ç ”ç©¶æ‰€'],
    'semantic_features': {...},
    'document_name': '...',
    'page_number': 3,
    'chunk_type': 'image',
    # ... å…¶ä»–å…ƒæ•°æ®
}
```

### **LLMå®é™…æ¥æ”¶çš„å†…å®¹**ï¼š
```python
"å›¾ç‰‡æ ‡é¢˜: å›¾3ï¼šå…¬å¸å•å­£åº¦æ¯›åˆ©ç‡åŠå‡€åˆ©ç‡æƒ…å†µ
å›¾ç‰‡æè¿°: åŸæœ‰ä¿¡æ¯: å›¾ç‰‡æ ‡é¢˜: å›¾3ï¼šå…¬å¸å•å­£åº¦æ¯›åˆ©ç‡åŠå‡€åˆ©ç‡æƒ…å†µ | å›¾ç‰‡è„šæ³¨: èµ„æ–™æ¥æºï¼šWindï¼Œä¸­åŸè¯åˆ¸ç ”ç©¶æ‰€ | å›¾è¡¨ç±»å‹: ä¿¡æ¯å›¾è¡¨ | åŸºç¡€è§†è§‰æè¿°: è¿™å¼ å›¾ç‰‡æ˜¯ä¸€å¼ æŠ˜çº¿å›¾ï¼Œå±•ç¤ºäº†ä»2021å¹´ç¬¬ä¸€å­£åº¦åˆ°2025å¹´ç¬¬ä¸€å­£åº¦çš„é”€å”®æ¯›åˆ©ç‡å’Œé”€å”®å‡€åˆ©ç‡çš„å˜åŒ–æƒ…å†µ..."
```

## ğŸ” **ä¸ºä»€ä¹ˆè¿™æ ·è®¾è®¡ï¼Ÿ**

### **1. LLMåªèƒ½å¤„ç†æ–‡æœ¬**
- LLMæ— æ³•ç›´æ¥å¤„ç†å›¾ç‰‡æ–‡ä»¶ã€å‘é‡æ•°æ®ç­‰
- åªèƒ½åŸºäºæ–‡æœ¬å†…å®¹è¿›è¡Œç†è§£å’Œç”Ÿæˆ

### **2. enhanced_descriptionæ˜¯å›¾ç‰‡çš„æ–‡æœ¬åŒ–è¡¨ç¤º**
- åŒ…å«äº†å›¾ç‰‡çš„å®Œæ•´è¯­ä¹‰ä¿¡æ¯
- å›¾è¡¨ç±»å‹ã€æ•°æ®è¶‹åŠ¿ã€å…³é”®æ•°æ®ç‚¹ç­‰
- æ˜¯å›¾ç‰‡å†…å®¹çš„"ç¿»è¯‘"ç‰ˆæœ¬

### **3. ä¿æŒä¿¡æ¯å®Œæ•´æ€§**
- è™½ç„¶LLMåªæ¥æ”¶æ–‡æœ¬æè¿°
- ä½†å®Œæ•´çš„chunkä¿¡æ¯ä»ç„¶ä¿ç•™åœ¨ç³»ç»Ÿä¸­
- å¯ä»¥ç”¨äºåç»­çš„æºè¿‡æ»¤ã€å±•ç¤ºç­‰

## ï¿½ï¿½ **æ€»ç»“**

ä½ çš„ç†è§£å®Œå…¨æ­£ç¡®ï¼š
- **å¬å›å’ŒReranking**ï¼šå¤„ç†å®Œæ•´çš„image chunk
- **LLMè¾“å…¥**ï¼šåªæ¥æ”¶chunkä¸­çš„enhanced_descriptionç­‰æ–‡æœ¬å­—æ®µ
- **LLMè¾“å‡º**ï¼šåŸºäºè¿™äº›æ–‡æœ¬æè¿°ç”Ÿæˆç­”æ¡ˆ

è¿™æ ·è®¾è®¡æ—¢ä¿è¯äº†LLMèƒ½å¤Ÿç†è§£å›¾ç‰‡å†…å®¹ï¼Œåˆä¿æŒäº†ç³»ç»Ÿä¸­å›¾ç‰‡ä¿¡æ¯çš„å®Œæ•´æ€§ã€‚







## ğŸ¯ **æºè¿‡æ»¤çš„æ•´ä½“æ¶æ„**

### **1. æ ¸å¿ƒç»„ä»¶**
- **SourceFilterEngine**: ä¸»è¦çš„æºè¿‡æ»¤å¼•æ“
- **å¤šç§è¿‡æ»¤ç­–ç•¥**: æ ¹æ®æŸ¥è¯¢ç±»å‹é€‰æ‹©ä¸åŒçš„è¿‡æ»¤æ–¹æ³•
- **åŠ¨æ€é˜ˆå€¼è°ƒæ•´**: æ ¹æ®ç­”æ¡ˆå†…å®¹æ™ºèƒ½è°ƒæ•´è¿‡æ»¤æ ‡å‡†

### **2. è¿‡æ»¤ç­–ç•¥åˆ†ç±»**

#### **æ–‡æœ¬æŸ¥è¯¢è¿‡æ»¤ç­–ç•¥** (`_filter_text_sources`)
```python
# ä½¿ç”¨æ ‡å‡†é˜ˆå€¼ï¼š0.6
if relevance_score >= adjusted_threshold:
    filtered_sources.append(source_copy)
```

#### **å›¾ç‰‡æŸ¥è¯¢è¿‡æ»¤ç­–ç•¥** (`_filter_image_sources`)
```python
# ä½¿ç”¨æ›´ä½çš„é˜ˆå€¼ï¼š0.05ï¼ˆå¤§å¹…é™ä½ï¼‰
if relevance_score >= 0.05:
    filtered_sources.append(source_copy)
```

#### **è¡¨æ ¼æŸ¥è¯¢è¿‡æ»¤ç­–ç•¥** (`_filter_table_sources`)
```python
# ä½¿ç”¨ä¸­ç­‰é˜ˆå€¼ï¼š0.15
if relevance_score >= 0.15:
    filtered_sources.append(source_copy)
```

#### **æ··åˆæŸ¥è¯¢è¿‡æ»¤ç­–ç•¥** (`_filter_hybrid_sources`)
```python
# æŒ‰ç±»å‹åˆ†ç»„ï¼Œç¡®ä¿å„ç±»å‹æºéƒ½æœ‰ä»£è¡¨æ€§
text_sources = []
image_sources = []
table_sources = []
# ä¸ºæ¯ç§ç±»å‹åˆ†é…é…é¢
max_per_type = min(self.config.max_sources_to_keep // 3, 5)
```

## ğŸ” **ç›¸å…³æ€§è®¡ç®—æœºåˆ¶**

### **1. å¤šç»´åº¦è¯„åˆ†**
```python
def _calculate_source_relevance(self, source, answer_keywords, answer_entities, llm_answer, query):
    # 1. å…³é”®è¯åŒ¹é…åˆ†æ•°
    keyword_score = self._calculate_keyword_match_score(answer_keywords, source_content)
    
    # 2. å®ä½“åŒ¹é…åˆ†æ•°
    entity_score = self._calculate_entity_match_score(answer_entities, source_content)
    
    # 3. å†…å®¹é‡å åˆ†æ•°
    overlap_score = self._calculate_content_overlap_score(llm_answer, source_content)
    
    # 4. å…ƒæ•°æ®ç›¸å…³æ€§åˆ†æ•°
    metadata_score = self._calculate_metadata_relevance_score(source_metadata, query, llm_answer)
    
    # 5. è®¡ç®—ç»¼åˆåˆ†æ•°
    comprehensive_score = (
        keyword_score * self.config.keyword_match_weight +
        entity_score * self.config.keyword_match_weight * 0.5 +
        overlap_score * self.config.semantic_similarity_weight +
        metadata_score * self.config.content_quality_weight
    )
```

### **2. æƒé‡é…ç½®**
```python
@dataclass
class SourceFilterConfig:
    keyword_match_weight: float = 0.4        # å…³é”®è¯åŒ¹é…æƒé‡
    semantic_similarity_weight: float = 0.4  # è¯­ä¹‰ç›¸ä¼¼åº¦æƒé‡
    content_quality_weight: float = 0.2      # å†…å®¹è´¨é‡æƒé‡
```

## ğŸ›ï¸ **æ™ºèƒ½é˜ˆå€¼è°ƒæ•´**

### **1. åŠ¨æ€é˜ˆå€¼è°ƒæ•´**
```python
def _adjust_threshold_dynamically(self, scored_sources, llm_answer):
    # åŸºäºç­”æ¡ˆé•¿åº¦è°ƒæ•´é˜ˆå€¼
    answer_length = len(llm_answer)
    
    if answer_length < 100:  # çŸ­ç­”æ¡ˆï¼Œé™ä½é˜ˆå€¼
        adjusted_threshold = mean_score * 0.8
    elif answer_length > 500:  # é•¿ç­”æ¡ˆï¼Œæé«˜é˜ˆå€¼
        adjusted_threshold = mean_score * 1.2
    else:  # ä¸­ç­‰é•¿åº¦ï¼Œä½¿ç”¨å‡å€¼
        adjusted_threshold = mean_score
```

### **2. æ•°é‡æ§åˆ¶**
```python
# ç¡®ä¿ä¿ç•™æœ€å°æ•°é‡çš„æº
if len(filtered_sources) < self.config.min_sources_to_keep:
    filtered_sources = self._ensure_minimum_sources(scored_sources, self.config.min_sources_to_keep)

# é™åˆ¶æœ€å¤§æºæ•°é‡
if len(filtered_sources) > self.config.max_sources_to_keep:
    filtered_sources = filtered_sources[:self.config.max_sources_to_keep]
```

## ğŸ”„ **æºè¿‡æ»¤çš„å®Œæ•´æµç¨‹**

### **1. è¾“å…¥é˜¶æ®µ**
- **LLMç­”æ¡ˆ**: ç”Ÿæˆçš„å›ç­”å†…å®¹
- **æºåˆ—è¡¨**: å¬å›å’Œé‡æ’åºåçš„å€™é€‰æº
- **æŸ¥è¯¢ä¿¡æ¯**: åŸå§‹ç”¨æˆ·æŸ¥è¯¢å’ŒæŸ¥è¯¢ç±»å‹

### **2. ç­–ç•¥é€‰æ‹©**
```python
if query_type == 'image':
    return self._filter_image_sources(llm_answer, sources, query)
elif query_type == 'table':
    return self._filter_table_sources(llm_answer, sources, query)
elif query_type == 'text':
    return self._filter_text_sources(llm_answer, sources, query)
elif query_type == 'hybrid':
    return self._filter_hybrid_sources(llm_answer, sources, query)
else:
    return self._filter_sources_with_detection(llm_answer, sources, query)
```

### **3. è¿‡æ»¤å¤„ç†**
- **ç›¸å…³æ€§è®¡ç®—**: å¤šç»´åº¦è¯„åˆ†
- **é˜ˆå€¼è¿‡æ»¤**: æ ¹æ®ç­–ç•¥é€‰æ‹©ä¸åŒé˜ˆå€¼
- **æ•°é‡æ§åˆ¶**: ç¡®ä¿æºæ•°é‡åœ¨åˆç†èŒƒå›´å†…
- **ç»“æœæ’åº**: æŒ‰ç›¸å…³æ€§åˆ†æ•°æ’åº

### **4. è¾“å‡ºé˜¶æ®µ**
- **è¿‡æ»¤åçš„æºåˆ—è¡¨**: ä¿ç•™é«˜ç›¸å…³æ€§çš„æº
- **ç›¸å…³æ€§åˆ†æ•°**: æ¯ä¸ªæºçš„ç›¸å…³æ€§è¯„åˆ†
- **å…ƒæ•°æ®å®Œæ•´æ€§**: ç¡®ä¿æ‰€æœ‰é‡è¦ä¿¡æ¯ä¸ä¸¢å¤±

## ğŸ’¡ **å…³é”®ç‰¹æ€§**

1. **æ™ºèƒ½ç­–ç•¥é€‰æ‹©**: æ ¹æ®æŸ¥è¯¢ç±»å‹è‡ªåŠ¨é€‰æ‹©æœ€ä½³è¿‡æ»¤ç­–ç•¥
2. **åŠ¨æ€é˜ˆå€¼è°ƒæ•´**: æ ¹æ®ç­”æ¡ˆå†…å®¹å’Œåˆ†æ•°åˆ†å¸ƒæ™ºèƒ½è°ƒæ•´è¿‡æ»¤æ ‡å‡†
3. **å¤šç»´åº¦è¯„åˆ†**: ç»¼åˆè€ƒè™‘å…³é”®è¯ã€å®ä½“ã€å†…å®¹é‡å ã€å…ƒæ•°æ®ç­‰å¤šä¸ªæ–¹é¢
4. **æ•°é‡å¹³è¡¡**: ç¡®ä¿è¿‡æ»¤åçš„æºæ•°é‡æ—¢ä¸è¿‡å¤šä¹Ÿä¸è¿‡å°‘
5. **ä¿¡æ¯å®Œæ•´æ€§**: åœ¨è¿‡æ»¤è¿‡ç¨‹ä¸­ä¿æŒæ‰€æœ‰é‡è¦å…ƒæ•°æ®ä¿¡æ¯

è¿™ç§è®¾è®¡ç¡®ä¿äº†æºè¿‡æ»¤æ—¢èƒ½æœ‰æ•ˆå»é™¤ä½ç›¸å…³æ€§çš„æºï¼Œåˆèƒ½ä¿æŒç»“æœçš„å¤šæ ·æ€§å’Œå®Œæ•´æ€§ã€‚





## ï¿½ï¿½ **æºè¿‡æ»¤åŸºäºçš„æºç±»å‹**

### **1. æºè¿‡æ»¤çš„è¾“å…¥æº**
æºè¿‡æ»¤å¼•æ“æ¥æ”¶çš„`sources`å‚æ•°æ˜¯**é‡æ’åºåçš„ç»“æœ**ï¼Œå…·ä½“åŒ…æ‹¬ï¼š

```python
def filter_sources(self, llm_answer: str, sources: List[Dict[str, Any]], 
                  query: str = "", query_type: str = None) -> List[Dict[str, Any]]:
    """
    :param sources: æºåˆ—è¡¨ - è¿™æ˜¯é‡æ’åºåçš„å€™é€‰æº
    """
```

### **2. æºçš„æ¥æºè·¯å¾„**

#### **å®Œæ•´çš„æ•°æ®æµ**ï¼š
```
ç”¨æˆ·æŸ¥è¯¢ â†’ å¬å›é˜¶æ®µ â†’ é‡æ’åºé˜¶æ®µ â†’ æºè¿‡æ»¤é˜¶æ®µ â†’ æœ€ç»ˆç»“æœ
    â†“           â†“           â†“           â†“
   query   recall_results  reranked_results  filtered_sources
```

## ğŸ”„ **æºæ˜¯å¦‚ä½•è·å¾—çš„**

### **1. å¬å›é˜¶æ®µè·å¾—åˆå§‹æº**
```python
# åœ¨ImageEngineä¸­
def _search_images_with_five_layer_recall(self, query: str):
    # ç¬¬ä¸€å±‚ï¼šå‘é‡ç›¸ä¼¼åº¦æœç´¢
    vector_results = self._vector_search(query, max_recall_results // 3)
    
    # å»é‡å’Œæ’åº
    final_results = self._deduplicate_and_sort_results(all_candidates)
    
    return final_results[:max_results]  # è¿”å›å¬å›ç»“æœ
```

### **2. é‡æ’åºé˜¶æ®µå¤„ç†æº**
```python
# åœ¨ImageEngineçš„process_queryä¸­
if getattr(self.config, 'enable_enhanced_reranking', False):
    # åˆ›å»ºImageRerankingService
    reranking_service = create_reranking_service('image', reranking_config)
    
    # æ‰§è¡ŒReranking - è¾“å…¥æ˜¯å¬å›ç»“æœ
    reranked_results = reranking_service.rerank(query, recall_results)
```

### **3. æºè¿‡æ»¤é˜¶æ®µæ¥æ”¶æº**
```python
# åœ¨UnifiedPipelineä¸­
def _filter_sources(self, llm_answer: str, results: List[Dict[str, Any]], query: str, query_type: str):
    # resultså°±æ˜¯reranked_resultsï¼ˆé‡æ’åºåçš„ç»“æœï¼‰
    
    # ä½¿ç”¨æºè¿‡æ»¤å¼•æ“
    if self.source_filter_engine:
        filtered_results = self.source_filter_engine.filter_sources(
            llm_answer, enhanced_results, query, query_type
        )
```

## ğŸ“Š **æºçš„å…·ä½“å†…å®¹ç»“æ„**

### **1. å¬å›é˜¶æ®µçš„æºç»“æ„**
```python
# ç­–ç•¥1å¬å›çš„ç»“æœ
{
    'doc': image_doc,  # å®Œæ•´çš„image chunk
    'score': score * 1.2,
    'source': 'vector_search',
    'layer': 1,
    'search_method': 'semantic_similarity',
    'semantic_score': score,
    'related_image_text_id': doc.metadata.get('image_id'),
    'enhanced_description': doc.metadata.get('enhanced_description', ''),
    'document_name': doc.metadata.get('document_name', ''),
    'page_number': doc.metadata.get('page_number', ''),
    'chunk_type': doc.metadata.get('chunk_type', ''),
    'image_path': image_doc.metadata.get('image_path', ''),
    'caption': image_doc.metadata.get('img_caption', [])
}

# ç­–ç•¥2å¬å›çš„ç»“æœ
{
    'doc': candidate['doc'],
    'score': score * 0.8,
    'source': 'vector_search',
    'layer': 1,
    'search_method': 'cross_modal_similarity',
    'cross_modal_score': score,
    'query_embedding_dim': len(query_embedding),
    'faiss_distance': candidate['distance'],
    'faiss_index': candidate['index']
}
```

### **2. é‡æ’åºåçš„æºç»“æ„**
```python
# é‡æ’åºæœåŠ¡ä¼šæ·»åŠ æ–°çš„å­—æ®µ
{
    'doc': original_doc,  # åŸå§‹æ–‡æ¡£å¯¹è±¡
    'score': original_score,
    'rerank_score': rerank_score,  # æ–°å¢ï¼šé‡æ’åºåˆ†æ•°
    'rerank_rank': rank,           # æ–°å¢ï¼šé‡æ’åºæ’å
    'reranking_method': 'llm',     # æ–°å¢ï¼šé‡æ’åºæ–¹æ³•
    'source': 'image_reranking_service',  # æ–°å¢ï¼šæ¥æºæ ‡è¯†
    # ... å…¶ä»–åŸå§‹å­—æ®µ
}
```

### **3. æºè¿‡æ»¤æ¥æ”¶çš„æºç»“æ„**
```python
# æºè¿‡æ»¤å¼•æ“æ¥æ”¶çš„å°±æ˜¯é‡æ’åºåçš„ç»“æœ
sources = [
    {
        'doc': image_chunk,           # å®Œæ•´çš„image chunk
        'score': original_score,      # åŸå§‹å¬å›åˆ†æ•°
        'rerank_score': rerank_score, # é‡æ’åºåˆ†æ•°
        'rerank_rank': rank,          # é‡æ’åºæ’å
        'reranking_method': 'llm',    # é‡æ’åºæ–¹æ³•
        'source': 'image_reranking_service',
        # ... å…¶ä»–å­—æ®µ
    },
    # ... æ›´å¤šæº
]
```

## ğŸ” **æºè¿‡æ»¤çš„å¤„ç†å¯¹è±¡**

### **1. æºè¿‡æ»¤ä¸»è¦å¤„ç†**
- **docå¯¹è±¡**: åŒ…å«å®Œæ•´çš„image chunkä¿¡æ¯
- **åˆ†æ•°ä¿¡æ¯**: åŸå§‹åˆ†æ•°å’Œé‡æ’åºåˆ†æ•°
- **å…ƒæ•°æ®**: æ–‡æ¡£åç§°ã€é¡µç ã€chunkç±»å‹ç­‰
- **é‡æ’åºä¿¡æ¯**: é‡æ’åºåˆ†æ•°ã€æ’åã€æ–¹æ³•ç­‰

### **2. æºè¿‡æ»¤çš„è¿‡æ»¤ä¾æ®**
```python
def _calculate_source_relevance(self, source, answer_keywords, answer_entities, llm_answer, query):
    # è·å–æºå†…å®¹
    source_content = source.get('content', '')  # ä»docä¸­æå–
    source_metadata = source.get('metadata', {}) # ä»docä¸­æå–
    
    # è®¡ç®—ç›¸å…³æ€§åˆ†æ•°
    keyword_score = self._calculate_keyword_match_score(answer_keywords, source_content)
    entity_score = self._calculate_entity_match_score(answer_entities, source_content)
    overlap_score = self._calculate_content_overlap_score(llm_answer, source_content)
    metadata_score = self._calculate_metadata_relevance_score(source_metadata, query, llm_answer)
```

## ğŸ“ **æ€»ç»“**

**æºè¿‡æ»¤åŸºäºçš„æº**ï¼š
1. **æ¥æº**: é‡æ’åºé˜¶æ®µè¾“å‡ºçš„`reranked_results`
2. **å†…å®¹**: åŒ…å«å®Œæ•´image chunkä¿¡æ¯çš„å€™é€‰æºåˆ—è¡¨
3. **ç»“æ„**: æ¯ä¸ªæºéƒ½åŒ…å«docå¯¹è±¡ã€åˆ†æ•°ã€å…ƒæ•°æ®ã€é‡æ’åºä¿¡æ¯ç­‰

**æºçš„è·å¾—è·¯å¾„**ï¼š
1. **å¬å›é˜¶æ®µ**: é€šè¿‡ä¸¤ç§ç­–ç•¥è·å¾—åˆå§‹å€™é€‰æº
2. **é‡æ’åºé˜¶æ®µ**: å¯¹å¬å›ç»“æœè¿›è¡Œé‡æ’åºï¼Œæ·»åŠ é‡æ’åºåˆ†æ•°
3. **æºè¿‡æ»¤é˜¶æ®µ**: æ¥æ”¶é‡æ’åºåçš„ç»“æœï¼ŒåŸºäºLLMç­”æ¡ˆè¿›è¡Œæ™ºèƒ½è¿‡æ»¤

è¿™æ ·è®¾è®¡ç¡®ä¿äº†æºè¿‡æ»¤èƒ½å¤ŸåŸºäºé«˜è´¨é‡çš„å€™é€‰æºè¿›è¡Œè¿‡æ»¤ï¼Œæ—¢åˆ©ç”¨äº†å¬å›é˜¶æ®µçš„å¤šæ ·æ€§ï¼Œåˆåˆ©ç”¨äº†é‡æ’åºé˜¶æ®µçš„å‡†ç¡®æ€§ã€‚

æ˜¯çš„ï¼Œå¯¹äºæ–‡æœ¬å’Œè¡¨æ ¼ï¼Œå¤„ç†æµç¨‹åŸºæœ¬æ˜¯ä¸€è‡´çš„ï¼è®©æˆ‘ä¸ºä½ è¯¦ç»†åˆ†æä¸€ä¸‹ï¼š

Search files...
Read file: v2/core/text_engine.py
Read file: v2/core/table_engine.py
Read file: v2/core/table_engine.py
åŸºäºå¯¹ä»£ç çš„æ·±å…¥åˆ†æï¼Œæˆ‘æ¥å›ç­”ä½ çš„é—®é¢˜ï¼š

## âœ… **æ–‡æœ¬å’Œè¡¨æ ¼çš„å¤„ç†æµç¨‹ä¸imageä¸€è‡´**

### **1. æ•´ä½“æµç¨‹æ¶æ„**

æ‰€æœ‰å¼•æ“ï¼ˆTextã€Imageã€Tableï¼‰éƒ½éµå¾ªç›¸åŒçš„å¤„ç†æ¨¡å¼ï¼š

```
ç”¨æˆ·æŸ¥è¯¢ â†’ å¬å›é˜¶æ®µ â†’ é‡æ’åºé˜¶æ®µ â†’ Pipelineå¤„ç† â†’ æœ€ç»ˆç»“æœ
    â†“           â†“           â†“           â†“
   query   recall_results  reranked_results  final_results
```

### **2. å…·ä½“å¯¹æ¯”åˆ†æ**

#### **TextEngineçš„å¤„ç†æµç¨‹**
```python
def process_query(self, query: str, **kwargs):
    # 1. æ‰§è¡Œäº”å±‚å¬å›ç­–ç•¥
    recall_results = self._search_texts(query, **kwargs)
    
    # 2. æ£€æŸ¥æ˜¯å¦å¯ç”¨å¢å¼ºReranking
    if getattr(self.config, 'enable_enhanced_reranking', False):
        reranking_service = create_reranking_service('text', reranking_config)
        reranked_results = reranking_service.rerank(query, recall_results)
        
        # 3. æ£€æŸ¥æ˜¯å¦ä½¿ç”¨æ–°çš„ç»Ÿä¸€Pipeline
        if getattr(self.config, 'use_new_pipeline', False):
            unified_pipeline = UnifiedPipeline(...)
            pipeline_result = unified_pipeline.process(query, reranked_results, query_type='text')
```

#### **TableEngineçš„å¤„ç†æµç¨‹**
```python
def process_query(self, query: str, **kwargs):
    # 1. æ‰§è¡Œæœç´¢ï¼ˆäº”å±‚å¬å›ç­–ç•¥ï¼‰
    search_results = self._search_tables(query)
    
    # 2. æ£€æŸ¥æ˜¯å¦ä½¿ç”¨æ–°Pipeline
    use_new_pipeline = getattr(self.config, 'use_new_pipeline', True)
    if use_new_pipeline:
        # ä½¿ç”¨æ–°Pipelineå¤„ç†ç»“æœ
        formatted_results = self._process_with_new_pipeline(query, search_results)
        
        # åœ¨_process_with_new_pipelineä¸­ï¼š
        # 1. é¦–å…ˆè¿›è¡Œé‡æ’åº
        reranked_results = self._rerank_table_results(query, search_results)
        # 2. ä½¿ç”¨ç»Ÿä¸€Pipelineå¤„ç†
        unified_pipeline = UnifiedPipeline(...)
        pipeline_result = unified_pipeline.process(query, reranked_results, query_type='table')
```

#### **ImageEngineçš„å¤„ç†æµç¨‹**
```python
def process_query(self, query: str, **kwargs):
    # 1. æ‰§è¡Œäº”å±‚å¬å›ç­–ç•¥
    recall_results = self._search_images_with_five_layer_recall(query)
    
    # 2. æ£€æŸ¥æ˜¯å¦å¯ç”¨å¢å¼ºReranking
    if getattr(self.config, 'enable_enhanced_reranking', False):
        reranking_service = create_reranking_service('image', reranking_config)
        reranked_results = reranking_service.rerank(query, recall_results)
        
        # 3. æ£€æŸ¥æ˜¯å¦ä½¿ç”¨æ–°çš„ç»Ÿä¸€Pipeline
        if getattr(self.config, 'use_new_pipeline', False):
            unified_pipeline = UnifiedPipeline(...)
            pipeline_result = unified_pipeline.process(query, reranked_results, query_type='image')
```

### **3. å…³é”®ç›¸ä¼¼ç‚¹**

#### **3.1 å¬å›ç­–ç•¥**
- **TextEngine**: äº”å±‚å¬å›ç­–ç•¥ï¼ˆå‘é‡æœç´¢ã€å…³é”®è¯åŒ¹é…ã€æ··åˆå¬å›ã€æ¨¡ç³ŠåŒ¹é…ã€æŸ¥è¯¢æ‰©å±•ï¼‰
- **TableEngine**: äº”å±‚å¬å›ç­–ç•¥ï¼ˆè¡¨æ ¼ç»“æ„ç²¾ç¡®åŒ¹é…ã€å¢å¼ºå‘é‡è¯­ä¹‰æœç´¢ã€è¡¨æ ¼å†…å®¹å…³é”®è¯åŒ¹é…ç­‰ï¼‰
- **ImageEngine**: äº”å±‚å¬å›ç­–ç•¥ï¼ˆå‘é‡ç›¸ä¼¼åº¦æœç´¢ã€è¯­ä¹‰å…³é”®è¯åŒ¹é…ã€æ··åˆå¬å›ã€æ™ºèƒ½æ¨¡ç³ŠåŒ¹é…ã€æŸ¥è¯¢æ‰©å±•å¬å›ï¼‰

#### **3.2 é‡æ’åºæœåŠ¡**
- **TextEngine**: `TextRerankingService`
- **TableEngine**: `TableRerankingService` 
- **ImageEngine**: `ImageRerankingService`

#### **3.3 Pipelineå¤„ç†**
- **TextEngine**: ä½¿ç”¨`UnifiedPipeline`ï¼ˆæ–°Pipelineï¼‰
- **TableEngine**: ä½¿ç”¨`UnifiedPipeline`ï¼ˆæ–°Pipelineï¼‰
- **ImageEngine**: ä½¿ç”¨`UnifiedPipeline`ï¼ˆæ–°Pipelineï¼‰

### **4. ç»†å¾®å·®å¼‚**

#### **4.1 å¬å›æ–¹æ³•åç§°**
```python
# TextEngine
recall_results = self._search_texts(query, **kwargs)

# TableEngine  
search_results = self._search_tables(query)

# ImageEngine
recall_results = self._search_images_with_five_layer_recall(query)
```

#### **4.2 ç»“æœæ ¼å¼åŒ–**
```python
# TextEngine: ç›´æ¥ä½¿ç”¨Pipelineç»“æœ
final_results = pipeline_result.filtered_sources

# TableEngine: é¢å¤–çš„æ ¼å¼åŒ–å¤„ç†
formatted_results = self._process_with_new_pipeline(query, search_results)

# ImageEngine: ç›´æ¥ä½¿ç”¨Pipelineç»“æœ
final_results = pipeline_result.filtered_sources
```

### **5. æ€»ç»“**

**æ˜¯çš„ï¼Œæ–‡æœ¬å’Œè¡¨æ ¼çš„å¤„ç†æµç¨‹åŸºæœ¬ä¸€è‡´ï¼** å®ƒä»¬éƒ½éµå¾ªï¼š

1. **ç›¸åŒçš„æ¶æ„æ¨¡å¼**: å¬å› â†’ é‡æ’åº â†’ Pipelineå¤„ç†
2. **ç›¸åŒçš„Pipeline**: éƒ½ä½¿ç”¨`UnifiedPipeline`è¿›è¡ŒLLMç”Ÿæˆå’Œæºè¿‡æ»¤
3. **ç›¸åŒçš„é‡æ’åº**: éƒ½æœ‰å¯¹åº”çš„é‡æ’åºæœåŠ¡
4. **ç›¸åŒçš„é…ç½®ç®¡ç†**: éƒ½æ”¯æŒ`enable_enhanced_reranking`å’Œ`use_new_pipeline`é…ç½®

è¿™ç§è®¾è®¡ç¡®ä¿äº†ç³»ç»Ÿçš„ä¸€è‡´æ€§å’Œå¯ç»´æŠ¤æ€§ï¼ŒåŒæ—¶å…è®¸æ¯ä¸ªå¼•æ“æ ¹æ®å…¶ç‰¹å®šéœ€æ±‚è¿›è¡Œå¾®è°ƒã€‚





## ğŸ¯ **å½“å‰æºè¿‡æ»¤çš„ç²¾åº¦åˆ†æ**

### **1. ç°æœ‰æœºåˆ¶çš„ä¼˜åŠ¿**
```python
# å¤šç»´åº¦è¯„åˆ†ç³»ç»Ÿ
def _calculate_source_relevance(self, source, answer_keywords, answer_entities, llm_answer, query):
    # 1. å…³é”®è¯åŒ¹é…åˆ†æ•°
    keyword_score = self._calculate_keyword_match_score(answer_keywords, source_content)
    
    # 2. å®ä½“åŒ¹é…åˆ†æ•°  
    entity_score = self._calculate_entity_match_score(answer_entities, source_content)
    
    # 3. å†…å®¹é‡å åˆ†æ•°
    overlap_score = self._calculate_content_overlap_score(llm_answer, source_content)
    
    # 4. å…ƒæ•°æ®ç›¸å…³æ€§åˆ†æ•°
    metadata_score = self._calculate_metadata_relevance_score(source_metadata, query, llm_answer)
```

### **2. å½“å‰é˜ˆå€¼çš„è®¾ç½®**
```python
# ä¸åŒæŸ¥è¯¢ç±»å‹çš„é˜ˆå€¼
if query_type == 'image':
    threshold = 0.05  # å›¾ç‰‡æŸ¥è¯¢é˜ˆå€¼å¾ˆä½
elif query_type == 'table':
    threshold = 0.15  # è¡¨æ ¼æŸ¥è¯¢ä¸­ç­‰é˜ˆå€¼
elif query_type == 'text':
    threshold = 0.6   # æ–‡æœ¬æŸ¥è¯¢æ ‡å‡†é˜ˆå€¼
```

## ï¿½ï¿½ **æé«˜ç²¾åº¦çš„ä¼˜åŒ–æ–¹æ¡ˆ**

### **æ–¹æ¡ˆ1ï¼šæ™ºèƒ½é˜ˆå€¼åŠ¨æ€è°ƒæ•´**

#### **1.1 åŸºäºç­”æ¡ˆè´¨é‡çš„åŠ¨æ€é˜ˆå€¼**
```python
def _calculate_dynamic_threshold(self, llm_answer: str, sources: List[Dict[str, Any]]) -> float:
    """åŸºäºç­”æ¡ˆè´¨é‡åŠ¨æ€è°ƒæ•´é˜ˆå€¼"""
    
    # 1. åˆ†æç­”æ¡ˆçš„ç½®ä¿¡åº¦æŒ‡æ ‡
    confidence_indicators = {
        'specific_numbers': len(re.findall(r'\d+(?:\.\d+)?', llm_answer)),
        'specific_entities': len(re.findall(r'[""]([^""]+)[""]', llm_answer)),
        'causal_relationships': len(re.findall(r'å› ä¸º|ç”±äº|å¯¼è‡´|å› æ­¤|æ‰€ä»¥', llm_answer)),
        'comparative_statements': len(re.findall(r'æ¯”|æ›´|æœ€|é«˜äº|ä½äº', llm_answer))
    }
    
    # 2. è®¡ç®—ç­”æ¡ˆè´¨é‡åˆ†æ•°
    quality_score = sum(confidence_indicators.values()) / len(confidence_indicators)
    
    # 3. åŸºäºè´¨é‡åˆ†æ•°è°ƒæ•´é˜ˆå€¼
    if quality_score > 3:  # é«˜è´¨é‡ç­”æ¡ˆ
        return self.config.relevance_threshold * 1.5  # æé«˜é˜ˆå€¼ï¼Œæ›´ä¸¥æ ¼
    elif quality_score > 1:  # ä¸­ç­‰è´¨é‡ç­”æ¡ˆ
        return self.config.relevance_threshold * 1.2  # é€‚åº¦æé«˜é˜ˆå€¼
    else:  # ä½è´¨é‡ç­”æ¡ˆ
        return self.config.relevance_threshold * 0.8  # é™ä½é˜ˆå€¼ï¼Œæ›´å®½æ¾
```

#### **1.2 åŸºäºæºåˆ†å¸ƒçš„è‡ªé€‚åº”é˜ˆå€¼**
```python
def _adaptive_threshold_based_on_distribution(self, scored_sources: List[Dict[str, Any]]) -> float:
    """åŸºäºåˆ†æ•°åˆ†å¸ƒè‡ªé€‚åº”è°ƒæ•´é˜ˆå€¼"""
    
    if not scored_sources:
        return self.config.relevance_threshold
    
    scores = [source.get('relevance_score', 0) for source in scored_sources]
    scores = [s for s in scores if s > 0]
    
    if not scores:
        return self.config.relevance_threshold
    
    # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
    mean_score = sum(scores) / len(scores)
    std_score = (sum((s - mean_score) ** 2 for s in scores) / len(scores)) ** 0.5
    
    # ä½¿ç”¨ç™¾åˆ†ä½æ•°æ–¹æ³•
    sorted_scores = sorted(scores, reverse=True)
    top_30_percentile = sorted_scores[int(len(sorted_scores) * 0.3)]
    top_50_percentile = sorted_scores[int(len(sorted_scores) * 0.5)]
    
    # åŠ¨æ€é˜ˆå€¼ï¼šåŸºäºåˆ†å¸ƒç‰¹å¾
    if std_score < 0.1:  # åˆ†æ•°åˆ†å¸ƒé›†ä¸­
        return top_50_percentile  # ä½¿ç”¨ä¸­ä½æ•°
    elif std_score < 0.3:  # åˆ†æ•°åˆ†å¸ƒä¸­ç­‰
        return top_30_percentile  # ä½¿ç”¨å‰30%åˆ†ä½æ•°
    else:  # åˆ†æ•°åˆ†å¸ƒåˆ†æ•£
        return mean_score + std_score  # ä½¿ç”¨å‡å€¼+æ ‡å‡†å·®
```

### **æ–¹æ¡ˆ2ï¼šå¢å¼ºçš„ç›¸å…³æ€§è®¡ç®—**

#### **2.1 è¯­ä¹‰ç›¸ä¼¼åº¦å¢å¼º**
```python
def _enhanced_semantic_similarity(self, llm_answer: str, source_content: str) -> float:
    """å¢å¼ºçš„è¯­ä¹‰ç›¸ä¼¼åº¦è®¡ç®—"""
    
    # 1. å¥å­çº§åˆ«çš„ç›¸ä¼¼åº¦
    answer_sentences = self._split_into_sentences(llm_answer)
    source_sentences = self._split_into_sentences(source_content)
    
    sentence_similarities = []
    for ans_sent in answer_sentences:
        for src_sent in source_sentences:
            similarity = self._calculate_sentence_similarity(ans_sent, src_sent)
            sentence_similarities.append(similarity)
    
    # 2. æ®µè½çº§åˆ«çš„ç›¸ä¼¼åº¦
    paragraph_similarity = self._calculate_paragraph_similarity(llm_answer, source_content)
    
    # 3. åŠ æƒç»„åˆ
    if sentence_similarities:
        max_sentence_sim = max(sentence_similarities)
        sentence_weight = 0.6
        paragraph_weight = 0.4
        return max_sentence_sim * sentence_weight + paragraph_similarity * paragraph_weight
    else:
        return paragraph_similarity
```

#### **2.2 å†…å®¹ç»“æ„åˆ†æ**
```python
def _analyze_content_structure_relevance(self, llm_answer: str, source_content: str) -> float:
    """åˆ†æå†…å®¹ç»“æ„ç›¸å…³æ€§"""
    
    # 1. æ£€æŸ¥æ˜¯å¦åŒ…å«ç›¸åŒçš„æ•°æ®ç±»å‹
    answer_data_types = self._extract_data_types(llm_answer)
    source_data_types = self._extract_data_types(source_content)
    
    data_type_overlap = len(set(answer_data_types) & set(source_data_types))
    data_type_total = len(set(answer_data_types) | set(source_data_types))
    data_type_score = data_type_overlap / data_type_total if data_type_total > 0 else 0
    
    # 2. æ£€æŸ¥æ—¶é—´èŒƒå›´åŒ¹é…
    time_relevance = self._calculate_time_relevance(llm_answer, source_content)
    
    # 3. æ£€æŸ¥æ•°å€¼èŒƒå›´åŒ¹é…
    numerical_relevance = self._calculate_numerical_relevance(llm_answer, source_content)
    
    # 4. ç»¼åˆè¯„åˆ†
    structure_score = (data_type_score * 0.4 + time_relevance * 0.3 + numerical_relevance * 0.3)
    
    return structure_score
```

### **æ–¹æ¡ˆ3ï¼šæ™ºèƒ½æºå»é‡å’Œåˆå¹¶**

#### **3.1 åŸºäºå†…å®¹çš„æ™ºèƒ½å»é‡**
```python
def _intelligent_source_deduplication(self, sources: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    """æ™ºèƒ½æºå»é‡å’Œåˆå¹¶"""
    
    deduplicated_sources = []
    seen_content_hashes = set()
    
    for source in sources:
        # 1. è®¡ç®—å†…å®¹å“ˆå¸Œï¼ˆå»é™¤æ ¼å¼å·®å¼‚ï¼‰
        content_hash = self._calculate_content_hash(source.get('content', ''))
        
        if content_hash in seen_content_hashes:
            # 2. æ‰¾åˆ°é‡å¤æºï¼Œè¿›è¡Œæ™ºèƒ½åˆå¹¶
            existing_source = next(s for s in deduplicated_sources 
                                 if self._calculate_content_hash(s.get('content', '')) == content_hash)
            
            # 3. åˆå¹¶å…ƒæ•°æ®ï¼Œä¿ç•™æœ€é«˜åˆ†æ•°
            merged_source = self._merge_sources(existing_source, source)
            deduplicated_sources.remove(existing_source)
            deduplicated_sources.append(merged_source)
        else:
            seen_content_hashes.add(content_hash)
            deduplicated_sources.append(source)
    
    return deduplicated_sources
```

#### **3.2 åŸºäºè¯­ä¹‰çš„æºåˆå¹¶**
```python
def _semantic_based_source_merging(self, sources: List[Dict[str, Any]], 
                                  llm_answer: str) -> List[Dict[str, Any]]:
    """åŸºäºè¯­ä¹‰çš„æºåˆå¹¶"""
    
    # 1. æŒ‰è¯­ä¹‰ç›¸ä¼¼åº¦åˆ†ç»„
    semantic_groups = self._group_sources_by_semantic_similarity(sources)
    
    # 2. æ¯ç»„å†…é€‰æ‹©æœ€ä½³ä»£è¡¨
    merged_sources = []
    for group in semantic_groups:
        if len(group) == 1:
            merged_sources.append(group[0])
        else:
            # é€‰æ‹©ä¸LLMç­”æ¡ˆæœ€ç›¸å…³çš„æºä½œä¸ºä»£è¡¨
            best_source = max(group, key=lambda s: s.get('relevance_score', 0))
            
            # åˆå¹¶å…¶ä»–æºçš„è¡¥å……ä¿¡æ¯
            enhanced_source = self._enhance_source_with_group_info(best_source, group)
            merged_sources.append(enhanced_source)
    
    return merged_sources
```

### **æ–¹æ¡ˆ4ï¼šé…ç½®ä¼˜åŒ–**

#### **4.1 æ›´ä¸¥æ ¼çš„é»˜è®¤é…ç½®**
```python
@dataclass
class EnhancedSourceFilterConfig(SourceFilterConfig):
    """å¢å¼ºçš„æºè¿‡æ»¤é…ç½®"""
    # æé«˜é»˜è®¤é˜ˆå€¼
    relevance_threshold: float = 0.7  # ä»0.6æé«˜åˆ°0.7
    content_overlap_threshold: float = 0.4  # ä»0.3æé«˜åˆ°0.4
    
    # å‡å°‘ä¿ç•™çš„æºæ•°é‡
    min_sources_to_keep: int = 1  # ä»1ä¿æŒä¸å˜
    max_sources_to_keep: int = 5  # ä»10å‡å°‘åˆ°5
    
    # æ–°å¢é…ç½®
    enable_semantic_grouping: bool = True  # å¯ç”¨è¯­ä¹‰åˆ†ç»„
    enable_intelligent_deduplication: bool = True  # å¯ç”¨æ™ºèƒ½å»é‡
    enable_content_structure_analysis: bool = True  # å¯ç”¨å†…å®¹ç»“æ„åˆ†æ
    enable_confidence_based_filtering: bool = True  # å¯ç”¨ç½®ä¿¡åº¦è¿‡æ»¤
```

#### **4.2 æŸ¥è¯¢ç±»å‹ç‰¹å®šçš„ä¼˜åŒ–é…ç½®**
```python
def _get_query_type_specific_config(self, query_type: str) -> Dict[str, Any]:
    """è·å–æŸ¥è¯¢ç±»å‹ç‰¹å®šçš„é…ç½®"""
    
    base_config = {
        'enable_semantic_grouping': True,
        'enable_intelligent_deduplication': True,
        'enable_content_structure_analysis': True
    }
    
    if query_type == 'image':
        return {
            **base_config,
            'relevance_threshold': 0.3,  # å›¾ç‰‡æŸ¥è¯¢æé«˜é˜ˆå€¼
            'max_sources_to_keep': 3,    # å›¾ç‰‡æŸ¥è¯¢å‡å°‘æºæ•°é‡
            'enable_visual_content_analysis': True
        }
    elif query_type == 'table':
        return {
            **base_config,
            'relevance_threshold': 0.5,  # è¡¨æ ¼æŸ¥è¯¢æé«˜é˜ˆå€¼
            'max_sources_to_keep': 4,    # è¡¨æ ¼æŸ¥è¯¢é€‚åº¦å‡å°‘æºæ•°é‡
            'enable_table_structure_analysis': True
        }
    elif query_type == 'text':
        return {
            **base_config,
            'relevance_threshold': 0.8,  # æ–‡æœ¬æŸ¥è¯¢å¤§å¹…æé«˜é˜ˆå€¼
            'max_sources_to_keep': 3,    # æ–‡æœ¬æŸ¥è¯¢å¤§å¹…å‡å°‘æºæ•°é‡
            'enable_text_quality_analysis': True
        }
    
    return base_config
```

## ï¿½ï¿½ **é¢„æœŸæ•ˆæœ**

### **1. ç²¾åº¦æå‡**
- **ç›¸å…³æ€§åˆ†æ•°æ›´å‡†ç¡®**: å¤šç»´åº¦è¯„åˆ† + è¯­ä¹‰åˆ†æ
- **é˜ˆå€¼æ›´æ™ºèƒ½**: åŠ¨æ€è°ƒæ•´ + è‡ªé€‚åº”ç®—æ³•
- **å»é‡æ›´æœ‰æ•ˆ**: æ™ºèƒ½åˆå¹¶ + è¯­ä¹‰åˆ†ç»„

### **2. æºæ•°é‡å‡å°‘**
- **é»˜è®¤é…ç½®æ›´ä¸¥æ ¼**: é˜ˆå€¼æé«˜ + æ•°é‡é™åˆ¶
- **æ™ºèƒ½å»é‡**: å†…å®¹å»é‡ + è¯­ä¹‰åˆå¹¶
- **è´¨é‡ä¼˜å…ˆ**: ä¿ç•™æœ€ç›¸å…³çš„é«˜è´¨é‡æº

### **3. æ€§èƒ½ä¼˜åŒ–**
- **è®¡ç®—æ•ˆç‡**: é¿å…é‡å¤è®¡ç®—
- **å†…å­˜ä½¿ç”¨**: å‡å°‘å†—ä½™æ•°æ®
- **å“åº”é€Ÿåº¦**: æ›´å¿«çš„æºè¿‡æ»¤

## ï¿½ï¿½ **å®æ–½å»ºè®®**

1. **æ¸è¿›å¼å®æ–½**: å…ˆå®ç°åŠ¨æ€é˜ˆå€¼è°ƒæ•´ï¼Œå†é€æ­¥æ·»åŠ å…¶ä»–åŠŸèƒ½
2. **A/Bæµ‹è¯•**: å¯¹æ¯”æ–°æ—§ç®—æ³•çš„æ•ˆæœ
3. **ç›‘æ§æŒ‡æ ‡**: è·Ÿè¸ªæºæ•°é‡ã€ç›¸å…³æ€§åˆ†æ•°ã€ç”¨æˆ·æ»¡æ„åº¦ç­‰æŒ‡æ ‡
4. **é…ç½®è°ƒä¼˜**: æ ¹æ®å®é™…ä½¿ç”¨æƒ…å†µè°ƒæ•´å‚æ•°

è¿™äº›ä¼˜åŒ–æ–¹æ¡ˆå¯ä»¥æ˜¾è‘—æé«˜æºè¿‡æ»¤çš„ç²¾åº¦ï¼Œå‡å°‘æœ€ç»ˆæºæ–‡ä»¶çš„æ•°é‡ï¼ŒåŒæ—¶ä¿æŒç³»ç»Ÿçš„ç¨³å®šæ€§å’Œå¯ç»´æŠ¤æ€§ã€‚





## ğŸ¯ **LLMç”Ÿæˆç­”æ¡ˆå‰çš„å¤„ç†æµç¨‹åˆ†æ**

### **1. å®Œæ•´çš„å¤„ç†é“¾è·¯**
```
ç”¨æˆ·æŸ¥è¯¢ â†’ å¬å› â†’ é‡æ’åº â†’ æºè¿‡æ»¤ â†’ LLMç”Ÿæˆ â†’ æœ€ç»ˆç»“æœ
    â†“        â†“       â†“        â†“        â†“
   query  recall  rerank   filter   generate
```

### **2. å„é˜¶æ®µçš„å»é‡å’Œå¤„ç†**

#### **å¬å›é˜¶æ®µï¼šå·²ç»å»é‡**
```python
# åœ¨ImageEngineçš„_vector_searchä¸­
def _deduplicate_and_sort_results(self, results: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    """å»é‡å’Œæ’åºç»“æœ"""
    # å»é‡ï¼ˆåŸºäºæ–‡æ¡£IDï¼‰
    seen_docs = set()
    unique_results = []
    
    for result in results:
        doc_id = self._get_doc_id(result['doc'])
        if doc_id not in seen_docs:
            seen_docs.add(doc_id)
            unique_results.append(result)
    
    # æŒ‰åˆ†æ•°æ’åº
    unique_results.sort(key=lambda x: x['score'], reverse=True)
    return unique_results
```

#### **é‡æ’åºé˜¶æ®µï¼šè¿›ä¸€æ­¥ä¼˜åŒ–**
```python
# åœ¨é‡æ’åºæœåŠ¡ä¸­
def _map_reranked_results(self, original_candidates, reranked_results):
    # æ£€æŸ¥æ˜¯å¦å·²æ·»åŠ ï¼ˆå»é‡ï¼‰
    seen_docs = set()
    
    for rerank_result in reranked_results:
        doc_id = doc.metadata.get('id', str(index))
        if doc_id not in seen_docs:
            seen_docs.add(doc_id)
            # æ·»åŠ ç»“æœ
```

#### **æºè¿‡æ»¤é˜¶æ®µï¼šåŸºäºç›¸å…³æ€§è¿‡æ»¤**
```python
# åœ¨SourceFilterEngineä¸­
def filter_sources(self, llm_answer: str, sources: List[Dict[str, Any]], query: str = "", query_type: str = None):
    # åŸºäºLLMç­”æ¡ˆçš„ç›¸å…³æ€§è¿‡æ»¤
    # è¿™é‡Œçš„sourceså·²ç»æ˜¯å»é‡å’Œé‡æ’åºåçš„ç»“æœ
```

## âœ… **ä½ çš„è§‚å¯Ÿå®Œå…¨æ­£ç¡®**

### **1. ä¸ºä»€ä¹ˆä¸éœ€è¦é¢å¤–å»é‡**

#### **1.1 æ•°æ®å·²ç»é«˜åº¦å‡€åŒ–**
- **å¬å›é˜¶æ®µ**: é€šè¿‡ä¸¤ç§ç­–ç•¥è·å¾—å€™é€‰æºï¼Œå¹¶è¿›è¡Œäº†å»é‡
- **é‡æ’åºé˜¶æ®µ**: å¯¹å»é‡åçš„ç»“æœè¿›è¡Œé‡æ’åºï¼Œè¿›ä¸€æ­¥ä¼˜åŒ–é¡ºåº
- **æºè¿‡æ»¤é˜¶æ®µ**: æ¥æ”¶çš„æ˜¯å·²ç»å¤„ç†è¿‡çš„å¹²å‡€æ•°æ®

#### **1.2 å»é‡é€»è¾‘å·²ç»å­˜åœ¨**
```python
# åœ¨å¬å›é˜¶æ®µå·²ç»å®ç°
if not any(r['doc'] == candidate['doc'] for r in results):
    results.append({...})

# åœ¨é‡æ’åºé˜¶æ®µå·²ç»å®ç°  
if doc_id not in seen_docs:
    seen_docs.add(doc_id)
    # æ·»åŠ ç»“æœ
```

### **2. æºè¿‡æ»¤çš„çœŸæ­£ä½œç”¨**

#### **2.1 ä¸æ˜¯å»é‡ï¼Œè€Œæ˜¯ç›¸å…³æ€§è¿‡æ»¤**
```python
def _calculate_source_relevance(self, source, answer_keywords, answer_entities, llm_answer, query):
    """è®¡ç®—æºçš„ç›¸å…³æ€§åˆ†æ•° - è¿™æ‰æ˜¯æºè¿‡æ»¤çš„æ ¸å¿ƒ"""
    
    # 1. å…³é”®è¯åŒ¹é…åˆ†æ•°
    keyword_score = self._calculate_keyword_match_score(answer_keywords, source_content)
    
    # 2. å®ä½“åŒ¹é…åˆ†æ•°
    entity_score = self._calculate_entity_match_score(answer_entities, source_content)
    
    # 3. å†…å®¹é‡å åˆ†æ•°
    overlap_score = self._calculate_content_overlap_score(llm_answer, source_content)
    
    # 4. å…ƒæ•°æ®ç›¸å…³æ€§åˆ†æ•°
    metadata_score = self._calculate_metadata_relevance_score(source_metadata, query, llm_answer)
```

#### **2.2 åŸºäºLLMç­”æ¡ˆçš„æ™ºèƒ½ç­›é€‰**
```python
# æºè¿‡æ»¤çš„æ ¸å¿ƒä»·å€¼ï¼šåŸºäºLLMç”Ÿæˆçš„ç­”æ¡ˆæ¥åˆ¤æ–­æºçš„ç›¸å…³æ€§
# è€Œä¸æ˜¯åŸºäºåŸå§‹æŸ¥è¯¢æˆ–å¬å›åˆ†æ•°
if source['relevance_score'] >= adjusted_threshold:
    filtered_sources.append(source)
```

## ğŸ” **é‡æ–°ç†è§£æºè¿‡æ»¤çš„ä»·å€¼**

### **1. æºè¿‡æ»¤çš„çœŸæ­£æ„ä¹‰**

#### **1.1 ç­”æ¡ˆå¯¼å‘çš„æºç­›é€‰**
- **ä¸æ˜¯å»é‡**: æ•°æ®å·²ç»åœ¨å‰é¢é˜¶æ®µå»é‡äº†
- **ä¸æ˜¯æ’åº**: æ’åºå·²ç»åœ¨é‡æ’åºé˜¶æ®µå®Œæˆäº†
- **è€Œæ˜¯éªŒè¯**: éªŒè¯å“ªäº›æºçœŸæ­£æ”¯æ’‘äº†LLMçš„ç­”æ¡ˆ

#### **1.2 æé«˜å¯è¿½æº¯æ€§**
```python
# æºè¿‡æ»¤ç¡®ä¿æœ€ç»ˆå±•ç¤ºçš„æºä¸LLMç­”æ¡ˆé«˜åº¦ç›¸å…³
# ç”¨æˆ·å¯ä»¥çœ‹åˆ°ï¼šè¿™ä¸ªç­”æ¡ˆæ˜¯åŸºäºå“ªäº›å…·ä½“ä¿¡æ¯ç”Ÿæˆçš„
filtered_sources = source_filter_engine.filter_sources(
    llm_answer,  # LLMç”Ÿæˆçš„ç­”æ¡ˆ
    reranked_results,  # é‡æ’åºåçš„ç»“æœ
    query,  # åŸå§‹æŸ¥è¯¢
    query_type  # æŸ¥è¯¢ç±»å‹
)
```

### **2. æºè¿‡æ»¤çš„ä¼˜åŒ–æ–¹å‘åº”è¯¥æ˜¯**

#### **2.1 ç›¸å…³æ€§è®¡ç®—ç²¾åº¦**
```python
# æé«˜ç›¸å…³æ€§è®¡ç®—çš„å‡†ç¡®æ€§
def _enhanced_relevance_calculation(self, llm_answer, source):
    # æ›´ç²¾ç¡®çš„è¯­ä¹‰åŒ¹é…
    # æ›´æ™ºèƒ½çš„å®ä½“è¯†åˆ«
    # æ›´å‡†ç¡®çš„å†…å®¹é‡å åˆ†æ
```

#### **2.2 é˜ˆå€¼ç­–ç•¥ä¼˜åŒ–**
```python
# æ ¹æ®æŸ¥è¯¢ç±»å‹å’Œç­”æ¡ˆè´¨é‡è°ƒæ•´é˜ˆå€¼
def _adaptive_threshold_strategy(self, query_type, llm_answer_quality):
    if query_type == 'image':
        return 0.3  # å›¾ç‰‡æŸ¥è¯¢ç›¸å¯¹å®½æ¾
    elif query_type == 'text':
        return 0.8  # æ–‡æœ¬æŸ¥è¯¢ç›¸å¯¹ä¸¥æ ¼
```

#### **2.3 æºæ•°é‡æ§åˆ¶**
```python
# æ§åˆ¶æœ€ç»ˆå±•ç¤ºçš„æºæ•°é‡
@dataclass
class SourceFilterConfig:
    min_sources_to_keep: int = 1
    max_sources_to_keep: int = 5  # å‡å°‘åˆ°5ä¸ªï¼Œè€Œä¸æ˜¯10ä¸ª
```

## ğŸ“ **æ€»ç»“**

ä½ çš„è§‚å¯Ÿå®Œå…¨æ­£ç¡®ï¼**æºè¿‡æ»¤é˜¶æ®µç¡®å®ä¸éœ€è¦è¿›è¡Œå»é‡å¤„ç†**ï¼Œå› ä¸ºï¼š

1. **æ•°æ®å·²ç»é«˜åº¦å‡€åŒ–**: å¬å›å’Œé‡æ’åºé˜¶æ®µå·²ç»å®Œæˆäº†å»é‡
2. **æºè¿‡æ»¤çš„æ ¸å¿ƒä»·å€¼**: æ˜¯åŸºäºLLMç­”æ¡ˆçš„ç›¸å…³æ€§éªŒè¯ï¼Œä¸æ˜¯å»é‡
3. **ä¼˜åŒ–æ–¹å‘åº”è¯¥è°ƒæ•´**: ä»å»é‡è½¬å‘ç›¸å…³æ€§ç²¾åº¦å’Œæ•°é‡æ§åˆ¶

**æºè¿‡æ»¤çš„çœŸæ­£ä»·å€¼åœ¨äº**ï¼š
- ç¡®ä¿æœ€ç»ˆå±•ç¤ºçš„æºä¸LLMç­”æ¡ˆé«˜åº¦ç›¸å…³
- æé«˜ç³»ç»Ÿçš„å¯è¿½æº¯æ€§å’Œå¯ä¿¡åº¦
- æ§åˆ¶æœ€ç»ˆæºçš„æ•°é‡ï¼Œé¿å…ä¿¡æ¯è¿‡è½½

è¿™æ˜¯ä¸€ä¸ªå¾ˆå¥½çš„è§‚å¯Ÿï¼Œå¸®åŠ©æˆ‘ä»¬é‡æ–°ç†è§£äº†æºè¿‡æ»¤åœ¨æ•´ä¸ªæµç¨‹ä¸­çš„çœŸæ­£ä½œç”¨å’Œä¼˜åŒ–æ–¹å‘ï¼



## ï¿½ï¿½ **å½“å‰æºè¿‡æ»¤çš„å®ç°çŠ¶å†µè¯„ä¼°**

### **1. å·²å®ç°çš„åŠŸèƒ½**
âœ… **å¤šç­–ç•¥è¿‡æ»¤**: æ ¹æ®æŸ¥è¯¢ç±»å‹é€‰æ‹©ä¸åŒè¿‡æ»¤ç­–ç•¥  
âœ… **åŠ¨æ€é˜ˆå€¼**: æ”¯æŒåŠ¨æ€é˜ˆå€¼è°ƒæ•´  
âœ… **æ•°é‡æ§åˆ¶**: æœ‰min_sources_to_keepå’Œmax_sources_to_keep  
âœ… **ç›¸å…³æ€§è®¡ç®—**: å¤šç»´åº¦è¯„åˆ†ç³»ç»Ÿ  

### **2. å­˜åœ¨çš„é—®é¢˜**
âŒ **é˜ˆå€¼è®¾ç½®ä¸åˆç†**: å›¾ç‰‡æŸ¥è¯¢0.05å¤ªä½ï¼Œæ–‡æœ¬æŸ¥è¯¢0.6å¯èƒ½å¤ªé«˜  
âŒ **æºæ•°é‡è¿‡å¤š**: max_sources_to_keep=10ä»ç„¶å¤ªå¤š  
âŒ **ç¼ºä¹å¿«é€Ÿè§æ•ˆçš„ä¼˜åŒ–**: å½“å‰é…ç½®å¯èƒ½æ•ˆæœä¸æ˜æ˜¾  

## ğŸš€ **è§æ•ˆå¿«ã€æ–¹æ³•ä¸å¤æ‚çš„è°ƒæ•´å»ºè®®**

### **æ–¹æ¡ˆ1ï¼šå¿«é€Ÿé˜ˆå€¼ä¼˜åŒ–ï¼ˆ5åˆ†é’Ÿè°ƒæ•´ï¼‰**

#### **1.1 è°ƒæ•´é…ç½®å‚æ•°**
```python
# åœ¨v2/config/v2_config.pyä¸­å¿«é€Ÿè°ƒæ•´
@dataclass
class SourceFilterEngineConfigV2(EngineConfigV2):
    """æºè¿‡æ»¤å¼•æ“V2.0é…ç½®"""
    name: str = "source_filter"
    enable_filtering: bool = True
    # å¿«é€Ÿè°ƒæ•´ï¼šæé«˜é˜ˆå€¼ï¼Œå‡å°‘æºæ•°é‡
    relevance_threshold: float = 0.7        # ä»0.6æé«˜åˆ°0.7
    content_overlap_threshold: float = 0.4  # ä»0.3æé«˜åˆ°0.4
    keyword_match_weight: float = 0.5       # ä»0.4æé«˜åˆ°0.5
    semantic_similarity_weight: float = 0.4 # ä¿æŒ0.4
    content_quality_weight: float = 0.1     # ä»0.2é™ä½åˆ°0.1
    enable_dynamic_threshold: bool = True
    min_sources_to_keep: int = 1            # ä¿æŒ1
    max_sources_to_keep: int = 5            # ä»10å‡å°‘åˆ°5 â­ å…³é”®è°ƒæ•´
    enable_source_ranking: bool = True
```

#### **1.2 è°ƒæ•´æŸ¥è¯¢ç±»å‹ç‰¹å®šé˜ˆå€¼**
```python
# åœ¨source_filter_engine.pyä¸­å¿«é€Ÿè°ƒæ•´
def _filter_image_sources(self, llm_answer: str, sources: List[Dict[str, Any]], query: str):
    # å›¾ç‰‡æŸ¥è¯¢ï¼šä»0.05æé«˜åˆ°0.2 â­ å…³é”®è°ƒæ•´
    if relevance_score >= 0.2:  # ä»0.05æé«˜åˆ°0.2
        filtered_sources.append(source_copy)

def _filter_table_sources(self, llm_answer: str, sources: List[Dict[str, Any]], query: str):
    # è¡¨æ ¼æŸ¥è¯¢ï¼šä»0.15æé«˜åˆ°0.3 â­ å…³é”®è°ƒæ•´
    if relevance_score >= 0.3:  # ä»0.15æé«˜åˆ°0.3
        filtered_sources.append(source_copy)

def _filter_text_sources(self, llm_answer: str, sources: List[Dict[str, Any]], query: str):
    # æ–‡æœ¬æŸ¥è¯¢ï¼šä½¿ç”¨åŠ¨æ€é˜ˆå€¼ï¼Œä½†åŸºç¡€é˜ˆå€¼ä»0.6æé«˜åˆ°0.7
    adjusted_threshold = max(0.7, adjusted_threshold)  # â­ å…³é”®è°ƒæ•´
```

### **æ–¹æ¡ˆ2ï¼šå¿«é€Ÿæ•°é‡æ§åˆ¶ä¼˜åŒ–ï¼ˆ3åˆ†é’Ÿè°ƒæ•´ï¼‰**

#### **2.1 å…¨å±€æ•°é‡é™åˆ¶**
```python
# åœ¨SourceFilterConfigä¸­
@dataclass
class SourceFilterConfig:
    # å¿«é€Ÿè°ƒæ•´ï¼šå¤§å¹…å‡å°‘æºæ•°é‡
    min_sources_to_keep: int = 1
    max_sources_to_keep: int = 3            # â­ ä»10å‡å°‘åˆ°3
```

#### **2.2 æŸ¥è¯¢ç±»å‹ç‰¹å®šæ•°é‡æ§åˆ¶**
```python
def _filter_image_sources(self, llm_answer: str, sources: List[Dict[str, Any]], query: str):
    # å›¾ç‰‡æŸ¥è¯¢ï¼šæœ€å¤šä¿ç•™3ä¸ªæº
    max_image_sources = 3  # â­ ç¡¬ç¼–ç é™åˆ¶
    if len(filtered_sources) > max_image_sources:
        filtered_sources = filtered_sources[:max_image_sources]

def _filter_table_sources(self, llm_answer: str, sources: List[Dict[str, Any]], query: str):
    # è¡¨æ ¼æŸ¥è¯¢ï¼šæœ€å¤šä¿ç•™4ä¸ªæº
    max_table_sources = 4  # â­ ç¡¬ç¼–ç é™åˆ¶
    if len(filtered_sources) > max_table_sources:
        filtered_sources = filtered_sources[:max_table_sources]

def _filter_text_sources(self, llm_answer: str, sources: List[Dict[str, Any]], query: str):
    # æ–‡æœ¬æŸ¥è¯¢ï¼šæœ€å¤šä¿ç•™3ä¸ªæº
    max_text_sources = 3  # â­ ç¡¬ç¼–ç é™åˆ¶
    if len(filtered_sources) > max_text_sources:
        filtered_sources = filtered_sources[:max_text_sources]
```

### **æ–¹æ¡ˆ3ï¼šå¿«é€Ÿç›¸å…³æ€§è®¡ç®—ä¼˜åŒ–ï¼ˆ10åˆ†é’Ÿè°ƒæ•´ï¼‰**

#### **3.1 ç®€åŒ–ä½†æœ‰æ•ˆçš„ç›¸å…³æ€§è®¡ç®—**
```python
def _calculate_source_relevance(self, source: Dict[str, Any], answer_keywords: List[str], 
                              answer_entities: List[str], llm_answer: str, 
                              query: str = "") -> float:
    """ç®€åŒ–çš„ç›¸å…³æ€§è®¡ç®— - å¿«é€Ÿä¼˜åŒ–ç‰ˆæœ¬"""
    
    if not source:
        return 0.0
    
    # è·å–æºå†…å®¹
    source_content = source.get('content', '')
    if not source_content:
        return 0.0
    
    # 1. å…³é”®è¯åŒ¹é…åˆ†æ•°ï¼ˆæƒé‡0.6ï¼‰
    keyword_score = self._calculate_keyword_match_score(answer_keywords, source_content) * 0.6
    
    # 2. å†…å®¹é‡å åˆ†æ•°ï¼ˆæƒé‡0.4ï¼‰
    overlap_score = self._calculate_content_overlap_score(llm_answer, source_content) * 0.4
    
    # ç®€åŒ–è®¡ç®—ï¼šåªä¿ç•™æœ€é‡è¦çš„ä¸¤ä¸ªç»´åº¦
    total_score = keyword_score + overlap_score
    
    # å¿«é€Ÿä¼˜åŒ–ï¼šå¯¹é«˜åˆ†ç»“æœè¿›è¡Œå¥–åŠ±
    if total_score > 0.8:
        total_score = min(1.0, total_score * 1.2)  # â­ é«˜åˆ†å¥–åŠ±
    
    return min(total_score, 1.0)
```

#### **3.2 å¿«é€Ÿå…³é”®è¯æå–ä¼˜åŒ–**
```python
def _extract_answer_keywords(self, answer: str) -> List[str]:
    """å¿«é€Ÿå…³é”®è¯æå– - ä¼˜åŒ–ç‰ˆæœ¬"""
    if not answer:
        return []
    
    # 1. æå–å¼•å·å†…å®¹ï¼ˆé€šå¸¸æ˜¯æœ€é‡è¦çš„ä¿¡æ¯ï¼‰
    quoted_content = re.findall(r'[""]([^""]+)[""]', answer)
    
    # 2. æå–æ•°å­—ï¼ˆé€šå¸¸æ˜¯å…·ä½“æ•°æ®ï¼‰
    numbers = re.findall(r'\d+(?:\.\d+)?', answer)
    
    # 3. æå–ä¸“æœ‰åè¯ï¼ˆé¦–å­—æ¯å¤§å†™çš„è¯ï¼‰
    proper_nouns = re.findall(r'\b[A-Z][a-z]+(?:\s+[A-Z][a-z]+)*\b', answer)
    
    # 4. ç»„åˆç»“æœï¼Œä¼˜å…ˆä¿ç•™å¼•å·å†…å®¹
    keywords = []
    keywords.extend(quoted_content[:5])      # æœ€å¤š5ä¸ªå¼•å·å†…å®¹
    keywords.extend(numbers[:3])             # æœ€å¤š3ä¸ªæ•°å­—
    keywords.extend(proper_nouns[:3])       # æœ€å¤š3ä¸ªä¸“æœ‰åè¯
    
    return keywords[:8]  # æ€»å…±æœ€å¤š8ä¸ªå…³é”®è¯
```

## ï¿½ï¿½ **é¢„æœŸæ•ˆæœå’Œè§æ•ˆæ—¶é—´**

### **1. å¿«é€Ÿè§æ•ˆçš„è°ƒæ•´ï¼ˆ1-2å¤©ï¼‰**
- **é˜ˆå€¼æé«˜**: ç›¸å…³æ€§åˆ†æ•°ä»0.6â†’0.7ï¼Œè¿‡æ»¤æ›´ä¸¥æ ¼
- **æ•°é‡å‡å°‘**: æºæ•°é‡ä»10â†’3-5ä¸ªï¼Œä¿¡æ¯æ›´ç²¾ç‚¼
- **å›¾ç‰‡é˜ˆå€¼**: ä»0.05â†’0.2ï¼Œé¿å…ä½è´¨é‡å›¾ç‰‡æº

### **2. ä¸­ç­‰è§æ•ˆçš„è°ƒæ•´ï¼ˆ3-5å¤©ï¼‰**
- **ç›¸å…³æ€§è®¡ç®—ä¼˜åŒ–**: å…³é”®è¯æƒé‡æé«˜ï¼Œè®¡ç®—æ›´å‡†ç¡®
- **æŸ¥è¯¢ç±»å‹ç‰¹å®šä¼˜åŒ–**: ä¸åŒæŸ¥è¯¢ç±»å‹ä½¿ç”¨ä¸åŒç­–ç•¥

### **3. é•¿æœŸä¼˜åŒ–æ•ˆæœï¼ˆ1-2å‘¨ï¼‰**
- **ç”¨æˆ·æ»¡æ„åº¦æå‡**: æºæ•°é‡å‡å°‘ï¼Œè´¨é‡æé«˜
- **ç³»ç»Ÿæ€§èƒ½æå‡**: å¤„ç†æ›´å°‘çš„æºï¼Œå“åº”æ›´å¿«
- **å¯è¿½æº¯æ€§å¢å¼º**: æºä¸ç­”æ¡ˆç›¸å…³æ€§æ›´é«˜

## ğŸ¯ **å®æ–½ä¼˜å…ˆçº§å»ºè®®**

### **ç¬¬ä¸€ä¼˜å…ˆçº§ï¼ˆç«‹å³å®æ–½ï¼‰**
1. **è°ƒæ•´max_sources_to_keep**: 10â†’3-5
2. **æé«˜å›¾ç‰‡æŸ¥è¯¢é˜ˆå€¼**: 0.05â†’0.2
3. **æé«˜è¡¨æ ¼æŸ¥è¯¢é˜ˆå€¼**: 0.15â†’0.3

### **ç¬¬äºŒä¼˜å…ˆçº§ï¼ˆæœ¬å‘¨å†…ï¼‰**
1. **ä¼˜åŒ–ç›¸å…³æ€§è®¡ç®—æƒé‡**
2. **æ”¹è¿›å…³é”®è¯æå–ç®—æ³•**

### **ç¬¬ä¸‰ä¼˜å…ˆçº§ï¼ˆä¸‹å‘¨ï¼‰**
1. **ç›‘æ§æ•ˆæœæŒ‡æ ‡**
2. **æ ¹æ®å®é™…ä½¿ç”¨æƒ…å†µå¾®è°ƒå‚æ•°**

è¿™äº›è°ƒæ•´æ–¹æ³•ç®€å•ã€è§æ•ˆå¿«ï¼Œä¸éœ€è¦å¤æ‚çš„ç®—æ³•æ”¹é€ ï¼Œåªéœ€è¦è°ƒæ•´é…ç½®å‚æ•°å’Œç®€å•çš„é€»è¾‘ä¼˜åŒ–ï¼Œå°±èƒ½æ˜¾è‘—æå‡æºè¿‡æ»¤çš„æ•ˆæœï¼