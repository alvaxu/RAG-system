我需要先查看text_engine中的向量相似度搜索实现，然后对比image_engine中的实现，找出差异。

Search files...
让我继续查看text_engine中向量相似度搜索的具体实现：

Read file: v2/core/text_engine.py
现在让我查看image_engine中向量搜索的具体实现：

Read file: v2/core/image_engine.py
让我继续查看image_engine中阈值设置和配置部分：

Read file: v2/core/image_engine.py
现在让我查看配置文件中的阈值设置：

Ran tool
基于我的分析，现在可以总结text_engine和image_engine在语义相似度搜索（第一层向量搜索）上的异同：

## Text Engine vs Image Engine 语义相似度搜索对比

### **相同点**

1. **基础架构**：都使用LangChain的`vector_store.similarity_search()`方法
2. **错误处理**：都有完善的异常处理和备选方案
3. **日志记录**：都有详细的日志输出用于调试

### **关键差异**

#### **1. 阈值设置差异**
- **Text Engine**：`text_similarity_threshold: 0.3`（相对宽松）
- **Image Engine**：`image_similarity_threshold: 0.05`（过于严格）

#### **2. 搜索策略差异**

**Text Engine（简单直接）**：
```python
# 直接搜索，无filter
vector_results = self.vector_store.similarity_search(query, k=top_k)
```

**Image Engine（复杂filter策略）**：
```python
# 使用filter搜索特定类型文档
image_text_candidates = self.vector_store.similarity_search(
    query, 
    k=max_results * 2,
    filter={'chunk_type': 'image_text'}  # 这里可能有问题
)
```

#### **3. 结果处理差异**

**Text Engine**：
- 直接处理搜索结果
- 计算内容相关性分数
- 无复杂的关联查找逻辑

**Image Engine**：
- 需要通过`related_image_id`查找对应的image chunk
- 有复杂的关联关系处理
- 涉及多个文档类型的协调

### **问题根源分析**

#### **主要问题：阈值过低**
- `image_similarity_threshold: 0.05` 这个阈值设置过低
- 从日志看，150个候选结果全部被过滤掉
- 说明向量相似度分数都低于0.05

#### **次要问题：Filter策略可能失效**
- 使用`filter={'chunk_type': 'image_text'}`可能在某些情况下不工作
- 降级策略虽然存在，但阈值问题导致仍然无结果

### **建议解决方案**

1. **调整阈值**：将`image_similarity_threshold`从0.05提高到0.3-0.5
2. **简化搜索策略**：参考text_engine的实现，先获取结果再过滤
3. **增强降级策略**：当filter搜索失败时，使用更宽松的阈值

这个对比清楚地显示了image_engine在向量搜索上的配置问题，阈值设置过低是导致第一层搜索完全失败的主要原因。




是的，有几种方法可以实现正确的先过滤再比对的策略！让我分析一下可行的方案：

## 方案1：使用FAISS的filter功能（推荐）

### **正确的FAISS filter用法**
```python
def _vector_search_with_proper_filter(self, query: str, max_results: int):
    """使用正确的FAISS filter进行向量搜索"""
    try:
        # 方法1：使用FAISS的metadata_filter
        image_text_candidates = self.vector_store.similarity_search(
            query, 
            k=max_results * 2,
            filter={"chunk_type": "image_text"}  # FAISS原生支持
        )
        
        # 方法2：如果上面不行，使用search_with_score + filter
        if not image_text_candidates:
            # 获取所有候选结果和分数
            docs_and_scores = self.vector_store.similarity_search_with_score(
                query, 
                k=max_results * 5  # 搜索更多结果用于过滤
            )
            
            # 手动过滤image_text类型
            image_text_candidates = [
                (doc, score) for doc, score in docs_and_scores
                if doc.metadata.get('chunk_type') == 'image_text'
            ]
            
            # 按分数排序
            image_text_candidates.sort(key=lambda x: x[1], reverse=True)
            # 只保留前max_results * 2个
            image_text_candidates = image_text_candidates[:max_results * 2]
            
    except Exception as e:
        logger.error(f"Filter搜索失败: {e}")
        return []
```

## 方案2：分步式过滤搜索

### **先获取类型列表，再逐个搜索**
```python
def _step_by_step_filter_search(self, query: str, max_results: int):
    """分步式过滤搜索：先获取类型，再搜索"""
    try:
        # 第一步：获取所有image_text文档的ID列表
        image_text_ids = self._get_all_image_text_ids()
        
        if not image_text_ids:
            logger.warning("未找到任何image_text类型的文档")
            return []
        
        # 第二步：使用ID列表进行精确搜索
        results = []
        for doc_id in image_text_ids[:max_results * 3]:  # 限制搜索数量
            try:
                # 获取单个文档
                doc = self.vector_store.docstore.get(doc_id)
                if doc and doc.metadata.get('chunk_type') == 'image_text':
                    # 计算查询与该文档的相似度
                    similarity_score = self._calculate_similarity(query, doc)
                    if similarity_score >= self.config.image_similarity_threshold:
                        results.append({
                            'doc': doc,
                            'score': similarity_score,
                            'source': 'filtered_vector_search'
                        })
            except Exception as e:
                logger.debug(f"处理文档 {doc_id} 时出错: {e}")
                continue
        
        # 按分数排序
        results.sort(key=lambda x: x['score'], reverse=True)
        return results[:max_results]
        
    except Exception as e:
        logger.error(f"分步式过滤搜索失败: {e}")
        return []
```

## 方案3：使用向量数据库的query方法

### **直接查询特定类型的向量**
```python
def _direct_vector_query(self, query: str, max_results: int):
    """直接查询特定类型的向量"""
    try:
        # 获取查询向量
        query_vector = self._get_query_embedding(query)
        
        # 获取所有image_text文档的向量
        image_text_vectors = self._get_image_text_vectors()
        
        if not image_text_vectors:
            return []
        
        # 计算相似度
        similarities = []
        for doc_id, doc_vector in image_text_vectors.items():
            similarity = self._cosine_similarity(query_vector, doc_vector)
            if similarity >= self.config.image_similarity_threshold:
                similarities.append((doc_id, similarity))
        
        # 排序并获取top结果
        similarities.sort(key=lambda x: x[1], reverse=True)
        top_results = similarities[:max_results]
        
        # 获取对应的文档对象
        results = []
        for doc_id, score in top_results:
            doc = self.vector_store.docstore.get(doc_id)
            if doc:
                results.append({
                    'doc': doc,
                    'score': score,
                    'source': 'direct_vector_query'
                })
        
        return results
        
    except Exception as e:
        logger.error(f"直接向量查询失败: {e}")
        return []
```

## 方案4：混合策略（最稳定）

### **结合多种方法的混合策略**
```python
def _hybrid_filter_search(self, query: str, max_results: int):
    """混合过滤搜索策略"""
    results = []
    
    # 策略1：尝试FAISS原生filter
    try:
        filter_results = self.vector_store.similarity_search(
            query, 
            k=max_results * 2,
            filter={"chunk_type": "image_text"}
        )
        if filter_results:
            logger.info(f"FAISS filter成功，返回 {len(filter_results)} 个结果")
            results.extend(self._process_filter_results(filter_results))
    except Exception as e:
        logger.warning(f"FAISS filter失败: {e}")
    
    # 策略2：如果filter失败，使用分步式搜索
    if not results:
        logger.info("尝试分步式过滤搜索...")
        results = self._step_by_step_filter_search(query, max_results)
    
    # 策略3：如果还是失败，使用降级策略
    if not results:
        logger.info("使用降级策略：搜索所有文档后过滤...")
        results = self._fallback_search_with_filter(query, max_results)
    
    return results
```

## 推荐实施方案

我建议使用**方案4（混合策略）**，因为：

1. **容错性强**：多种方法互为备选
2. **性能优化**：优先使用高效的FAISS filter
3. **结果稳定**：即使某种方法失败，仍有备选方案
4. **易于调试**：可以清楚看到每种策略的执行情况

这样既能实现正确的先过滤再比对，又能保证系统的稳定性和性能。你觉得哪种方案更适合你的需求？