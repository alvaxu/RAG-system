'''
ç¨‹åºè¯´æ˜ï¼š

## 1. ç»Ÿä¸€æ–‡æ¡£åŠ è½½ç®¡ç†å™¨ - è§£å†³é‡å¤åŠ è½½é—®é¢˜
## 2. ä¸€æ¬¡æ€§åŠ è½½æ‰€æœ‰æ–‡æ¡£ï¼ŒæŒ‰ç±»å‹åˆ†ç±»ç®¡ç†
## 3. ä¸ºå„ä¸ªå­å¼•æ“æä¾›ç»Ÿä¸€çš„æ–‡æ¡£è®¿é—®æ¥å£
## 4. ä¼˜åŒ–å†…å­˜ä½¿ç”¨å’Œå¯åŠ¨æ€§èƒ½
## 5. æ”¯æŒå»¶è¿ŸåŠ è½½å’Œé”™è¯¯é‡è¯•æœºåˆ¶
'''

import logging
import time
from typing import Dict, Any, Optional
from pathlib import Path

logger = logging.getLogger(__name__)


class DocumentLoader:
    """ç»Ÿä¸€æ–‡æ¡£åŠ è½½ç®¡ç†å™¨"""
    
    def __init__(self, vector_store, max_retries: int = 3):
        """
        åˆå§‹åŒ–æ–‡æ¡£åŠ è½½ç®¡ç†å™¨
        
        :param vector_store: å‘é‡æ•°æ®åº“å­˜å‚¨
        :param max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°
        """
        self.vector_store = vector_store
        self._docs_cache = {}  # ç»Ÿä¸€ç¼“å­˜
        self._loaded = False
        self._load_time = 0.0
        self._max_retries = max_retries
        self._retry_count = 0
        
        logger.info("æ–‡æ¡£åŠ è½½ç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆ")
    
    def load_all_documents(self, force_reload: bool = False) -> Dict[str, Dict[str, Any]]:
        """
        ä¸€æ¬¡æ€§åŠ è½½æ‰€æœ‰æ–‡æ¡£ï¼ŒæŒ‰ç±»å‹åˆ†ç±»
        
        :param force_reload: æ˜¯å¦å¼ºåˆ¶é‡æ–°åŠ è½½
        :return: æŒ‰ç±»å‹åˆ†ç±»çš„æ–‡æ¡£å­—å…¸
        """
        if self._loaded and not force_reload:
            logger.debug("æ–‡æ¡£å·²åŠ è½½ï¼Œè·³è¿‡é‡å¤åŠ è½½")
            return self._docs_cache
        
        start_time = time.time()
        logger.info("å¼€å§‹ç»Ÿä¸€åŠ è½½æ‰€æœ‰æ–‡æ¡£...")
        
        # æŒ‰ç±»å‹åˆ†ç±»åŠ è½½
        docs_by_type = {
            'text': {},
            'image': {},
            'table': {},
            'image_text': {},  # æ–°å¢ï¼šå›¾ç‰‡æè¿°æ–‡æœ¬chunks
            'hybrid': {}
        }
        
        try:
            # æ£€æŸ¥å‘é‡æ•°æ®åº“çŠ¶æ€
            if not self.vector_store or not hasattr(self.vector_store, 'docstore'):
                raise ValueError("å‘é‡æ•°æ®åº“æœªæä¾›æˆ–æ²¡æœ‰docstoreå±æ€§")
            
            # ä¸€æ¬¡æ€§éå†å‘é‡æ•°æ®åº“
            total_docs = 0
            for doc_id, doc in self.vector_store.docstore._dict.items():
                # æ£€æŸ¥æ–‡æ¡£å¯¹è±¡æ˜¯å¦æœ‰æ•ˆ
                if not hasattr(doc, 'metadata'):
                    logger.warning(f"è·³è¿‡æ— æ•ˆæ–‡æ¡£ {doc_id}: ç¼ºå°‘metadataå±æ€§ï¼Œæ–‡æ¡£ç±»å‹: {type(doc)}")
                    continue
                
                if not hasattr(doc, 'page_content'):
                    logger.warning(f"è·³è¿‡æ— æ•ˆæ–‡æ¡£ {doc_id}: ç¼ºå°‘page_contentå±æ€§ï¼Œæ–‡æ¡£ç±»å‹: {type(doc)}")
                    continue
                
                # è·å–chunk_typeï¼Œå¦‚æœmetadataä¸æ˜¯å­—å…¸åˆ™è·³è¿‡
                if not isinstance(doc.metadata, dict):
                    logger.warning(f"è·³è¿‡æ— æ•ˆæ–‡æ¡£ {doc_id}: metadataä¸æ˜¯å­—å…¸ç±»å‹ï¼Œå®é™…ç±»å‹: {type(doc.metadata)}")
                    continue
                
                chunk_type = doc.metadata.get('chunk_type', 'text')  # é»˜è®¤text
                
                # æ ¹æ®ç±»å‹åˆ†ç±»
                if chunk_type in docs_by_type:
                    docs_by_type[chunk_type][doc_id] = doc
                    total_docs += 1
                else:
                    # æœªçŸ¥ç±»å‹ï¼Œå½’ç±»åˆ°text
                    docs_by_type['text'][doc_id] = doc
                    total_docs += 1
                    logger.debug(f"æœªçŸ¥ç±»å‹æ–‡æ¡£å½’ç±»åˆ°text: {doc_id}, chunk_type: {chunk_type}")
            
            # ç»Ÿè®¡ä¿¡æ¯
            text_count = len(docs_by_type['text'])
            image_count = len(docs_by_type['image'])
            table_count = len(docs_by_type['table'])
            image_text_count = len(docs_by_type['image_text'])  # æ–°å¢ç»Ÿè®¡
            hybrid_count = len(docs_by_type['hybrid'])
            
            # æ·»åŠ æ–‡æ¡£ç»“æ„è°ƒè¯•æ—¥å¿—
            logger.info("ğŸ” DEBUG: ç»Ÿä¸€æ–‡æ¡£åŠ è½½å™¨æ–‡æ¡£ç»“æ„åˆ†æ:")
            logger.info(f"ğŸ” DEBUG: textæ–‡æ¡£ç±»å‹: {type(docs_by_type['text'])}")
            logger.info(f"ğŸ” DEBUG: imageæ–‡æ¡£ç±»å‹: {type(docs_by_type['image'])}")
            logger.info(f"ğŸ” DEBUG: tableæ–‡æ¡£ç±»å‹: {type(docs_by_type['table'])}")
            logger.info(f"ğŸ” DEBUG: image_textæ–‡æ¡£ç±»å‹: {type(docs_by_type['image_text'])}")
            
            # æ£€æŸ¥å‰å‡ ä¸ªæ–‡æ¡£çš„ç»“æ„
            if docs_by_type['text']:
                first_text_doc = list(docs_by_type['text'].values())[0] if isinstance(docs_by_type['text'], dict) else docs_by_type['text'][0]
                logger.info(f"ğŸ” DEBUG: ç¬¬ä¸€ä¸ªtextæ–‡æ¡£ç±»å‹: {type(first_text_doc)}")
                if hasattr(first_text_doc, 'metadata'):
                    logger.info(f"ğŸ” DEBUG: ç¬¬ä¸€ä¸ªtextæ–‡æ¡£çš„chunk_type: {first_text_doc.metadata.get('chunk_type', 'unknown')}")
                    logger.info(f"ğŸ” DEBUG: ç¬¬ä¸€ä¸ªtextæ–‡æ¡£çš„metadata: {first_text_doc.metadata}")
                    if hasattr(first_text_doc, 'page_content'):
                        logger.info(f"ğŸ” DEBUG: ç¬¬ä¸€ä¸ªtextæ–‡æ¡£çš„page_content: {first_text_doc.page_content[:100]}...")
            
            if docs_by_type['image']:
                first_image_doc = list(docs_by_type['image'].values())[0] if isinstance(docs_by_type['image'], dict) else docs_by_type['image'][0]
                logger.info(f"ğŸ” DEBUG: ç¬¬ä¸€ä¸ªimageæ–‡æ¡£ç±»å‹: {type(first_image_doc)}")
                if hasattr(first_image_doc, 'metadata'):
                    logger.info(f"ğŸ” DEBUG: ç¬¬ä¸€ä¸ªimageæ–‡æ¡£çš„chunk_type: {first_image_doc.metadata.get('chunk_type', 'unknown')}")
                    logger.info(f"ğŸ” DEBUG: ç¬¬ä¸€ä¸ªimageæ–‡æ¡£çš„metadata: {first_image_doc.metadata}")
                    if hasattr(first_image_doc, 'page_content'):
                        logger.info(f"ğŸ” DEBUG: ç¬¬ä¸€ä¸ªimageæ–‡æ¡£çš„page_content: {first_image_doc.page_content[:100]}...")
            
            if docs_by_type['table']:
                first_table_doc = list(docs_by_type['table'].values())[0] if isinstance(docs_by_type['table'], dict) else docs_by_type['table'][0]
                logger.info(f"ğŸ” DEBUG: ç¬¬ä¸€ä¸ªtableæ–‡æ¡£ç±»å‹: {type(first_table_doc)}")
                if hasattr(first_table_doc, 'metadata'):
                    logger.info(f"ğŸ” DEBUG: ç¬¬ä¸€ä¸ªtableæ–‡æ¡£çš„chunk_type: {first_table_doc.metadata.get('chunk_type', 'unknown')}")
                    logger.info(f"ğŸ” DEBUG: ç¬¬ä¸€ä¸ªtableæ–‡æ¡£çš„metadata: {first_table_doc.metadata}")
                    if hasattr(first_table_doc, 'page_content'):
                        logger.info(f"ğŸ” DEBUG: ç¬¬ä¸€ä¸ªtableæ–‡æ¡£çš„page_content: {first_table_doc.page_content[:100]}...")
            
            logger.info(f"æ–‡æ¡£åŠ è½½å®Œæˆ:")
            logger.info(f"  - æ–‡æœ¬æ–‡æ¡£: {text_count} ä¸ª")
            logger.info(f"  - å›¾ç‰‡æ–‡æ¡£: {image_count} ä¸ª")
            logger.info(f"  - è¡¨æ ¼æ–‡æ¡£: {table_count} ä¸ª")
            logger.info(f"  - å›¾ç‰‡æè¿°æ–‡æœ¬: {image_text_count} ä¸ª")
            logger.info(f"  - æ··åˆæ–‡æ¡£: {hybrid_count} ä¸ª")
            logger.info(f"  - æ€»è®¡: {total_docs} ä¸ª")
            
            # æ›´æ–°ç¼“å­˜å’ŒçŠ¶æ€
            self._docs_cache = docs_by_type
            self._loaded = True
            self._load_time = time.time() - start_time
            self._retry_count = 0  # é‡ç½®é‡è¯•è®¡æ•°
            
            logger.info(f"æ–‡æ¡£åŠ è½½æˆåŠŸï¼Œè€—æ—¶: {self._load_time:.2f}ç§’")
            return self._docs_cache
            
        except Exception as e:
            logger.error(f"æ–‡æ¡£åŠ è½½å¤±è´¥ï¼Œç¬¬{self._retry_count}æ¬¡å°è¯•: {e}")
            
            if self._retry_count < self._max_retries:
                logger.info(f"ç­‰å¾…1ç§’åè¿›è¡Œç¬¬{self._retry_count + 1}æ¬¡é‡è¯•...")
                time.sleep(1)
                return self.load_all_documents(force_reload=True)
            else:
                logger.error(f"æ–‡æ¡£åŠ è½½æœ€ç»ˆå¤±è´¥ï¼Œå·²é‡è¯•{self._max_retries}æ¬¡")
                self._loaded = False
                self._docs_cache = {}
                raise RuntimeError(f"æ–‡æ¡£åŠ è½½å¤±è´¥: {e}")
    
    def get_documents_by_type(self, doc_type: str, ensure_loaded: bool = True) -> list:
        """
        è·å–æŒ‡å®šç±»å‹çš„æ–‡æ¡£
        
        :param doc_type: æ–‡æ¡£ç±»å‹ (text, image, table, hybrid)
        :param ensure_loaded: æ˜¯å¦ç¡®ä¿æ–‡æ¡£å·²åŠ è½½
        :return: æŒ‡å®šç±»å‹çš„æ–‡æ¡£å¯¹è±¡åˆ—è¡¨
        """
        if ensure_loaded and not self._loaded:
            self.load_all_documents()
        
        # è¿”å›æ–‡æ¡£å¯¹è±¡åˆ—è¡¨ï¼Œè€Œä¸æ˜¯å­—å…¸
        docs_dict = self._docs_cache.get(doc_type, {})
        return list(docs_dict.values())
    
    def get_document_by_id(self, doc_id: str, doc_type: str = None) -> Optional[Any]:
        """
        æ ¹æ®IDè·å–æŒ‡å®šæ–‡æ¡£
        
        :param doc_id: æ–‡æ¡£ID
        :param doc_type: æ–‡æ¡£ç±»å‹ï¼ˆå¯é€‰ï¼Œç”¨äºä¼˜åŒ–æŸ¥æ‰¾ï¼‰
        :return: æ–‡æ¡£å¯¹è±¡æˆ–None
        """
        if not self._loaded:
            self.load_all_documents()
        
        if doc_type:
            # æŒ‡å®šç±»å‹æŸ¥æ‰¾
            return self._docs_cache.get(doc_type, {}).get(doc_id)
        else:
            # åœ¨æ‰€æœ‰ç±»å‹ä¸­æŸ¥æ‰¾
            for docs in self._docs_cache.values():
                if doc_id in docs:
                    return docs[doc_id]
            return None
    
    def get_document_statistics(self) -> Dict[str, Any]:
        """
        è·å–æ–‡æ¡£ç»Ÿè®¡ä¿¡æ¯
        
        :return: ç»Ÿè®¡ä¿¡æ¯å­—å…¸
        """
        if not self._loaded:
            return {'error': 'æ–‡æ¡£æœªåŠ è½½'}
        
        stats = {
            'total_documents': sum(len(docs) for docs in self._docs_cache.values()),
            'documents_by_type': {
                doc_type: len(docs) for doc_type, docs in self._docs_cache.items()
            },
            'load_time': self._load_time,
            'loaded': self._loaded,
            'cache_size': len(self._docs_cache)
        }
        
        # è®¡ç®—æ€»å­—ç¬¦æ•°ï¼ˆä»…æ–‡æœ¬æ–‡æ¡£ï¼‰
        if 'text' in self._docs_cache:
            total_chars = sum(
                len(doc.page_content) if hasattr(doc, 'page_content') else 0 
                for doc in self._docs_cache['text'].values()
            )
            stats['total_text_chars'] = total_chars
        
        return stats
    
    def refresh_cache(self) -> bool:
        """
        åˆ·æ–°æ–‡æ¡£ç¼“å­˜
        
        :return: æ˜¯å¦æˆåŠŸ
        """
        try:
            logger.info("å¼€å§‹åˆ·æ–°æ–‡æ¡£ç¼“å­˜...")
            self._loaded = False
            self.load_all_documents(force_reload=True)
            logger.info("æ–‡æ¡£ç¼“å­˜åˆ·æ–°æˆåŠŸ")
            return True
        except Exception as e:
            logger.error(f"æ–‡æ¡£ç¼“å­˜åˆ·æ–°å¤±è´¥: {e}")
            return False
    
    def is_loaded(self) -> bool:
        """æ£€æŸ¥æ–‡æ¡£æ˜¯å¦å·²åŠ è½½"""
        return self._loaded
    
    def get_load_time(self) -> float:
        """è·å–æ–‡æ¡£åŠ è½½è€—æ—¶"""
        return self._load_time
    
    def clear_cache(self):
        """æ¸…ç©ºæ–‡æ¡£ç¼“å­˜"""
        self._docs_cache = {}
        self._loaded = False
        self._load_time = 0.0
        logger.info("æ–‡æ¡£ç¼“å­˜å·²æ¸…ç©º")
