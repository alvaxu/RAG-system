# M16-RAG系统text和table召回策略详细设计文档

## 一、文档基础信息

| 模块名称 | M16-RAG系统召回策略模块                                      | 所属项目 | V3版本RAG系统                     |
| -------- | ------------------------------------------------------------ | -------- | --------------------------------- |
| 文档版本 | V1.0                                                         | 文档状态 | ☑ 草稿 □ 评审中 □ 已确认 □ 已归档 |
| 编写人   | AI助手                                                       | 编写日期 | 2025年8月                         |
| 关联文档 | 《M12-RAG查询处理模块详细设计文档》《V3版本向量数据库构建系统简要设计文档》 |          |                                   |

## 二、模块概述

### 1. 定位与目标

作为RAG系统的**核心召回模块**，召回策略模块承担所有查询的文档召回职责，采用分层召回策略，确保召回质量和数量的平衡。与V3系统的向量数据库形成紧密集成，为整个RAG系统提供高效、准确的文档召回服务。

### 2. 设计原则

- **简化设计**：避免V2系统的过度复杂化，采用清晰的分层策略
- **配置驱动**：所有关键参数都可配置，避免硬编码
- **性能优先**：充分利用V3系统的过滤查询能力，减少计算开销
- **策略一致**：文本和表格召回采用相同的架构模式，便于维护
- **逻辑递进**：从精确到模糊，从结构到内容，层次递进更自然

### 3. 依赖与交互

| 关联模块        | 交互方向 | 核心交互内容                     |
| --------------- | -------- | -------------------------------- |
| V3向量数据库    | 依赖     | 执行向量相似度搜索，获取候选文档 |
| V3元数据管理    | 依赖     | 读取文档元数据，进行结构匹配     |
| V3配置管理      | 依赖     | 获取召回策略配置参数             |
| RAG查询处理模块 | 被调用   | 提供召回结果，支持后续处理       |

## 三、核心功能设计

### 1. 功能清单

| 功能ID | 功能名称     | 核心描述                   | 操作角色 | 前置条件             |
| ------ | ------------ | -------------------------- | -------- | -------------------- |
| F001   | 文本召回策略 | 执行文本内容的三层召回策略 | RAG系统  | 向量数据库初始化完成 |
| F002   | 表格召回策略 | 执行表格内容的四层召回策略 | RAG系统  | 向量数据库初始化完成 |
| F003   | 相似度计算   | 计算查询与文档的相似度分数 | 召回服务 | 文档和查询向量化完成 |
| F004   | 结果去重     | 对多层召回结果进行去重处理 | 召回服务 | 多层结果获取完成     |
| F005   | 结果排序     | 对召回结果按分数进行排序   | 召回服务 | 去重处理完成         |

### 2. 核心业务流程

#### 2.1 文本召回流程
```
用户查询 → 第一层向量搜索 → 检查结果数量 → 
第二层关键词搜索 → 检查结果数量 → 
第三层扩展搜索 → 结果去重排序 → 返回最终结果
```

#### 2.2 表格召回流程
```
用户查询 → 第一层结构搜索 → 检查结果数量 → 
第二层语义搜索 → 检查结果数量 → 
第三层关键词搜索 → 检查结果数量 → 
第四层扩展搜索 → 结果去重排序 → 返回最终结果
```

## 四、详细设计

### 1. 文本召回策略设计

#### 1.1 三层策略架构

**第一层：向量语义搜索（主要策略）**
- **功能描述**：使用V3向量数据库进行语义相似度搜索
- **技术实现**：过滤查询 + 重新计算分数
- **配置参数**：
  - `similarity_threshold`: 0.7（相似度阈值）
  - `search_k_multiplier`: 2.0（搜索范围倍数）
- **预期效果**：召回率80%，准确率90%
- **启动条件**：所有查询都启动
- **停止条件**：结果数量达到80%或启动下一层

**第二层：关键词搜索（补充策略）**
- **功能描述**：使用jieba分词进行关键词匹配
- **技术实现**：jieba分词 + 文本相似度计算
- **配置参数**：
  - `similarity_threshold`: 0.7（相似度阈值）
- **预期效果**：召回率60%，准确率70%
- **启动条件**：第一层结果数量不足80%
- **停止条件**：结果数量达到70%或启动下一层

**第三层：扩展搜索（兜底策略）**
- **功能描述**：使用同义词和相关概念进行扩展搜索
- **技术实现**：同义词词典 + 向量搜索
- **配置参数**：
  - `similarity_threshold`: 0.7（相似度阈值）
- **预期效果**：召回率40%，准确率50%
- **启动条件**：前两层结果数量不足70%
- **停止条件**：结果数量达到60%或返回所有结果

#### 1.2 文本召回核心算法

**相似度分数计算**
```python
def _calculate_text_relevance(self, query: str, content: str) -> float:
    """计算文本相关性分数 - 核心算法1"""
    
    try:
        if not query or not content:
            return 0.0
        
        # 1. 快速文本相似度（权重：0.4）
        fast_similarity = self._calculate_fast_text_similarity(query, content)
        
        # 2. 向量相似度（权重：0.6）
        vector_similarity = self._calculate_vector_similarity(query, content)
        
        # 加权计算最终相关性分数
        relevance_score = (fast_similarity * 0.4) + (vector_similarity * 0.6)
        
        # 确保分数在0.0-1.0范围内
        return max(0.0, min(1.0, relevance_score))
        
    except Exception as e:
        logger.error(f"计算文本相关性失败: {e}")
        return 0.0
```

**快速文本相似度算法**
```python
def _calculate_fast_text_similarity(self, query: str, content: str) -> float:
    """计算快速文本相似度 - 核心算法2"""
    
    try:
        if not query or not content:
            return 0.0
        
        # 使用jieba分词工具（如果可用）
        if JIEBA_AVAILABLE:
            query_words = set(jieba.lcut(query))
            content_words = set(jieba.lcut(content))
        else:
            # 备选方案：基础分词
            query_words = set(query.lower().split())
            content_words = set(content.lower().split())
        
        if not query_words or not content_words:
            return 0.0
        
        # 计算Jaccard相似度
        intersection = len(query_words.intersection(content_words))
        union = len(query_words.union(content_words))
        
        if union == 0:
            return 0.0
        
        jaccard_similarity = intersection / union
        
        # 考虑查询词在内容中的密度
        content_length = len(content)
        if content_length > 0:
            word_count = sum(content.lower().count(word) for word in query_words)
            density_score = min(word_count / content_length * 100, 1.0)
            
            # 综合分数：Jaccard相似度 + 密度分数
            final_score = (jaccard_similarity * 0.7) + (density_score * 0.3)
            return min(final_score, 1.0)
        
        return jaccard_similarity
        
    except Exception as e:
        logger.error(f"计算快速文本相似度失败: {e}")
        return 0.0
```

**向量相似度算法**
```python
def _calculate_vector_similarity(self, query: str, content: str) -> float:
    """计算向量相似度 - 核心算法3"""
    
    try:
        if not query or not content:
            return 0.0
        
        # 使用向量数据库计算相似度
        if hasattr(self.vector_db, 'calculate_similarity'):
            # 如果向量数据库支持直接相似度计算
            return self.vector_db.calculate_similarity(query, content)
        
        # 备选方案：基于TF-IDF的相似度计算
        return self._calculate_tfidf_similarity(query, content)
        
    except Exception as e:
        logger.error(f"计算向量相似度失败: {e}")
        return 0.0
```

### 2. 表格召回策略设计

#### 2.1 四层策略架构

**第一层：表格语义搜索（主要策略）**
- **功能描述**：使用text-embedding-v1模型在text_embedding向量空间中搜索表格
- **技术实现**：过滤查询 + 向量相似度计算
- **配置参数**：
  - `similarity_threshold`: 0.3（相似度阈值）
- **预期效果**：召回率80%，准确率85%
- **启动条件**：所有表格查询都启动
- **停止条件**：结果数量达到80%或启动下一层

**第二层：表格结构搜索（补充策略）**
- **功能描述**：基于表格标题、列名、类型进行精确匹配
- **技术实现**：向量搜索 + 结构特征匹配
- **配置参数**：
  - `similarity_threshold`: 0.3（相似度阈值）
- **预期效果**：召回率60%，准确率70%
- **启动条件**：第一层结果数量不足80%
- **停止条件**：结果数量达到70%或启动下一层

**第三层：表格内容关键词搜索（补充策略）**
- **功能描述**：使用jieba分词在表格内容中搜索关键词
- **技术实现**：jieba分词 + 多字段关键词匹配
- **配置参数**：
  - `similarity_threshold`: 0.3（相似度阈值）
- **预期效果**：召回率50%，准确率60%
- **启动条件**：前两层结果数量不足70%
- **停止条件**：结果数量达到60%或启动下一层

**第四层：表格扩展搜索（兜底策略）**
- **功能描述**：使用同义词和相关概念进行扩展搜索
- **技术实现**：同义词词典 + 向量搜索
- **配置参数**：
  - `similarity_threshold`: 0.3（相似度阈值）
- **预期效果**：召回率40%，准确率50%
- **启动条件**：前三层结果数量不足60%
- **停止条件**：返回所有结果

#### 2.2 表格召回核心算法

**结构匹配分数计算**
```python
def _calculate_structure_match(self, query: str, metadata: Dict) -> float:
    """计算表格结构匹配分数"""
    
    try:
        total_score = 0.0
        weight_sum = 0.0
        
        # 1. 表格标题匹配（权重40%）
        if 'table_title' in metadata:
            title_score = self._calculate_title_similarity(query, metadata['table_title'])
            total_score += title_score * 0.4
            weight_sum += 0.4
        
        # 2. 列名匹配（权重35%）
        if 'table_headers' in metadata:
            headers_score = self._calculate_headers_similarity(query, metadata['table_headers'])
            total_score += headers_score * 0.35
            weight_sum += 0.35
        
        # 3. 表格类型匹配（权重25%）
        if 'table_type' in metadata:
            type_score = self._calculate_type_similarity(query, metadata['table_type'])
            total_score += type_score * 0.25
            weight_sum += 0.25
        
        # 4. 计算加权平均分数
        if weight_sum > 0:
            return total_score / weight_sum
        else:
            return 0.0
    except Exception as e:
        logger.warning(f"计算结构匹配分数失败: {e}")
        return 0.0
```

**关键词匹配分数计算**
```python
def _calculate_keyword_match(self, query_keywords: List[str], doc) -> float:
    """计算关键词匹配分数"""
    
    total_score = 0.0
    
    # 1. 表格标题匹配（权重40%）
    if hasattr(doc, 'metadata') and doc.metadata:
        title = doc.metadata.get('table_title', '')
        title_score = self._calculate_text_keyword_match(query_keywords, title)
        total_score += title_score * 0.4
    
    # 2. 列名匹配（权重30%）
    if hasattr(doc, 'metadata') and doc.metadata:
        headers = doc.metadata.get('table_headers', [])
        headers_score = self._calculate_headers_keyword_match(query_keywords, headers)
        total_score += headers_score * 0.3
    
    # 3. 表格内容匹配（权重30%）
    if hasattr(doc, 'page_content'):
        content = doc.page_content
        content_score = self._calculate_content_keyword_match(query_keywords, content)
        total_score += content_score * 0.3
    
    return total_score
```

**关键词提取算法**
```python
def _extract_table_keywords(self, query: str) -> List[str]:
    """提取表格查询关键词"""
    
    try:
        import jieba
        
        # 1. 使用jieba分词
        words = jieba.lcut(query)
        
        # 2. 过滤停用词和短词
        stop_words = {'的', '是', '在', '有', '和', '与', '或', '但', '而', '了', '着', '过'}
        filtered_words = [
            word for word in words 
            if len(word) >= 2 and word not in stop_words
        ]
        
        # 3. 添加表格相关的专业词汇
        table_keywords = self._get_table_specific_keywords(query)
        filtered_words.extend(table_keywords)
        
        # 4. 去重
        return list(set(filtered_words))
        
    except Exception as e:
        self.logger.warning(f"关键词提取失败: {e}")
        return query.split()
```

### 3. 配置管理设计

#### 3.1 配置结构
```json
{
  "rag_system": {
    "engines": {
      "text_engine": {
        "similarity_threshold": 0.7
      },
      "table_engine": {
        "similarity_threshold": 0.3
      }
    }
  }
}
```

#### 3.2 配置参数说明

| 参数名称               | 文本引擎 | 表格引擎 | 默认值   | 说明               |
| ---------------------- | -------- | -------- | -------- | ------------------ |
| `similarity_threshold` | ✓        | ✓        | 0.7/0.3  | 相似度阈值         |

**注意**：实际实现中，所有搜索策略（关键词搜索、扩展搜索等）都是硬编码启用的，不需要配置开关。

### 4. 性能优化设计

#### 4.1 搜索范围优化
- **智能搜索范围**：`search_k = top_k * 2.0`（经过验证的最佳值）
- **过滤查询优先**：直接使用V3的过滤查询，避免post-filter开销
- **结果数量控制**：每层都有明确的结果数量限制

#### 4.2 分数计算优化
- **分层阈值控制**：每层使用不同的相似度阈值
- **权重分配优化**：基于实际效果验证的权重分配
- **缓存机制**：对重复计算的结果进行缓存

#### 4.3 去重排序优化
- **文档ID去重**：使用文档ID进行快速去重
- **分数排序**：使用高效的排序算法
- **结果限制**：严格控制最终结果数量

## 五、接口设计

### 1. 核心接口

#### 1.1 文本召回接口
```python
def retrieve_texts(self, query: str, max_results: int = 30, relevance_threshold: float = None) -> List[Dict[str, Any]]:
    """
    文本内容召回
    
    :param query: 查询文本
    :param max_results: 最大结果数量
    :param relevance_threshold: 相关性阈值，如果为None则使用配置文件中的值
    :return: 召回结果列表
    """
```

#### 1.2 表格召回接口
```python
def retrieve_tables(self, query: str, max_results: int = 15, relevance_threshold: float = None) -> List[Dict[str, Any]]:
    """
    表格内容召回
    
    :param query: 查询文本
    :param max_results: 最大结果数量
    :param relevance_threshold: 相关性阈值，如果为None则使用配置文件中的值
    :return: 召回结果列表
    """
```

### 2. 返回数据结构

```python
{
    'doc': Document,                    # 文档对象
    'score': float,                     # 相似度分数
    'strategy': str,                    # 搜索策略
    'layer': int,                       # 召回层数
    'content': str,                     # 文档内容
    'metadata': Dict,                   # 文档元数据
    'doc_id': str,                      # 文档ID
    'document_name': str,               # 文档名称
    'vector_type': str,                 # 向量类型（新增）
    'similarity_score': float,          # 相似度分数（新增）
    'keyword': str,                     # 关键词（关键词搜索时新增）
    'expanded_query': str               # 扩展查询（扩展搜索时新增）
}
```

## 六、错误处理

### 1. 错误类型

| 错误类型       | 错误描述             | 处理策略             |
| -------------- | -------------------- | -------------------- |
| 向量搜索失败   | 向量数据库查询异常   | 降级到关键词搜索     |
| 关键词搜索失败 | jieba分词或匹配异常  | 跳过该层，继续下一层 |
| 扩展搜索失败   | 同义词词典或扩展异常 | 返回已有结果         |
| 分数计算失败   | 相似度计算异常       | 使用默认分数         |

### 2. 降级策略

**文本召回降级**：
```
向量搜索失败 → 关键词搜索 → 扩展搜索 → 返回空结果
```

**表格召回降级**：
```
结构搜索失败 → 语义搜索 → 关键词搜索 → 扩展搜索 → 返回空结果
```

## 七、监控与日志

### 1. 性能监控

| 监控指标 | 监控内容           | 监控方式 |
| -------- | ------------------ | -------- |
| 召回时间 | 每层召回的执行时间 | 时间统计 |
| 召回数量 | 每层召回的结果数量 | 数量统计 |
| 召回质量 | 每层召回的准确率   | 分数统计 |
| 资源消耗 | CPU和内存使用情况  | 系统监控 |

### 2. 日志记录

**日志级别**：
- **INFO**：正常流程记录
- **WARNING**：降级处理记录
- **ERROR**：错误异常记录

**日志内容**：
- 查询信息：查询文本、目标数量
- 执行状态：每层的执行结果
- 性能指标：执行时间、结果数量
- 错误信息：异常类型、处理策略

## 八、测试策略

### 1. 单元测试

| 测试类型   | 测试内容     | 测试方法     |
| ---------- | ------------ | ------------ |
| 功能测试   | 各层召回功能 | 模拟查询测试 |
| 性能测试   | 召回响应时间 | 压力测试     |
| 准确率测试 | 召回结果质量 | 人工评估     |
| 边界测试   | 异常情况处理 | 边界值测试   |

### 2. 集成测试

| 测试场景   | 测试内容     | 预期结果       |
| ---------- | ------------ | -------------- |
| 正常查询   | 完整召回流程 | 返回预期结果   |
| 高并发查询 | 系统性能表现 | 响应时间稳定   |
| 异常查询   | 错误处理能力 | 优雅降级       |
| 大数据量   | 系统扩展性   | 性能不显著下降 |

## 九、部署与运维

### 1. 部署要求

| 组件   | 版本要求 | 说明           |
| ------ | -------- | -------------- |
| Python | 3.8+     | 支持类型注解   |
| FAISS  | 1.7+     | 向量数据库支持 |
| jieba  | 0.42+    | 中文分词支持   |
| numpy  | 1.20+    | 数值计算支持   |

### 2. 配置管理

| 配置项   | 配置方式 | 说明           |
| -------- | -------- | -------------- |
| 召回参数 | 配置文件 | JSON格式配置   |
| 阈值参数 | 环境变量 | 运行时调整     |
| 模型参数 | 配置文件 | 预训练模型配置 |

## 十、总结

### 1. 设计亮点

1. **架构简化**：从V2的五层复杂策略简化为清晰的分层策略
2. **策略一致**：文本和表格召回采用相同的架构模式
3. **配置驱动**：所有关键参数都可配置，便于运维调整
4. **性能优化**：充分利用V3系统的过滤查询能力
5. **逻辑递进**：从精确到模糊，从结构到内容，层次递进更自然

### 2. 技术优势

1. **召回质量**：分层策略确保召回质量和数量的平衡
2. **系统性能**：避免重复计算，提高响应速度
3. **维护成本**：代码结构清晰，易于理解和维护
4. **扩展能力**：支持新增召回策略和优化算法

### 3. 应用价值

1. **用户体验**：快速、准确的文档召回
2. **系统稳定**：完善的错误处理和降级策略
3. **运维友好**：配置化参数，便于调整和优化
4. **开发效率**：统一的接口设计，便于集成和扩展

### 4. 策略对比总结

| 方面         | 文本召回         | 表格召回              |
| ------------ | ---------------- | --------------------- |
| **层数**     | 3层              | 4层                   |
| **第一层**   | 向量语义搜索     | 语义搜索              |
| **第二层**   | 关键词搜索       | 结构搜索              |
| **第三层**   | 扩展搜索         | 关键词搜索            |
| **第四层**   | -                | 扩展搜索              |
| **核心逻辑** | 语义→关键词→扩展 | 语义→结构→关键词→扩展 |

这个召回策略模块为V3 RAG系统提供了强大、高效的文档召回能力，是系统性能和质量的重要保障。通过调整后的策略顺序，表格召回的逻辑更加合理，性能更加优化，完全符合V3"简化设计"的原则。

## 十一、实际代码实现说明

### 1. 向量搜索调用方式

**重要说明**：实际代码中的向量搜索调用方式与设计文档中描述的不同：

#### 1.1 文本搜索
- **设计文档**：通过 `vector_db.search_texts()` 调用
- **实际代码**：通过 `vector_db.search_texts()` 调用 ✅ **一致**

#### 1.2 图片搜索
- **设计文档**：通过 `vector_db.search_images()` 调用
- **实际代码**：通过 `vector_db.vector_store_manager.similarity_search()` 调用 ❌ **不一致**

#### 1.3 表格搜索
- **设计文档**：通过 `vector_db.search_tables()` 调用
- **实际代码**：通过 `vector_db.vector_store_manager.similarity_search()` 调用 ❌ **不一致**

### 2. 弃用的方法

实际代码中发现以下方法已弃用，未被使用：
- `vector_db.search_images()` - 完全未被使用
- `vector_db.search_tables()` - 完全未被使用
- `vector_db.hybrid_search()` - 完全未被使用

### 3. 实际调用示例

#### 3.1 图片搜索实际调用
```python
results = self.vector_db.vector_store_manager.similarity_search(
    query=query, 
    k=100,
    filter_dict={'chunk_type': 'image'},
    fetch_k=200
)
```

#### 3.2 表格搜索实际调用
```python
results = self.vector_db.vector_store_manager.similarity_search(
    query=query, 
    k=100,
    filter_dict={'chunk_type': 'table'},
    fetch_k=200
)
```

### 4. 未使用的函数

实际代码中存在以下未使用的函数，可以安全删除：
- `_calculate_content_similarity()` - 图片内容相似度计算
- `_calculate_style_similarity()` - 图片风格相似度计算
- `_calculate_semantic_similarity()` - 图片语义相似度计算
- `_calculate_concept_type_similarity()` - 概念类型相似度计算
- `_calculate_art_style_similarity()` - 艺术风格相似度计算
- `_calculate_photo_style_similarity()` - 摄影风格相似度计算
- `_calculate_tfidf_similarity()` - TF-IDF相似度计算

这些函数是为了实现设计文档中描述的复杂视觉搜索算法而定义的，但实际实现中选择了更简单的方法。