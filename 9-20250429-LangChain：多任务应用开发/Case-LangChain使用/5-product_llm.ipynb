{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc58720-b781-4b53-b562-a513f089a2e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_18896\\4265487943.py:201: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  llm_chain = LLMChain(llm=llm, prompt=agent_prompt)\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_18896\\4265487943.py:205: LangChainDeprecationWarning: LangChain agents will continue to be supported, but it is recommended for new use cases to be built with LangGraph. LangGraph offers a more flexible and full-featured framework for building agents, including support for tool-calling, persistence of state, and human-in-the-loop workflows. For details, refer to the `LangGraph documentation <https://langchain-ai.github.io/langgraph/>`_ as well as guides for `Migrating from AgentExecutor <https://python.langchain.com/docs/how_to/migrate_agent/>`_ and LangGraph's `Pre-built ReAct agent <https://langchain-ai.github.io/langgraph/how-tos/create-react-agent/>`_.\n",
      "  agent = LLMSingleActionAgent(\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "请输入您的问题： model 3怎么样\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_18896\\4265487943.py:220: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  response = agent_executor.run(user_input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "intermediate_steps= []\n",
      "==============================\n",
      "\u001b[32;1m\u001b[1;3m---\n",
      "Question: model 3怎么样  \n",
      "Thought: 用户想了解Model 3的情况，我需要查询这款产品的详细信息。  \n",
      "Action: 查询产品名称  \n",
      "Action Input: Model 3  \u001b[0m\n",
      "\n",
      "Observation:\u001b[36;1m\u001b[1;3m具有简洁、动感的外观设计，流线型车身和现代化前脸。定价23.19-33.19万\u001b[0m\n",
      "intermediate_steps= [(AgentAction(tool='查询产品名称', tool_input='Model 3', log='---\\nQuestion: model 3怎么样  \\nThought: 用户想了解Model 3的情况，我需要查询这款产品的详细信息。  \\nAction: 查询产品名称  \\nAction Input: Model 3  '), '具有简洁、动感的外观设计，流线型车身和现代化前脸。定价23.19-33.19万')]\n",
      "==============================\n",
      "\u001b[32;1m\u001b[1;3m我现在知道最终答案  \n",
      "Final Answer: Model 3是一款具有简洁、动感外观设计的车型，其流线型车身和现代化前脸非常吸引人。价格区间为23.19万至33.19万。\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Model \n",
      "3是一款具有简洁、动感外观设计的车型，其流线型车身和现代化前脸非常吸引人。价格区间为23.19万至33.19万。 \n",
      "----------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "请输入您的问题： 特斯拉有哪些产品\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "intermediate_steps= []\n",
      "==============================\n",
      "\u001b[32;1m\u001b[1;3m---\n",
      "Question: 特斯拉有哪些产品  \n",
      "Thought: 要回答这个问题，我需要查询特斯拉公司所生产的产品名称。  \n",
      "Action: 查询产品名称  \n",
      "Action Input: 特斯拉  \u001b[0m\n",
      "\n",
      "Observation:\u001b[36;1m\u001b[1;3m没有找到这个产品\u001b[0m\n",
      "intermediate_steps= [(AgentAction(tool='查询产品名称', tool_input='特斯拉', log='---\\nQuestion: 特斯拉有哪些产品  \\nThought: 要回答这个问题，我需要查询特斯拉公司所生产的产品名称。  \\nAction: 查询产品名称  \\nAction Input: 特斯拉  '), '没有找到这个产品')]\n",
      "==============================\n",
      "\u001b[32;1m\u001b[1;3m查询工具未能直接提供特斯拉的产品列表，但我可以通过已知信息或公司相关信息来获取特斯拉的主要产品。\n",
      "\n",
      "---\n",
      "Thought: 我需要使用公司相关信息工具来了解特斯拉的业务范围和主要产品。  \n",
      "Action: 公司相关信息  \n",
      "Action Input: 特斯拉  \u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_18896\\4265487943.py:76: LangChainDeprecationWarning: The method `BaseLLM.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  return self.llm(prompt)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Observation:\u001b[33;1m\u001b[1;3m特斯拉是一家全球知名的电动汽车及能源公司，以其创新的技术和高性能产品而闻名。其主要产品包括多款电动车型，如 **Model S**、**Model 3**、**Model X** 和 **Model Y**。这些车辆不仅以环保的电力驱动为核心，还配备了先进的技术功能。\n",
      "\n",
      "特斯拉在自动驾驶领域处于领先地位，不断推动相关技术研发。其车辆内置了多种驾驶辅助功能，例如：\n",
      "- **自动紧急制动**：在检测到潜在碰撞时自动刹车。\n",
      "- **自适应巡航控制**：根据前方车辆的速度自动调整车速。\n",
      "- **车道保持辅助**：帮助车辆保持在车道内行驶。\n",
      "\n",
      "通过这些技术创新，特斯拉不仅改变了汽车行业，还为可持续能源的未来提供了重要解决方案。如果您有具体问题或想了解更多细节，请告诉我！\u001b[0m\n",
      "intermediate_steps= [(AgentAction(tool='查询产品名称', tool_input='特斯拉', log='---\\nQuestion: 特斯拉有哪些产品  \\nThought: 要回答这个问题，我需要查询特斯拉公司所生产的产品名称。  \\nAction: 查询产品名称  \\nAction Input: 特斯拉  '), '没有找到这个产品'), (AgentAction(tool='公司相关信息', tool_input='特斯拉', log='查询工具未能直接提供特斯拉的产品列表，但我可以通过已知信息或公司相关信息来获取特斯拉的主要产品。\\n\\n---\\nThought: 我需要使用公司相关信息工具来了解特斯拉的业务范围和主要产品。  \\nAction: 公司相关信息  \\nAction Input: 特斯拉  '), '特斯拉是一家全球知名的电动汽车及能源公司，以其创新的技术和高性能产品而闻名。其主要产品包括多款电动车型，如 **Model S**、**Model 3**、**Model X** 和 **Model Y**。这些车辆不仅以环保的电力驱动为核心，还配备了先进的技术功能。\\n\\n特斯拉在自动驾驶领域处于领先地位，不断推动相关技术研发。其车辆内置了多种驾驶辅助功能，例如：\\n- **自动紧急制动**：在检测到潜在碰撞时自动刹车。\\n- **自适应巡航控制**：根据前方车辆的速度自动调整车速。\\n- **车道保持辅助**：帮助车辆保持在车道内行驶。\\n\\n通过这些技术创新，特斯拉不仅改变了汽车行业，还为可持续能源的未来提供了重要解决方案。如果您有具体问题或想了解更多细节，请告诉我！')]\n",
      "==============================\n",
      "\u001b[32;1m\u001b[1;3m我现在知道特斯拉的主要产品。\n",
      "\n",
      "---\n",
      "Final Answer: 特斯拉的主要产品包括多款电动车型，如 **Model S**、**Model 3**、**Model X** 和 **Model Y**。此外，特斯拉还专注于自动驾驶技术，提供多种驾驶辅助功能，例如自动紧急制动、自适应巡航控制和车道保持辅助等。这些产品和技术不仅推动了汽车行业的发展，还为可持续能源的未来提供了重要解决方案。\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "特斯拉的主要产品包括多款电动车型，如 **Model S**、**Model 3**、**Model X** 和 \n",
      "**Model Y**。此外，特斯拉还专注于自动驾驶技术，提供多种驾驶辅助功能，例如自动紧急制动、自适应巡航控制和车道保 \n",
      "持辅助等。这些产品和技术不仅推动了汽车行业的发展，还为可持续能源的未来提供了重要解决方案。 \n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from typing import List, Union\n",
    "# Python内置模块，用于格式化和包装文本\n",
    "import textwrap\n",
    "import time\n",
    "\n",
    "from langchain.agents import (\n",
    "    Tool,          # 可用工具\n",
    "    AgentExecutor, # Agent执行\n",
    "    LLMSingleActionAgent, # 定义Agent\n",
    "    AgentOutputParser, # 输出结果解析\n",
    ")\n",
    "from langchain.prompts import StringPromptTemplate\n",
    "# LLMChain，包含一个PromptTemplate和一个LLM\n",
    "from langchain_community.llms import Tongyi  # 导入通义千问Tongyi模型\n",
    "from langchain import LLMChain\n",
    "# Agent执行，Agent结束\n",
    "from langchain.schema import AgentAction, AgentFinish\n",
    "# PromptTemplate: 管理LLMs的Prompts\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms.base import BaseLLM\n",
    "\n",
    "# 定义了LLM的Prompt Template\n",
    "CONTEXT_QA_TMPL = \"\"\"\n",
    "根据以下提供的信息，回答用户的问题\n",
    "信息：{context}\n",
    "\n",
    "问题：{query}\n",
    "\"\"\"\n",
    "CONTEXT_QA_PROMPT = PromptTemplate(\n",
    "    input_variables=[\"query\", \"context\"],\n",
    "    template=CONTEXT_QA_TMPL,\n",
    ")\n",
    "\n",
    "# 输出结果显示，每行最多60字符，每个字符显示停留0.1秒（动态显示效果）\n",
    "def output_response(response: str) -> None:\n",
    "    if not response:\n",
    "        exit(0)\n",
    "    # 每行最多60个字符\n",
    "    for line in textwrap.wrap(response, width=60):\n",
    "        for word in line.split():\n",
    "            for char in word:\n",
    "                print(char, end=\"\", flush=True)\n",
    "                time.sleep(0.1)  # Add a delay of 0.1 seconds between each character\n",
    "            print(\" \", end=\"\", flush=True)  # Add a space between each word\n",
    "        print()  # Move to the next line after each line is printed\n",
    "    # 遇到这里，这个问题的回答就结束了\n",
    "    print(\"----------------------------------------------------------------\")\n",
    "\n",
    "# 模拟公司产品和公司介绍的数据源\n",
    "class TeslaDataSource:\n",
    "    def __init__(self, llm: BaseLLM):\n",
    "        self.llm = llm\n",
    "\n",
    "    # 工具1：产品描述\n",
    "    def find_product_description(self, product_name: str) -> str:\n",
    "        \"\"\"模拟公司产品的数据库\"\"\"\n",
    "        product_info = {\n",
    "            \"Model 3\": \"具有简洁、动感的外观设计，流线型车身和现代化前脸。定价23.19-33.19万\",\n",
    "            \"Model Y\": \"在外观上与Model 3相似，但采用了更高的车身和更大的后备箱空间。定价26.39-36.39万\",\n",
    "            \"Model X\": \"拥有独特的翅子门设计和更加大胆的外观风格。定价89.89-105.89万\",\n",
    "        }\n",
    "        # 基于产品名称 => 产品描述\n",
    "        return product_info.get(product_name, \"没有找到这个产品\")\n",
    "\n",
    "    # 工具2：公司介绍\n",
    "    def find_company_info(self, query: str) -> str:\n",
    "        \"\"\"模拟公司介绍文档数据库，让llm根据信息回答问题\"\"\"\n",
    "        context = \"\"\"\n",
    "        特斯拉最知名的产品是电动汽车，其中包括Model S、Model 3、Model X和Model Y等多款车型。\n",
    "        特斯拉以其技术创新、高性能和领先的自动驾驶技术而闻名。公司不断推动自动驾驶技术的研发，并在车辆中引入了各种驾驶辅助功能，如自动紧急制动、自适应巡航控制和车道保持辅助等。\n",
    "        \"\"\"\n",
    "        # prompt模板 = 上下文context + 用户的query\n",
    "        prompt = CONTEXT_QA_PROMPT.format(query=query, context=context)\n",
    "        # 使用LLM进行推理\n",
    "        return self.llm(prompt)\n",
    "\n",
    "\n",
    "AGENT_TMPL = \"\"\"按照给定的格式回答以下问题。你可以使用下面这些工具：\n",
    "\n",
    "{tools}\n",
    "\n",
    "回答时需要遵循以下用---括起来的格式：\n",
    "\n",
    "---\n",
    "Question: 我需要回答的问题\n",
    "Thought: 回答这个上述我需要做些什么\n",
    "Action: \"{tool_names}\" 中的一个工具名\n",
    "Action Input: 选择这个工具所需要的输入\n",
    "Observation: 选择这个工具返回的结果\n",
    "...（这个 思考/行动/行动输入/观察 可以重复N次）\n",
    "Thought: 我现在知道最终答案\n",
    "Final Answer: 原始输入问题的最终答案\n",
    "---\n",
    "\n",
    "现在开始回答，记得在给出最终答案前，需要按照指定格式进行一步一步的推理。\n",
    "\n",
    "Question: {input}\n",
    "{agent_scratchpad}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class CustomPromptTemplate(StringPromptTemplate):\n",
    "    template: str  # 标准模板\n",
    "    tools: List[Tool]  # 可使用工具集合\n",
    "\n",
    "    def format(self, **kwargs) -> str:\n",
    "        \"\"\"\n",
    "        按照定义的 template，将需要的值都填写进去。\n",
    "        Returns:\n",
    "            str: 填充好后的 template。\n",
    "        \"\"\"\n",
    "        # 取出中间步骤并进行执行\n",
    "        intermediate_steps = kwargs.pop(\"intermediate_steps\")  \n",
    "        print('intermediate_steps=', intermediate_steps)\n",
    "        print('='*30)\n",
    "        thoughts = \"\"\n",
    "        for action, observation in intermediate_steps:\n",
    "            thoughts += action.log\n",
    "            thoughts += f\"\\nObservation: {observation}\\nThought: \"\n",
    "        # 记录下当前想法 => 赋值给agent_scratchpad\n",
    "        kwargs[\"agent_scratchpad\"] = thoughts  \n",
    "        # 枚举所有可使用的工具名+工具描述\n",
    "        kwargs[\"tools\"] = \"\\n\".join(\n",
    "            [f\"{tool.name}: {tool.description}\" for tool in self.tools]\n",
    "        )  \n",
    "        # 枚举所有的工具名称\n",
    "        kwargs[\"tool_names\"] = \", \".join(\n",
    "            [tool.name for tool in self.tools]\n",
    "        )  \n",
    "        cur_prompt = self.template.format(**kwargs)\n",
    "        #print(cur_prompt)\n",
    "        return cur_prompt\n",
    "\n",
    "\"\"\"\n",
    "    对Agent返回结果进行解析，有两种可能：\n",
    "    1）还在思考中 AgentAction\n",
    "    2）找到了答案 AgentFinal\n",
    "\"\"\"\n",
    "class CustomOutputParser(AgentOutputParser):\n",
    "    def parse(self, llm_output: str) -> Union[AgentAction, AgentFinish]:\n",
    "        \"\"\"\n",
    "        解析 llm 的输出，根据输出文本找到需要执行的决策。\n",
    "        Args:\n",
    "            llm_output (str): _description_\n",
    "        Raises:\n",
    "            ValueError: _description_\n",
    "        Returns:\n",
    "            Union[AgentAction, AgentFinish]: _description_\n",
    "        \"\"\"\n",
    "        # 如果句子中包含 Final Answer 则代表已经完成\n",
    "        if \"Final Answer:\" in llm_output:  \n",
    "            return AgentFinish(\n",
    "                return_values={\"output\": llm_output.split(\"Final Answer:\")[-1].strip()},\n",
    "                log=llm_output,\n",
    "            )\n",
    "\n",
    "        # 需要进行 AgentAction\n",
    "        regex = r\"Action\\s*\\d*\\s*:(.*?)\\nAction\\s*\\d*\\s*Input\\s*\\d*\\s*:[\\s]*(.*)\"  # 解析 action_input 和 action\n",
    "        match = re.search(regex, llm_output, re.DOTALL)\n",
    "        if not match:\n",
    "            raise ValueError(f\"Could not parse LLM output: `{llm_output}`\")\n",
    "        action = match.group(1).strip()\n",
    "        action_input = match.group(2)\n",
    "        # Agent执行\n",
    "        return AgentAction(\n",
    "            tool=action, tool_input=action_input.strip(\" \").strip('\"'), log=llm_output\n",
    "        )\n",
    "\n",
    "# 设置通义千问API密钥\n",
    "DASHSCOPE_API_KEY = 'sk-882e296067b744289acf27e6e20f3ec0'\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 定义LLM\n",
    "    llm = Tongyi(model_name=\"qwen-turbo\", dashscope_api_key=DASHSCOPE_API_KEY)  # 使用通义千问qwen-turbo模型\n",
    "    # 自有数据\n",
    "    tesla_data_source = TeslaDataSource(llm)\n",
    "    # 定义的Tools\n",
    "    tools = [\n",
    "        Tool(\n",
    "            name=\"查询产品名称\",\n",
    "            func=tesla_data_source.find_product_description,\n",
    "            description=\"通过产品名称找到产品描述时用的工具，输入的是产品名称\",\n",
    "        ),\n",
    "        Tool(\n",
    "            name=\"公司相关信息\",\n",
    "            func=tesla_data_source.find_company_info,\n",
    "            description=\"当用户询问公司相关的问题，可以通过这个工具了解公司信息\",\n",
    "        ),\n",
    "    ]\n",
    "    \n",
    "    # 用户定义的模板\n",
    "    agent_prompt = CustomPromptTemplate(\n",
    "        template=AGENT_TMPL,\n",
    "        tools=tools,\n",
    "        input_variables=[\"input\", \"intermediate_steps\"],\n",
    "    )\n",
    "    # Agent返回结果解析\n",
    "    output_parser = CustomOutputParser()\n",
    "    # 最常用的Chain, 由LLM + PromptTemplate组成\n",
    "    llm_chain = LLMChain(llm=llm, prompt=agent_prompt)\n",
    "    # 定义的工具名称\n",
    "    tool_names = [tool.name for tool in tools]\n",
    "    # 定义Agent = llm_chain + output_parser + tools_names\n",
    "    agent = LLMSingleActionAgent(\n",
    "        llm_chain=llm_chain,\n",
    "        output_parser=output_parser,\n",
    "        stop=[\"\\nObservation:\"],\n",
    "        allowed_tools=tool_names,\n",
    "    )\n",
    "    # 定义Agent执行器 = Agent + Tools\n",
    "    agent_executor = AgentExecutor.from_agent_and_tools(\n",
    "        agent=agent, tools=tools, verbose=True\n",
    "    )\n",
    "\n",
    "    # 主过程：可以一直提问下去，直到Ctrl+C\n",
    "    while True:\n",
    "        try:\n",
    "            user_input = input(\"请输入您的问题：\")\n",
    "            response = agent_executor.run(user_input)\n",
    "            output_response(response)\n",
    "        except KeyboardInterrupt:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a8b152b-ab24-416e-818e-2f1e925f2af8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sk-dd7ae33a0056483a82660b9392f4eedc'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "#DASHSCOPE_API_KEY = 'sk-882e296067b744289acf27e6e20f3ec0'\n",
    "os.getenv(\"DASHSCOPE_API_KEY\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
