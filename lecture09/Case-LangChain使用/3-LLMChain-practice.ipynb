{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa82b9a1-ebed-40d6-98bb-a6d63574d014",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Collecting numexpr\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/b8/25/9ae599994076ef2a42d35ff6b0430da002647f212567851336a6c7b132d6/numexpr-2.10.2-cp312-cp312-win_amd64.whl (145 kB)\n",
      "Requirement already satisfied: numpy>=1.23.0 in c:\\users\\administrator\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from numexpr) (1.26.4)\n",
      "Installing collected packages: numexpr\n",
      "Successfully installed numexpr-2.10.2\n"
     ]
    }
   ],
   "source": [
    "!pip install numexpr\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b8b5249",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_23720\\568626535.py:28: LangChainDeprecationWarning: LangChain agents will continue to be supported, but it is recommended for new use cases to be built with LangGraph. LangGraph offers a more flexible and full-featured framework for building agents, including support for tool-calling, persistence of state, and human-in-the-loop workflows. For details, refer to the `LangGraph documentation <https://langchain-ai.github.io/langgraph/>`_ as well as guides for `Migrating from AgentExecutor <https://python.langchain.com/docs/how_to/migrate_agent/>`_ and LangGraph's `Pre-built ReAct agent <https://langchain-ai.github.io/langgraph/how-tos/create-react-agent/>`_.\n",
      "  agent = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True)\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_23720\\568626535.py:31: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  agent.run(\"当前北京的温度是多少华氏度？这个温度的1/4是多少\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m我需要查找当前北京的温度，然后将其转换为华氏度。之后，我需要计算这个温度的1/4。\n",
      "Action: Search\n",
      "Action Input: 北京 当前 温度\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m{'type': 'weather_result', 'temperature': '71', 'unit': 'Fahrenheit', 'precipitation': '0%', 'humidity': '25%', 'wind': '2 mph', 'location': '中国北京市', 'date': 'Tuesday 1:00 PM', 'weather': 'Mostly sunny'}\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m当前北京的温度是71华氏度。现在我需要计算这个温度的1/4。\n",
      "Action: Calculator\n",
      "Action Input: 71 / 4\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mAnswer: 17.75\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m我已计算出当前北京温度的1/4。\n",
      "Final Answer: 当前北京的温度是71华氏度，这个温度的1/4是17.75华氏度。\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'当前北京的温度是71华氏度，这个温度的1/4是17.75华氏度。'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from langchain.agents import load_tools\n",
    "from langchain.agents import initialize_agent\n",
    "from langchain_community.llms import Tongyi  # 导入通义千问Tongyi模型\n",
    "from langchain.agents import AgentType\n",
    "\n",
    " # 你需要在环境变量中添加 OPENAI_API_KEY 和 SERPAPI_API_KEY\n",
    "#os.environ[\"OPENAI_API_KEY\"] = '*******'\n",
    "#os.environ[\"SERPAPI_API_KEY\"] = '*******'\n",
    "os.environ[\"SERPAPI_API_KEY\"] = '0d5f2fc3573b1017a130e75b5ce659e9bd7d4badb9bc9246225059820cf1cb9b' \n",
    "# 设置通义千问API密钥\n",
    "DASHSCOPE_API_KEY = 'sk-882e296067b744289acf27e6e20f3ec0'\n",
    " \n",
    "# 加载 Tongyi 模型\n",
    "llm = Tongyi(model_name=\"qwen-turbo\", dashscope_api_key=DASHSCOPE_API_KEY)  # 使用通义千问qwen-turbo模型\n",
    " \n",
    "# 加载 serpapi, llm-math工具, 因为llm-math要使用LLM，所以后面需要指定LLM\n",
    "tools = load_tools([\"serpapi\", \"llm-math\"], llm=llm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2857dff5-186d-4a7b-99cc-7c19cee24724",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search\n",
      "Calculator\n",
      "A search engine. Useful for when you need to answer questions about current events. Input should be a search query.\n",
      "Useful for when you need to answer questions about math.\n"
     ]
    }
   ],
   "source": [
    "# 查看工具信息\n",
    "print(tools[0].name)  # 输出: \"serpapi\"\n",
    "print(tools[1].name)  # 输出: \"Calculator\"\n",
    "print(tools[0].description) \n",
    "print(tools[1].description) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bdb7b0b4-2c57-4aba-a43b-a026a4b9fef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m我需要查找当前北京的温度，然后将其转换为华氏度。之后，我需要计算这个温度的1/4。\n",
      "Action: Search\n",
      "Action Input: 北京 当前 温度\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m{'type': 'weather_result', 'temperature': '71', 'unit': 'Fahrenheit', 'precipitation': '0%', 'humidity': '25%', 'wind': '2 mph', 'location': '中国北京市', 'date': 'Tuesday 1:00 PM', 'weather': 'Mostly sunny'}\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m当前北京的温度是71华氏度。现在我需要计算这个温度的1/4。\n",
      "Action: Calculator\n",
      "Action Input: 71 / 4\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mAnswer: 17.75\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m我已计算出当前北京温度的1/4。\n",
      "Final Answer: 当前北京的温度是71华氏度，这个温度的1/4是17.75华氏度。\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'当前北京的温度是71华氏度，这个温度的1/4是17.75华氏度。'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " \n",
    "\"\"\"\n",
    "agent：代理类型  \n",
    "    zero-shot-react-description: 根据工具的描述和请求内容的来决定使用哪个工具（最常用）\n",
    "    react-docstore: 使用 ReAct 框架和 docstore 交互, 使用Search 和Lookup 工具, 前者用来搜, 后者寻找term, 举例: Wipipedia 工具\n",
    "    self-ask-with-search 此代理只使用一个工具: Intermediate Answer, 它会为问题寻找事实答案(指的非 gpt 生成的答案, 而是在网络中,文本中已存在的), 如 Google search API 工具\n",
    "    conversational-react-description: 为会话设置而设计的代理, 它的prompt会被设计的具有会话性, 且还是会使用 ReAct 框架来决定使用来个工具, 并且将过往的会话交互存入内存\n",
    "\"\"\"\n",
    "# 工具加载后需要初始化，verbose=True 代表打印执行详情\n",
    "agent = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True)\n",
    " \n",
    "# 运行 agent\n",
    "agent.run(\"当前北京的温度是多少华氏度？这个温度的1/4是多少\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c47cb9f3-27e9-42ef-b6f5-e8cc9e04409a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[31mSignature:\u001b[39m\n",
       "load_tools(\n",
       "    tool_names: List[str],\n",
       "    llm: Optional[langchain_core.language_models.base.BaseLanguageModel] = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
       "    callbacks: Union[list[langchain_core.callbacks.base.BaseCallbackHandler], langchain_core.callbacks.base.BaseCallbackManager, NoneType] = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
       "    allow_dangerous_tools: bool = \u001b[38;5;28;01mFalse\u001b[39;00m,\n",
       "    **kwargs: Any,\n",
       ") -> List[langchain_core.tools.base.BaseTool]\n",
       "\u001b[31mDocstring:\u001b[39m\n",
       "Load tools based on their name.\n",
       "\n",
       "Tools allow agents to interact with various resources and services like\n",
       "APIs, databases, file systems, etc.\n",
       "\n",
       "Please scope the permissions of each tools to the minimum required for the\n",
       "application.\n",
       "\n",
       "For example, if an application only needs to read from a database,\n",
       "the database tool should not be given write permissions. Moreover\n",
       "consider scoping the permissions to only allow accessing specific\n",
       "tables and impose user-level quota for limiting resource usage.\n",
       "\n",
       "Please read the APIs of the individual tools to determine which configuration\n",
       "they support.\n",
       "\n",
       "See [Security](https://python.langchain.com/docs/security) for more information.\n",
       "\n",
       "Args:\n",
       "    tool_names: name of tools to load.\n",
       "    llm: An optional language model may be needed to initialize certain tools.\n",
       "        Defaults to None.\n",
       "    callbacks: Optional callback manager or list of callback handlers.\n",
       "        If not provided, default global callback manager will be used.\n",
       "    allow_dangerous_tools: Optional flag to allow dangerous tools.\n",
       "        Tools that contain some level of risk.\n",
       "        Please use with caution and read the documentation of these tools\n",
       "        to understand the risks and how to mitigate them.\n",
       "        Refer to https://python.langchain.com/docs/security\n",
       "        for more information.\n",
       "        Please note that this list may not be fully exhaustive.\n",
       "        It is your responsibility to understand which tools\n",
       "        you're using and the risks associated with them.\n",
       "        Defaults to False.\n",
       "    kwargs: Additional keyword arguments.\n",
       "\n",
       "Returns:\n",
       "    List of tools.\n",
       "\n",
       "Raises:\n",
       "    ValueError: If the tool name is unknown.\n",
       "    ValueError: If the tool requires an LLM to be provided.\n",
       "    ValueError: If the tool requires some parameters that were not provided.\n",
       "    ValueError: If the tool is a dangerous tool and allow_dangerous_tools is False.\n",
       "\u001b[31mFile:\u001b[39m      c:\\users\\administrator\\appdata\\local\\programs\\python\\python312\\lib\\site-packages\\langchain_community\\agent_toolkits\\load_tools.py\n",
       "\u001b[31mType:\u001b[39m      function"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "load_tools?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8890f6e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
