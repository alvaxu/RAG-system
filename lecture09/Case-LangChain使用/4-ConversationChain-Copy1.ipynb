{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b8b5249",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cheny\\AppData\\Local\\Temp\\ipykernel_2444\\3597648652.py:14: LangChainDeprecationWarning: The class `ConversationChain` was deprecated in LangChain 0.2.7 and will be removed in 1.0. Use :meth:`~RunnableWithMessageHistory: https://python.langchain.com/v0.2/api_reference/core/runnables/langchain_core.runnables.history.RunnableWithMessageHistory.html` instead.\n",
      "  conversation = ConversationChain(llm=llm, verbose=True)\n",
      "D:\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pydantic\\main.py:212: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Hi there!\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Hello! How can I assist you today? If you have any questions or need information on a topic, feel free to ask!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain.agents import load_tools\n",
    "from langchain.agents import initialize_agent\n",
    "from langchain_community.llms import Tongyi  # 导入通义千问Tongyi模型\n",
    "from langchain.agents import AgentType\n",
    "from langchain import ConversationChain\n",
    "\n",
    "# 设置通义千问API密钥\n",
    "DASHSCOPE_API_KEY = 'sk-882e296067b744289acf27e6e20f3ec0'\n",
    "\n",
    "# 加载 Tongyi 模型\n",
    "llm = Tongyi(model_name=\"qwen-turbo\", dashscope_api_key=DASHSCOPE_API_KEY)  # 使用通义千问qwen-turbo模型\n",
    "# 使用带有memory的ConversationChain\n",
    "conversation = ConversationChain(llm=llm, verbose=True)\n",
    "\n",
    "output = conversation.predict(input=\"Hi there!\")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8890f6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi there!\n",
      "AI: Hello! How can I assist you today? If you have any questions or need information on a topic, feel free to ask!\n",
      "Human: I'm doing well! Just having a conversation with an AI.\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "That's great! I enjoy having conversations and providing helpful information. So, what interesting topics or questions do you have in mind? We can chat about anything from technology and science to hobbies and travel experiences. Or, if you prefer, we could just casually talk about your day or something fun!\n"
     ]
    }
   ],
   "source": [
    "output = conversation.predict(input=\"I'm doing well! Just having a conversation with an AI.\")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4412cd7c-1cfc-4916-be55-8d2df24d3c9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! How can I assist you today? Feel free to ask me any questions or let me know if you need help with anything specific.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_community.llms import Tongyi\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain.memory import ChatMessageHistory\n",
    "\n",
    "# 设置通义千问API密钥\n",
    "DASHSCOPE_API_KEY = 'sk-882e296067b744289acf27e6e20f3ec0'\n",
    "\n",
    "# 1. 加载 Tongyi 模型\n",
    "llm = Tongyi(model_name=\"qwen-turbo\", dashscope_api_key=DASHSCOPE_API_KEY)\n",
    "\n",
    "# 2. 定义对话流程（替代ConversationChain）\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant.\"),\n",
    "    MessagesPlaceholder(variable_name=\"history\"),\n",
    "    (\"human\", \"{input}\")\n",
    "])\n",
    "\n",
    "chain = prompt | llm\n",
    "\n",
    "# 3. 添加对话历史功能\n",
    "message_history = ChatMessageHistory()\n",
    "chain_with_history = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    lambda session_id: message_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"history\"\n",
    ")\n",
    "\n",
    "# 4. 使用对话\n",
    "output = chain_with_history.invoke(\n",
    "    {\"input\": \"Hi there!\"},\n",
    "    config={\"configurable\": {\"session_id\": \"test\"}}\n",
    ")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ca53232-d15d-49e4-b4d7-f4767791aaff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That's great! I'm here to chat and help with whatever you need. It's always fun to have a conversation and explore topics. Is there anything interesting you'd like to talk about or any questions you have?\n"
     ]
    }
   ],
   "source": [
    "# 5. 继续对话\n",
    "output = chain_with_history.invoke(\n",
    "    {\"input\": \"I'm doing well! Just having a conversation with an AI.\"},\n",
    "    config={\"configurable\": {\"session_id\": \"test\"}}\n",
    ")\n",
    "print(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
