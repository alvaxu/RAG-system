{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba5ff69-5fec-4cfe-9cfe-98e5ac3243fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#模型下载，bge-rerank模型由北京智源研究院（BAAI）开发，适合中英文任务;还有COhere Rerank模型 \n",
    "from modelscope import snapshot_download\n",
    "model_dir = snapshot_download('BAAI/bge-reranker-large', cache_dir=\"D:\\\\AInewModels\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51fe6363-8f2e-4cdb-9815-ab408b12f244",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4.9538], grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# 作用：\n",
    "# 加载分词器（tokenizer）和模型（model）\n",
    "# 设置模型为评估模式（model.eval()）\n",
    "# 关键点：\n",
    "# 该模型本质是一个序列分类模型，输出的是相关性分数（而非分类标签）\n",
    "# 适用于 (query, document) 对的语义匹配\n",
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "model_name=\"D:/AInewModels/BAAI/bge-reranker-large\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "model.eval()\n",
    "# 作用：计算问题与答案的相关性分数 \n",
    "# 流程：\n",
    "    # 分词器将文本对转换为模型可处理的输入（包括填充和截断）\n",
    "    # 模型输出原始 logits（未归一化的分数）\n",
    "    # view(-1) 将结果展平为一维张量\n",
    "# 输出解释：\n",
    "    # 分数越高表示相关性越强（通常 >1 表示相关，<0 表示不相关）\n",
    "pairs = [['what is panda?', 'The giant panda is a bear species endemic to China.']]\n",
    "inputs = tokenizer(pairs, padding=True, truncation=True, return_tensors='pt')\n",
    "scores = model(**inputs).logits.view(-1).float()\n",
    "print(scores)  # 输出相关性分数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92b5eef6-bb6b-4f90-8318-2b3a73ab1aed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 4.9538, -0.4951, -9.4803], grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "pairs = [\n",
    "    ['what is panda?', 'The giant panda is a bear species endemic to China.'],  # 高相关\n",
    "    ['what is panda?', 'Pandas are cute.'],                                     # 中等相关\n",
    "    ['what is panda?', 'The Eiffel Tower is in Paris.']                        # 不相关\n",
    "]\n",
    "inputs = tokenizer(pairs, padding=True, truncation=True, return_tensors='pt')\n",
    "scores = model(**inputs).logits.view(-1).float()\n",
    "print(scores)  # 输出相关性分数"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
