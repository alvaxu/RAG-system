Q：老师好，我的二手车预测怎么优化也没到800分以下，大概也知道是特征值有问题，但不知道怎样改进
=> 问题在特征工程
创建时间特征（如车龄、注册季节等）。
创建车辆特征（如功率、品牌-车型组合、异常值处理等）。
创建统计特征（如品牌均价、品牌价格比等）。
编码分类特征（如频率编码、CatBoost 分类特征标记）。

Q：feature_missing好像重要性很低，是不是可以删掉
可以删掉

Q：我本地部署的RAGFlow，为啥效果非常不好？是不是因为我是用的本地ds1.5b的模型有关系呢？
ds1.5会差一些
可以用ds7b，或者qwen-4b
https://modelscope.cn/models/Qwen/Qwen3-4B

Q：最好跑到408，再用cursor改进几轮反而mae变大了不少
优化空间已经不大了
后面如果优化，也可能会出现过拟合的情况

Q：老师 实际预测中 mae 四五百是个什么水平
前5%

在AI大赛中（预测比赛），经常使用的模型是 XGBoost, LightGBM, CatBoost 
=> 追求准确率

Q：KNN是聚类么？
KNN是分类
KMeans是聚类
K邻居
K=3
(x1, x2, ..., x31) => y=?
KNN 找邻居K=3个，
(x1', x2', ..., x31') =>y1  No
(x1'', x2'', ..., x31''） => y2 No
(x1''', x2''', ..., x31''') => y3 Yes
少数服从多数，用邻居的y进行投票 => No

邻居一般是相似的，
(x1', x2', ..., x31') => (x1, x2, .., x31)

# 对于分类特征进行特征值编码
attr=['BusinessTravel','Department','Education','EducationField','Gender','JobRole','MaritalStatus','Over18','OverTime']

@attrition_lr.py 帮我改成KNN分类，编写到 attrition_knn.py

@attrition_knn.py  帮我结果写入到 submit_knn.csv 表头为 user_id,Attrition
Attrtition=0或1

@attrition_lr.py 帮我数据LR的系数，并将系数进行可视化（保留正负）

帮我对LR系数进行解释，分析哪些人容易离职，哪些人不容易离职，写入到 .md中

AI数据决策
价值1：得到预测结果，以及预测的准确率
价值：可解释性

归一化：
将所有特征，放到同样的标准中进行衡量。
age 0-100
收入 1000-100000

帮我做归一化处理，写入到 新的 .py

Q：老师，在大模型能力不断涌现的过程中应该持有哪种学习态度，感觉总会质疑所学东西的意义。在AI编程实践中积累的是啥呢？
学习不仅仅是input，还可以是output
output > input
打卡
===
对于和距离相关的模型，比如 LR, SVM, KNN，一般需要先做归一化处理，然后再放到模型中进行训练

Q：老师，如何把这个模型程序编译成应用？如何应用到工作中？
举一反三

客户购买理财的预测 => Yes or No
@之前的代码.py 撰写新的需求 .py

Q: 这些课程学习下来，哪些是主要的，要掌握到什么程度。确实学习了不少，但不知道重点应该放在哪里

不同的任务，不同的需求（diversity 多样性） => 你的解决方案也会不同
整理下学习的内容，归归类 => 你自己的RAG

1）分类预测， 打卡：人员离职预测
2）回归预测，打卡：二手车价格预测
3）时间序列预测，打卡：资金流入流出预测

RAG，打卡：Faiss + DeepSeek（浦发个金客户经理考核办法）
知识图谱RAG，打卡：GraphRAG

@attrition_lr.py 帮我改成 CART决策树分类(depth=4)，帮我打印出决策树的规则，并进行决策树可视化，编写新的 .py

帮我不显示 warnings，图表中中文有乱码

帮我对决策树进行解释，哪些人容易离职，哪些人不容易离职，写入到 .md

帮我对决策树模型进行保存，方便后续进行预测

===

Q: 老师，我是想问一下，这个模型，如何编译成可运行的程序，安装在电脑上用！？还是编译成WEB页面，部署在本地通过URL进行使用
web页面更常见，更方便；
Step1，先把模型保存下来 mode.save
Step2，fastapi, flask 对后台的调用封装成接口
Step3，编写页面，调用后端的预测结果

dify + HTTP节点（fastapi, flask）

Q：模型如何保存
import joblib  # 用于模型保存
# 保存模型
joblib.dump(model, 'cart_model.pkl')  # 保存为cart_model.pkl

Q：老师 决策树不应该精确度低于 随机森林吗 为什么要用决策树
决策树(depth=4)的优势是在于可视化，以及模型解读 => 输出 容易离职人的画像

Q：老师，我如果用这些训练数据微调一个大模型，然后让大模型去预测，这样的效果会好吗？
大模型微调主要是用于 <Q, A>

1）文本生成 => 用于通用的任务 （生成式AI）
2）专业模型（LR, CART, RF, SVM, XGBoost,...）
（决策式AI）

让大模型 做Chat，通过function calling，调用专业模型，得到专业模型预测结果 => 返回给用户

https://www.kaggle.com/competitions/bi-attrition-predict

Q：什么叫做基于距离？
LR, SVM, KNN
KNN 是通过找邻居，让邻居来投票 =>决定这个人 是否离职
(x1, x2, ..., x31)
(x1', x2', ..., x31')

距离是否要统一标准 => 影响到模型的预测

XGBoost 可以做分类，也可以做回归
分类和回归是一家，只是输出的结果不同。分类可以看成是 回归结果的sigmoid变化
预测器

Q: 为什么XGBoost在2014年AI大赛中大火？
在Loss + 正则化项（防止模型过拟合）
XGBoost，iteration = 2000

XGBoost = GBDT（原理，基于Boosting的多颗决策树的拟合算法）的工程化版本

Q：实际上是否相当于复合的模型有更个参数
之前的权重是人工给的
现在的权重（系数）是LR拟合出来的

Q：讲讲特征多重共线性的影响
x1, x2, ..., 税前收入、税后收入, => 是否离职
特征多重共线性 => 说明特征之间是一致


https://tianchi.aliyun.com/
https://www.kaggle.com/search

特征相关性系数 进行热力图呈现 .corr
x1, x2, ..., x31
df.corr()
