# ChatPDF - 基于RAG技术的文档问答系统

## 项目概述

本项目是一个基于RAG（Retrieval-Augmented Generation）技术的智能文档问答系统，能够对PDF文档进行解析、分块处理，并基于这些文档内容回答用户提出的问题。系统支持通过命令行界面和Web界面进行交互式问答，具有准确的来源追踪和成本计算功能。

### 核心特性

- **智能文档解析**：使用minerU工具将PDF文档转换为结构化的Markdown和JSON格式
- **语义分块处理**：对文档内容进行智能分块，保留文档出处信息
- **向量数据库检索**：使用FAISS构建高效的向量数据库，支持相似度检索
- **大模型问答**：基于通义千问大模型实现智能问答功能
- **准确来源追踪**：精确追踪答案的来源文档和页码信息
- **实时成本计算**：准确计算LLM查询的token消耗和成本
- **双界面支持**：提供命令行界面和Web界面两种交互方式
- **响应式设计**：Web界面支持移动端和桌面端自适应

## 技术架构

### 整体架构图

```
用户界面层
├── Web前端 (HTML/CSS/JavaScript)
└── 命令行界面 (Python)

应用服务层
├── Flask Web服务 (V303_app_with_cost.py)
└── 问答系统 (V303_vector_store_qa_with_cost.py)

核心处理层
├── 文档加载与分块 (V100_document_loader_chunker.py)
├── 向量存储管理 (VectorStoreManager)
├── 问答系统 (QuestionAnsweringSystem)
└── 成本计算器 (TongyiCostCalculator)

数据存储层
├── FAISS向量数据库
├── 文档元数据存储
└── 向量索引文件

外部服务层
├── DashScope API (通义千问)
├── DashScope Embeddings API
└── MinerU API (PDF解析)
```

## RAG技术实现详解

### 1. 文档处理与分块 (V100_document_loader_chunker.py)

#### 1.1 文档加载器 (DocumentLoader)

```python
class DocumentLoader:
    """
    文档加载器类，负责加载Markdown文件和对应的JSON元数据
    """
```

**核心功能：**

- 扫描指定目录下的Markdown文件
- 加载对应的JSON元数据文件
- 解析文档结构和内容信息
- 提取文本内容及其页码信息

**技术特点：**

- 支持批量文档处理
- 保留文档的原始结构信息
- 自动关联Markdown和JSON元数据

#### 1.2 语义分块器 (SemanticChunker)

```python
class SemanticChunker:
    """
    语义分块器类，使用LangChain的RecursiveCharacterTextSplitter进行智能分块
    """
```

**分块策略：**

- **分块大小**：默认1000字符，可配置
- **重叠大小**：默认200字符，确保上下文连续性
- **分隔符优先级**：`["\n\n", "\n", ".", "!", "?", "。", "！", "？", " ", ""]`
- **长度函数**：使用字符长度计算

**技术优势：**

- 保持语义完整性
- 避免在关键信息处截断
- 支持中英文混合文本
- 保留页码映射关系

#### 1.3 文档分块数据结构

```python
@dataclass
class DocumentChunk:
    content: str           # 分块内容
    document_name: str     # 文档名称
    page_number: int       # 页码
    chunk_index: int       # 分块索引
```

### 2. 向量存储与检索 (V303_vector_store_qa_with_cost.py)

#### 2.1 向量存储管理器 (VectorStoreManager)

```python
class VectorStoreManager:
    """
    向量存储管理器类，负责创建和管理FAISS向量数据库
    """
```

**核心功能：**

- 使用DashScope的text-embedding-v1模型生成向量
- 创建FAISS向量数据库
- 管理文档元数据关联
- 支持向量数据库的保存和加载

**技术实现：**

- **向量化模型**：DashScope text-embedding-v1
- **向量维度**：1536维
- **索引类型**：FAISS CPU版本
- **相似度算法**：余弦相似度

#### 2.2 元数据管理机制

```python
# 使用文档内容哈希值作为唯一标识符
identifier = f"{hash(chunk.content)}_{chunk.document_name}_{chunk.page_number}"
metadata[identifier] = {
    'document_name': chunk.document_name,
    'page_number': chunk.page_number,
    'chunk_index': chunk.chunk_index,
    'content': chunk.content  # 用于匹配验证
}
```

**技术优势：**

- 避免索引计算错误
- 确保文档引用的准确性
- 支持内容匹配验证
- 便于调试和问题排查

### 3. 问答系统 (QuestionAnsweringSystem)

#### 3.1 检索增强生成 (RAG) 流程

```python
def answer_question(self, question: str, k: int = 10) -> Dict[str, Any]:
    # 1. 执行相似度搜索
    docs = self.vector_store.similarity_search(question, k=k)
  
    # 2. 准备输入数据
    input_data = {"input_documents": docs, "question": question}
  
    # 3. 执行问答链
    response = self.qa_chain.invoke(input=input_data)
  
    # 4. 提取答案和来源信息
    answer = response["output_text"]
    sources = self._extract_sources(docs)
  
    # 5. 计算成本
    cost_info = self._calculate_cost(input_data, answer)
  
    return {
        'question': question,
        'answer': answer,
        'sources': sources,
        'cost': cost_info['total_cost'],
        'input_tokens': cost_info['input_tokens'],
        'output_tokens': cost_info['output_tokens'],
        'processing_time': cost_info['processing_time']
    }
```

**RAG流程详解：**

1. **问题理解**：接收用户问题
2. **向量化查询**：将问题转换为向量表示
3. **相似度检索**：在向量数据库中检索相关文档片段
4. **上下文构建**：将检索到的文档片段作为上下文
5. **答案生成**：使用大模型基于上下文生成答案
6. **来源追踪**：记录答案的来源文档和页码
7. **成本计算**：统计token消耗和计算成本

#### 3.2 来源信息提取

```python
def _extract_sources(self, docs):
    sources = []
    unique_sources = set()
  
    for doc in docs:
        # 通过匹配文档内容来查找对应的元数据
        found_metadata = None
        for identifier, metadata in self.vector_store.metadata.items():
            if metadata['content'] == doc.page_content:
                found_metadata = metadata
                break
      
        if found_metadata:
            source_key = (found_metadata['document_name'], found_metadata['page_number'])
            if source_key not in unique_sources:
                unique_sources.add(source_key)
                sources.append({
                    'document_name': found_metadata['document_name'],
                    'page_number': found_metadata['page_number'],
                    'content': doc.page_content[:200] + "..." if len(doc.page_content) > 200 else doc.page_content
                })
  
    return sources
```

**技术特点：**

- 去重处理，避免重复来源
- 内容截断，提高显示效果
- 准确匹配，确保来源正确性

## 成本计算技术详解

### 1. 通义千问API成本计算器 (TongyiCostCalculator)

#### 1.1 定价模型

```python
class TongyiCostCalculator:
    def __init__(self):
        # 通义千问qwen-turbo模型的定价（每1000个token的价格，单位：元）
        # 根据阿里云官方文档：https://help.aliyun.com/zh/model-studio/billing-for-model-studio
        self.input_price_per_1k_tokens = 0.0003   # 输入token价格
        self.output_price_per_1k_tokens = 0.0006  # 输出token价格
```

**定价说明：**

- **输入Token价格**：0.0003元/千Token
- **输出Token价格**：0.0006元/千Token
- **计费方式**：按实际消耗的Token数量计费
- **最小计费单位**：1 Token

#### 1.2 Token数量估算算法

```python
def count_tokens_approximate(self, text: str) -> int:
    """
    近似计算文本的token数量（基于字符数估算）
    """
    # 对于中文文本，大约1个字符 = 1个token
    # 对于英文文本，大约4个字符 = 1个token
    chinese_chars = sum(1 for char in text if '\u4e00' <= char <= '\u9fff')
    other_chars = len(text) - chinese_chars
  
    # 估算token数量
    estimated_tokens = chinese_chars + (other_chars // 4)
    return max(estimated_tokens, 1)  # 至少返回1个token
```

**估算原理：**

- **中文字符**：1字符 ≈ 1 Token
- **英文字符**：4字符 ≈ 1 Token
- **混合文本**：分别计算后求和
- **最小保证**：至少返回1个Token

#### 1.3 成本计算公式

```python
def calculate_cost(self, input_tokens: int, output_tokens: int) -> float:
    """
    计算通义千问API调用成本
    """
    input_cost = (input_tokens / 1000) * self.input_price_per_1k_tokens
    output_cost = (output_tokens / 1000) * self.output_price_per_1k_tokens
    total_cost = input_cost + output_cost
    return total_cost
```

**成本构成：**

- **输入成本** = 输入Token数 × 输入单价
- **输出成本** = 输出Token数 × 输出单价
- **总成本** = 输入成本 + 输出成本

### 2. 成本计算集成

#### 2.1 问答过程中的成本计算

```python
def answer_question(self, question: str, k: int = 10) -> Dict[str, Any]:
    # 计算输入token数量
    input_text = question
    for doc in docs:
        input_text += "\n" + doc.page_content
  
    input_tokens = self.cost_calculator.count_tokens_approximate(input_text)
  
    # 执行问答链
    start_time = time.time()
    response = self.qa_chain.invoke(input=input_data)
    end_time = time.time()
  
    # 计算输出token数量
    answer = response["output_text"]
    output_tokens = self.cost_calculator.count_tokens_approximate(answer)
  
    # 计算总成本
    total_cost = self.cost_calculator.calculate_cost(input_tokens, output_tokens)
```

#### 2.2 成本信息返回

```python
return {
    'question': question,
    'answer': answer,
    'sources': sources,
    'processing_time': end_time - start_time,
    'cost': total_cost,
    'input_tokens': input_tokens,
    'output_tokens': output_tokens,
    'retrieved_documents': len(docs)
}
```

## Web应用架构

### 1. 后端服务 (V303_app_with_cost.py)

#### 1.1 Flask应用结构

```python
app = Flask(__name__)
CORS(app)  # 启用跨域支持

# 初始化组件
vector_manager = VectorStoreManager(DASHSCOPE_API_KEY)
vector_store = vector_manager.load_vector_store(vector_db_path)
qa_system = QuestionAnsweringSystem(vector_store, DASHSCOPE_API_KEY)
```

#### 1.2 API端点设计

**预设问题接口：**

```python
@app.route('/api/preset-questions', methods=['GET'])
def get_preset_questions():
    return jsonify({'questions': preset_questions})
```

**问答接口：**

```python
@app.route('/api/ask', methods=['POST'])
def ask_question():
    data = request.get_json()
    question = data.get('question', '').strip()
    result = qa_system.answer_question(question)
    return jsonify(result)
```

**健康检查接口：**

```python
@app.route('/health', methods=['GET'])
def health_check():
    return jsonify({
        'status': 'healthy',
        'message': '问答系统后端服务运行正常（V303版本，支持成本计算）'
    })
```

### 2. 前端界面 (index.html)

#### 2.1 响应式布局设计

```css
.container {
    display: flex;
    flex: 1;
    padding: 1rem;
    gap: 1rem;
    max-width: 1200px;
    margin: 0 auto;
    width: 100%;
}

.panel {
    background: white;
    border-radius: 8px;
    box-shadow: 0 2px 8px rgba(0,0,0,0.1);
    padding: 1.5rem;
    height: calc(100vh - 120px);
    display: flex;
    flex-direction: column;
}
```

#### 2.2 成本信息展示

```javascript
function displayAnswer(data) {
    let html = `
        <div class="question-display">
            <strong>问题:</strong> ${data.question}
        </div>
        <div class="answer-display">
            <strong>答案:</strong> ${data.answer}
        </div>
        <div class="cost-info-row">
            <div class="cost-info-item"><strong>查询时间:</strong> ${data.processing_time ? data.processing_time.toFixed(2) + ' 秒' : 'N/A'}</div>
            <div class="cost-info-item"><strong>输入Token数:</strong> ${data.input_tokens ? data.input_tokens : 'N/A'}</div>
            <div class="cost-info-item"><strong>输出Token数:</strong> ${data.output_tokens ? data.output_tokens : 'N/A'}</div>
            <div class="cost-info-item"><strong>LLM成本:</strong> ${data.cost ? data.cost.toFixed(6) + ' 元' : 'N/A'}</div>
        </div>
        <div class="sources-title">相关信息来源:</div>
    `;
}
```

#### 2.3 预设问题滚动设计

```css
.preset-list {
    max-height: 320px;
    overflow-y: auto;
    padding-right: 4px;
}
```

## 性能优化策略

### 1. 向量检索优化

- **FAISS索引**：使用高效的向量索引算法
- **批量处理**：支持批量文档处理
- **缓存机制**：向量数据库本地存储

### 2. 成本控制策略

- **Token估算**：使用高效的Token估算算法
- **实时监控**：实时显示成本信息
- **批量调用**：支持Batch调用降低成本

### 3. 用户体验优化

- **异步处理**：非阻塞的问答处理
- **进度提示**：实时显示处理状态
- **错误处理**：完善的异常处理机制

## 部署说明

### 1. 环境要求

- Python 3.8+
- DashScope API Key
- MinerU API Key（可选）

### 2. 安装步骤

```bash
# 1. 克隆项目
git clone <repository-url>
cd CASE-ChatPDF-Faiss-250726

# 2. 安装依赖
pip install -r requirements.txt

# 3. 配置环境变量
cp .env.example .env
# 编辑.env文件，填入API密钥

# 4. 处理文档
python main.py

# 5. 启动Web服务
cd web_app
python V303_app_with_cost.py
```

### 3. 配置说明

**环境变量配置：**

```bash
DASHSCOPE_API_KEY=你的DashScope_API密钥
MINERU_API_KEY=你的MinerU_API密钥（可选）
```

## 技术亮点总结

### 1. RAG技术创新

- **精确来源追踪**：通过内容匹配确保文档引用的准确性
- **智能分块策略**：基于语义的分块算法，保持上下文完整性
- **高效向量检索**：使用FAISS实现毫秒级的相似度检索

### 2. 成本计算创新

- **实时成本监控**：准确计算和显示每次查询的成本
- **Token估算算法**：支持中英文混合文本的Token数量估算
- **定价模型更新**：基于官方定价的实时成本计算

### 3. 用户体验优化

- **响应式设计**：支持多设备访问
- **实时反馈**：显示处理进度和成本信息
- **智能预设**：提供常用问题快速访问

### 4. 系统架构优势

- **模块化设计**：各组件独立，便于维护和扩展
- **版本管理**：清晰的版本号命名规范
- **错误处理**：完善的异常处理和日志记录

## 未来扩展方向

### 1. 功能扩展

- **多文档支持**：支持同时处理多个文档
- **对话历史**：支持多轮对话
- **文档上传**：支持在线文档上传

### 2. 技术优化

- **更精确的Token计算**：集成官方Tokenizer
- **缓存优化**：实现智能缓存机制
- **性能监控**：添加详细的性能指标

### 3. 用户体验

- **个性化设置**：支持用户偏好配置
- **导出功能**：支持问答结果导出
- **移动端优化**：进一步优化移动端体验

---

**项目版本**：V303
**最后更新**：2025年7月26日
**技术支持**：基于LangChain + FAISS + 通义千问
