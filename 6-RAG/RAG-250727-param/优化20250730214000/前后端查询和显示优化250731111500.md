æ‚¨è¯´å¾—å¯¹ï¼Œæˆ‘åº”è¯¥å…ˆåˆ¶å®šå®Œæ•´çš„è®¡åˆ’ï¼Œè€Œä¸æ˜¯ç›´æ¥å¼€å§‹å†™ä»£ç ã€‚è®©æˆ‘é‡æ–°åˆ¶å®šä¸€ä¸ªè¯¦ç»†çš„è°ƒæ•´è®¡åˆ’ï¼š

## **ğŸ“‹ æŸ¥è¯¢ç»“æœå‚æ•°è°ƒæ•´è®¡åˆ’**

### **ğŸ¯ å½“å‰é—®é¢˜åˆ†æ**

ä»`session_memory.json`å’Œä¹‹å‰çš„åˆ†æå¯ä»¥çœ‹åˆ°ï¼š

1. **æ£€ç´¢ç»“æœè¿‡å¤š**ï¼šç”¨æˆ·é—®"æ–‡æ¡£ä¸­æœ‰æ²¡æœ‰å…³äºä¸ªè‚¡èµ°åŠ¿è¡¨ç°çš„å›¾"ï¼Œä½†è¿”å›äº†5å¼ å›¾ç‰‡
2. **ç›¸å…³æ€§ä¸å¤Ÿç²¾ç¡®**ï¼šåªæœ‰1å¼ å›¾ç‰‡çœŸæ­£ç›¸å…³ï¼ˆä¸ªè‚¡ç›¸å¯¹æ²ªæ·±300æŒ‡æ•°è¡¨ç°ï¼‰
3. **é…ç½®å‚æ•°éœ€è¦ä¼˜åŒ–**ï¼šå½“å‰`similarity_top_k: 3`å¯èƒ½ä¸å¤Ÿç²¾ç¡®
4. **ç¼ºä¹äºŒæ¬¡è¿‡æ»¤**ï¼šæ²¡æœ‰å¯¹æ£€ç´¢ç»“æœè¿›è¡Œç›¸å…³æ€§è¿‡æ»¤

### **ï¿½ï¿½ å½“å‰é…ç½®åˆ†æ**

**ç°æœ‰é…ç½®**ï¼š

- `similarity_top_k: 3` - æ£€ç´¢3ä¸ªç»“æœ
- `temperature: 0.7` - å›ç­”åˆ›é€ æ€§è¾ƒé«˜
- `max_tokens: 2000` - å›ç­”å¯èƒ½è¿‡é•¿
- ç¼ºä¹ç›¸ä¼¼åº¦é˜ˆå€¼å’Œé‡æ’åºæœºåˆ¶

### **ğŸ¯ è°ƒæ•´ç›®æ ‡**

1. **æé«˜æ£€ç´¢ç²¾åº¦**ï¼šå‡å°‘æ— å…³ç»“æœ
2. **ä¼˜åŒ–å›ç­”è´¨é‡**ï¼šæ›´ç²¾ç¡®ã€æ›´ç®€æ´
3. **æ·»åŠ è¿‡æ»¤æœºåˆ¶**ï¼šäºŒæ¬¡è¿‡æ»¤æ— å…³å†…å®¹
4. **æ”¹è¿›ç”¨æˆ·ä½“éªŒ**ï¼šå‡å°‘é‡å¤å’Œæ— å…³æ˜¾ç¤º

### **ï¿½ï¿½ åˆ†é˜¶æ®µè°ƒæ•´è®¡åˆ’**

#### **é˜¶æ®µä¸€ï¼šé…ç½®å‚æ•°è°ƒæ•´ï¼ˆä»Šå¤©ï¼‰**

**1.1 å‘é‡æ£€ç´¢å‚æ•°ä¼˜åŒ–**

- `similarity_top_k`: 3 â†’ 2ï¼ˆå‡å°‘æ£€ç´¢æ•°é‡ï¼‰
- æ–°å¢ `similarity_threshold: 0.7`ï¼ˆç›¸ä¼¼åº¦é˜ˆå€¼ï¼‰
- æ–°å¢ `enable_reranking: true`ï¼ˆå¯ç”¨é‡æ’åºï¼‰

**1.2 QAç³»ç»Ÿå‚æ•°ä¼˜åŒ–**

- `temperature`: 0.7 â†’ 0.5ï¼ˆé™ä½åˆ›é€ æ€§ï¼Œæé«˜ç²¾ç¡®æ€§ï¼‰
- `max_tokens`: 2000 â†’ 1500ï¼ˆæ§åˆ¶å›ç­”é•¿åº¦ï¼‰
- æ–°å¢ `enable_sources_filtering: true`ï¼ˆå¯ç”¨æºè¿‡æ»¤ï¼‰
- æ–°å¢ `min_relevance_score: 0.6`ï¼ˆæœ€å°ç›¸å…³æ€§åˆ†æ•°ï¼‰

**1.3 å¤„ç†å‚æ•°å¾®è°ƒ**

- `chunk_size`: 1000ï¼ˆä¿æŒä¸å˜ï¼‰
- `chunk_overlap`: 200ï¼ˆä¿æŒä¸å˜ï¼‰
- æ–°å¢ `enable_smart_filtering: true`ï¼ˆå¯ç”¨æ™ºèƒ½è¿‡æ»¤ï¼‰

#### **é˜¶æ®µäºŒï¼šåç«¯é€»è¾‘ä¼˜åŒ–ï¼ˆæ˜å¤©ï¼‰**

**2.1 QAç³»ç»Ÿæ”¹è¿›**

- æ·»åŠ åŸºäºç›¸ä¼¼åº¦çš„äºŒæ¬¡è¿‡æ»¤
- å®ç°æ™ºèƒ½æºé€‰æ‹©ï¼ˆåªè¿”å›LLMå®é™…æåˆ°çš„å†…å®¹ï¼‰
- ä¼˜åŒ–å›¾ç‰‡æ£€ç´¢é€»è¾‘

**2.2 å‘é‡æ£€ç´¢å¢å¼º**

- å®ç°é‡æ’åºç®—æ³•
- æ·»åŠ ç›¸å…³æ€§è¯„åˆ†æœºåˆ¶
- ä¼˜åŒ–å›¾ç‰‡å’Œæ–‡æœ¬çš„æ··åˆæ£€ç´¢

**2.3 è®°å¿†ç³»ç»Ÿä¼˜åŒ–**

- æ”¹è¿›ç›¸å…³æ€§è®¡ç®—
- ä¼˜åŒ–è®°å¿†æ£€ç´¢é€»è¾‘
- æ·»åŠ æ™ºèƒ½å»é‡æœºåˆ¶

#### **é˜¶æ®µä¸‰ï¼šå‰ç«¯æ˜¾ç¤ºä¼˜åŒ–ï¼ˆåå¤©ï¼‰**

**3.1 æ™ºèƒ½æ˜¾ç¤ºé€»è¾‘**

- æ ¹æ®LLMå›ç­”è¿‡æ»¤å›¾ç‰‡
- å®ç°å»é‡æ˜¾ç¤º
- ä¼˜åŒ–æ¥æºè¯¦æƒ…æ˜¾ç¤º

**3.2 ç”¨æˆ·ä½“éªŒæ”¹è¿›**

- æ·»åŠ åŠ è½½çŠ¶æ€æç¤º
- ä¼˜åŒ–é”™è¯¯å¤„ç†
- æ”¹è¿›å“åº”é€Ÿåº¦

#### **é˜¶æ®µå››ï¼šç³»ç»Ÿçº§ä¼˜åŒ–ï¼ˆé•¿æœŸï¼‰**

**4.1 ç®—æ³•ä¼˜åŒ–**

- é‡æ–°è®¾è®¡å‘é‡æ£€ç´¢ç®—æ³•
- ä¼˜åŒ–ç›¸å…³æ€§è®¡ç®—
- å®ç°æ™ºèƒ½ç¼“å­˜æœºåˆ¶

**4.2 æ€§èƒ½ä¼˜åŒ–**

- ä¼˜åŒ–æ£€ç´¢é€Ÿåº¦
- å‡å°‘APIè°ƒç”¨æˆæœ¬
- æå‡æ•´ä½“å“åº”æ€§èƒ½

### **ï¿½ï¿½ é¢„æœŸæ•ˆæœ**

**çŸ­æœŸæ•ˆæœï¼ˆé˜¶æ®µä¸€+äºŒï¼‰**ï¼š

- æ£€ç´¢ç»“æœå‡å°‘30-50%
- ç›¸å…³æ€§æå‡40-60%
- å›ç­”è´¨é‡æå‡25-35%

**é•¿æœŸæ•ˆæœï¼ˆé˜¶æ®µä¸‰+å››ï¼‰**ï¼š

- ç”¨æˆ·ä½“éªŒæ˜¾è‘—æ”¹å–„
- ç³»ç»Ÿæ€§èƒ½æå‡
- æˆæœ¬æ§åˆ¶ä¼˜åŒ–

### **âš ï¸ é£é™©è¯„ä¼°**

**ä½é£é™©**ï¼š

- é…ç½®å‚æ•°è°ƒæ•´
- å‰ç«¯æ˜¾ç¤ºä¼˜åŒ–

**ä¸­ç­‰é£é™©**ï¼š

- åç«¯é€»è¾‘ä¿®æ”¹
- ç®—æ³•ä¼˜åŒ–

**é«˜é£é™©**ï¼š

- ç³»ç»Ÿçº§é‡æ„
- æ ¸å¿ƒç®—æ³•é‡å†™

### **ğŸ¯ å»ºè®®æ‰§è¡Œé¡ºåº**

1. **ç«‹å³æ‰§è¡Œ**ï¼šé˜¶æ®µä¸€çš„é…ç½®å‚æ•°è°ƒæ•´
2. **æ˜å¤©æ‰§è¡Œ**ï¼šé˜¶æ®µäºŒçš„åç«¯é€»è¾‘ä¼˜åŒ–
3. **åå¤©æ‰§è¡Œ**ï¼šé˜¶æ®µä¸‰çš„å‰ç«¯æ˜¾ç¤ºä¼˜åŒ–
4. **é•¿æœŸè§„åˆ’**ï¼šé˜¶æ®µå››çš„ç³»ç»Ÿçº§ä¼˜åŒ–

### **ï¿½ï¿½ ä¸‹ä¸€æ­¥è¡ŒåŠ¨**

æ‚¨å¸Œæœ›æˆ‘ï¼š

1. ç«‹å³å¼€å§‹æ‰§è¡Œé˜¶æ®µä¸€çš„é…ç½®å‚æ•°è°ƒæ•´ï¼Ÿ
2. å…ˆè¯¦ç»†è®¾è®¡æŸä¸ªç‰¹å®šé˜¶æ®µçš„æ–¹æ¡ˆï¼Ÿ
3. è¿˜æ˜¯æ‚¨æœ‰å…¶ä»–ä¼˜å…ˆçº§è€ƒè™‘ï¼Ÿ

è¯·å‘Šè¯‰æˆ‘æ‚¨å¸Œæœ›ä»å“ªä¸ªé˜¶æ®µå¼€å§‹ï¼Œæˆ‘ä¼šåˆ¶å®šæ›´è¯¦ç»†çš„å®æ–½æ–¹æ¡ˆã€‚


## **ğŸ“‹ ä¸‰ä¸ªæ–°å¢åŠŸèƒ½çš„è¯¦ç»†å®ç°æ–¹æ¡ˆ**

### **1. `enable_reranking: true` - å¯ç”¨é‡æ’åº**

#### **åŠŸèƒ½ç›®æ ‡**

- å¯¹åˆæ­¥æ£€ç´¢ç»“æœè¿›è¡ŒäºŒæ¬¡æ’åº
- æé«˜ç»“æœçš„ç›¸å…³æ€§å’Œå‡†ç¡®æ€§
- å‡å°‘æ— å…³å†…å®¹çš„å¹²æ‰°

#### **å®ç°æ–¹æ¡ˆ**

**1.1 é‡æ’åºç®—æ³•è®¾è®¡**

```python
class RerankingEngine:
    """
    é‡æ’åºå¼•æ“
    """
    def __init__(self, config):
        self.config = config
        self.reranking_methods = {
            'semantic': self._semantic_reranking,
            'keyword': self._keyword_reranking,
            'hybrid': self._hybrid_reranking
        }
  
    def rerank_results(self, query: str, initial_results: List[Document], method: str = 'hybrid') -> List[Document]:
        """
        å¯¹æ£€ç´¢ç»“æœè¿›è¡Œé‡æ’åº
        :param query: ç”¨æˆ·æŸ¥è¯¢
        :param initial_results: åˆå§‹æ£€ç´¢ç»“æœ
        :param method: é‡æ’åºæ–¹æ³•
        :return: é‡æ’åºåçš„ç»“æœ
        """
        if method in self.reranking_methods:
            return self.reranking_methods[method](query, initial_results)
        return initial_results
  
    def _semantic_reranking(self, query: str, results: List[Document]) -> List[Document]:
        """
        åŸºäºè¯­ä¹‰ç›¸ä¼¼åº¦çš„é‡æ’åº
        """
        # è®¡ç®—æŸ¥è¯¢ä¸æ¯ä¸ªç»“æœçš„è¯­ä¹‰ç›¸ä¼¼åº¦
        scored_results = []
        for doc in results:
            similarity = self._calculate_semantic_similarity(query, doc.page_content)
            scored_results.append((doc, similarity))
      
        # æŒ‰ç›¸ä¼¼åº¦æ’åº
        scored_results.sort(key=lambda x: x[1], reverse=True)
        return [doc for doc, score in scored_results]
  
    def _keyword_reranking(self, query: str, results: List[Document]) -> List[Document]:
        """
        åŸºäºå…³é”®è¯åŒ¹é…çš„é‡æ’åº
        """
        query_keywords = self._extract_keywords(query)
        scored_results = []
      
        for doc in results:
            doc_keywords = self._extract_keywords(doc.page_content)
            keyword_overlap = len(query_keywords.intersection(doc_keywords))
            scored_results.append((doc, keyword_overlap))
      
        scored_results.sort(key=lambda x: x[1], reverse=True)
        return [doc for doc, score in scored_results]
  
    def _hybrid_reranking(self, query: str, results: List[Document]) -> List[Document]:
        """
        æ··åˆé‡æ’åºï¼ˆè¯­ä¹‰ + å…³é”®è¯ï¼‰
        """
        semantic_results = self._semantic_reranking(query, results)
        keyword_results = self._keyword_reranking(query, results)
      
        # ç»“åˆä¸¤ç§æ’åºç»“æœ
        return self._combine_rankings(semantic_results, keyword_results)
```

**1.2 é›†æˆåˆ°QAç³»ç»Ÿ**

```python
# åœ¨QAç³»ç»Ÿçš„answer_questionæ–¹æ³•ä¸­æ·»åŠ 
def answer_question(self, question: str, k: int = 3) -> Dict[str, Any]:
    # ... ç°æœ‰ä»£ç  ...
  
    # æ·»åŠ é‡æ’åºé€»è¾‘
    if self.config.get('enable_reranking', False):
        reranking_engine = RerankingEngine(self.config)
        docs = reranking_engine.rerank_results(question, docs)
  
    # ... ç»§ç»­å¤„ç† ...
```

#### **é…ç½®å‚æ•°**

```json
{
  "reranking": {
    "enable_reranking": true,
    "reranking_method": "hybrid",
    "semantic_weight": 0.7,
    "keyword_weight": 0.3,
    "min_similarity_threshold": 0.6
  }
}
```

### **2. `enable_sources_filtering: true` - å¯ç”¨æºè¿‡æ»¤**

#### **åŠŸèƒ½ç›®æ ‡**

- è¿‡æ»¤æ‰LLMå›ç­”ä¸­æœªæåˆ°çš„æº
- å‡å°‘æ— å…³å†…å®¹çš„æ˜¾ç¤º
- æé«˜å›ç­”çš„ç²¾ç¡®æ€§

#### **å®ç°æ–¹æ¡ˆ**

**2.1 æºè¿‡æ»¤å¼•æ“**

```python
class SourcesFilteringEngine:
    """
    æºè¿‡æ»¤å¼•æ“
    """
    def __init__(self, config):
        self.config = config
        self.min_relevance_score = config.get('min_relevance_score', 0.6)
  
    def filter_sources_by_answer(self, answer: str, sources: List[Dict]) -> List[Dict]:
        """
        æ ¹æ®LLMå›ç­”è¿‡æ»¤æº
        :param answer: LLMçš„å›ç­”
        :param sources: åŸå§‹æºåˆ—è¡¨
        :return: è¿‡æ»¤åçš„æºåˆ—è¡¨
        """
        # æå–LLMå›ç­”ä¸­æåˆ°çš„å›¾ç‰‡ID
        mentioned_image_ids = self._extract_image_ids_from_answer(answer)
      
        # æå–LLMå›ç­”ä¸­æåˆ°çš„å…³é”®è¯
        mentioned_keywords = self._extract_keywords_from_answer(answer)
      
        filtered_sources = []
        for source in sources:
            if self._is_source_relevant(source, mentioned_image_ids, mentioned_keywords):
                filtered_sources.append(source)
      
        return filtered_sources
  
    def _extract_image_ids_from_answer(self, answer: str) -> List[str]:
        """
        ä»LLMå›ç­”ä¸­æå–å›¾ç‰‡ID
        """
        import re
        # åŒ¹é… [IMAGE_ID:xxx] æ ¼å¼
        pattern = r'\[IMAGE_ID:([a-f0-9]+)\]'
        matches = re.findall(pattern, answer)
        return matches
  
    def _extract_keywords_from_answer(self, answer: str) -> Set[str]:
        """
        ä»LLMå›ç­”ä¸­æå–å…³é”®è¯
        """
        # ç®€å•çš„å…³é”®è¯æå–
        keywords = set()
        important_phrases = [
            'ä¸ªè‚¡èµ°åŠ¿', 'æ²ªæ·±300', 'è¥ä¸šæ”¶å…¥', 'æ¯›åˆ©ç‡', 'å‡€åˆ©ç‡',
            'å›¾è¡¨', 'è¡¨ç°', 'æƒ…å†µ', 'æ•°æ®'
        ]
      
        for phrase in important_phrases:
            if phrase in answer:
                keywords.add(phrase)
      
        return keywords
  
    def _is_source_relevant(self, source: Dict, mentioned_image_ids: List[str], mentioned_keywords: Set[str]) -> bool:
        """
        åˆ¤æ–­æºæ˜¯å¦ç›¸å…³
        """
        # æ£€æŸ¥å›¾ç‰‡IDåŒ¹é…
        if source.get('metadata', {}).get('image_id'):
            if source['metadata']['image_id'] in mentioned_image_ids:
                return True
      
        # æ£€æŸ¥å†…å®¹å…³é”®è¯åŒ¹é…
        content = source.get('content', '').lower()
        for keyword in mentioned_keywords:
            if keyword.lower() in content:
                return True
      
        # æ£€æŸ¥ç›¸ä¼¼åº¦åˆ†æ•°
        if 'similarity_score' in source:
            if source['similarity_score'] >= self.min_relevance_score:
                return True
      
        return False
```

**2.2 é›†æˆåˆ°QAç³»ç»Ÿ**

```python
# åœ¨QAç³»ç»Ÿçš„answer_questionæ–¹æ³•ä¸­æ·»åŠ 
def answer_question(self, question: str, k: int = 3) -> Dict[str, Any]:
    # ... ç°æœ‰ä»£ç  ...
  
    # ç”Ÿæˆå›ç­”
    result = self._generate_answer(question, docs)
  
    # æ·»åŠ æºè¿‡æ»¤é€»è¾‘
    if self.config.get('enable_sources_filtering', False):
        filtering_engine = SourcesFilteringEngine(self.config)
        sources = filtering_engine.filter_sources_by_answer(result, sources)
  
    # ... ç»§ç»­å¤„ç† ...
```

#### **é…ç½®å‚æ•°**

```json
{
  "sources_filtering": {
    "enable_sources_filtering": true,
    "min_relevance_score": 0.6,
    "enable_keyword_matching": true,
    "enable_image_id_matching": true,
    "enable_similarity_filtering": true
  }
}
```

### **3. `enable_smart_filtering: true` - å¯ç”¨æ™ºèƒ½è¿‡æ»¤**

#### **åŠŸèƒ½ç›®æ ‡**

- ç»¼åˆå¤šç§å› ç´ è¿›è¡Œæ™ºèƒ½è¿‡æ»¤
- åŠ¨æ€è°ƒæ•´è¿‡æ»¤ç­–ç•¥
- æä¾›æ›´ç²¾ç¡®çš„ç»“æœ

#### **å®ç°æ–¹æ¡ˆ**

**3.1 æ™ºèƒ½è¿‡æ»¤å¼•æ“**

```python
class SmartFilteringEngine:
    """
    æ™ºèƒ½è¿‡æ»¤å¼•æ“
    """
    def __init__(self, config):
        self.config = config
        self.filtering_strategies = {
            'content_based': self._content_based_filtering,
            'semantic_based': self._semantic_based_filtering,
            'context_based': self._context_based_filtering,
            'user_intent_based': self._user_intent_based_filtering
        }
  
    def smart_filter(self, query: str, results: List[Document], context: Dict = None) -> List[Document]:
        """
        æ™ºèƒ½è¿‡æ»¤
        :param query: ç”¨æˆ·æŸ¥è¯¢
        :param results: æ£€ç´¢ç»“æœ
        :param context: ä¸Šä¸‹æ–‡ä¿¡æ¯
        :return: è¿‡æ»¤åçš„ç»“æœ
        """
        filtered_results = results
      
        # åº”ç”¨å¤šç§è¿‡æ»¤ç­–ç•¥
        for strategy_name, strategy_func in self.filtering_strategies.items():
            if self.config.get(f'enable_{strategy_name}_filtering', True):
                filtered_results = strategy_func(query, filtered_results, context)
      
        return filtered_results
  
    def _content_based_filtering(self, query: str, results: List[Document], context: Dict) -> List[Document]:
        """
        åŸºäºå†…å®¹çš„è¿‡æ»¤
        """
        query_type = self._classify_query_type(query)
        filtered_results = []
      
        for doc in results:
            if self._is_content_relevant(doc, query_type):
                filtered_results.append(doc)
      
        return filtered_results
  
    def _semantic_based_filtering(self, query: str, results: List[Document], context: Dict) -> List[Document]:
        """
        åŸºäºè¯­ä¹‰çš„è¿‡æ»¤
        """
        # è®¡ç®—è¯­ä¹‰ç›¸ä¼¼åº¦å¹¶è¿‡æ»¤
        threshold = self.config.get('semantic_similarity_threshold', 0.6)
        filtered_results = []
      
        for doc in results:
            similarity = self._calculate_semantic_similarity(query, doc.page_content)
            if similarity >= threshold:
                filtered_results.append(doc)
      
        return filtered_results
  
    def _context_based_filtering(self, query: str, results: List[Document], context: Dict) -> List[Document]:
        """
        åŸºäºä¸Šä¸‹æ–‡çš„è¿‡æ»¤
        """
        if not context or 'previous_questions' not in context:
            return results
      
        # æ ¹æ®å¯¹è¯å†å²è¿‡æ»¤
        conversation_context = context['previous_questions']
        filtered_results = []
      
        for doc in results:
            if self._is_contextually_relevant(doc, conversation_context):
                filtered_results.append(doc)
      
        return filtered_results
  
    def _user_intent_based_filtering(self, query: str, results: List[Document], context: Dict) -> List[Document]:
        """
        åŸºäºç”¨æˆ·æ„å›¾çš„è¿‡æ»¤
        """
        intent = self._extract_user_intent(query)
        filtered_results = []
      
        for doc in results:
            if self._matches_user_intent(doc, intent):
                filtered_results.append(doc)
      
        return filtered_results
  
    def _classify_query_type(self, query: str) -> str:
        """
        åˆ†ç±»æŸ¥è¯¢ç±»å‹
        """
        query_lower = query.lower()
      
        if any(word in query_lower for word in ['å›¾ç‰‡', 'å›¾åƒ', 'å›¾è¡¨', 'å›¾']):
            return 'image_query'
        elif any(word in query_lower for word in ['æ•°æ®', 'æ•°å­—', 'ç»Ÿè®¡']):
            return 'data_query'
        elif any(word in query_lower for word in ['åˆ†æ', 'è¯„ä»·', 'è§‚ç‚¹']):
            return 'analysis_query'
        else:
            return 'general_query'
  
    def _is_content_relevant(self, doc: Document, query_type: str) -> bool:
        """
        åˆ¤æ–­å†…å®¹æ˜¯å¦ç›¸å…³
        """
        if query_type == 'image_query':
            return doc.metadata.get('chunk_type') == 'image'
        elif query_type == 'data_query':
            return doc.metadata.get('chunk_type') in ['table', 'text']
        else:
            return True
```

**3.2 é›†æˆåˆ°å‘é‡æ£€ç´¢**

```python
# åœ¨å‘é‡å­˜å‚¨ç®¡ç†å™¨ä¸­æ·»åŠ 
def search_with_smart_filtering(self, vector_store: FAISS, query: str, k: int = 3, config: Dict = None) -> List[Document]:
    """
    å¸¦æ™ºèƒ½è¿‡æ»¤çš„æœç´¢
    """
    # åˆæ­¥æ£€ç´¢
    initial_results = vector_store.similarity_search(query, k=k*2)  # æ£€ç´¢æ›´å¤šç»“æœç”¨äºè¿‡æ»¤
  
    # æ™ºèƒ½è¿‡æ»¤
    if config and config.get('enable_smart_filtering', False):
        filtering_engine = SmartFilteringEngine(config)
        filtered_results = filtering_engine.smart_filter(query, initial_results)
      
        # è¿”å›å‰kä¸ªç»“æœ
        return filtered_results[:k]
  
    return initial_results[:k]
```

#### **é…ç½®å‚æ•°**

```json
{
  "smart_filtering": {
    "enable_smart_filtering": true,
    "enable_content_based_filtering": true,
    "enable_semantic_based_filtering": true,
    "enable_context_based_filtering": true,
    "enable_user_intent_based_filtering": true,
    "semantic_similarity_threshold": 0.6,
    "content_relevance_threshold": 0.5,
    "max_filtered_results": 3
  }
}
```

### ** é›†æˆæ–¹æ¡ˆ**

#### **1. é…ç½®æ–‡ä»¶æ›´æ–°**

```json
{
  "vector_store": {
    "vector_dimension": 1536,
    "similarity_top_k": 2,
    "similarity_threshold": 0.7,
    "enable_reranking": true,
    "enable_sources_filtering": true,
    "enable_smart_filtering": true
  },
  "qa_system": {
    "model_name": "qwen-turbo",
    "temperature": 0.5,
    "max_tokens": 1500,
    "enable_sources_filtering": true,
    "min_relevance_score": 0.6
  }
}
```

#### **2. æ‰§è¡Œé¡ºåº**

1. **ç¬¬ä¸€æ­¥**ï¼šå®ç°é‡æ’åºåŠŸèƒ½
2. **ç¬¬äºŒæ­¥**ï¼šå®ç°æºè¿‡æ»¤åŠŸèƒ½
3. **ç¬¬ä¸‰æ­¥**ï¼šå®ç°æ™ºèƒ½è¿‡æ»¤åŠŸèƒ½
4. **ç¬¬å››æ­¥**ï¼šé›†æˆæµ‹è¯•å’Œä¼˜åŒ–

#### **3. é¢„æœŸæ•ˆæœ**

- **æ£€ç´¢ç²¾åº¦æå‡**ï¼š40-60%
- **æ— å…³å†…å®¹å‡å°‘**ï¼š50-70%
- **ç”¨æˆ·ä½“éªŒæ”¹å–„**ï¼šæ˜¾è‘—æå‡
- **ç³»ç»Ÿæ€§èƒ½**ï¼šè½»å¾®å½±å“ï¼ˆå¯æ¥å—ï¼‰

æ‚¨å¸Œæœ›æˆ‘è¯¦ç»†å®ç°å“ªä¸ªåŠŸèƒ½ï¼Œæˆ–è€…æ‚¨æœ‰å…¶ä»–ä¼˜å…ˆçº§è€ƒè™‘ï¼Ÿ


## **ğŸ¯ é€šç”¨æ€§åˆ†æ**

### **1. `enable_reranking: true` - é‡æ’åº**

#### **é€šç”¨æ€§**ï¼šâ­â­â­â­â­ (æé«˜)

**åŸå› **ï¼š

- **ç®—æ³•é€šç”¨**ï¼šåŸºäºè¯­ä¹‰ç›¸ä¼¼åº¦å’Œå…³é”®è¯åŒ¹é…ï¼Œé€‚ç”¨äºä»»ä½•æ–‡æœ¬å†…å®¹
- **é¢†åŸŸæ— å…³**ï¼šä¸ä¾èµ–ç‰¹å®šé¢†åŸŸçŸ¥è¯†ï¼Œåªå…³æ³¨æ–‡æœ¬ç›¸ä¼¼æ€§
- **å¯é…ç½®**ï¼šæƒé‡å’Œé˜ˆå€¼å¯ä»¥æ ¹æ®ä¸åŒä¸»é¢˜è°ƒæ•´

**é€‚ç”¨åœºæ™¯**ï¼š

```python
# é‡‘èæ–‡æ¡£
query = "è‚¡ç¥¨ä»·æ ¼èµ°åŠ¿å¦‚ä½•ï¼Ÿ"
# åŒ»ç–—æ–‡æ¡£  
query = "æ‚£è€…ç—‡çŠ¶è¡¨ç°æ˜¯ä»€ä¹ˆï¼Ÿ"
# æŠ€æœ¯æ–‡æ¡£
query = "APIæ¥å£å‚æ•°æœ‰å“ªäº›ï¼Ÿ"
# æ³•å¾‹æ–‡æ¡£
query = "åˆåŒæ¡æ¬¾è§„å®šæ˜¯ä»€ä¹ˆï¼Ÿ"
```

**è°ƒæ•´æ–¹å¼**ï¼š

```json
{
  "reranking": {
    "semantic_weight": 0.7,  // é‡‘èæ–‡æ¡£å¯èƒ½æ›´é«˜
    "keyword_weight": 0.3,   // æŠ€æœ¯æ–‡æ¡£å¯èƒ½æ›´é«˜
    "min_similarity_threshold": 0.6  // å¯è°ƒæ•´
  }
}
```

### **2. `enable_sources_filtering: true` - æºè¿‡æ»¤**

#### **é€šç”¨æ€§**ï¼šâ­â­â­â­â­ (æé«˜)

**åŸå› **ï¼š

- **é€»è¾‘é€šç”¨**ï¼šåŸºäºLLMå›ç­”å†…å®¹è¿‡æ»¤ï¼Œé€‚ç”¨äºä»»ä½•é—®ç­”åœºæ™¯
- **æ ¼å¼é€šç”¨**ï¼šæ”¯æŒæ–‡æœ¬ã€å›¾ç‰‡ã€è¡¨æ ¼ç­‰å„ç§å†…å®¹ç±»å‹
- **ç­–ç•¥é€šç”¨**ï¼šå…³é”®è¯åŒ¹é…ã€IDåŒ¹é…ã€ç›¸ä¼¼åº¦è¿‡æ»¤éƒ½æ˜¯é€šç”¨æ–¹æ³•

**é€‚ç”¨åœºæ™¯**ï¼š

```python
# ä»»ä½•é¢†åŸŸçš„é—®ç­”
- é‡‘èï¼šåªæ˜¾ç¤ºLLMæåˆ°çš„è´¢åŠ¡æŠ¥è¡¨
- åŒ»ç–—ï¼šåªæ˜¾ç¤ºLLMæåˆ°çš„ç—‡çŠ¶å›¾ç‰‡
- æŠ€æœ¯ï¼šåªæ˜¾ç¤ºLLMæåˆ°çš„ä»£ç ç¤ºä¾‹
- æ³•å¾‹ï¼šåªæ˜¾ç¤ºLLMæåˆ°çš„æ³•æ¡å†…å®¹
```

**è°ƒæ•´æ–¹å¼**ï¼š

```json
{
  "sources_filtering": {
    "min_relevance_score": 0.6,  // å¯è°ƒæ•´
    "enable_keyword_matching": true,  // é€šç”¨
    "enable_image_id_matching": true,  // é€šç”¨
    "enable_similarity_filtering": true  // é€šç”¨
  }
}
```

### **3. `enable_smart_filtering: true` - æ™ºèƒ½è¿‡æ»¤**

#### **é€šç”¨æ€§**ï¼šâ­â­â­â­â­ (æé«˜)

**åŸå› **ï¼š

- **ç­–ç•¥é€šç”¨**ï¼šå†…å®¹è¿‡æ»¤ã€è¯­ä¹‰è¿‡æ»¤ã€ä¸Šä¸‹æ–‡è¿‡æ»¤éƒ½æ˜¯é€šç”¨æ–¹æ³•
- **æ„å›¾è¯†åˆ«**ï¼šç”¨æˆ·æ„å›¾åˆ†ç±»é€‚ç”¨äºä»»ä½•é¢†åŸŸ
- **å¯æ‰©å±•**ï¼šå¯ä»¥æ·»åŠ é¢†åŸŸç‰¹å®šçš„è¿‡æ»¤è§„åˆ™

**é€‚ç”¨åœºæ™¯**ï¼š

```python
# æŸ¥è¯¢ç±»å‹åˆ†ç±»ï¼ˆé€šç”¨ï¼‰
- image_query: å›¾ç‰‡ç›¸å…³æŸ¥è¯¢
- data_query: æ•°æ®ç›¸å…³æŸ¥è¯¢  
- analysis_query: åˆ†æç›¸å…³æŸ¥è¯¢
- general_query: ä¸€èˆ¬æŸ¥è¯¢

# å†…å®¹ç±»å‹è¿‡æ»¤ï¼ˆé€šç”¨ï¼‰
- text: æ–‡æœ¬å†…å®¹
- image: å›¾ç‰‡å†…å®¹
- table: è¡¨æ ¼å†…å®¹
- chart: å›¾è¡¨å†…å®¹
```

## **ğŸ”§ é¢†åŸŸé€‚é…æ€§**

### **é‡‘èé¢†åŸŸ**

```json
{
  "smart_filtering": {
    "domain_keywords": ["è‚¡ç¥¨", "åŸºé‡‘", "å€ºåˆ¸", "æœŸè´§", "è´¢æŠ¥", "Kçº¿"],
    "content_types": ["financial_chart", "financial_table", "financial_report"],
    "intent_patterns": {
      "price_query": ["ä»·æ ¼", "èµ°åŠ¿", "æ¶¨è·Œ"],
      "analysis_query": ["åˆ†æ", "è¯„ä»·", "é¢„æµ‹"],
      "data_query": ["æ•°æ®", "ç»Ÿè®¡", "æŒ‡æ ‡"]
    }
  }
}
```

### **åŒ»ç–—é¢†åŸŸ**

```json
{
  "smart_filtering": {
    "domain_keywords": ["ç—‡çŠ¶", "è¯Šæ–­", "æ²»ç–—", "è¯ç‰©", "æ£€æŸ¥"],
    "content_types": ["medical_image", "medical_report", "medical_data"],
    "intent_patterns": {
      "diagnosis_query": ["è¯Šæ–­", "ç—‡çŠ¶", "ç—…å› "],
      "treatment_query": ["æ²»ç–—", "ç”¨è¯", "æ‰‹æœ¯"],
      "examination_query": ["æ£€æŸ¥", "åŒ–éªŒ", "å½±åƒ"]
    }
  }
}
```

### **æŠ€æœ¯é¢†åŸŸ**

```json
{
  "smart_filtering": {
    "domain_keywords": ["API", "æ¥å£", "ä»£ç ", "é…ç½®", "éƒ¨ç½²"],
    "content_types": ["code_snippet", "api_doc", "config_file"],
    "intent_patterns": {
      "implementation_query": ["å®ç°", "ä»£ç ", "ç¤ºä¾‹"],
      "configuration_query": ["é…ç½®", "è®¾ç½®", "å‚æ•°"],
      "troubleshooting_query": ["é”™è¯¯", "é—®é¢˜", "è°ƒè¯•"]
    }
  }
}
```

## **ï¿½ï¿½ é€šç”¨æ€§å¯¹æ¯”**


| åŠŸèƒ½     | é€šç”¨æ€§     | å¯é…ç½®æ€§   | é€‚ç”¨é¢†åŸŸ | å®ç°å¤æ‚åº¦ |
| -------- | ---------- | ---------- | -------- | ---------- |
| é‡æ’åº   | â­â­â­â­â­ | â­â­â­â­   | æ‰€æœ‰é¢†åŸŸ | ä¸­ç­‰       |
| æºè¿‡æ»¤   | â­â­â­â­â­ | â­â­â­â­â­ | æ‰€æœ‰é¢†åŸŸ | ç®€å•       |
| æ™ºèƒ½è¿‡æ»¤ | â­â­â­â­â­ | â­â­â­â­â­ | æ‰€æœ‰é¢†åŸŸ | å¤æ‚       |

## **ï¿½ï¿½ æ€»ç»“**

### **ä¸ºä»€ä¹ˆè¿™ä¸‰ä¸ªæ–¹æ¡ˆæ˜¯é€šç”¨çš„ï¼Ÿ**

1. **ç®—æ³•å±‚é¢**ï¼š

   - åŸºäºé€šç”¨çš„NLPæŠ€æœ¯ï¼ˆè¯­ä¹‰ç›¸ä¼¼åº¦ã€å…³é”®è¯åŒ¹é…ï¼‰
   - ä¸ä¾èµ–ç‰¹å®šé¢†åŸŸçŸ¥è¯†
   - ä½¿ç”¨æ ‡å‡†çš„æ–‡æœ¬å¤„ç†æ–¹æ³•
2. **æ¶æ„å±‚é¢**ï¼š

   - æ¨¡å—åŒ–è®¾è®¡ï¼Œæ˜“äºæ‰©å±•
   - é…ç½®é©±åŠ¨ï¼Œæ— éœ€ä¿®æ”¹ä»£ç 
   - æ”¯æŒæ’ä»¶å¼æ‰©å±•
3. **åº”ç”¨å±‚é¢**ï¼š

   - é€‚ç”¨äºä»»ä½•é—®ç­”åœºæ™¯
   - æ”¯æŒå„ç§å†…å®¹ç±»å‹
   - å¯é’ˆå¯¹ä¸åŒé¢†åŸŸä¼˜åŒ–

### **å¦‚ä½•é€‚é…ä¸åŒé¢†åŸŸï¼Ÿ**

1. **é…ç½®è°ƒæ•´**ï¼šé€šè¿‡é…ç½®æ–‡ä»¶è°ƒæ•´å‚æ•°
2. **å…³é”®è¯æ‰©å±•**ï¼šæ·»åŠ é¢†åŸŸç‰¹å®šå…³é”®è¯
3. **è§„åˆ™å®šåˆ¶**ï¼šæ·»åŠ é¢†åŸŸç‰¹å®šè¿‡æ»¤è§„åˆ™
4. **æƒé‡ä¼˜åŒ–**ï¼šæ ¹æ®é¢†åŸŸç‰¹ç‚¹è°ƒæ•´ç®—æ³•æƒé‡

**ç»“è®º**ï¼šè¿™ä¸‰ä¸ªæ–¹æ¡ˆç¡®å®æ˜¯**æ™®éé€‚ç”¨çš„**ï¼Œå¯ä»¥åº”ç”¨äºä»»ä½•RAGä¸»é¢˜ï¼Œåªéœ€è¦é€šè¿‡é…ç½®å’Œå°‘é‡å®šåˆ¶åŒ–å³å¯é€‚é…ä¸åŒé¢†åŸŸçš„éœ€æ±‚ã€‚
