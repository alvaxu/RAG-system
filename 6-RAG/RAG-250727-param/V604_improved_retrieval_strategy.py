"""
ç¨‹åºè¯´æ˜Žï¼š
## 1. æ”¹è¿›çš„æ£€ç´¢ç­–ç•¥ï¼Œç¡®ä¿æ–‡æ¡£æ¥æºçš„å¹³è¡¡
## 2. ä¸ä»…æŒ‰chunk_typeå¹³è¡¡ï¼Œè¿˜è¦æŒ‰document_nameå¹³è¡¡
## 3. æµ‹è¯•æ–°çš„æ£€ç´¢ç­–ç•¥æ•ˆæžœ
"""

import os
import json
from typing import List, Dict, Any
from langchain_community.vectorstores import FAISS
from langchain_community.embeddings import DashScopeEmbeddings
from langchain.schema import Document

def improved_retrieval_strategy(vector_store: FAISS, question: str, k: int = 10) -> List[Document]:
    """
    æ”¹è¿›çš„æ£€ç´¢ç­–ç•¥
    :param vector_store: å‘é‡å­˜å‚¨
    :param question: æŸ¥è¯¢é—®é¢˜
    :param k: æ£€ç´¢æ•°é‡
    :return: æ£€ç´¢åˆ°çš„æ–‡æ¡£
    """
    print(f"ðŸ” æ”¹è¿›æ£€ç´¢ç­–ç•¥æµ‹è¯•: '{question}'")
    
    # ç¬¬ä¸€æ­¥ï¼šèŽ·å–æ‰€æœ‰æ–‡æ¡£çš„æ–‡æ¡£åç§°
    doc_names = set()
    for doc in vector_store.docstore._dict.values():
        doc_name = doc.metadata.get('document_name', 'æœªçŸ¥æ–‡æ¡£')
        doc_names.add(doc_name)
    
    print(f"ðŸ“š å¯ç”¨æ–‡æ¡£: {list(doc_names)}")
    
    # ç¬¬äºŒæ­¥ï¼šä¸ºæ¯ä¸ªæ–‡æ¡£åˆ†é…æ£€ç´¢é…é¢
    total_docs = len(doc_names)
    base_k_per_doc = max(1, k // total_docs)  # æ¯ä¸ªæ–‡æ¡£è‡³å°‘æ£€ç´¢1ä¸ª
    remaining_k = k - (base_k_per_doc * total_docs)
    
    print(f"ðŸ“Š æ£€ç´¢é…é¢: æ¯ä¸ªæ–‡æ¡£ {base_k_per_doc} ä¸ªï¼Œå‰©ä½™ {remaining_k} ä¸ª")
    
    # ç¬¬ä¸‰æ­¥ï¼šåˆ†åˆ«ä»Žæ¯ä¸ªæ–‡æ¡£æ£€ç´¢
    all_docs = []
    doc_results = {}
    
    for doc_name in doc_names:
        try:
            # ä¸ºæ¯ä¸ªæ–‡æ¡£æ£€ç´¢æŒ‡å®šæ•°é‡çš„æ–‡æ¡£
            docs = vector_store.similarity_search(
                question, 
                k=base_k_per_doc,
                filter={"document_name": doc_name}
            )
            doc_results[doc_name] = len(docs)
            all_docs.extend(docs)
            print(f"  {doc_name}: æ£€ç´¢åˆ° {len(docs)} ä¸ªæ–‡æ¡£")
        except Exception as e:
            print(f"  {doc_name}: æ£€ç´¢å¤±è´¥ - {e}")
            doc_results[doc_name] = 0
    
    # ç¬¬å››æ­¥ï¼šå¦‚æžœè¿˜æœ‰å‰©ä½™é…é¢ï¼ŒæŒ‰ç›¸ä¼¼åº¦è¡¥å……
    if remaining_k > 0 and len(all_docs) < k:
        try:
            # èŽ·å–æ‰€æœ‰æ–‡æ¡£ï¼ŒæŒ‰ç›¸ä¼¼åº¦æŽ’åº
            all_available_docs = vector_store.similarity_search(question, k=k*2)
            
            # è¿‡æ»¤æŽ‰å·²ç»é€‰ä¸­çš„æ–‡æ¡£
            selected_doc_ids = {doc.page_content for doc in all_docs}
            additional_docs = []
            
            for doc in all_available_docs:
                if doc.page_content not in selected_doc_ids and len(additional_docs) < remaining_k:
                    additional_docs.append(doc)
                    selected_doc_ids.add(doc.page_content)
            
            all_docs.extend(additional_docs)
            print(f"  ðŸ“ˆ è¡¥å……æ£€ç´¢: æ–°å¢ž {len(additional_docs)} ä¸ªæ–‡æ¡£")
            
        except Exception as e:
            print(f"  âŒ è¡¥å……æ£€ç´¢å¤±è´¥: {e}")
    
    # ç¬¬äº”æ­¥ï¼šç»Ÿè®¡æœ€ç»ˆç»“æžœ
    final_doc_sources = {}
    for doc in all_docs[:k]:
        doc_name = doc.metadata.get('document_name', 'æœªçŸ¥æ–‡æ¡£')
        final_doc_sources[doc_name] = final_doc_sources.get(doc_name, 0) + 1
    
    print(f"ðŸ“‹ æœ€ç»ˆæ£€ç´¢ç»“æžœåˆ†å¸ƒ: {final_doc_sources}")
    print(f"ðŸ“Š æ€»è®¡æ£€ç´¢åˆ°: {len(all_docs[:k])} ä¸ªæ–‡æ¡£")
    
    return all_docs[:k]

def test_improved_retrieval():
    """
    æµ‹è¯•æ”¹è¿›çš„æ£€ç´¢ç­–ç•¥
    """
    print("=== æµ‹è¯•æ”¹è¿›çš„æ£€ç´¢ç­–ç•¥ ===")
    
    # é…ç½®APIå¯†é’¥
    api_key = os.getenv('MY_DASHSCOPE_API_KEY', '')
    if not api_key or api_key == 'ä½ çš„APIKEY':
        print("âŒ æœªé…ç½®æœ‰æ•ˆçš„DashScope APIå¯†é’¥")
        return
    
    embeddings = DashScopeEmbeddings(dashscope_api_key=api_key, model="text-embedding-v1")
    
    # åŠ è½½å‘é‡æ•°æ®åº“
    vector_db_path = "central/vector_db"
    if not os.path.exists(vector_db_path):
        print(f"âŒ å‘é‡æ•°æ®åº“è·¯å¾„ä¸å­˜åœ¨: {vector_db_path}")
        return
    
    try:
        vector_store = FAISS.load_local(vector_db_path, embeddings, allow_dangerous_deserialization=True)
        print(f"âœ… å‘é‡æ•°æ®åº“åŠ è½½æˆåŠŸ")
        
        # æµ‹è¯•æŸ¥è¯¢
        test_queries = [
            "ä¸­èŠ¯å›½é™…çš„ä¸»è¦ä¸šåŠ¡",
            "ä¸­èŠ¯å›½é™…çš„äº§èƒ½åˆ©ç”¨çŽ‡",
            "ä¸­èŠ¯å›½é™…çš„æ¯›åˆ©çŽ‡",
            "ä¸­èŠ¯å›½é™…çš„å¸‚åœºåœ°ä½",
            "ä¸­èŠ¯å›½é™…çš„è´¢åŠ¡è¡¨çŽ°"
        ]
        
        for query in test_queries:
            print(f"\n{'='*50}")
            improved_retrieval_strategy(vector_store, query, k=8)
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")

if __name__ == "__main__":
    test_improved_retrieval() 