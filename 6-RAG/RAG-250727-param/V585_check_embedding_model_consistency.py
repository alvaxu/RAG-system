#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç¨‹åºè¯´æ˜ï¼š
## 1. æ£€æŸ¥ç³»ç»Ÿä¸­æ‰€æœ‰ç»„ä»¶çš„åµŒå…¥æ¨¡å‹ä½¿ç”¨æƒ…å†µ
## 2. ç¡®ä¿æ–‡æœ¬åµŒå…¥æ¨¡å‹å’Œ multimodal åµŒå…¥æ¨¡å‹çš„ä¸€è‡´æ€§
## 3. è¯†åˆ«ç¡¬ç¼–ç çš„æ¨¡å‹åç§°
## 4. éªŒè¯é…ç½®ç®¡ç†æ˜¯å¦æ­£ç¡®åº”ç”¨
"""

import os
import sys
import json
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent
sys.path.append(str(project_root))

from config.settings import Settings

def check_embedding_models():
    """
    æ£€æŸ¥ç³»ç»Ÿä¸­æ‰€æœ‰ç»„ä»¶çš„åµŒå…¥æ¨¡å‹ä½¿ç”¨æƒ…å†µ
    """
    print("ğŸ” æ£€æŸ¥åµŒå…¥æ¨¡å‹ä¸€è‡´æ€§...")
    print("=" * 60)
    
    # 1. æ£€æŸ¥é…ç½®æ–‡ä»¶
    print("\nğŸ“‹ 1. é…ç½®æ–‡ä»¶æ£€æŸ¥:")
    config_file = "config.json"
    if os.path.exists(config_file):
        with open(config_file, 'r', encoding='utf-8') as f:
            config = json.load(f)
        
        vector_store_config = config.get('vector_store', {})
        text_model = vector_store_config.get('text_embedding_model', 'æœªé…ç½®')
        multimodal_model = vector_store_config.get('multimodal_embedding_model', 'æœªé…ç½®')
        
        print(f"   config.json ä¸­çš„é…ç½®:")
        print(f"   - text_embedding_model: {text_model}")
        print(f"   - multimodal_embedding_model: {multimodal_model}")
    else:
        print(f"   âŒ {config_file} ä¸å­˜åœ¨")
    
    # 2. æ£€æŸ¥ Settings ç±»
    print("\nâš™ï¸ 2. Settings ç±»æ£€æŸ¥:")
    try:
        settings = Settings.load_from_file("config.json")
        settings_dict = settings.to_dict()
        vector_store_config = settings_dict.get('vector_store', {})
        text_model = vector_store_config.get('text_embedding_model', 'æœªé…ç½®')
        multimodal_model = vector_store_config.get('multimodal_embedding_model', 'æœªé…ç½®')
        
        print(f"   Settings ç±»ä¸­çš„é…ç½®:")
        print(f"   - text_embedding_model: {text_model}")
        print(f"   - multimodal_embedding_model: {multimodal_model}")
    except Exception as e:
        print(f"   âŒ Settings ç±»æ£€æŸ¥å¤±è´¥: {e}")
    
    # 3. æ£€æŸ¥å…³é”®æ–‡ä»¶ä¸­çš„ç¡¬ç¼–ç æ¨¡å‹
    print("\nğŸ”§ 3. å…³é”®æ–‡ä»¶ä¸­çš„æ¨¡å‹ä½¿ç”¨æƒ…å†µ:")
    
    files_to_check = [
        "core/enhanced_qa_system.py",
        "core/vector_store.py", 
        "document_processing/enhanced_vector_generator.py",
        "document_processing/enhanced_image_processor.py",
        "document_processing/image_processor.py"
    ]
    
    text_model_usage = {}
    multimodal_model_usage = {}
    
    for file_path in files_to_check:
        if os.path.exists(file_path):
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # æ£€æŸ¥æ–‡æœ¬åµŒå…¥æ¨¡å‹
            if 'text-embedding-v4' in content:
                lines = content.split('\n')
                text_lines = []
                for i, line in enumerate(lines, 1):
                    if 'text-embedding-v4' in line:
                        text_lines.append(f"ç¬¬{i}è¡Œ: {line.strip()}")
                text_model_usage[file_path] = text_lines
            
            # æ£€æŸ¥ multimodal åµŒå…¥æ¨¡å‹
            if 'multimodal_embedding_one_peace_v1' in content:
                lines = content.split('\n')
                multimodal_lines = []
                for i, line in enumerate(lines, 1):
                    if 'multimodal_embedding_one_peace_v1' in line:
                        multimodal_lines.append(f"ç¬¬{i}è¡Œ: {line.strip()}")
                multimodal_model_usage[file_path] = multimodal_lines
        else:
            print(f"   âš ï¸ æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
    
    # æ˜¾ç¤ºæ–‡æœ¬åµŒå…¥æ¨¡å‹ä½¿ç”¨æƒ…å†µ
    print("\n   ğŸ“ æ–‡æœ¬åµŒå…¥æ¨¡å‹ (text-embedding-v4) ä½¿ç”¨æƒ…å†µ:")
    if text_model_usage:
        for file_path, lines in text_model_usage.items():
            print(f"   ğŸ“„ {file_path}:")
            for line in lines:
                print(f"      {line}")
    else:
        print("   âœ… æœªå‘ç°ç¡¬ç¼–ç çš„ text-embedding-v4")
    
    # æ˜¾ç¤º multimodal åµŒå…¥æ¨¡å‹ä½¿ç”¨æƒ…å†µ
    print("\n   ğŸ–¼ï¸ Multimodal åµŒå…¥æ¨¡å‹ (multimodal_embedding_one_peace_v1) ä½¿ç”¨æƒ…å†µ:")
    if multimodal_model_usage:
        for file_path, lines in multimodal_model_usage.items():
            print(f"   ğŸ“„ {file_path}:")
            for line in lines:
                print(f"      {line}")
    else:
        print("   âœ… æœªå‘ç°ç¡¬ç¼–ç çš„ multimodal_embedding_one_peace_v1")
    
    # 4. æ£€æŸ¥é…ç½®ç®¡ç†å®ç°
    print("\nğŸ”§ 4. é…ç½®ç®¡ç†å®ç°æ£€æŸ¥:")
    
    # æ£€æŸ¥æ˜¯å¦ä½¿ç”¨äº†é…ç½®å‚æ•°
    config_usage_files = [
        "core/enhanced_qa_system.py",
        "core/vector_store.py",
        "document_processing/enhanced_vector_generator.py",
        "document_processing/enhanced_image_processor.py",
        "document_processing/image_processor.py"
    ]
    
    for file_path in config_usage_files:
        if os.path.exists(file_path):
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # æ£€æŸ¥æ˜¯å¦æ¥å— config å‚æ•°
            has_config_param = 'def __init__(self, config' in content or 'def __init__(self, *, config' in content
            # æ£€æŸ¥æ˜¯å¦ä»é…ç½®ä¸­è·å–æ¨¡å‹
            uses_config_model = 'config.get' in content and ('text_embedding_model' in content or 'multimodal_embedding_model' in content)
            
            status = "âœ…" if has_config_param and uses_config_model else "âŒ"
            print(f"   {status} {file_path}:")
            print(f"      - æ¥å— config å‚æ•°: {'æ˜¯' if has_config_param else 'å¦'}")
            print(f"      - ä½¿ç”¨é…ç½®ä¸­çš„æ¨¡å‹: {'æ˜¯' if uses_config_model else 'å¦'}")
    
    # 5. æ€»ç»“å’Œå»ºè®®
    print("\nğŸ“Š 5. æ€»ç»“å’Œå»ºè®®:")
    
    issues_found = []
    
    # æ£€æŸ¥é…ç½®æ–‡ä»¶æ˜¯å¦åŒ…å«åµŒå…¥æ¨¡å‹é…ç½®
    if not os.path.exists(config_file) or 'text_embedding_model' not in str(config):
        issues_found.append("config.json ä¸­ç¼ºå°‘åµŒå…¥æ¨¡å‹é…ç½®")
    
    # æ£€æŸ¥æ˜¯å¦æœ‰ç¡¬ç¼–ç çš„æ¨¡å‹åç§°
    if text_model_usage or multimodal_model_usage:
        issues_found.append("å‘ç°ç¡¬ç¼–ç çš„æ¨¡å‹åç§°ï¼Œéœ€è¦æ”¹ä¸ºä½¿ç”¨é…ç½®")
    
    if issues_found:
        print("   âŒ å‘ç°ä»¥ä¸‹é—®é¢˜:")
        for issue in issues_found:
            print(f"      - {issue}")
        
        print("\n   ğŸ’¡ å»ºè®®ä¿®å¤:")
        print("      1. åœ¨ config.json ä¸­æ·»åŠ åµŒå…¥æ¨¡å‹é…ç½®")
        print("      2. ä¿®æ”¹ç¡¬ç¼–ç çš„æ¨¡å‹åç§°ä¸ºä½¿ç”¨é…ç½®")
        print("      3. ç¡®ä¿æ‰€æœ‰ç»„ä»¶éƒ½æ¥å— config å‚æ•°")
    else:
        print("   âœ… åµŒå…¥æ¨¡å‹é…ç½®ä¸€è‡´ï¼Œæœªå‘ç°é—®é¢˜")
    
    print("\n" + "=" * 60)

if __name__ == "__main__":
    check_embedding_models() 