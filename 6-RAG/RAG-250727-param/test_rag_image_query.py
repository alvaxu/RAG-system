'''
æµ‹è¯•RAGç³»ç»Ÿå¦‚ä½•å›ç­”å›¾åƒç›¸å…³é—®é¢˜
'''

import os
import sys
import logging
from typing import List, Dict, Any

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from config.settings import Settings
from core.enhanced_qa_system import EnhancedQASystem

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def test_image_query():
    """æµ‹è¯•RAGç³»ç»Ÿå¯¹å›¾åƒé—®é¢˜çš„å›ç­”"""
    try:
        # åŠ è½½é…ç½®
        config = Settings.load_from_file('config.json')
        from langchain_community.vectorstores import FAISS
        from langchain_community.embeddings import DashScopeEmbeddings
        
        # åˆå§‹åŒ–å‘é‡æ•°æ®åº“
        embeddings = DashScopeEmbeddings(
            dashscope_api_key=config.dashscope_api_key,
            model="text-embedding-v1"
        )
        
        vector_store = FAISS.load_local(
            config.vector_db_dir,
            embeddings,
            allow_dangerous_deserialization=True
        )
        
        # åˆå§‹åŒ–QAç³»ç»Ÿ
        qa_system = EnhancedQASystem(
            vector_store,
            config.dashscope_api_key,
            None,
            config.to_dict()
        )
        
        # æµ‹è¯•é—®é¢˜
        test_questions = [
            "è¿™å¼ å›¾æ˜¯ä»€ä¹ˆï¼Ÿ",
            "å›¾ç‰‡é‡Œæ˜¾ç¤ºäº†ä»€ä¹ˆå†…å®¹ï¼Ÿ",
            "è¿™å¼ å›¾è¡¨æ˜¯ä»€ä¹ˆç±»å‹çš„ï¼Ÿ",
            "å›¾ç‰‡ä¸­çš„ä¿¡æ¯æ˜¯ä»€ä¹ˆï¼Ÿ"
        ]
        
        print("ğŸ” æµ‹è¯•RAGç³»ç»Ÿå¯¹å›¾åƒé—®é¢˜çš„å›ç­”...")
        print("="*60)
        
        for i, question in enumerate(test_questions, 1):
            print(f"\nğŸ“ é—®é¢˜ {i}: {question}")
            print("-" * 40)
            
            try:
                # è·å–å›ç­”
                result = qa_system.answer_question(question)
                answer = result.get('answer', result)  # å…¼å®¹è¿”å›å­—å…¸æˆ–å­—ç¬¦ä¸²
                
                print("ğŸ¤– RAGç³»ç»Ÿå›ç­”:")
                print(answer)
                
                # åˆ†æå›ç­”çš„æ¥æº
                print("\nğŸ“Š å›ç­”åˆ†æ:")
                if "å›¾ç‰‡" in answer or "å›¾è¡¨" in answer or "å›¾åƒ" in answer:
                    print("âœ… å›ç­”ä¸­åŒ…å«äº†å›¾åƒç›¸å…³å†…å®¹")
                else:
                    print("âŒ å›ç­”ä¸­æ²¡æœ‰æ˜æ˜¾çš„å›¾åƒå†…å®¹")
                    
            except Exception as e:
                print(f"âŒ è·å–å›ç­”å¤±è´¥: {e}")
        
        print("\n" + "="*60)
        print("ğŸ’¡ åˆ†æç»“è®º:")
        print("1. RAGç³»ç»Ÿå¯èƒ½é€šè¿‡ä»¥ä¸‹æ–¹å¼æä¾›å›¾åƒä¿¡æ¯:")
        print("   - åˆ©ç”¨å›¾ç‰‡çš„å…ƒæ•°æ®ï¼ˆæ ‡é¢˜ã€è„šæ³¨ï¼‰")
        print("   - åŸºäºembeddingçš„è¯­ä¹‰åŒ¹é…")
        print("   - LLMçš„æ¨ç†å’Œä¸Šä¸‹æ–‡ç†è§£")
        print("2. è™½ç„¶ONE-PEACEä¸èƒ½ç›´æ¥è¾“å‡ºæ–‡å­—æè¿°ï¼Œä½†RAGç³»ç»Ÿ")
        print("   å¯ä»¥é€šè¿‡å…¶ä»–æ–¹å¼æä¾›ä¸°å¯Œçš„å›¾åƒä¿¡æ¯")
        
    except Exception as e:
        logger.error(f"æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

def analyze_image_metadata():
    """åˆ†æå›¾ç‰‡çš„å…ƒæ•°æ®ä¿¡æ¯"""
    try:
        from langchain_community.vectorstores import FAISS
        from langchain_community.embeddings import DashScopeEmbeddings
        
        # åŠ è½½å‘é‡æ•°æ®åº“
        embeddings = DashScopeEmbeddings(
            dashscope_api_key="sk-bfff6cdc92e84b2f89064cd382fdbe4a",
            model="text-embedding-v1"
        )
        
        vector_store = FAISS.load_local(
            "./central/vector_db",
            embeddings,
            allow_dangerous_deserialization=True
        )
        
        print("\nğŸ” åˆ†æå›¾ç‰‡å…ƒæ•°æ®ä¿¡æ¯...")
        print("="*60)
        
        image_count = 0
        for doc_id, doc in vector_store.docstore._dict.items():
            metadata = doc.metadata if hasattr(doc, 'metadata') and doc.metadata else {}
            
            if metadata.get('chunk_type') == 'image':
                image_count += 1
                print(f"\nğŸ“· å›¾ç‰‡ {image_count}:")
                print(f"   æ–‡æ¡£ID: {doc_id}")
                print(f"   æ–‡æ¡£åç§°: {metadata.get('document_name', 'æœªçŸ¥')}")
                print(f"   å›¾ç‰‡æ ‡é¢˜: {metadata.get('img_caption', [])}")
                print(f"   å›¾ç‰‡è„šæ³¨: {metadata.get('img_footnote', [])}")
                print(f"   å¢å¼ºæè¿°: {metadata.get('enhanced_description', 'æ— ')}")
                print(f"   è¯­ä¹‰æè¿°: {metadata.get('semantic_description', 'æ— ')}")
                
                if image_count >= 3:  # åªæ˜¾ç¤ºå‰3å¼ å›¾ç‰‡
                    break
        
        print(f"\nğŸ“Š å…ƒæ•°æ®åˆ†æ:")
        print(f"æ€»å…±æ‰¾åˆ° {image_count} å¼ å›¾ç‰‡")
        print("è¿™äº›å…ƒæ•°æ®ä¿¡æ¯ä¸ºRAGç³»ç»Ÿæä¾›äº†ä¸°å¯Œçš„å›¾åƒæè¿°åŸºç¡€")
        
    except Exception as e:
        logger.error(f"åˆ†æå…ƒæ•°æ®å¤±è´¥: {e}")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ” å¼€å§‹æµ‹è¯•RAGç³»ç»Ÿçš„å›¾åƒé—®ç­”èƒ½åŠ›...")
    
    # æµ‹è¯•RAGç³»ç»Ÿçš„å›¾åƒé—®ç­”
    test_image_query()
    
    # åˆ†æå›¾ç‰‡å…ƒæ•°æ®
    analyze_image_metadata()

if __name__ == "__main__":
    main() 