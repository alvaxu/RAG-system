# V501_2_å‘é‡æ•°æ®åº“ç”ŸæˆæŠ€æœ¯å®ç°æ·±åº¦å‰–æ

## ğŸ“‹ æ¦‚è¿°

æœ¬æ–‡æ¡£åŸºäº`pipeline.py`ç¬¬260-274è¡Œçš„å‘é‡æ•°æ®åº“ç”Ÿæˆå®ç°ï¼Œæ·±å…¥åˆ†æRAGç³»ç»Ÿä¸­å‘é‡æ•°æ®åº“ç”Ÿæˆæ¨¡å—çš„æŠ€æœ¯æ¶æ„ã€å®ç°åŸç†å’Œè°ƒç”¨å…³ç³»ã€‚

## ğŸ¯ æ ¸å¿ƒä»£ç åˆ†æ

### å…³é”®ä»£ç æ®µï¼ˆpipeline.py 260-274è¡Œï¼‰

```python
# æ­¥éª¤4: ç”Ÿæˆå‘é‡æ•°æ®åº“
logger.info("æ­¥éª¤4: å¼€å§‹ç”Ÿæˆå‘é‡æ•°æ®åº“...")
vector_store = self.vector_generator.create_vector_store(chunks, vector_db_path)
if vector_store:
    self.processing_status['vector_generation'] = True
    result['steps']['vector_generation'] = {
        'status': 'success',
        'vector_store_path': vector_db_path,
        'total_chunks': len(chunks)
    }
    logger.info("å‘é‡æ•°æ®åº“ç”Ÿæˆå®Œæˆ")
else:
    result['errors'].append("å‘é‡æ•°æ®åº“ç”Ÿæˆå¤±è´¥")
    logger.error("å‘é‡æ•°æ®åº“ç”Ÿæˆå¤±è´¥")
    return result
```

## ğŸ—ï¸ æ¶æ„è®¾è®¡

### 1. åˆ†å±‚æ¶æ„

```
Pipelineå±‚ (pipeline.py)
    â†“ è°ƒç”¨
VectorGeneratorå±‚ (vector_generator.py)
    â†“ è°ƒç”¨
ImageProcessorå±‚ (image_processor.py)
    â†“ è°ƒç”¨
DashScope API (ONE-PEACEæ¨¡å‹)
```

### 2. æ ¸å¿ƒç»„ä»¶å…³ç³»å›¾

```mermaid
graph TD
    A[pipeline.py] --> B[vector_generator.py]
    B --> C[image_processor.py]
    C --> D[DashScope API]
    
    A --> E[DocumentProcessingPipeline]
    B --> F[VectorGenerator]
    C --> G[ImageProcessor]
    D --> H[ONE-PEACEæ¨¡å‹]
    
    E --> F
    F --> G
    G --> H
    
    I[FAISSå‘é‡å­˜å‚¨] --> J[index.pkl]
    I --> K[metadata.pkl]
    I --> L[å›¾ç‰‡å‘é‡]
    I --> M[æ–‡æœ¬å‘é‡]
```

## ğŸ“ æ–‡ä»¶åŠŸèƒ½åˆ†æ

### 1. pipeline.py - ç®¡é“åè°ƒå±‚

**åŠŸèƒ½æè¿°ï¼š**
- ä½œä¸ºæ•´ä¸ªæ–‡æ¡£å¤„ç†æµç¨‹çš„åè°ƒå™¨
- è´Ÿè´£è°ƒç”¨å‘é‡ç”Ÿæˆå™¨å¹¶ç®¡ç†å¤„ç†çŠ¶æ€
- æä¾›ç»Ÿä¸€çš„é”™è¯¯å¤„ç†å’Œç»“æœç»Ÿè®¡

**å…³é”®æ–¹æ³•ï¼š**
```python
def _process_from_markdown_files(self, md_files: List[str], vector_db_path: str)
```

**æŠ€æœ¯å®ç°ï¼š**
- ä½¿ç”¨çŠ¶æ€ç®¡ç†æœºåˆ¶è·Ÿè¸ªå‘é‡ç”Ÿæˆè¿›åº¦
- é‡‡ç”¨ç»Ÿä¸€çš„è¿”å›æ ¼å¼åŒ…å«æˆåŠŸçŠ¶æ€ã€ç»Ÿè®¡ä¿¡æ¯å’Œé”™è¯¯åˆ—è¡¨
- å®ç°åˆ†æ­¥éª¤çš„é”™è¯¯å¤„ç†å’Œå›æ»šæœºåˆ¶

### 2. vector_generator.py - å‘é‡ç”Ÿæˆæ ¸å¿ƒå±‚

**åŠŸèƒ½æè¿°ï¼š**
- è´Ÿè´£åˆ›å»ºå’Œç®¡ç†FAISSå‘é‡å­˜å‚¨
- å¤„ç†æ–‡æœ¬å’Œå›¾ç‰‡çš„å‘é‡åŒ–
- è§£å†³å‘é‡å­˜å‚¨IDæ˜ å°„é—®é¢˜

**æ ¸å¿ƒç±»ï¼š**

#### VectorGenerator
```python
class VectorGenerator:
    def create_vector_store(self, documents: List[Document], save_path: str) -> Optional[FAISS]
    def add_images_to_store(self, vector_store: FAISS, image_files: List[Dict[str, Any]], save_path: str) -> bool
```

**æŠ€æœ¯å®ç°ï¼š**
- **APIå¯†é’¥ç®¡ç†**ï¼šä»é…ç½®ä¸­è·å–DashScope APIå¯†é’¥
- **åµŒå…¥æ¨¡å‹åˆå§‹åŒ–**ï¼šä½¿ç”¨DashScopeEmbeddingsæ¨¡å‹
- **å‘é‡å­˜å‚¨åˆ›å»º**ï¼šä½¿ç”¨FAISS.from_textsæ–¹æ³•åˆ›å»ºå‘é‡å­˜å‚¨
- **IDæ˜ å°„ä¿®å¤**ï¼šè§£å†³ç´¢å¼•å’Œæ–‡æ¡£å­˜å‚¨çš„IDæ˜ å°„ä¸ä¸€è‡´é—®é¢˜
- **å…ƒæ•°æ®ä¿å­˜**ï¼šä¿å­˜å®Œæ•´çš„å…ƒæ•°æ®ä¿¡æ¯åˆ°metadata.pklæ–‡ä»¶

#### å…³é”®æ–¹æ³•åˆ†æ

**create_vector_storeæ–¹æ³•ï¼š**
```python
def create_vector_store(self, documents: List[Document], save_path: str) -> Optional[FAISS]:
    # 1. æå–æ–‡æœ¬å’Œå…ƒæ•°æ®
    texts = []
    metadatas = []
    
    for doc in documents:
        texts.append(doc.page_content)
        metadata = doc.metadata.copy() if doc.metadata else {}
        # ç¡®ä¿å…ƒæ•°æ®åŒ…å«å¿…è¦ä¿¡æ¯
        if 'page_number' not in metadata:
            metadata['page_number'] = metadata.get('page', 1)
        if 'document_name' not in metadata:
            metadata['document_name'] = metadata.get('source', 'unknown')
        if 'chunk_type' not in metadata:
            metadata['chunk_type'] = 'text'
        metadatas.append(metadata)
    
    # 2. åˆ›å»ºå‘é‡å­˜å‚¨
    vector_store = FAISS.from_texts(
        texts=texts,
        embedding=self.embeddings,
        metadatas=metadatas
    )
    
    # 3. ä¿®å¤IDæ˜ å°„é—®é¢˜
    self._fix_index_mapping(vector_store)
    
    # 4. ä¿å­˜å‘é‡å­˜å‚¨
    self._save_vector_store_with_metadata(vector_store, save_path)
```

**add_images_to_storeæ–¹æ³•ï¼š**
```python
def add_images_to_store(self, vector_store: FAISS, image_files: List[Dict[str, Any]], save_path: str) -> bool:
    # 1. å¤„ç†æ¯å¼ å›¾ç‰‡
    for image_info in image_files:
        result = self.image_processor.process_image_for_vector_store(
            image_path=image_path,
            image_id=image_info.get('image_hash', 'unknown'),
            document_name=image_info.get('document_name', 'æœªçŸ¥æ–‡æ¡£'),
            page_number=image_info.get('page_number', 1),
            img_caption=image_info.get('img_caption', []),
            img_footnote=image_info.get('img_footnote', [])
        )
    
    # 2. æ„å»ºå›¾ç‰‡æè¿°å’Œå…ƒæ•°æ®
    text_embeddings = []
    metadatas = []
    
    # 3. æ·»åŠ åˆ°å‘é‡å­˜å‚¨
    vector_store.add_embeddings(text_embeddings, metadatas)
```

### 3. image_processor.py - å›¾ç‰‡å¤„ç†å±‚

**åŠŸèƒ½æè¿°ï¼š**
- ä¸“é—¨å¤„ç†å›¾ç‰‡çš„å‘é‡åŒ–
- ä½¿ç”¨DashScopeçš„ONE-PEACEå¤šæ¨¡æ€embeddingæ¨¡å‹
- æ”¯æŒæœ¬åœ°å›¾ç‰‡æ–‡ä»¶å’ŒURLå›¾ç‰‡çš„å¤„ç†

**æ ¸å¿ƒç±»ï¼š**

#### ImageProcessor
```python
class ImageProcessor:
    def process_image_for_vector_store(self, image_path: str, image_id: str = None, document_name: str = None, page_number: int = None, img_caption: List[str] = None, img_footnote: List[str] = None) -> Optional[Dict[str, Any]]
    def generate_image_embedding(self, image_path: str = None, image_url: str = None) -> List[float]
```

**æŠ€æœ¯å®ç°ï¼š**
- **å›¾ç‰‡ç¼–ç **ï¼šå°†æœ¬åœ°å›¾ç‰‡æ–‡ä»¶ç¼–ç ä¸ºbase64å­—ç¬¦ä¸²
- **APIè°ƒç”¨**ï¼šä½¿ç”¨DashScope MultiModalEmbedding API
- **é‡è¯•æœºåˆ¶**ï¼šå®ç°æŒ‡æ•°é€€é¿å’ŒéšæœºæŠ–åŠ¨çš„é‡è¯•ç­–ç•¥
- **å¢å¼ºæè¿°**ï¼šç»“åˆå›¾ç‰‡æ ‡é¢˜å’Œè„šæ³¨ç”Ÿæˆå¢å¼ºæè¿°

#### å…³é”®æ–¹æ³•åˆ†æ

**generate_image_embeddingæ–¹æ³•ï¼š**
```python
def generate_image_embedding(self, image_path: str = None, image_url: str = None) -> List[float]:
    # 1. æ„å»ºè¾“å…¥å‚æ•°
    input_data = []
    if image_path:
        image_base64 = self.encode_image_to_base64(image_path)
        input_data.append({'image': f"data:image/jpeg;base64,{image_base64}"})
    
    # 2. è°ƒç”¨DashScope API
    result = MultiModalEmbedding.call(
        model=MultiModalEmbedding.Models.multimodal_embedding_one_peace_v1,
        input=input_data,
        auto_truncation=True
    )
    
    # 3. è¿”å›embeddingå‘é‡
    return result.output["embedding"]
```

**process_image_for_vector_storeæ–¹æ³•ï¼š**
```python
def process_image_for_vector_store(self, image_path: str, image_id: str = None, document_name: str = None, page_number: int = None, img_caption: List[str] = None, img_footnote: List[str] = None) -> Optional[Dict[str, Any]]:
    # 1. ç”Ÿæˆå›¾ç‰‡embedding
    embedding = self.generate_image_embedding(image_path=image_path)
    
    # 2. ç”Ÿæˆå¢å¼ºæè¿°
    enhanced_description = self._generate_enhanced_image_description(
        image_path, img_caption, img_footnote
    )
    
    # 3. è¿”å›å®Œæ•´ç»“æœ
    return {
        'image_id': image_id,
        'image_path': image_path,
        'embedding': embedding,
        'document_name': document_name or 'æœªçŸ¥æ–‡æ¡£',
        'page_number': page_number or 1,
        'img_caption': img_caption or [],
        'img_footnote': img_footnote or [],
        'enhanced_description': enhanced_description,
        'image_type': self._detect_image_type(image_path),
        'semantic_features': self._extract_semantic_features(embedding)
    }
```

## ğŸ”„ è°ƒç”¨æµç¨‹åˆ†æ

### 1. ä¸»è°ƒç”¨é“¾

```python
# pipeline.py ç¬¬262è¡Œ
vector_store = self.vector_generator.create_vector_store(chunks, vector_db_path)

# vector_generator.py ç¬¬60è¡Œ
def create_vector_store(self, documents: List[Document], save_path: str) -> Optional[FAISS]:
    # æå–æ–‡æœ¬å’Œå…ƒæ•°æ®
    texts = []
    metadatas = []
    
    # åˆ›å»ºå‘é‡å­˜å‚¨
    vector_store = FAISS.from_texts(texts=texts, embedding=self.embeddings, metadatas=metadatas)
    
    # ä¿®å¤IDæ˜ å°„
    self._fix_index_mapping(vector_store)
    
    # ä¿å­˜å‘é‡å­˜å‚¨
    self._save_vector_store_with_metadata(vector_store, save_path)
```

### 2. è¯¦ç»†æ‰§è¡Œæµç¨‹

#### æ­¥éª¤1ï¼šæ–‡æ¡£å‡†å¤‡
```python
# ä»Documentå¯¹è±¡ä¸­æå–æ–‡æœ¬å’Œå…ƒæ•°æ®
for doc in documents:
    texts.append(doc.page_content)
    metadata = doc.metadata.copy() if doc.metadata else {}
    # ç¡®ä¿å…ƒæ•°æ®å®Œæ•´æ€§
    if 'page_number' not in metadata:
        metadata['page_number'] = metadata.get('page', 1)
    metadatas.append(metadata)
```

#### æ­¥éª¤2ï¼šå‘é‡å­˜å‚¨åˆ›å»º
```python
# ä½¿ç”¨LangChainçš„FAISS.from_textsæ–¹æ³•
vector_store = FAISS.from_texts(
    texts=texts,
    embedding=self.embeddings,
    metadatas=metadatas
)
```

#### æ­¥éª¤3ï¼šIDæ˜ å°„ä¿®å¤
```python
# æ£€æŸ¥ç´¢å¼•å’Œæ–‡æ¡£å­˜å‚¨çš„ä¸€è‡´æ€§
index_total = vector_store.index.ntotal
docstore_ids = list(vector_store.docstore._dict.keys())

if len(docstore_ids) != index_total:
    # é‡å»ºç´¢å¼•æ˜ å°„
    new_index_to_docstore_id = {}
    for i, doc_id in enumerate(docstore_ids):
        if i < index_total:
            new_index_to_docstore_id[i] = str(doc_id)
    vector_store.index_to_docstore_id = new_index_to_docstore_id
```

#### æ­¥éª¤4ï¼šå‘é‡å­˜å‚¨ä¿å­˜
```python
# ä¿å­˜FAISSç´¢å¼•
vector_store.save_local(save_path)

# ä¿å­˜å…ƒæ•°æ®
metadata_path = save_path_obj / "metadata.pkl"
with open(metadata_path, "wb") as f:
    pickle.dump(vector_store.metadata, f)
```

#### æ­¥éª¤5ï¼šå›¾ç‰‡å‘é‡æ·»åŠ ï¼ˆå¯é€‰ï¼‰
```python
# å¤„ç†æ¯å¼ å›¾ç‰‡
for image_info in image_files:
    result = self.image_processor.process_image_for_vector_store(
        image_path=image_path,
        image_id=image_info.get('image_hash', 'unknown'),
        document_name=image_info.get('document_name', 'æœªçŸ¥æ–‡æ¡£'),
        page_number=image_info.get('page_number', 1),
        img_caption=image_info.get('img_caption', []),
        img_footnote=image_info.get('img_footnote', [])
    )
    
    # æ·»åŠ åˆ°å‘é‡å­˜å‚¨
    text_embedding_pair = (image_description, result["embedding"])
    vector_store.add_embeddings([text_embedding_pair], [metadata])
```

## ğŸ› ï¸ æŠ€æœ¯å®ç°ç»†èŠ‚

### 1. å‘é‡åŒ–æŠ€æœ¯

**DashScope Embeddingsé…ç½®ï¼š**
```python
self.embeddings = DashScopeEmbeddings(dashscope_api_key=self.api_key, model="text-embedding-v1")
```
- **æ¨¡å‹é€‰æ‹©**ï¼šä½¿ç”¨text-embedding-v1æ¨¡å‹è¿›è¡Œæ–‡æœ¬å‘é‡åŒ–
- **APIé›†æˆ**ï¼šé€šè¿‡DashScope APIè¿›è¡Œå‘é‡ç”Ÿæˆ
- **é”™è¯¯å¤„ç†**ï¼šå®Œå–„çš„APIè°ƒç”¨é”™è¯¯å¤„ç†æœºåˆ¶

### 2. å›¾ç‰‡å‘é‡åŒ–æŠ€æœ¯

**ONE-PEACEå¤šæ¨¡æ€æ¨¡å‹ï¼š**
```python
result = MultiModalEmbedding.call(
    model=MultiModalEmbedding.Models.multimodal_embedding_one_peace_v1,
    input=input_data,
    auto_truncation=True
)
```
- **æ¨¡å‹ç‰¹ç‚¹**ï¼šæ”¯æŒå›¾ç‰‡å’Œæ–‡æœ¬çš„å¤šæ¨¡æ€ç†è§£
- **è¾“å…¥æ ¼å¼**ï¼šæ”¯æŒbase64ç¼–ç çš„æœ¬åœ°å›¾ç‰‡å’ŒURLå›¾ç‰‡
- **è¾“å‡ºç»´åº¦**ï¼šç”Ÿæˆé«˜ç»´åº¦çš„è¯­ä¹‰å‘é‡è¡¨ç¤º

### 3. FAISSå‘é‡å­˜å‚¨æŠ€æœ¯

**å­˜å‚¨ç»“æ„ï¼š**
```python
# FAISSç´¢å¼•æ–‡ä»¶
index.pkl  # å‘é‡ç´¢å¼•
metadata.pkl  # å…ƒæ•°æ®ä¿¡æ¯
```
- **ç´¢å¼•ç±»å‹**ï¼šä½¿ç”¨FAISSçš„é«˜æ•ˆå‘é‡ç´¢å¼•
- **å…ƒæ•°æ®ä¿å­˜**ï¼šå®Œæ•´çš„æ–‡æ¡£å…ƒæ•°æ®ä¿¡æ¯
- **IDæ˜ å°„**ï¼šè§£å†³ç´¢å¼•å’Œæ–‡æ¡£å­˜å‚¨çš„æ˜ å°„é—®é¢˜

### 4. é‡è¯•å’Œå®¹é”™æœºåˆ¶

**APIè°ƒç”¨é‡è¯•ï¼š**
```python
max_retries = 3
retry_delay = 5

for attempt in range(max_retries):
    try:
        result = MultiModalEmbedding.call(...)
        if result.status_code == 200:
            return result.output["embedding"]
        elif result.status_code == 429:
            # æŒ‡æ•°é€€é¿ + éšæœºæŠ–åŠ¨
            delay = retry_delay * (2 ** attempt) + random.uniform(2, 5)
            time.sleep(delay)
    except Exception as e:
        if attempt == max_retries - 1:
            raise e
```
- **æŒ‡æ•°é€€é¿**ï¼šé¿å…APIé¢‘ç‡é™åˆ¶
- **éšæœºæŠ–åŠ¨**ï¼šå‡å°‘å¹¶å‘å†²çª
- **é”™è¯¯æ¢å¤**ï¼šæ”¯æŒéƒ¨åˆ†å¤±è´¥æ—¶çš„æ¢å¤

### 5. å…ƒæ•°æ®ç®¡ç†

**å…ƒæ•°æ®ç»“æ„ï¼š**
```python
metadata = {
    'document_name': 'æ–‡æ¡£åç§°',
    'page_number': 1,
    'chunk_type': 'text',  # text/table/image
    'chunk_index': 0,
    'table_id': 'table_123',  # ä»…è¡¨æ ¼ç±»å‹
    'table_type': 'æ•°æ®è¡¨æ ¼',  # ä»…è¡¨æ ¼ç±»å‹
    'image_id': 'img_456',  # ä»…å›¾ç‰‡ç±»å‹
    'img_caption': ['å›¾ç‰‡æ ‡é¢˜'],  # ä»…å›¾ç‰‡ç±»å‹
    'img_footnote': ['å›¾ç‰‡è„šæ³¨'],  # ä»…å›¾ç‰‡ç±»å‹
}
```
- **ç±»å‹æ ‡è¯†**ï¼šæ˜ç¡®åŒºåˆ†æ–‡æœ¬ã€è¡¨æ ¼ã€å›¾ç‰‡åˆ†å—
- **ä½ç½®ä¿¡æ¯**ï¼šåŒ…å«é¡µç å’Œåˆ†å—ç´¢å¼•
- **å†…å®¹æè¿°**ï¼šå›¾ç‰‡çš„æ ‡é¢˜å’Œè„šæ³¨ä¿¡æ¯

## ğŸ“Š æ€§èƒ½ä¼˜åŒ–

### 1. å†…å­˜ç®¡ç†
- **æµå¼å¤„ç†**ï¼šé€ä¸ªæ–‡æ¡£å¤„ç†ï¼Œé¿å…ä¸€æ¬¡æ€§åŠ è½½æ‰€æœ‰å†…å®¹
- **åŠæ—¶é‡Šæ”¾**ï¼šå¤„ç†å®ŒæˆååŠæ—¶é‡Šæ”¾ä¸´æ—¶å˜é‡
- **å‘é‡ç¼“å­˜**ï¼šä½¿ç”¨FAISSçš„é«˜æ•ˆå‘é‡å­˜å‚¨

### 2. APIè°ƒç”¨ä¼˜åŒ–
- **æ‰¹é‡å¤„ç†**ï¼šæ”¯æŒæ‰¹é‡å›¾ç‰‡å¤„ç†
- **é‡è¯•æœºåˆ¶**ï¼šæ™ºèƒ½çš„é‡è¯•å’Œé€€é¿ç­–ç•¥
- **é”™è¯¯æ¢å¤**ï¼šæ”¯æŒéƒ¨åˆ†å¤±è´¥æ—¶çš„æ¢å¤

### 3. å­˜å‚¨ä¼˜åŒ–
- **å‹ç¼©å­˜å‚¨**ï¼šFAISSæä¾›é«˜æ•ˆçš„å‘é‡å‹ç¼©
- **å…ƒæ•°æ®åˆ†ç¦»**ï¼šå°†å…ƒæ•°æ®å•ç‹¬å­˜å‚¨ï¼Œä¾¿äºæŸ¥è¯¢
- **å¢é‡æ›´æ–°**ï¼šæ”¯æŒå‘ç°æœ‰å‘é‡å­˜å‚¨æ·»åŠ æ–°å†…å®¹

## ğŸ” å…³é”®ç‰¹æ€§

### 1. å¤šæ¨¡æ€æ”¯æŒ
- **æ–‡æœ¬å‘é‡åŒ–**ï¼šæ”¯æŒMarkdownæ–‡æœ¬çš„å‘é‡åŒ–
- **è¡¨æ ¼å‘é‡åŒ–**ï¼šä¸“é—¨çš„è¡¨æ ¼å†…å®¹å‘é‡åŒ–
- **å›¾ç‰‡å‘é‡åŒ–**ï¼šä½¿ç”¨ONE-PEACEæ¨¡å‹è¿›è¡Œå›¾ç‰‡ç†è§£

### 2. è¯­ä¹‰ä¿æŒ
- **ä¸Šä¸‹æ–‡ä¿æŒ**ï¼šé€šè¿‡å…ƒæ•°æ®ä¿æŒæ–‡æ¡£çš„ä¸Šä¸‹æ–‡ä¿¡æ¯
- **ç»“æ„ä¿æŒ**ï¼šè¡¨æ ¼å’Œå›¾ç‰‡çš„ç»“æ„åŒ–ä¿¡æ¯å¾—åˆ°ä¿æŒ
- **ä½ç½®ä¿æŒ**ï¼šé¡µç å’Œåˆ†å—ç´¢å¼•ä¿¡æ¯å®Œæ•´ä¿å­˜

### 3. å¯æ‰©å±•æ€§
- **æ¨¡å—åŒ–è®¾è®¡**ï¼šå„æ¨¡å—ç‹¬ç«‹ï¼Œä¾¿äºæ‰©å±•
- **æ¥å£æ ‡å‡†åŒ–**ï¼šç»Ÿä¸€çš„å‘é‡å­˜å‚¨æ¥å£
- **é…ç½®çµæ´»**ï¼šæ”¯æŒå¤šç§é…ç½®å‚æ•°

## ğŸ¯ æ€»ç»“

å‘é‡æ•°æ®åº“ç”Ÿæˆæ¨¡å—é‡‡ç”¨äº†åˆ†å±‚æ¶æ„è®¾è®¡ï¼Œé€šè¿‡Pipelineå±‚ã€VectorGeneratorå±‚å’ŒImageProcessorå±‚çš„åä½œï¼Œå®ç°äº†é«˜æ•ˆã€æ™ºèƒ½çš„å‘é‡åŒ–å¤„ç†ã€‚è¯¥æ¨¡å—ä¸ä»…æ”¯æŒä¼ ç»Ÿçš„æ–‡æœ¬å‘é‡åŒ–ï¼Œè¿˜ä¸“é—¨é’ˆå¯¹è¡¨æ ¼å’Œå›¾ç‰‡å†…å®¹è¿›è¡Œäº†ä¼˜åŒ–ï¼Œä¸ºRAGç³»ç»Ÿæä¾›äº†é«˜è´¨é‡çš„å‘é‡æ•°æ®ã€‚

**æ ¸å¿ƒä¼˜åŠ¿ï¼š**
1. **å¤šæ¨¡æ€å‘é‡åŒ–**ï¼šæ”¯æŒæ–‡æœ¬ã€è¡¨æ ¼ã€å›¾ç‰‡çš„æ··åˆå‘é‡åŒ–
2. **æ™ºèƒ½é‡è¯•æœºåˆ¶**ï¼šå®Œå–„çš„APIè°ƒç”¨é‡è¯•å’Œå®¹é”™æœºåˆ¶
3. **å…ƒæ•°æ®ä¸°å¯Œ**ï¼šå®Œæ•´çš„æ–‡æ¡£å…ƒæ•°æ®ä¿¡æ¯ä¿å­˜
4. **æ€§èƒ½ä¼˜åŒ–**ï¼šé«˜æ•ˆçš„FAISSå‘é‡å­˜å‚¨å’Œç´¢å¼•
5. **å¯æ‰©å±•æ€§**ï¼šæ¨¡å—åŒ–è®¾è®¡ï¼Œä¾¿äºåŠŸèƒ½æ‰©å±•

è¿™ä¸ªæ¨¡å—ä¸ºæ•´ä¸ªRAGç³»ç»Ÿæä¾›äº†åšå®çš„å‘é‡åŒ–åŸºç¡€ï¼Œç¡®ä¿äº†åç»­æ£€ç´¢å’Œé—®ç­”çš„è´¨é‡ã€‚ 