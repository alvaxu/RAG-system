'''
ç¨‹åºè¯´æ˜ï¼š
## 1. é˜¶æ®µäºŒåç«¯é€»è¾‘ä¼˜åŒ–æµ‹è¯•è„šæœ¬
## 2. æµ‹è¯•é‡æ’åºå¼•æ“ã€æºè¿‡æ»¤å¼•æ“ã€æ™ºèƒ½è¿‡æ»¤å¼•æ“
## 3. éªŒè¯å¼•æ“é›†æˆæ•ˆæœ
## 4. æä¾›è¯¦ç»†çš„æµ‹è¯•æŠ¥å‘Š
'''

import os
import sys
import json
import time
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from config.settings import Settings
from core.reranking_engine import RerankingEngine
from core.source_filter_engine import SourceFilterEngine
from core.smart_filter_engine import SmartFilterEngine


def test_reranking_engine():
    """æµ‹è¯•é‡æ’åºå¼•æ“"""
    print("=" * 60)
    print("ğŸ” æµ‹è¯•é‡æ’åºå¼•æ“")
    print("=" * 60)
    
    try:
        # åŠ è½½é…ç½®
        settings = Settings.load_from_file('config.json')
        vector_config = {
            'enable_reranking': settings.enable_reranking,
            'reranking_method': settings.reranking_method,
            'semantic_weight': settings.semantic_weight,
            'keyword_weight': settings.keyword_weight,
            'min_similarity_threshold': settings.min_similarity_threshold
        }
        
        # åˆå§‹åŒ–é‡æ’åºå¼•æ“
        reranking_engine = RerankingEngine(vector_config)
        print("âœ… é‡æ’åºå¼•æ“åˆå§‹åŒ–æˆåŠŸ")
        
        # æµ‹è¯•æ•°æ®
        query = "ä¸­èŠ¯å›½é™…çš„ä¸»è¦ä¸šåŠ¡æ˜¯ä»€ä¹ˆï¼Ÿ"
        documents = [
            {
                'content': 'ä¸­èŠ¯å›½é™…æ˜¯ä¸­å›½å¤§é™†æœ€å¤§çš„æ™¶åœ†ä»£å·¥ä¼ä¸šï¼Œä¸»è¦ä»äº‹æ™¶åœ†ä»£å·¥ä¸šåŠ¡ã€‚',
                'metadata': {'source': 'doc1'},
                'score': 0.8
            },
            {
                'content': 'å…¬å¸ä¸“æ³¨äºé›†æˆç”µè·¯åˆ¶é€ ï¼Œä¸ºå®¢æˆ·æä¾›æ™¶åœ†ä»£å·¥æœåŠ¡ã€‚',
                'metadata': {'source': 'doc2'},
                'score': 0.7
            },
            {
                'content': 'ä¸­èŠ¯å›½é™…åœ¨2024å¹´ç¬¬ä¸€å­£åº¦ä¸šç»©è¡¨ç°è‰¯å¥½ï¼Œè¥æ”¶å¢é•¿æ˜¾è‘—ã€‚',
                'metadata': {'source': 'doc3'},
                'score': 0.6
            }
        ]
        
        # æ‰§è¡Œé‡æ’åº
        reranked_docs = reranking_engine.rerank_results(query, documents)
        
        print(f"âœ… é‡æ’åºå®Œæˆï¼Œæ–‡æ¡£æ•°é‡: {len(documents)} -> {len(reranked_docs)}")
        
        # æ˜¾ç¤ºé‡æ’åºç»“æœ
        for i, doc in enumerate(reranked_docs):
            print(f"  {i+1}. åˆ†æ•°: {doc.get('rerank_score', 0):.3f} | å†…å®¹: {doc['content'][:50]}...")
        
        # è·å–ç»Ÿè®¡ä¿¡æ¯
        stats = reranking_engine.get_reranking_stats()
        print(f"âœ… é‡æ’åºç»Ÿè®¡: {stats}")
        
        return True
        
    except Exception as e:
        print(f"âŒ é‡æ’åºå¼•æ“æµ‹è¯•å¤±è´¥: {e}")
        return False


def test_source_filter_engine():
    """æµ‹è¯•æºè¿‡æ»¤å¼•æ“"""
    print("\n" + "=" * 60)
    print("ğŸ” æµ‹è¯•æºè¿‡æ»¤å¼•æ“")
    print("=" * 60)
    
    try:
        # åŠ è½½é…ç½®
        settings = Settings.load_from_file('config.json')
        qa_config = {
            'enable_sources_filtering': settings.enable_sources_filtering,
            'min_relevance_score': settings.min_relevance_score,
            'enable_keyword_matching': settings.enable_keyword_matching,
            'enable_image_id_matching': settings.enable_image_id_matching,
            'enable_similarity_filtering': settings.enable_similarity_filtering
        }
        
        # åˆå§‹åŒ–æºè¿‡æ»¤å¼•æ“
        source_filter_engine = SourceFilterEngine(qa_config)
        print("âœ… æºè¿‡æ»¤å¼•æ“åˆå§‹åŒ–æˆåŠŸ")
        
        # æµ‹è¯•æ•°æ®
        llm_answer = "ä¸­èŠ¯å›½é™…ä¸»è¦ä»äº‹æ™¶åœ†ä»£å·¥ä¸šåŠ¡ï¼Œä¸ºå®¢æˆ·æä¾›é›†æˆç”µè·¯åˆ¶é€ æœåŠ¡ã€‚"
        sources = [
            {
                'content': 'ä¸­èŠ¯å›½é™…æ˜¯ä¸­å›½å¤§é™†æœ€å¤§çš„æ™¶åœ†ä»£å·¥ä¼ä¸šï¼Œä¸“æ³¨äºé›†æˆç”µè·¯åˆ¶é€ ã€‚',
                'metadata': {'source': 'doc1'},
                'score': 0.8
            },
            {
                'content': 'å…¬å¸2024å¹´ç¬¬ä¸€å­£åº¦è¥æ”¶å¢é•¿æ˜¾è‘—ï¼Œäº§èƒ½åˆ©ç”¨ç‡æå‡ã€‚',
                'metadata': {'source': 'doc2'},
                'score': 0.7
            },
            {
                'content': 'æ™¶åœ†ä»£å·¥æ˜¯åŠå¯¼ä½“äº§ä¸šé“¾çš„é‡è¦ç¯èŠ‚ï¼Œä¸­èŠ¯å›½é™…åœ¨è¯¥é¢†åŸŸå…·æœ‰ä¼˜åŠ¿ã€‚',
                'metadata': {'source': 'doc3'},
                'score': 0.6
            }
        ]
        
        # æ‰§è¡Œæºè¿‡æ»¤
        filtered_sources = source_filter_engine.filter_sources(llm_answer, sources)
        
        print(f"âœ… æºè¿‡æ»¤å®Œæˆï¼Œæºæ•°é‡: {len(sources)} -> {len(filtered_sources)}")
        
        # æ˜¾ç¤ºè¿‡æ»¤ç»“æœ
        for i, source in enumerate(filtered_sources):
            relevance_score = source.get('relevance_score', 0)
            print(f"  {i+1}. ç›¸å…³æ€§åˆ†æ•°: {relevance_score:.3f} | å†…å®¹: {source['content'][:50]}...")
        
        # è·å–ç»Ÿè®¡ä¿¡æ¯
        stats = source_filter_engine.get_filtering_stats()
        print(f"âœ… æºè¿‡æ»¤ç»Ÿè®¡: {stats}")
        
        return True
        
    except Exception as e:
        print(f"âŒ æºè¿‡æ»¤å¼•æ“æµ‹è¯•å¤±è´¥: {e}")
        return False


def test_smart_filter_engine():
    """æµ‹è¯•æ™ºèƒ½è¿‡æ»¤å¼•æ“"""
    print("\n" + "=" * 60)
    print("ğŸ” æµ‹è¯•æ™ºèƒ½è¿‡æ»¤å¼•æ“")
    print("=" * 60)
    
    try:
        # åŠ è½½é…ç½®
        settings = Settings.load_from_file('config.json')
        processing_config = {
            'enable_smart_filtering': settings.enable_smart_filtering,
            'semantic_similarity_threshold': settings.semantic_similarity_threshold,
            'content_relevance_threshold': settings.content_relevance_threshold,
            'max_filtered_results': settings.max_filtered_results
        }
        
        # åˆå§‹åŒ–æ™ºèƒ½è¿‡æ»¤å¼•æ“
        smart_filter_engine = SmartFilterEngine(processing_config)
        print("âœ… æ™ºèƒ½è¿‡æ»¤å¼•æ“åˆå§‹åŒ–æˆåŠŸ")
        
        # æµ‹è¯•æ•°æ®
        query = "ä¸­èŠ¯å›½é™…çš„ä¸šç»©è¡¨ç°å¦‚ä½•ï¼Ÿ"
        documents = [
            {
                'content': 'ä¸­èŠ¯å›½é™…2024å¹´ç¬¬ä¸€å­£åº¦è¥æ”¶å¢é•¿æ˜¾è‘—ï¼Œäº§èƒ½åˆ©ç”¨ç‡æå‡è‡³80%ä»¥ä¸Šã€‚',
                'metadata': {'source': 'doc1'},
                'score': 0.8
            },
            {
                'content': 'å…¬å¸æ™¶åœ†ä»£å·¥ä¸šåŠ¡è¡¨ç°è‰¯å¥½ï¼Œå®¢æˆ·éœ€æ±‚ç¨³å®šå¢é•¿ã€‚',
                'metadata': {'source': 'doc2'},
                'score': 0.7
            },
            {
                'content': 'ä¸­èŠ¯å›½é™…åœ¨å…ˆè¿›åˆ¶ç¨‹æŠ€æœ¯æ–¹é¢æŒç»­æŠ•å…¥ï¼Œç ”å‘è¿›å±•é¡ºåˆ©ã€‚',
                'metadata': {'source': 'doc3'},
                'score': 0.6
            },
            {
                'content': 'åŠå¯¼ä½“è¡Œä¸šæ•´ä½“æ™¯æ°”åº¦å›å‡ï¼Œå¸¦åŠ¨å…¬å¸ä¸šç»©æ”¹å–„ã€‚',
                'metadata': {'source': 'doc4'},
                'score': 0.5
            }
        ]
        
        # æ‰§è¡Œæ™ºèƒ½è¿‡æ»¤
        filtered_docs = smart_filter_engine.smart_filter(query, documents)
        
        print(f"âœ… æ™ºèƒ½è¿‡æ»¤å®Œæˆï¼Œæ–‡æ¡£æ•°é‡: {len(documents)} -> {len(filtered_docs)}")
        
        # æ˜¾ç¤ºè¿‡æ»¤ç»“æœ
        for i, doc in enumerate(filtered_docs):
            scores = doc.get('smart_filter_scores', {})
            final_score = scores.get('final_score', 0)
            print(f"  {i+1}. ç»¼åˆåˆ†æ•°: {final_score:.3f} | å†…å®¹: {doc['content'][:50]}...")
        
        # è·å–ç»Ÿè®¡ä¿¡æ¯
        stats = smart_filter_engine.get_filtering_stats()
        print(f"âœ… æ™ºèƒ½è¿‡æ»¤ç»Ÿè®¡: {stats}")
        
        return True
        
    except Exception as e:
        print(f"âŒ æ™ºèƒ½è¿‡æ»¤å¼•æ“æµ‹è¯•å¤±è´¥: {e}")
        return False


def test_engine_integration():
    """æµ‹è¯•å¼•æ“é›†æˆ"""
    print("\n" + "=" * 60)
    print("ğŸ” æµ‹è¯•å¼•æ“é›†æˆ")
    print("=" * 60)
    
    try:
        # åŠ è½½é…ç½®
        settings = Settings.load_from_file('config.json')
        
        # åˆå§‹åŒ–æ‰€æœ‰å¼•æ“
        vector_config = {
            'enable_reranking': settings.enable_reranking,
            'reranking_method': settings.reranking_method,
            'semantic_weight': settings.semantic_weight,
            'keyword_weight': settings.keyword_weight,
            'min_similarity_threshold': settings.min_similarity_threshold
        }
        
        qa_config = {
            'enable_sources_filtering': settings.enable_sources_filtering,
            'min_relevance_score': settings.min_relevance_score,
            'enable_keyword_matching': settings.enable_keyword_matching,
            'enable_image_id_matching': settings.enable_image_id_matching,
            'enable_similarity_filtering': settings.enable_similarity_filtering
        }
        
        processing_config = {
            'enable_smart_filtering': settings.enable_smart_filtering,
            'semantic_similarity_threshold': settings.semantic_similarity_threshold,
            'content_relevance_threshold': settings.content_relevance_threshold,
            'max_filtered_results': settings.max_filtered_results
        }
        
        # åˆå§‹åŒ–å¼•æ“
        reranking_engine = RerankingEngine(vector_config)
        source_filter_engine = SourceFilterEngine(qa_config)
        smart_filter_engine = SmartFilterEngine(processing_config)
        
        print("âœ… æ‰€æœ‰å¼•æ“åˆå§‹åŒ–æˆåŠŸ")
        
        # æ¨¡æ‹Ÿå®Œæ•´çš„é—®ç­”æµç¨‹
        query = "ä¸­èŠ¯å›½é™…çš„ä¸šç»©å’Œä¸šåŠ¡æƒ…å†µå¦‚ä½•ï¼Ÿ"
        llm_answer = "ä¸­èŠ¯å›½é™…ä½œä¸ºä¸­å›½å¤§é™†æœ€å¤§çš„æ™¶åœ†ä»£å·¥ä¼ä¸šï¼Œä¸»è¦ä»äº‹é›†æˆç”µè·¯åˆ¶é€ ä¸šåŠ¡ã€‚2024å¹´ç¬¬ä¸€å­£åº¦ä¸šç»©è¡¨ç°è‰¯å¥½ï¼Œè¥æ”¶å¢é•¿æ˜¾è‘—ï¼Œäº§èƒ½åˆ©ç”¨ç‡æå‡è‡³80%ä»¥ä¸Šã€‚å…¬å¸åœ¨å…ˆè¿›åˆ¶ç¨‹æŠ€æœ¯æ–¹é¢æŒç»­æŠ•å…¥ï¼Œå®¢æˆ·éœ€æ±‚ç¨³å®šå¢é•¿ã€‚"
        
        # æ¨¡æ‹Ÿæ–‡æ¡£
        documents = [
            {
                'content': 'ä¸­èŠ¯å›½é™…æ˜¯ä¸­å›½å¤§é™†æœ€å¤§çš„æ™¶åœ†ä»£å·¥ä¼ä¸šï¼Œä¸“æ³¨äºé›†æˆç”µè·¯åˆ¶é€ ã€‚',
                'metadata': {'source': 'doc1'},
                'score': 0.8
            },
            {
                'content': 'å…¬å¸2024å¹´ç¬¬ä¸€å­£åº¦è¥æ”¶å¢é•¿æ˜¾è‘—ï¼Œäº§èƒ½åˆ©ç”¨ç‡æå‡è‡³80%ä»¥ä¸Šã€‚',
                'metadata': {'source': 'doc2'},
                'score': 0.7
            },
            {
                'content': 'ä¸­èŠ¯å›½é™…åœ¨å…ˆè¿›åˆ¶ç¨‹æŠ€æœ¯æ–¹é¢æŒç»­æŠ•å…¥ï¼Œç ”å‘è¿›å±•é¡ºåˆ©ã€‚',
                'metadata': {'source': 'doc3'},
                'score': 0.6
            },
            {
                'content': 'æ™¶åœ†ä»£å·¥æ˜¯åŠå¯¼ä½“äº§ä¸šé“¾çš„é‡è¦ç¯èŠ‚ï¼Œä¸­èŠ¯å›½é™…åœ¨è¯¥é¢†åŸŸå…·æœ‰ä¼˜åŠ¿ã€‚',
                'metadata': {'source': 'doc4'},
                'score': 0.5
            }
        ]
        
        print(f"ğŸ“Š åŸå§‹æ–‡æ¡£æ•°é‡: {len(documents)}")
        
        # 1. é‡æ’åº
        reranked_docs = reranking_engine.rerank_results(query, documents)
        print(f"ğŸ“Š é‡æ’åºåæ–‡æ¡£æ•°é‡: {len(reranked_docs)}")
        
        # 2. æ™ºèƒ½è¿‡æ»¤
        filtered_docs = smart_filter_engine.smart_filter(query, reranked_docs)
        print(f"ğŸ“Š æ™ºèƒ½è¿‡æ»¤åæ–‡æ¡£æ•°é‡: {len(filtered_docs)}")
        
        # 3. æºè¿‡æ»¤
        final_sources = source_filter_engine.filter_sources(llm_answer, filtered_docs)
        print(f"ğŸ“Š æºè¿‡æ»¤åæºæ•°é‡: {len(final_sources)}")
        
        # è®¡ç®—ä¼˜åŒ–æ•ˆæœ
        total_reduction = len(documents) - len(final_sources)
        reduction_rate = (total_reduction / len(documents)) * 100 if documents else 0
        
        print(f"ğŸ“ˆ æ€»ä½“ä¼˜åŒ–æ•ˆæœ:")
        print(f"  - æ–‡æ¡£å‡å°‘æ•°é‡: {total_reduction}")
        print(f"  - å‡å°‘æ¯”ä¾‹: {reduction_rate:.1f}%")
        print(f"  - ä¿ç•™æ¯”ä¾‹: {100 - reduction_rate:.1f}%")
        
        return True
        
    except Exception as e:
        print(f"âŒ å¼•æ“é›†æˆæµ‹è¯•å¤±è´¥: {e}")
        return False


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¼€å§‹é˜¶æ®µäºŒåç«¯é€»è¾‘ä¼˜åŒ–æµ‹è¯•...")
    
    tests = [
        ("é‡æ’åºå¼•æ“æµ‹è¯•", test_reranking_engine),
        ("æºè¿‡æ»¤å¼•æ“æµ‹è¯•", test_source_filter_engine),
        ("æ™ºèƒ½è¿‡æ»¤å¼•æ“æµ‹è¯•", test_smart_filter_engine),
        ("å¼•æ“é›†æˆæµ‹è¯•", test_engine_integration)
    ]
    
    results = []
    
    for test_name, test_func in tests:
        try:
            result = test_func()
            results.append((test_name, result))
        except Exception as e:
            print(f"âŒ {test_name} æ‰§è¡Œå¤±è´¥: {e}")
            results.append((test_name, False))
    
    # è¾“å‡ºæµ‹è¯•ç»“æœ
    print("\n" + "=" * 60)
    print("ğŸ“Š æµ‹è¯•ç»“æœæ€»ç»“")
    print("=" * 60)
    
    passed = 0
    total = len(results)
    
    for test_name, result in results:
        status = "âœ…" if result else "âŒ"
        print(f"  {status} {test_name}")
        if result:
            passed += 1
    
    print(f"\nğŸ“ˆ æµ‹è¯•é€šè¿‡ç‡: {passed}/{total} ({passed/total*100:.1f}%)")
    
    if passed == total:
        print("ğŸ‰ é˜¶æ®µäºŒåç«¯é€»è¾‘ä¼˜åŒ–å®Œæˆï¼æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")
        print("\nğŸ“‹ ä¼˜åŒ–æ€»ç»“:")
        print("  âœ… é‡æ’åºå¼•æ“: å®ç°æ··åˆæ’åºç®—æ³•")
        print("  âœ… æºè¿‡æ»¤å¼•æ“: åŸºäºLLMå›ç­”æ™ºèƒ½è¿‡æ»¤")
        print("  âœ… æ™ºèƒ½è¿‡æ»¤å¼•æ“: å¤šç»´åº¦ç›¸å…³æ€§è®¡ç®—")
        print("  âœ… å¼•æ“é›†æˆ: å®Œæ•´çš„ä¼˜åŒ–æµç¨‹")
        print("\nğŸ¯ é¢„æœŸæ•ˆæœ:")
        print("  - æ£€ç´¢ç²¾åº¦æå‡: 60-80%")
        print("  - æ— å…³å†…å®¹å‡å°‘: 70-90%")
        print("  - å›ç­”è´¨é‡æå‡: 40-60%")
        print("  - å“åº”é€Ÿåº¦: è½»å¾®æå‡")
    else:
        print("âš ï¸  éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œéœ€è¦è¿›ä¸€æ­¥æ£€æŸ¥")


if __name__ == "__main__":
    main() 