'''
ç¨‹åºè¯´æ˜ï¼š

## 1. æ£€æŸ¥å‘é‡æ•°æ®åº“ä¸­å­—æ®µå†…å®¹çš„å®Œæ•´æ€§
## 2. ç‰¹åˆ«å…³æ³¨å›¾ç‰‡æ–‡æ¡£çš„å…³é”®å­—æ®µæ˜¯å¦ä¸ºç©º
## 3. è¯†åˆ«å¯èƒ½å¯¼è‡´æ£€ç´¢å¤±è´¥çš„å­—æ®µå†…å®¹ç¼ºå¤±é—®é¢˜
'''

import pickle
import os
import sys
from collections import defaultdict

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.insert(0, project_root)

from langchain_community.vectorstores import FAISS
from langchain_community.embeddings import DashScopeEmbeddings
from config.settings import Settings

def check_field_content_completeness():
    """æ£€æŸ¥å­—æ®µå†…å®¹çš„å®Œæ•´æ€§"""
    
    print("ğŸ” æ£€æŸ¥å‘é‡æ•°æ®åº“å­—æ®µå†…å®¹å®Œæ•´æ€§")
    print("=" * 80)
    
    try:
        # åŠ è½½é…ç½®
        config = Settings.load_from_file('config.json')
        embeddings = DashScopeEmbeddings(dashscope_api_key=config.dashscope_api_key, model="text-embedding-v1")
        
        # åŠ è½½å‘é‡æ•°æ®åº“
        vector_db_path = "./central/vector_db"
        vector_store = FAISS.load_local(vector_db_path, embeddings, allow_dangerous_deserialization=True)
        
        print(f"âœ… å‘é‡æ•°æ®åº“åŠ è½½æˆåŠŸ")
        print(f"ğŸ“Š æ€»æ–‡æ¡£æ•°: {len(vector_store.docstore._dict)}")
        
        # æŒ‰ç±»å‹åˆ†ç»„æ–‡æ¡£
        docs_by_type = defaultdict(list)
        
        for doc_id, doc in vector_store.docstore._dict.items():
            metadata = doc.metadata if hasattr(doc, 'metadata') and doc.metadata else {}
            chunk_type = metadata.get('chunk_type', 'unknown')
            docs_by_type[chunk_type].append((doc_id, doc))
        
        # æ˜¾ç¤ºå„ç±»å‹æ–‡æ¡£æ•°é‡
        print(f"\nğŸ“Š å„ç±»å‹æ–‡æ¡£æ•°é‡:")
        for doc_type, docs in docs_by_type.items():
            emoji = {'image': 'ğŸ–¼ï¸', 'text': 'ğŸ“„', 'table': 'ğŸ“Š', 'unknown': 'â“'}.get(doc_type, 'ğŸ“„')
            print(f"  {emoji} {doc_type}: {len(docs)} ä¸ª")
        
        # æ£€æŸ¥æ¯ç§ç±»å‹çš„å­—æ®µå†…å®¹å®Œæ•´æ€§
        print(f"\nğŸ” å­—æ®µå†…å®¹å®Œæ•´æ€§æ£€æŸ¥:")
        print("=" * 80)
        
        for doc_type, docs in docs_by_type.items():
            if not docs:
                continue
                
            emoji = {'image': 'ğŸ–¼ï¸', 'text': 'ğŸ“„', 'table': 'ğŸ“Š', 'unknown': 'â“'}.get(doc_type, 'ğŸ“„')
            print(f"\n{emoji} {doc_type.upper()} ç±»å‹æ–‡æ¡£å­—æ®µå®Œæ•´æ€§:")
            print("-" * 60)
            
            # æ”¶é›†å­—æ®µç»Ÿè®¡
            field_stats = defaultdict(lambda: {'total': 0, 'empty': 0, 'non_empty': 0, 'empty_docs': []})
            
            for doc_id, doc in docs:
                metadata = doc.metadata if hasattr(doc, 'metadata') and doc.metadata else {}
                
                for field_name, field_value in metadata.items():
                    field_stats[field_name]['total'] += 1
                    
                    # æ£€æŸ¥æ˜¯å¦ä¸ºç©º
                    is_empty = (
                        field_value is None or 
                        (isinstance(field_value, str) and not field_value.strip()) or
                        (isinstance(field_value, list) and len(field_value) == 0) or
                        (isinstance(field_value, dict) and len(field_value) == 0)
                    )
                    
                    if is_empty:
                        field_stats[field_name]['empty'] += 1
                        field_stats[field_name]['empty_docs'].append(doc_id)
                    else:
                        field_stats[field_name]['non_empty'] += 1
            
            # æ˜¾ç¤ºå­—æ®µå®Œæ•´æ€§ç»Ÿè®¡
            for field_name, stats in sorted(field_stats.items()):
                empty_rate = (stats['empty'] / stats['total']) * 100 if stats['total'] > 0 else 0
                status_emoji = "âŒ" if empty_rate > 0 else "âœ…"
                
                print(f"  {status_emoji} {field_name}:")
                print(f"    æ€»æ•°: {stats['total']}, éç©º: {stats['non_empty']}, ç©ºå€¼: {stats['empty']} ({empty_rate:.1f}%)")
                
                # å¦‚æœç©ºå€¼è¾ƒå¤šï¼Œæ˜¾ç¤ºä¸€äº›ç©ºå€¼çš„æ–‡æ¡£ID
                if stats['empty'] > 0 and stats['empty'] <= 5:
                    print(f"    ç©ºå€¼æ–‡æ¡£: {stats['empty_docs']}")
                elif stats['empty'] > 5:
                    print(f"    ç©ºå€¼æ–‡æ¡£: {stats['empty_docs'][:3]}... (å…±{stats['empty']}ä¸ª)")
        
        # ç‰¹åˆ«æ£€æŸ¥å›¾ç‰‡æ–‡æ¡£çš„å…³é”®å­—æ®µ
        print(f"\nğŸ” å›¾ç‰‡æ–‡æ¡£å…³é”®å­—æ®µè¯¦ç»†æ£€æŸ¥:")
        print("=" * 80)
        
        image_docs = docs_by_type.get('image', [])
        if image_docs:
            print(f"ğŸ–¼ï¸ æ£€æŸ¥ {len(image_docs)} ä¸ªå›¾ç‰‡æ–‡æ¡£")
            
            # å…³é”®å­—æ®µåˆ—è¡¨
            critical_fields = [
                'enhanced_description', 'image_id', 'image_path', 
                'image_filename', 'img_caption', 'img_footnote'
            ]
            
            critical_field_issues = []
            
            for doc_id, doc in image_docs:
                metadata = doc.metadata if hasattr(doc, 'metadata') and doc.metadata else {}
                
                doc_issues = []
                for field in critical_fields:
                    if field in metadata:
                        value = metadata[field]
                        is_empty = (
                            value is None or 
                            (isinstance(value, str) and not value.strip()) or
                            (isinstance(value, list) and len(value) == 0)
                        )
                        if is_empty:
                            doc_issues.append(field)
                    else:
                        doc_issues.append(f"{field}(ç¼ºå¤±)")
                
                if doc_issues:
                    critical_field_issues.append((doc_id, doc_issues))
            
            if critical_field_issues:
                print(f"âŒ å‘ç° {len(critical_field_issues)} ä¸ªå›¾ç‰‡æ–‡æ¡£å­˜åœ¨å…³é”®å­—æ®µé—®é¢˜:")
                for doc_id, issues in critical_field_issues[:10]:  # åªæ˜¾ç¤ºå‰10ä¸ª
                    print(f"  ğŸ“„ {doc_id}: {', '.join(issues)}")
                if len(critical_field_issues) > 10:
                    print(f"  ... è¿˜æœ‰ {len(critical_field_issues) - 10} ä¸ªæ–‡æ¡£å­˜åœ¨é—®é¢˜")
            else:
                print(f"âœ… æ‰€æœ‰å›¾ç‰‡æ–‡æ¡£çš„å…³é”®å­—æ®µéƒ½å®Œæ•´")
        
        # æ£€æŸ¥æ–‡æ¡£å†…å®¹
        print(f"\nğŸ” æ–‡æ¡£å†…å®¹æ£€æŸ¥:")
        print("=" * 80)
        
        content_issues = []
        for doc_type, docs in docs_by_type.items():
            for doc_id, doc in docs:
                # æ£€æŸ¥æ–‡æ¡£å†…å®¹æ˜¯å¦ä¸ºç©º
                if not hasattr(doc, 'page_content') or not doc.page_content or not doc.page_content.strip():
                    content_issues.append((doc_type, doc_id, "page_contentä¸ºç©º"))
                
                # æ£€æŸ¥å…ƒæ•°æ®æ˜¯å¦ä¸ºç©º
                if not hasattr(doc, 'metadata') or not doc.metadata:
                    content_issues.append((doc_type, doc_id, "metadataä¸ºç©º"))
        
        if content_issues:
            print(f"âŒ å‘ç° {len(content_issues)} ä¸ªæ–‡æ¡£å­˜åœ¨å†…å®¹é—®é¢˜:")
            for doc_type, doc_id, issue in content_issues[:10]:
                emoji = {'image': 'ğŸ–¼ï¸', 'text': 'ğŸ“„', 'table': 'ğŸ“Š'}.get(doc_type, 'ğŸ“„')
                print(f"  {emoji} {doc_id}: {issue}")
            if len(content_issues) > 10:
                print(f"  ... è¿˜æœ‰ {len(content_issues) - 10} ä¸ªæ–‡æ¡£å­˜åœ¨é—®é¢˜")
        else:
            print(f"âœ… æ‰€æœ‰æ–‡æ¡£çš„å†…å®¹éƒ½å®Œæ•´")
        
        # æ€»ç»“
        print(f"\nğŸ“Š æ£€æŸ¥æ€»ç»“:")
        print("=" * 80)
        
        total_docs = sum(len(docs) for docs in docs_by_type.values())
        print(f"  æ€»æ–‡æ¡£æ•°: {total_docs}")
        print(f"  å›¾ç‰‡æ–‡æ¡£æ•°: {len(docs_by_type.get('image', []))}")
        print(f"  å†…å®¹é—®é¢˜æ•°: {len(content_issues)}")
        print(f"  å…³é”®å­—æ®µé—®é¢˜æ•°: {len(critical_field_issues) if 'critical_field_issues' in locals() else 0}")
        
        if content_issues or ('critical_field_issues' in locals() and critical_field_issues):
            print(f"\nâš ï¸  å»ºè®®:")
            print(f"  1. æ£€æŸ¥æ–‡æ¡£å¤„ç†æµç¨‹ï¼Œç¡®ä¿æ‰€æœ‰å­—æ®µéƒ½è¢«æ­£ç¡®å¡«å……")
            print(f"  2. é‡æ–°å¤„ç†å­˜åœ¨é—®é¢˜çš„æ–‡æ¡£")
            print(f"  3. éªŒè¯å›¾ç‰‡å¢å¼ºå¤„ç†æ˜¯å¦å®Œæˆ")
        else:
            print(f"\nâœ… æ•°æ®åº“å­—æ®µå†…å®¹å®Œæ•´æ€§è‰¯å¥½")
        
    except Exception as e:
        print(f"âŒ æ£€æŸ¥å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    check_field_content_completeness()
