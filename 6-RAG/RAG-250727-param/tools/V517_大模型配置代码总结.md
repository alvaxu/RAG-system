# RAG系统大模型配置代码总结

## 📋 概述

本项目使用了三个主要的大模型，分别用于不同的功能。以下是配置这些模型的程序文件和具体代码。

---

## 🤖 1. 通义千问 (Qwen-Turbo) - 问答模型

### 📁 主要配置文件
- **`core/qa_system.py`** - 问答系统核心
- **`config/settings.py`** - 模型配置

### 🔧 配置代码

#### 1.1 模型初始化 (`core/qa_system.py`)
```python
# 导入模块
from langchain_community.llms import Tongyi

# 初始化语言模型
self.llm = Tongyi(
    model_name="qwen-turbo", 
    dashscope_api_key=api_key
)

# 加载问答链
self.qa_chain = load_qa_chain(
    self.llm, 
    chain_type="stuff",
    prompt=self._create_enhanced_prompt()
)
```

#### 1.2 模型配置 (`config/settings.py`)
```python
# 问答系统配置
model_name: str = 'qwen-turbo'
temperature: float = 0.7
max_tokens: int = 2000
```

#### 1.3 成本计算器 (`core/qa_system.py`)
```python
class TongyiCostCalculator:
    """
    通义千问成本计算器
    """
    def __init__(self):
        # 通义千问qwen-turbo模型的定价（每1000个token的价格，单位：元）
        self.input_price_per_1k_tokens = 0.0005  # 输入价格
        self.output_price_per_1k_tokens = 0.002   # 输出价格
    
    def calculate_cost(self, input_tokens: int, output_tokens: int) -> float:
        """
        计算API调用成本
        :param input_tokens: 输入token数量
        :param output_tokens: 输出token数量
        :return: 成本（元）
        """
        input_cost = (input_tokens / 1000) * self.input_price_per_1k_tokens
        output_cost = (output_tokens / 1000) * self.output_price_per_1k_tokens
        return input_cost + output_cost
```

---

## 🔤 2. 文本嵌入模型 (Text Embedding V1) - 文本向量化

### 📁 主要配置文件
- **`document_processing/vector_generator.py`** - 向量生成器
- **`core/vector_store.py`** - 向量存储
- **`core/qa_system.py`** - 加载函数

### 🔧 配置代码

#### 2.1 向量生成器 (`document_processing/vector_generator.py`)
```python
# 导入模块
from langchain_community.embeddings import DashScopeEmbeddings

class VectorGenerator:
    def __init__(self, config):
        self.config = config
        self.api_key = self._get_api_key()
        # 初始化文本嵌入模型
        self.embeddings = DashScopeEmbeddings(
            dashscope_api_key=self.api_key, 
            model="text-embedding-v1"
        )
    
    def _get_api_key(self) -> str:
        """
        获取DashScope API密钥
        """
        api_key = os.getenv('MY_DASHSCOPE_API_KEY', '')
        if not api_key or api_key == '你的APIKEY':
            logger.warning("未找到有效的DashScope API密钥")
        return api_key
```

#### 2.2 向量存储 (`core/vector_store.py`)
```python
# 导入模块
from langchain_community.embeddings import DashScopeEmbeddings

class VectorStore:
    def __init__(self, api_key: str = None):
        self.api_key = api_key or os.getenv('MY_DASHSCOPE_API_KEY', '')
        # 初始化文本嵌入模型
        self.embeddings = DashScopeEmbeddings(
            dashscope_api_key=self.api_key, 
            model="text-embedding-v1"
        )
```

#### 2.3 加载函数 (`core/qa_system.py`)
```python
def load_qa_system(vector_db_path: str, api_key: str = "", memory_dir: str = None) -> QASystem:
    """
    加载问答系统
    """
    # 创建文本嵌入模型
    embeddings = DashScopeEmbeddings(
        dashscope_api_key=api_key, 
        model="text-embedding-v1"
    )
    
    # 加载向量存储
    vector_store = FAISS.load_local(
        vector_db_path, 
        embeddings, 
        allow_dangerous_deserialization=True
    )
```

---

## 🖼️ 3. 多模态嵌入模型 (ONE-PEACE V1) - 图片向量化

### 📁 主要配置文件
- **`document_processing/image_processor.py`** - 图片处理器

### 🔧 配置代码

#### 3.1 图片处理器 (`document_processing/image_processor.py`)
```python
# 导入模块
import dashscope
from dashscope import MultiModalEmbedding

class ImageProcessor:
    def __init__(self, api_key: str):
        """
        初始化图片处理器
        :param api_key: DashScope API密钥
        """
        dashscope.api_key = api_key
    
    def generate_image_embedding(self, image_path: str = None, image_url: str = None) -> List[float]:
        """
        生成图片embedding
        """
        # 准备输入数据
        if image_path:
            # 本地图片转base64
            image_base64 = self.encode_image_to_base64(image_path)
            input_data = [{"image": image_base64}]
        elif image_url:
            # 网络图片
            input_data = [{"image": image_url}]
        else:
            raise ValueError("必须提供image_path或image_url")
        
        # 调用ONE-PEACE模型
        result = MultiModalEmbedding.call(
            model=MultiModalEmbedding.Models.multimodal_embedding_one_peace_v1,
            input=input_data,
            auto_truncation=True
        )
        
        if result.status_code == 200:
            return result.output["embedding"]
        else:
            raise Exception(f"ONE-PEACE模型调用失败: {result}")
```

---

## ⚙️ 4. 统一配置管理

### 📁 配置文件
- **`config/settings.py`** - 统一设置类

### 🔧 配置代码

#### 4.1 统一设置类 (`config/settings.py`)
```python
@dataclass
class Settings:
    """
    统一设置类，管理所有配置项
    """
    # API配置
    dashscope_api_key: str = field(
        default_factory=lambda: os.getenv('MY_DASHSCOPE_API_KEY', '')
    )
    
    # 问答系统配置
    model_name: str = 'qwen-turbo'
    temperature: float = 0.7
    max_tokens: int = 2000
    
    # 向量存储配置
    vector_dimension: int = 1536
    similarity_top_k: int = 5
    
    def to_dict(self) -> Dict[str, Any]:
        """
        转换为字典
        """
        return {
            'api': {
                'dashscope_api_key': self.dashscope_api_key,
            },
            'qa_system': {
                'model_name': self.model_name,
                'temperature': self.temperature,
                'max_tokens': self.max_tokens
            },
            'vector_store': {
                'vector_dimension': self.vector_dimension,
                'similarity_top_k': self.similarity_top_k
            }
        }
```

---

## 📊 5. 模型使用场景总结

| 模型类型 | 模型名称 | 配置文件 | 主要功能 | 调用方式 |
|---------|---------|---------|---------|---------|
| **LLM** | `qwen-turbo` | `core/qa_system.py` | 问答生成 | `Tongyi(model_name="qwen-turbo")` |
| **文本嵌入** | `text-embedding-v1` | `document_processing/vector_generator.py` | 文本向量化 | `DashScopeEmbeddings(model="text-embedding-v1")` |
| **多模态嵌入** | `multimodal_embedding_one_peace_v1` | `document_processing/image_processor.py` | 图片向量化 | `MultiModalEmbedding.Models.multimodal_embedding_one_peace_v1` |

---

## 🔄 6. 模型调用流程

### 6.1 文本处理流程
```
文档输入 → 文本嵌入模型 → 向量存储 → 检索 → 通义千问 → 生成回答
```

### 6.2 图片处理流程
```
图片输入 → 多模态嵌入模型 → 向量存储 → 检索 → 通义千问 → 生成回答
```

### 6.3 统一处理流程
```
用户问题 → 判断类型 → 选择模型 → 向量检索 → 通义千问 → 生成回答
```

---

## 💡 7. 配置要点

### 7.1 API密钥管理
- 所有模型都使用同一个DashScope API密钥
- 通过环境变量 `MY_DASHSCOPE_API_KEY` 管理
- 在 `config/settings.py` 中统一配置

### 7.2 模型参数
- **qwen-turbo**: temperature=0.7, max_tokens=2000
- **text-embedding-v1**: 向量维度1536
- **multimodal_embedding_one_peace_v1**: 支持图片和文本

### 7.3 错误处理
- 所有模型调用都包含重试机制
- 详细的错误日志记录
- 优雅的异常处理

---

## 📝 8. 使用示例

### 8.1 初始化问答系统
```python
# 加载配置
from config.settings import Settings
settings = Settings()

# 初始化问答系统
qa_system = QASystem(
    vector_store=vector_store,
    api_key=settings.dashscope_api_key
)
```

### 8.2 处理文档
```python
# 初始化向量生成器
vector_generator = VectorGenerator(config)

# 创建向量存储
vector_store = vector_generator.create_vector_store(
    documents=documents,
    save_path="vector_db_test"
)
```

### 8.3 处理图片
```python
# 初始化图片处理器
image_processor = ImageProcessor(api_key)

# 生成图片向量
embedding = image_processor.generate_image_embedding(
    image_path="path/to/image.jpg"
)
```

---

*大模型配置代码总结 - 版本 1.0*
*最后更新: 2024年7月29日* 