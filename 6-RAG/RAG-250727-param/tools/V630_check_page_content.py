'''
ç¨‹åºè¯´æ˜ï¼š
## 1. æ£€æŸ¥å‘é‡æ•°æ®åº“ä¸­å›¾ç‰‡æ–‡æ¡£çš„page_contentå­—æ®µ
## 2. åˆ†æpage_contentä¸enhanced_descriptionçš„å…³ç³»
## 3. éªŒè¯å›¾ç‰‡æ–‡æ¡£çš„å®Œæ•´ç»“æ„
'''

import pickle
import os
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.insert(0, project_root)

from langchain_community.vectorstores import FAISS
from langchain_community.embeddings import DashScopeEmbeddings
from config.settings import Settings

def check_page_content():
    """æ£€æŸ¥å‘é‡æ•°æ®åº“ä¸­å›¾ç‰‡æ–‡æ¡£çš„page_contentå­—æ®µ"""
    
    print("ğŸ” æ£€æŸ¥å‘é‡æ•°æ®åº“ä¸­å›¾ç‰‡æ–‡æ¡£çš„page_contentå­—æ®µ")
    print("=" * 60)
    
    try:
        # åŠ è½½é…ç½®
        config = Settings.load_from_file('config.json')
        embeddings = DashScopeEmbeddings(dashscope_api_key=config.dashscope_api_key, model="text-embedding-v1")
        
        # åŠ è½½å‘é‡æ•°æ®åº“
        vector_db_path = "./central/vector_db"
        vector_store = FAISS.load_local(vector_db_path, embeddings, allow_dangerous_deserialization=True)
        
        print(f"âœ… å‘é‡æ•°æ®åº“åŠ è½½æˆåŠŸ")
        print(f"ğŸ“Š æ€»æ–‡æ¡£æ•°: {len(vector_store.docstore._dict)}")
        
        # ç»Ÿè®¡å›¾ç‰‡æ–‡æ¡£
        image_docs = []
        for doc_id, doc in vector_store.docstore._dict.items():
            metadata = doc.metadata if hasattr(doc, 'metadata') and doc.metadata else {}
            if metadata.get('chunk_type') == 'image':
                image_docs.append((doc_id, doc))
        
        print(f"ğŸ–¼ï¸  å›¾ç‰‡æ–‡æ¡£æ•°: {len(image_docs)}")
        
        if not image_docs:
            print("âŒ æ²¡æœ‰æ‰¾åˆ°å›¾ç‰‡æ–‡æ¡£")
            return
        
        # æ£€æŸ¥å‰5ä¸ªå›¾ç‰‡æ–‡æ¡£çš„page_content
        print(f"\nğŸ” å‰5ä¸ªå›¾ç‰‡æ–‡æ¡£çš„page_contentåˆ†æ:")
        print("=" * 60)
        
        for i, (doc_id, doc) in enumerate(image_docs[:5]):
            metadata = doc.metadata if hasattr(doc, 'metadata') and doc.metadata else {}
            
            print(f"\nğŸ“· å›¾ç‰‡æ–‡æ¡£ {i+1}:")
            print(f"  æ–‡æ¡£ID: {doc_id}")
            print(f"  å›¾ç‰‡ID: {metadata.get('image_id', 'No ID')}")
            print(f"  æ–‡æ¡£åç§°: {metadata.get('document_name', 'Unknown')}")
            
            # æ£€æŸ¥page_content
            page_content = doc.page_content
            print(f"  page_contenté•¿åº¦: {len(str(page_content))}")
            print(f"  page_contentå†…å®¹: {repr(page_content)}")
            
            # æ£€æŸ¥enhanced_description
            enhanced_desc = metadata.get('enhanced_description', '')
            print(f"  enhanced_description: {repr(enhanced_desc)}")
            
            # æ¯”è¾ƒä¸¤ä¸ªå­—æ®µ
            if page_content == enhanced_desc:
                print(f"  âœ… page_contentä¸enhanced_descriptionå†…å®¹ç›¸åŒ")
            else:
                print(f"  âš ï¸  page_contentä¸enhanced_descriptionå†…å®¹ä¸åŒ")
                print(f"     å·®å¼‚: page_contenté•¿åº¦={len(str(page_content))}, enhanced_descriptioné•¿åº¦={len(str(enhanced_desc))}")
            
            # æ£€æŸ¥å›¾ç‰‡æ ‡é¢˜
            img_caption = metadata.get('img_caption', [])
            if img_caption:
                caption_text = ' '.join(img_caption)
                print(f"  å›¾ç‰‡æ ‡é¢˜: {caption_text}")
        
        # ç»Ÿè®¡page_contentçš„æƒ…å†µ
        print(f"\nğŸ“Š page_contentç»Ÿè®¡:")
        print("=" * 60)
        
        empty_content_count = 0
        non_empty_content_count = 0
        same_as_enhanced_count = 0
        different_from_enhanced_count = 0
        
        for doc_id, doc in image_docs:
            metadata = doc.metadata if hasattr(doc, 'metadata') and doc.metadata else {}
            page_content = doc.page_content
            enhanced_desc = metadata.get('enhanced_description', '')
            
            if not page_content or len(str(page_content).strip()) == 0:
                empty_content_count += 1
            else:
                non_empty_content_count += 1
            
            if page_content == enhanced_desc:
                same_as_enhanced_count += 1
            else:
                different_from_enhanced_count += 1
        
        print(f"  ç©ºpage_contentçš„æ–‡æ¡£: {empty_content_count}")
        print(f"  æœ‰page_contentçš„æ–‡æ¡£: {non_empty_content_count}")
        print(f"  page_contentä¸enhanced_descriptionç›¸åŒçš„æ–‡æ¡£: {same_as_enhanced_count}")
        print(f"  page_contentä¸enhanced_descriptionä¸åŒçš„æ–‡æ¡£: {different_from_enhanced_count}")
        
        # æ£€æŸ¥metadata.pklæ–‡ä»¶
        print(f"\nğŸ” æ£€æŸ¥metadata.pklæ–‡ä»¶:")
        print("=" * 60)
        
        metadata_file = Path("central/vector_db/metadata.pkl")
        if metadata_file.exists():
            with open(metadata_file, 'rb') as f:
                metadata_list = pickle.load(f)
            
            print(f"  metadata.pklä¸­çš„è®°å½•æ•°: {len(metadata_list)}")
            
            # æ£€æŸ¥metadata.pklä¸­æ˜¯å¦æœ‰page_contentå­—æ®µ
            image_metadata = [item for item in metadata_list if item.get('chunk_type') == 'image']
            print(f"  metadata.pklä¸­çš„å›¾ç‰‡è®°å½•æ•°: {len(image_metadata)}")
            
            if image_metadata:
                first_image_metadata = image_metadata[0]
                print(f"  ç¬¬ä¸€ä¸ªå›¾ç‰‡è®°å½•çš„å­—æ®µ:")
                for key, value in first_image_metadata.items():
                    if key in ['page_content', 'content', 'enhanced_description']:
                        print(f"    {key}: {repr(value)}")
                    elif isinstance(value, list) and len(value) > 0:
                        print(f"    {key}: {value[:3]}... (å…±{len(value)}é¡¹)")
                    else:
                        print(f"    {key}: {value}")
        else:
            print("  âŒ metadata.pklæ–‡ä»¶ä¸å­˜åœ¨")
        
    except Exception as e:
        print(f"âŒ æ£€æŸ¥å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    check_page_content()
