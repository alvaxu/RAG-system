'''
ç¨‹åºè¯´æ˜ï¼š

## 1. æ£€æŸ¥å‘é‡æ•°æ®åº“ä¸­çš„å›¾ç‰‡æ–‡æ¡£
## 2. éªŒè¯å›¾ç‰‡æ£€ç´¢é€»è¾‘æ˜¯å¦æ­£ç¡®å·¥ä½œ
'''

import sys
import os

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.insert(0, project_root)

from langchain_community.vectorstores import FAISS
from langchain_community.embeddings import DashScopeEmbeddings
from config.settings import Settings

def check_image_docs_in_db():
    """æ£€æŸ¥å‘é‡æ•°æ®åº“ä¸­çš„å›¾ç‰‡æ–‡æ¡£"""
    
    print("ğŸ” æ£€æŸ¥å‘é‡æ•°æ®åº“ä¸­çš„å›¾ç‰‡æ–‡æ¡£")
    print("=" * 60)
    
    try:
        # åŠ è½½é…ç½®
        config = Settings.load_from_file('config.json')
        embeddings = DashScopeEmbeddings(dashscope_api_key=config.dashscope_api_key, model="text-embedding-v1")
        
        # åŠ è½½å‘é‡æ•°æ®åº“
        vector_db_path = "./central/vector_db"
        vector_store = FAISS.load_local(vector_db_path, embeddings, allow_dangerous_deserialization=True)
        
        print(f"å‘é‡æ•°æ®åº“åŠ è½½æˆåŠŸ")
        
        # ç»Ÿè®¡æ‰€æœ‰æ–‡æ¡£
        all_docs = list(vector_store.docstore._dict.values())
        print(f"æ€»æ–‡æ¡£æ•°: {len(all_docs)}")
        
        # ç»Ÿè®¡å›¾ç‰‡æ–‡æ¡£
        image_docs = [doc for doc in all_docs if doc.metadata.get('chunk_type') == 'image']
        print(f"å›¾ç‰‡æ–‡æ¡£æ•°: {len(image_docs)}")
        
        if image_docs:
            print(f"\nğŸ“Š å›¾ç‰‡æ–‡æ¡£è¯¦æƒ…:")
            print("-" * 50)
            
            for i, doc in enumerate(image_docs[:10], 1):  # åªæ˜¾ç¤ºå‰10ä¸ª
                caption = doc.metadata.get('img_caption', [])
                caption_text = ' '.join(caption) if caption else 'æ— æ ‡é¢˜'
                doc_name = doc.metadata.get('document_name', 'æœªçŸ¥æ–‡æ¡£')
                image_id = doc.metadata.get('image_id', 'æ— ID')
                
                print(f"{i}. å›¾ç‰‡ID: {image_id}")
                print(f"   æ ‡é¢˜: {caption_text}")
                print(f"   æ–‡æ¡£: {doc_name}")
                print()
            
            if len(image_docs) > 10:
                print(f"... è¿˜æœ‰ {len(image_docs) - 10} ä¸ªå›¾ç‰‡æ–‡æ¡£")
        
        # æµ‹è¯•å›¾ç‰‡æ£€ç´¢
        print(f"\nğŸ” æµ‹è¯•å›¾ç‰‡æ£€ç´¢:")
        print("-" * 50)
        
        # æµ‹è¯•ä¸åŒçš„æŸ¥è¯¢
        test_queries = [
            "å›¾4ï¼šå…¬å¸25Q1ä¸‹æ¸¸åº”ç”¨é¢†åŸŸç»“æ„æƒ…å†µ",
            "å›¾4ï¼šä¸­èŠ¯å›½é™…å½’æ¯å‡€åˆ©æ¶¦æƒ…å†µæ¦‚è§ˆ",
            "å›¾4",
            "å›¾1ï¼šä¸­èŠ¯å›½é™…å…¨çƒéƒ¨ç½²ç¤ºæ„å›¾"
        ]
        
        for query in test_queries:
            print(f"\næŸ¥è¯¢: {query}")
            try:
                results = vector_store.similarity_search(query, k=5)
                image_results = [doc for doc in results if doc.metadata.get('chunk_type') == 'image']
                print(f"  æ‰¾åˆ° {len(image_results)} ä¸ªå›¾ç‰‡æ–‡æ¡£")
                
                for j, doc in enumerate(image_results, 1):
                    caption = doc.metadata.get('img_caption', [])
                    caption_text = ' '.join(caption) if caption else 'æ— æ ‡é¢˜'
                    print(f"  {j}. {caption_text}")
                    
            except Exception as e:
                print(f"  æ£€ç´¢å¤±è´¥: {e}")
        
        print(f"\nâœ… æ£€æŸ¥å®Œæˆ")
        
    except Exception as e:
        print(f"âŒ æ£€æŸ¥å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    check_image_docs_in_db()
