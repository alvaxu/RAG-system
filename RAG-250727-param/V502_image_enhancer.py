"""
ç¨‹åºè¯´æ˜ï¼š

## 1. V502å›¾åƒå¢å¼ºå™¨
- ä½¿ç”¨DashScopeçš„Qwen-VL-Pluså›¾åƒå¤§æ¨¡å‹å¯¹å‘é‡æ•°æ®åº“ä¸­çš„å›¾ç‰‡è¿›è¡Œæ·±åº¦å†…å®¹è¯†åˆ«
- ç”Ÿæˆåˆ†å±‚æè¿°ï¼ˆåŸºç¡€è§†è§‰ã€å†…å®¹ç†è§£ã€æ•°æ®è¶‹åŠ¿ã€è¯­ä¹‰ç‰¹å¾ï¼‰
- æå–ç»“æ„åŒ–ä¿¡æ¯ï¼ˆå›¾è¡¨ç±»å‹ã€æ•°æ®ç‚¹ã€è¶‹åŠ¿ã€å…³é”®æ´å¯Ÿï¼‰
- å°†è¯†åˆ«ç»“æœè¿½åŠ åˆ°enhanced_descriptionå­—æ®µä¸­ï¼Œä¿ç•™åŸæœ‰ä¿¡æ¯
- ä»…æ”¯æŒæ‰¹é‡å¤„ç†ï¼Œä¸æ”¯æŒå•å¼ å›¾ç‰‡å¤„ç†
- é»˜è®¤ä½¿ç”¨config.jsonï¼Œæ— éœ€é¢å¤–æŒ‡å®š

## 2. ä¸»è¦åŠŸèƒ½
- æ™ºèƒ½è¯†åˆ«å·²å¤„ç†å›¾ç‰‡ï¼Œé¿å…é‡å¤å¤„ç†
- ä¿ç•™åŸæœ‰enhanced_descriptionä¿¡æ¯
- æ·»åŠ å¤§æ¨¡å‹ç”Ÿæˆçš„åˆ†å±‚æè¿°å’Œç»“æ„åŒ–ä¿¡æ¯
- æ”¯æŒæ‰¹é‡å¤„ç†å’Œæ–­ç‚¹ç»­ä¼ 
- ç»Ÿä¸€çš„é…ç½®ç®¡ç†å’Œé”™è¯¯å¤„ç†
"""

import os
import sys
import json
import time
import logging
import argparse
from typing import List, Dict, Any, Optional, Tuple
from pathlib import Path
from dataclasses import dataclass
import base64
import hashlib

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = os.path.dirname(os.path.abspath(__file__))
sys.path.insert(0, project_root)

try:
    import dashscope
    from dashscope import MultiModalConversation
    from langchain_community.vectorstores import FAISS
    from langchain_community.embeddings import DashScopeEmbeddings
except ImportError as e:
    print(f"âŒ ç¼ºå°‘å¿…è¦çš„ä¾èµ–åŒ…: {e}")
    print("è¯·å®‰è£…: pip install dashscope langchain-community")
    sys.exit(1)

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


@dataclass
class EnhancementResult:
    """å¢å¼ºç»“æœæ•°æ®ç±»"""
    total_images: int
    enhanced_images: int
    failed_images: int
    processing_time: float
    enhanced_descriptions: List[Dict[str, Any]]


class V502ImageEnhancer:
    """
    V502å›¾åƒå¢å¼ºå™¨ - ä½¿ç”¨Qwen-VL-Plusæ¨¡å‹å¢å¼ºå›¾ç‰‡æè¿°
    """
    
    def __init__(self):
        """
        åˆå§‹åŒ–å›¾åƒå¢å¼ºå™¨
        """
        # ä½¿ç”¨ç»Ÿä¸€é…ç½®ç®¡ç†
        self.settings = self._load_unified_config()
        self.api_key = self._get_api_key()
        if not self.api_key:
            raise ValueError("æœªæ‰¾åˆ°æœ‰æ•ˆçš„DashScope APIå¯†é’¥")
        
        self.model = "qwen-vl-plus"
        self.vector_store_path = self.settings.vector_db_dir
        
        # åˆå§‹åŒ–DashScope
        dashscope.api_key = self.api_key
        
        logger.info("V502å›¾åƒå¢å¼ºå™¨åˆå§‹åŒ–å®Œæˆ")
    
    def _load_unified_config(self) -> 'Settings':
        """
        ä½¿ç”¨ç»Ÿä¸€é…ç½®ç®¡ç†åŠ è½½é…ç½®
        :return: Settingså¯¹è±¡
        """
        try:
            from config.settings import Settings
            settings = Settings.load_from_file("config.json")
            logger.info("âœ… ä½¿ç”¨ç»Ÿä¸€é…ç½®ç®¡ç†åŠ è½½é…ç½®æˆåŠŸ")
            return settings
        except ImportError as e:
            logger.warning(f"æ— æ³•å¯¼å…¥ç»Ÿä¸€é…ç½®ç®¡ç†æ¨¡å—: {e}ï¼Œä½¿ç”¨ç®€å•é…ç½®åŠ è½½")
            return self._load_simple_config()
        except Exception as e:
            logger.warning(f"ç»Ÿä¸€é…ç½®ç®¡ç†åŠ è½½å¤±è´¥: {e}ï¼Œä½¿ç”¨ç®€å•é…ç½®åŠ è½½")
            return self._load_simple_config()
    
    def _load_simple_config(self) -> 'SimpleSettings':
        """
        ç®€å•é…ç½®åŠ è½½ï¼ˆå¤‡ç”¨æ–¹æ¡ˆï¼‰
        :return: ç®€å•é…ç½®å¯¹è±¡
        """
        class SimpleSettings:
            def __init__(self):
                self.vector_db_dir = './central/vector_db'
                self.dashscope_api_key = ''
        
        try:
            if os.path.exists("config.json"):
                with open("config.json", 'r', encoding='utf-8') as f:
                    config_data = json.load(f)
                
                settings = SimpleSettings()
                
                # åŠ è½½APIå¯†é’¥
                api_key = config_data.get('api', {}).get('dashscope_api_key', '')
                if api_key and api_key != 'ä½ çš„DashScope APIå¯†é’¥':
                    settings.dashscope_api_key = api_key
                
                # åŠ è½½è·¯å¾„é…ç½®
                vector_db_dir = config_data.get('paths', {}).get('vector_db_dir', '')
                if vector_db_dir:
                    settings.vector_db_dir = vector_db_dir
                
                logger.info("âœ… ä½¿ç”¨ç®€å•é…ç½®åŠ è½½æˆåŠŸ")
                return settings
            else:
                logger.warning("âš ï¸ config.jsonä¸å­˜åœ¨ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
                return SimpleSettings()
        except Exception as e:
            logger.warning(f"ç®€å•é…ç½®åŠ è½½å¤±è´¥: {e}ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
            return SimpleSettings()
    
    def _get_api_key(self) -> str:
        """
        è·å–DashScope APIå¯†é’¥ - ä¸ç°æœ‰ä»£ç ä¿æŒä¸€è‡´
        :return: APIå¯†é’¥
        """
        # 1. ä¼˜å…ˆä»ç»Ÿä¸€é…ç½®åŠ è½½
        if hasattr(self.settings, 'dashscope_api_key') and self.settings.dashscope_api_key:
            logger.info("âœ… ä»ç»Ÿä¸€é…ç½®åŠ è½½APIå¯†é’¥æˆåŠŸ")
            return self.settings.dashscope_api_key
        
        # 2. å¤‡é€‰ç¯å¢ƒå˜é‡
        api_key = os.getenv('MY_DASHSCOPE_API_KEY', '')
        if api_key and api_key != 'ä½ çš„APIKEY':
            logger.info("âœ… ä»ç¯å¢ƒå˜é‡åŠ è½½APIå¯†é’¥æˆåŠŸ")
            return api_key
        
        # 3. æœ€åå¤‡ç”¨
        logger.error("âŒ æœªæ‰¾åˆ°æœ‰æ•ˆçš„DashScope APIå¯†é’¥")
        return ""
    
    def _load_vector_store(self) -> Optional[FAISS]:
        """
        åŠ è½½å‘é‡æ•°æ®åº“
        :return: FAISSå‘é‡å­˜å‚¨å¯¹è±¡
        """
        try:
            if not os.path.exists(self.vector_store_path):
                logger.error(f"å‘é‡æ•°æ®åº“è·¯å¾„ä¸å­˜åœ¨: {self.vector_store_path}")
                return None
            
            embeddings = DashScopeEmbeddings(
                dashscope_api_key=self.api_key, 
                model="text-embedding-v1"
            )
            vector_store = FAISS.load_local(
                self.vector_store_path, 
                embeddings, 
                allow_dangerous_deserialization=True
            )
            logger.info(f"âœ… å‘é‡æ•°æ®åº“åŠ è½½æˆåŠŸï¼ŒåŒ…å« {len(vector_store.docstore._dict)} ä¸ªæ–‡æ¡£")
            return vector_store
        except Exception as e:
            logger.error(f"âŒ åŠ è½½å‘é‡æ•°æ®åº“å¤±è´¥: {e}")
            return None
    
    def _identify_image_documents(self, vector_store: FAISS) -> List[Tuple[str, Dict[str, Any]]]:
        """
        è¯†åˆ«å‘é‡æ•°æ®åº“ä¸­çš„å›¾ç‰‡æ–‡æ¡£
        :param vector_store: FAISSå‘é‡å­˜å‚¨å¯¹è±¡
        :return: å›¾ç‰‡æ–‡æ¡£åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ ä¸º(doc_id, doc_info)
        """
        image_docs = []
        
        try:
            for doc_id, doc in vector_store.docstore._dict.items():
                metadata = doc.metadata if hasattr(doc, 'metadata') and doc.metadata else {}
                
                # æ£€æŸ¥æ˜¯å¦ä¸ºå›¾ç‰‡ç±»å‹
                if metadata.get('chunk_type') == 'image':
                    doc_info = {
                        'doc_id': doc_id,
                        'content': doc.page_content,
                        'metadata': metadata,
                        'image_path': metadata.get('image_path', ''),
                        'document_name': metadata.get('document_name', 'æœªçŸ¥æ–‡æ¡£'),
                        'page_number': metadata.get('page_number', 1),
                        'img_caption': metadata.get('img_caption', []),
                        'img_footnote': metadata.get('img_footnote', []),
                        'enhanced_description': metadata.get('enhanced_description', ''),
                        'image_type': metadata.get('image_type', 'general'),
                        'semantic_features': metadata.get('semantic_features', {})
                    }
                    image_docs.append((doc_id, doc_info))
            
            logger.info(f"ğŸ” è¯†åˆ«åˆ° {len(image_docs)} ä¸ªå›¾ç‰‡æ–‡æ¡£")
            return image_docs
            
        except Exception as e:
            logger.error(f"âŒ è¯†åˆ«å›¾ç‰‡æ–‡æ¡£å¤±è´¥: {e}")
            return []
    
    def is_image_processed(self, doc_info: Dict[str, Any]) -> bool:
        """
        æ£€æŸ¥å›¾ç‰‡æ˜¯å¦å·²ç»é€šè¿‡V502ç¨‹åºå¤„ç†è¿‡
        :param doc_info: æ–‡æ¡£ä¿¡æ¯
        :return: Trueè¡¨ç¤ºå·²å¤„ç†ï¼ŒFalseè¡¨ç¤ºæœªå¤„ç†
        """
        metadata = doc_info.get('metadata', {})
        enhanced_description = metadata.get('enhanced_description', '')
        
        # æ£€æŸ¥V502ç‰¹æœ‰æ ‡è®°ï¼ˆæ›´ä¸¥æ ¼çš„æ£€æŸ¥ï¼‰
        v502_markers = [
            'V502_enhanced',
            'åŸºç¡€è§†è§‰æè¿°:',
            'å†…å®¹ç†è§£æè¿°:', 
            'æ•°æ®è¶‹åŠ¿æè¿°:',
            'è¯­ä¹‰ç‰¹å¾æè¿°:',
            'æ•°æ®ç‚¹:',
            'è¶‹åŠ¿åˆ†æ:',
            'å…³é”®æ´å¯Ÿ:'
        ]
        
        # æ£€æŸ¥æ˜¯å¦æœ‰V502ç‰¹æœ‰çš„æ ‡è®°
        if any(marker in enhanced_description for marker in v502_markers):
            # ä¸´æ—¶ï¼šå¦‚æœåªåŒ…å«åŸæœ‰ä¿¡æ¯ï¼Œå…è®¸é‡æ–°å¤„ç†
            if 'åŸºç¡€è§†è§‰æè¿°:' not in enhanced_description and 'å†…å®¹ç†è§£æè¿°:' not in enhanced_description:
                return False
            return True
        
        # æ£€æŸ¥æ—¶é—´æˆ³
        if metadata.get('v502_enhancement_timestamp'):
            return True
        
        # æ£€æŸ¥V502æ ‡è®°å­—æ®µ
        if metadata.get('v502_enhanced'):
            return True
        
        return False
    
    def filter_unprocessed_images(self, image_docs: List[Tuple[str, Dict[str, Any]]]) -> List[Tuple[str, Dict[str, Any]]]:
        """
        è¿‡æ»¤å‡ºæœªå¤„ç†çš„å›¾ç‰‡
        :param image_docs: æ‰€æœ‰å›¾ç‰‡æ–‡æ¡£åˆ—è¡¨
        :return: æœªå¤„ç†çš„å›¾ç‰‡æ–‡æ¡£åˆ—è¡¨
        """
        unprocessed_docs = []
        
        for doc_id, doc_info in image_docs:
            if not self.is_image_processed(doc_info):
                unprocessed_docs.append((doc_id, doc_info))
        
        logger.info(f"ğŸ“Š æ€»å›¾ç‰‡æ•°: {len(image_docs)}, æœªå¤„ç†å›¾ç‰‡æ•°: {len(unprocessed_docs)}")
        return unprocessed_docs
    
    def _encode_image_to_base64(self, image_path: str) -> str:
        """
        å°†å›¾ç‰‡ç¼–ç ä¸ºbase64å­—ç¬¦ä¸²
        :param image_path: å›¾ç‰‡è·¯å¾„
        :return: base64ç¼–ç çš„å›¾ç‰‡æ•°æ®
        """
        try:
            with open(image_path, "rb") as image_file:
                encoded_image = base64.b64encode(image_file.read()).decode('utf-8')
            return encoded_image
        except Exception as e:
            logger.error(f"ç¼–ç å›¾ç‰‡æ–‡ä»¶å¤±è´¥: {e}")
            raise
    
    def _call_qwen_vl_model(self, image_path: str) -> Optional[str]:
        """
        è°ƒç”¨Qwen-VL-Plusæ¨¡å‹è¿›è¡Œå›¾åƒç†è§£
        :param image_path: å›¾ç‰‡è·¯å¾„
        :return: æ¨¡å‹å“åº”
        """
        try:
            # ç¼–ç å›¾ç‰‡
            base64_image = self._encode_image_to_base64(image_path)
            # æ·»åŠ data URLå‰ç¼€
            image_data_url = f"data:image/jpeg;base64,{base64_image}"
            
            # æ„å»ºæç¤ºè¯
            prompt = """è¯·è¯¦ç»†åˆ†æè¿™å¼ å›¾ç‰‡çš„å†…å®¹ï¼ŒåŒ…æ‹¬ï¼š

1. åŸºç¡€è§†è§‰æè¿°ï¼šé¢œè‰²ã€å¸ƒå±€ã€ä¸»è¦å¯¹è±¡ã€åœºæ™¯ç­‰
2. å†…å®¹ç†è§£æè¿°ï¼šå›¾ç‰‡å±•ç¤ºçš„åœºæ™¯ã€æ´»åŠ¨ã€å…³ç³»ç­‰
3. æ•°æ®è¶‹åŠ¿æè¿°ï¼šå¦‚æœæ˜¯å›¾è¡¨ï¼Œè¯·è¯†åˆ«å›¾è¡¨ç±»å‹ã€æ•°æ®è¶‹åŠ¿ã€å…³é”®æ•°å€¼ç­‰
4. è¯­ä¹‰ç‰¹å¾æè¿°ï¼šå›¾ç‰‡çš„ä¸»é¢˜ã€æƒ…æ„Ÿã€ä¸Šä¸‹æ–‡ç­‰

è¯·æŒ‰ç…§ä»¥ä¸‹æ ¼å¼å›ç­”ï¼š
- åŸºç¡€è§†è§‰æè¿°ï¼š[æè¿°]
- å†…å®¹ç†è§£æè¿°ï¼š[æè¿°]
- æ•°æ®è¶‹åŠ¿æè¿°ï¼š[æè¿°]
- è¯­ä¹‰ç‰¹å¾æè¿°ï¼š[æè¿°]
- å›¾è¡¨ç±»å‹ï¼š[ç±»å‹]
- æ•°æ®ç‚¹ï¼š[å…³é”®æ•°æ®]
- è¶‹åŠ¿åˆ†æï¼š[è¶‹åŠ¿]
- å…³é”®æ´å¯Ÿï¼š[æ´å¯Ÿ]"""
            
            # è°ƒç”¨å¤šæ¨¡æ€å¯¹è¯æ¨¡å‹
            messages = [
                {
                    'role': 'user',
                    'content': [
                        {'text': prompt},
                        {'image': image_data_url}
                    ]
                }
            ]
            
            # è°ƒç”¨æ¨¡å‹
            response = MultiModalConversation.call(
                model=self.model,
                messages=messages,
                max_tokens=1000,
                temperature=0.1
            )
            
            if hasattr(response, 'status_code') and response.status_code == 200:
                if hasattr(response, 'output') and hasattr(response.output, 'choices'):
                    # å¤„ç†choicesæ ¼å¼
                    choices = response.output.choices
                    if choices and len(choices) > 0:
                        choice = choices[0]
                        if hasattr(choice, 'message') and hasattr(choice.message, 'content'):
                            content = choice.message.content
                            if isinstance(content, list) and len(content) > 0:
                                # å¦‚æœæ˜¯åˆ—è¡¨æ ¼å¼ï¼Œå–ç¬¬ä¸€ä¸ªtextå†…å®¹
                                for item in content:
                                    if isinstance(item, dict) and 'text' in item:
                                        return item['text']
                            elif isinstance(content, str):
                                return content
                        elif hasattr(choice, 'message') and hasattr(choice.message, 'text'):
                            return choice.message.text
                elif hasattr(response, 'output') and hasattr(response.output, 'text'):
                    return response.output.text
                else:
                    logger.error(f"å“åº”æ ¼å¼ä¸æ­£ç¡®: {response}")
                    return None
            elif hasattr(response, 'status_code'):
                logger.error(f"æ¨¡å‹è°ƒç”¨å¤±è´¥: {response.status_code} - {getattr(response, 'message', 'æœªçŸ¥é”™è¯¯')}")
                return None
            else:
                logger.error(f"å“åº”æ ¼å¼ä¸æ­£ç¡®: {response}")
                return None
                
        except Exception as e:
            logger.error(f"è°ƒç”¨Qwen-VLæ¨¡å‹å¤±è´¥: {e}")
            return None
    
    def _generate_layered_descriptions(self, image_path: str) -> Dict[str, str]:
        """
        ç”Ÿæˆåˆ†å±‚æè¿°
        :param image_path: å›¾ç‰‡è·¯å¾„
        :return: åˆ†å±‚æè¿°å­—å…¸
        """
        try:
            # è°ƒç”¨Qwen-VL-Plusæ¨¡å‹
            response = self._call_qwen_vl_model(image_path)
            
            if not response:
                return {}
            
            # è§£æå“åº”å¹¶ç”Ÿæˆåˆ†å±‚æè¿°
            descriptions = {}
            
            # æå–åŸºç¡€è§†è§‰æè¿°ï¼ˆæ”¯æŒå¤šç§æ ¼å¼ï¼‰
            if 'åŸºç¡€è§†è§‰æè¿°' in response:
                # å¤„ç†Markdownæ ¼å¼
                if '**åŸºç¡€è§†è§‰æè¿°**' in response:
                    start = response.find('**åŸºç¡€è§†è§‰æè¿°**') + len('**åŸºç¡€è§†è§‰æè¿°**')
                else:
                    start = response.find('åŸºç¡€è§†è§‰æè¿°') + len('åŸºç¡€è§†è§‰æè¿°')
                
                # æŸ¥æ‰¾ç»“æŸä½ç½®
                end_markers = ['**å†…å®¹ç†è§£æè¿°**', 'å†…å®¹ç†è§£æè¿°', '- å†…å®¹ç†è§£æè¿°', '\n\n']
                end = len(response)
                for marker in end_markers:
                    pos = response.find(marker, start)
                    if pos != -1 and pos < end:
                        end = pos
                
                descriptions['åŸºç¡€è§†è§‰æè¿°'] = response[start:end].strip().strip('ï¼š').strip()
            
            # æå–å†…å®¹ç†è§£æè¿°
            if 'å†…å®¹ç†è§£æè¿°' in response:
                if '**å†…å®¹ç†è§£æè¿°**' in response:
                    start = response.find('**å†…å®¹ç†è§£æè¿°**') + len('**å†…å®¹ç†è§£æè¿°**')
                else:
                    start = response.find('å†…å®¹ç†è§£æè¿°') + len('å†…å®¹ç†è§£æè¿°')
                
                end_markers = ['**æ•°æ®è¶‹åŠ¿æè¿°**', 'æ•°æ®è¶‹åŠ¿æè¿°', '- æ•°æ®è¶‹åŠ¿æè¿°', '\n\n']
                end = len(response)
                for marker in end_markers:
                    pos = response.find(marker, start)
                    if pos != -1 and pos < end:
                        end = pos
                
                descriptions['å†…å®¹ç†è§£æè¿°'] = response[start:end].strip().strip('ï¼š').strip()
            
            # æå–æ•°æ®è¶‹åŠ¿æè¿°
            if 'æ•°æ®è¶‹åŠ¿æè¿°' in response:
                if '**æ•°æ®è¶‹åŠ¿æè¿°**' in response:
                    start = response.find('**æ•°æ®è¶‹åŠ¿æè¿°**') + len('**æ•°æ®è¶‹åŠ¿æè¿°**')
                else:
                    start = response.find('æ•°æ®è¶‹åŠ¿æè¿°') + len('æ•°æ®è¶‹åŠ¿æè¿°')
                
                end_markers = ['**è¯­ä¹‰ç‰¹å¾æè¿°**', 'è¯­ä¹‰ç‰¹å¾æè¿°', '- è¯­ä¹‰ç‰¹å¾æè¿°', '\n\n']
                end = len(response)
                for marker in end_markers:
                    pos = response.find(marker, start)
                    if pos != -1 and pos < end:
                        end = pos
                
                descriptions['æ•°æ®è¶‹åŠ¿æè¿°'] = response[start:end].strip().strip('ï¼š').strip()
            
            # æå–è¯­ä¹‰ç‰¹å¾æè¿°
            if 'è¯­ä¹‰ç‰¹å¾æè¿°' in response:
                if '**è¯­ä¹‰ç‰¹å¾æè¿°**' in response:
                    start = response.find('**è¯­ä¹‰ç‰¹å¾æè¿°**') + len('**è¯­ä¹‰ç‰¹å¾æè¿°**')
                else:
                    start = response.find('è¯­ä¹‰ç‰¹å¾æè¿°') + len('è¯­ä¹‰ç‰¹å¾æè¿°')
                
                end_markers = ['**å›¾è¡¨ç±»å‹**', 'å›¾è¡¨ç±»å‹', '- å›¾è¡¨ç±»å‹', '\n\n']
                end = len(response)
                for marker in end_markers:
                    pos = response.find(marker, start)
                    if pos != -1 and pos < end:
                        end = pos
                
                descriptions['è¯­ä¹‰ç‰¹å¾æè¿°'] = response[start:end].strip().strip('ï¼š').strip()
            
            return descriptions
            
        except Exception as e:
            logger.error(f"ç”Ÿæˆåˆ†å±‚æè¿°å¤±è´¥: {e}")
            return {}
    
    def _extract_structured_info(self, image_path: str) -> Dict[str, Any]:
        """
        æå–ç»“æ„åŒ–ä¿¡æ¯
        :param image_path: å›¾ç‰‡è·¯å¾„
        :return: ç»“æ„åŒ–ä¿¡æ¯å­—å…¸
        """
        try:
            # è°ƒç”¨Qwen-VL-Plusæ¨¡å‹
            response = self._call_qwen_vl_model(image_path)
            
            if not response:
                return {}
            
            # è§£æå“åº”å¹¶æå–ç»“æ„åŒ–ä¿¡æ¯
            structured_info = {}
            
            # æå–å›¾è¡¨ç±»å‹
            if 'å›¾è¡¨ç±»å‹' in response:
                if '**å›¾è¡¨ç±»å‹**' in response:
                    start = response.find('**å›¾è¡¨ç±»å‹**') + len('**å›¾è¡¨ç±»å‹**')
                else:
                    start = response.find('å›¾è¡¨ç±»å‹') + len('å›¾è¡¨ç±»å‹')
                
                end_markers = ['**æ•°æ®ç‚¹**', 'æ•°æ®ç‚¹', '- æ•°æ®ç‚¹', '\n\n']
                end = len(response)
                for marker in end_markers:
                    pos = response.find(marker, start)
                    if pos != -1 and pos < end:
                        end = pos
                
                structured_info['chart_type'] = response[start:end].strip().strip('ï¼š').strip()
            
            # æå–æ•°æ®ç‚¹
            if 'æ•°æ®ç‚¹' in response:
                if '**æ•°æ®ç‚¹**' in response:
                    start = response.find('**æ•°æ®ç‚¹**') + len('**æ•°æ®ç‚¹**')
                else:
                    start = response.find('æ•°æ®ç‚¹') + len('æ•°æ®ç‚¹')
                
                end_markers = ['**è¶‹åŠ¿åˆ†æ**', 'è¶‹åŠ¿åˆ†æ', '- è¶‹åŠ¿åˆ†æ', '\n\n']
                end = len(response)
                for marker in end_markers:
                    pos = response.find(marker, start)
                    if pos != -1 and pos < end:
                        end = pos
                
                data_points_str = response[start:end].strip().strip('ï¼š').strip()
                structured_info['data_points'] = [point.strip() for point in data_points_str.split(',') if point.strip()]
            
            # æå–è¶‹åŠ¿åˆ†æ
            if 'è¶‹åŠ¿åˆ†æ' in response:
                if '**è¶‹åŠ¿åˆ†æ**' in response:
                    start = response.find('**è¶‹åŠ¿åˆ†æ**') + len('**è¶‹åŠ¿åˆ†æ**')
                else:
                    start = response.find('è¶‹åŠ¿åˆ†æ') + len('è¶‹åŠ¿åˆ†æ')
                
                end_markers = ['**å…³é”®æ´å¯Ÿ**', 'å…³é”®æ´å¯Ÿ', '- å…³é”®æ´å¯Ÿ', '\n\n']
                end = len(response)
                for marker in end_markers:
                    pos = response.find(marker, start)
                    if pos != -1 and pos < end:
                        end = pos
                
                structured_info['trends'] = response[start:end].strip().strip('ï¼š').strip()
            
            # æå–å…³é”®æ´å¯Ÿ
            if 'å…³é”®æ´å¯Ÿ' in response:
                if '**å…³é”®æ´å¯Ÿ**' in response:
                    start = response.find('**å…³é”®æ´å¯Ÿ**') + len('**å…³é”®æ´å¯Ÿ**')
                else:
                    start = response.find('å…³é”®æ´å¯Ÿ') + len('å…³é”®æ´å¯Ÿ')
                
                end_markers = ['\n\n', '\n', '']
                end = len(response)
                for marker in end_markers:
                    pos = response.find(marker, start)
                    if pos != -1 and pos < end:
                        end = pos
                
                structured_info['key_insights'] = response[start:end].strip().strip('ï¼š').strip()
            
            return structured_info
            
        except Exception as e:
            logger.error(f"æå–ç»“æ„åŒ–ä¿¡æ¯å¤±è´¥: {e}")
            return {}
    
    def _merge_descriptions(self, original_description: str, layered_descriptions: Dict[str, str], structured_info: Dict[str, Any]) -> str:
        """
        æ™ºèƒ½åˆå¹¶åŸæœ‰æè¿°å’Œæ–°ç”Ÿæˆçš„æè¿°
        :param original_description: åŸæœ‰æè¿°
        :param layered_descriptions: åˆ†å±‚æè¿°
        :param structured_info: ç»“æ„åŒ–ä¿¡æ¯
        :return: åˆå¹¶åçš„æè¿°
        """
        description_parts = []
        
        # 1. ä¿ç•™åŸæœ‰ä¿¡æ¯ï¼ˆå¦‚æœå­˜åœ¨ä¸”ä¸æ˜¯V502ç”Ÿæˆçš„ï¼‰
        if original_description and 'V502_enhanced' not in original_description:
            description_parts.append(f"åŸæœ‰ä¿¡æ¯: {original_description}")
        elif original_description:
            # å¦‚æœåŸæœ‰æè¿°å·²ç»åŒ…å«V502_enhancedæ ‡è®°ï¼Œä»ç„¶ä¿ç•™åŸæœ‰ä¿¡æ¯
            description_parts.append(f"åŸæœ‰ä¿¡æ¯: {original_description}")
        
        # 2. æ·»åŠ åˆ†å±‚æè¿°
        for layer, desc in layered_descriptions.items():
            if desc:
                description_parts.append(f"{layer}: {desc}")
        
        # 3. æ·»åŠ ç»“æ„åŒ–ä¿¡æ¯
        for key, value in structured_info.items():
            if value:
                if isinstance(value, list):
                    value_str = ', '.join(map(str, value))
                else:
                    value_str = str(value)
                description_parts.append(f"{key}: {value_str}")
        
        # 4. æ·»åŠ å¤„ç†æ ‡è®°ï¼ˆå¦‚æœè¿˜æ²¡æœ‰çš„è¯ï¼‰
        if "V502_enhanced" not in " | ".join(description_parts):
            description_parts.append("V502_enhanced")
        
        return " | ".join(description_parts)
    
    def enhance_single_image(self, doc_id: str, doc_info: Dict[str, Any], vector_store: FAISS) -> Optional[Dict[str, Any]]:
        """
        å¢å¼ºå•ä¸ªå›¾ç‰‡ï¼Œä¿ç•™åŸæœ‰ä¿¡æ¯
        :param doc_id: æ–‡æ¡£ID
        :param doc_info: æ–‡æ¡£ä¿¡æ¯
        :param vector_store: FAISSå‘é‡å­˜å‚¨å¯¹è±¡
        :return: å¢å¼ºåçš„ä¿¡æ¯
        """
        try:
            image_path = doc_info.get('image_path', '')
            
            if not image_path or not os.path.exists(image_path):
                logger.warning(f"å›¾ç‰‡æ–‡ä»¶ä¸å­˜åœ¨: {image_path}")
                return None
            
            # è·å–åŸæœ‰ä¿¡æ¯
            original_description = doc_info.get('enhanced_description', '')
            
            # ç”Ÿæˆæ–°çš„åˆ†å±‚æè¿°å’Œç»“æ„åŒ–ä¿¡æ¯
            layered_descriptions = self._generate_layered_descriptions(image_path)
            structured_info = self._extract_structured_info(image_path)
            
            # æ„å»ºæ–°çš„å¢å¼ºæè¿°ï¼Œä¿ç•™åŸæœ‰ä¿¡æ¯
            new_enhanced_description = self._merge_descriptions(
                original_description, 
                layered_descriptions, 
                structured_info
            )
            
            # æ›´æ–°å…ƒæ•°æ®
            updated_metadata = doc_info['metadata'].copy()
            updated_metadata['enhanced_description'] = new_enhanced_description
            updated_metadata['v502_layered_descriptions'] = layered_descriptions
            updated_metadata['v502_structured_info'] = structured_info
            updated_metadata['v502_enhancement_timestamp'] = int(time.time())
            updated_metadata['v502_enhanced'] = True
            
            # æ›´æ–°æ–‡æ¡£
            doc = vector_store.docstore._dict[doc_id]
            doc.metadata = updated_metadata
            
            return {
                'doc_id': doc_id,
                'image_path': image_path,
                'original_description': original_description,
                'enhanced_description': new_enhanced_description,
                'layered_descriptions': layered_descriptions,
                'structured_info': structured_info,
                'document_name': doc_info.get('document_name', 'æœªçŸ¥æ–‡æ¡£')
            }
            
        except Exception as e:
            logger.error(f"å¢å¼ºå•ä¸ªå›¾ç‰‡å¤±è´¥: {e}")
            return None
    
    def _save_vector_store(self, vector_store: FAISS) -> bool:
        """
        ä¿å­˜å‘é‡æ•°æ®åº“
        :param vector_store: FAISSå‘é‡å­˜å‚¨å¯¹è±¡
        :return: æ˜¯å¦ä¿å­˜æˆåŠŸ
        """
        try:
            vector_store.save_local(self.vector_store_path)
            logger.info("âœ… å‘é‡æ•°æ®åº“ä¿å­˜æˆåŠŸ")
            return True
        except Exception as e:
            logger.error(f"âŒ ä¿å­˜å‘é‡æ•°æ®åº“å¤±è´¥: {e}")
            return False
    
    def enhance_all_images(self, skip_processed: bool = True, batch_size: int = 10) -> EnhancementResult:
        """
        å¢å¼ºæ‰€æœ‰å›¾ç‰‡
        :param skip_processed: æ˜¯å¦è·³è¿‡å·²å¤„ç†çš„å›¾ç‰‡
        :param batch_size: æ‰¹æ¬¡å¤§å°
        :return: å¢å¼ºç»“æœ
        """
        start_time = time.time()
        
        # 1. åŠ è½½å‘é‡æ•°æ®åº“
        vector_store = self._load_vector_store()
        if not vector_store:
            raise ValueError("æ— æ³•åŠ è½½å‘é‡æ•°æ®åº“")
        
        # 2. è¯†åˆ«å›¾ç‰‡æ–‡æ¡£
        all_image_docs = self._identify_image_documents(vector_store)
        
        if not all_image_docs:
            logger.warning("âš ï¸ æœªæ‰¾åˆ°å›¾ç‰‡æ–‡æ¡£")
            return EnhancementResult(
                total_images=0,
                enhanced_images=0,
                failed_images=0,
                processing_time=time.time() - start_time,
                enhanced_descriptions=[]
            )
        
        # 3. è¿‡æ»¤æœªå¤„ç†å›¾ç‰‡ï¼ˆå¦‚æœéœ€è¦ï¼‰
        if skip_processed:
            image_docs = self.filter_unprocessed_images(all_image_docs)
            logger.info(f"ğŸ” è·³è¿‡å·²å¤„ç†å›¾ç‰‡ï¼Œå‰©ä½™ {len(image_docs)} ä¸ªå›¾ç‰‡éœ€è¦å¤„ç†")
        else:
            image_docs = all_image_docs
            logger.info(f"ğŸ” å¤„ç†æ‰€æœ‰å›¾ç‰‡ï¼Œå…± {len(image_docs)} ä¸ªå›¾ç‰‡")
        
        # 4. æ‰¹é‡å¤„ç†å›¾ç‰‡
        enhanced_count = 0
        failed_count = 0
        enhanced_descriptions = []
        
        for i in range(0, len(image_docs), batch_size):
            batch = image_docs[i:i + batch_size]
            batch_num = i // batch_size + 1
            total_batches = (len(image_docs) + batch_size - 1) // batch_size
            
            logger.info(f"ğŸ”„ å¤„ç†æ‰¹æ¬¡ {batch_num}/{total_batches}ï¼Œå…± {len(batch)} ä¸ªå›¾ç‰‡")
            
            for doc_id, doc_info in batch:
                try:
                    enhanced_info = self.enhance_single_image(doc_id, doc_info, vector_store)
                    if enhanced_info:
                        enhanced_descriptions.append(enhanced_info)
                        enhanced_count += 1
                        logger.info(f"âœ… æˆåŠŸå¢å¼ºå›¾ç‰‡: {doc_info.get('image_path', 'unknown')}")
                    else:
                        failed_count += 1
                        logger.warning(f"âŒ å¢å¼ºå¤±è´¥: {doc_info.get('image_path', 'unknown')}")
                except Exception as e:
                    failed_count += 1
                    logger.error(f"âŒ å¤„ç†å›¾ç‰‡æ—¶å‡ºé”™: {e}")
                    continue
            
            # æ¯æ‰¹æ¬¡ä¿å­˜ä¸€æ¬¡
            if enhanced_count > 0:
                self._save_vector_store(vector_store)
        
        # 5. æœ€ç»ˆä¿å­˜
        if enhanced_count > 0:
            self._save_vector_store(vector_store)
        
        processing_time = time.time() - start_time
        
        logger.info(f"ğŸ‰ å›¾ç‰‡å¢å¼ºå®Œæˆ")
        logger.info(f"ğŸ“Š æ€»å›¾ç‰‡æ•°: {len(image_docs)}")
        logger.info(f"âœ… æˆåŠŸå¢å¼º: {enhanced_count}")
        logger.info(f"âŒ å¤„ç†å¤±è´¥: {failed_count}")
        logger.info(f"â±ï¸ å¤„ç†æ—¶é—´: {processing_time:.2f}ç§’")
        
        return EnhancementResult(
            total_images=len(image_docs),
            enhanced_images=enhanced_count,
            failed_images=failed_count,
            processing_time=processing_time,
            enhanced_descriptions=enhanced_descriptions
        )

    def query_enhanced_descriptions(self, limit: int = 10, show_details: bool = False) -> List[Dict[str, Any]]:
        """
        æŸ¥è¯¢enhanced_descriptionå­—æ®µå†…å®¹
        :param limit: é™åˆ¶è¿”å›çš„å›¾ç‰‡æ•°é‡ï¼Œé»˜è®¤10ä¸ª
        :param show_details: æ˜¯å¦æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯ï¼Œé»˜è®¤False
        :return: å›¾ç‰‡æè¿°ä¿¡æ¯åˆ—è¡¨
        """
        try:
            # 1. åŠ è½½å‘é‡æ•°æ®åº“
            vector_store = self._load_vector_store()
            if not vector_store:
                logger.error("âŒ æ— æ³•åŠ è½½å‘é‡æ•°æ®åº“")
                return []
            
            # 2. è¯†åˆ«å›¾ç‰‡æ–‡æ¡£
            image_docs = self._identify_image_documents(vector_store)
            
            if not image_docs:
                logger.warning("âš ï¸ æœªæ‰¾åˆ°å›¾ç‰‡æ–‡æ¡£")
                return []
            
            # 3. æå–enhanced_descriptionä¿¡æ¯
            descriptions = []
            for doc_id, doc_info in image_docs[:limit]:
                enhanced_description = doc_info.get('enhanced_description', '')
                metadata = doc_info.get('metadata', {})
                
                description_info = {
                    'doc_id': doc_id,
                    'image_path': doc_info.get('image_path', ''),
                    'document_name': doc_info.get('document_name', 'æœªçŸ¥æ–‡æ¡£'),
                    'page_number': doc_info.get('page_number', 1),
                    'enhanced_description': enhanced_description,
                    'description_length': len(enhanced_description),
                    'v502_enhanced': metadata.get('v502_enhanced', False),
                    'v502_enhancement_timestamp': metadata.get('v502_enhancement_timestamp', None)
                }
                
                # å¦‚æœéœ€è¦æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯
                if show_details:
                    description_info.update({
                        'img_caption': doc_info.get('img_caption', []),
                        'img_footnote': doc_info.get('img_footnote', []),
                        'image_type': doc_info.get('image_type', 'general'),
                        'v502_layered_descriptions': metadata.get('v502_layered_descriptions', {}),
                        'v502_structured_info': metadata.get('v502_structured_info', {})
                    })
                
                descriptions.append(description_info)
            
            logger.info(f"ğŸ” æŸ¥è¯¢åˆ° {len(descriptions)} ä¸ªå›¾ç‰‡çš„enhanced_descriptionä¿¡æ¯")
            return descriptions
            
        except Exception as e:
            logger.error(f"âŒ æŸ¥è¯¢enhanced_descriptionå¤±è´¥: {e}")
            return []
    
    def print_enhanced_descriptions(self, limit: int = 10, show_details: bool = False):
        """
        æ‰“å°enhanced_descriptionå­—æ®µå†…å®¹
        :param limit: é™åˆ¶æ˜¾ç¤ºçš„å›¾ç‰‡æ•°é‡ï¼Œé»˜è®¤10ä¸ª
        :param show_details: æ˜¯å¦æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯ï¼Œé»˜è®¤False
        """
        descriptions = self.query_enhanced_descriptions(limit, show_details)
        
        if not descriptions:
            print("âŒ æœªæ‰¾åˆ°å›¾ç‰‡æè¿°ä¿¡æ¯")
            return
        
        print(f"\nğŸ“Š å›¾ç‰‡enhanced_descriptionæŸ¥è¯¢ç»“æœï¼ˆæ˜¾ç¤ºå‰{len(descriptions)}ä¸ªï¼‰:")
        print("=" * 80)
        
        for i, desc_info in enumerate(descriptions, 1):
            print(f"\nğŸ“· å›¾ç‰‡ {i}: {desc_info['image_path']}")
            print(f"   æ–‡æ¡£åç§°: {desc_info['document_name']}")
            print(f"   é¡µé¢: {desc_info['page_number']}")
            print(f"   æè¿°é•¿åº¦: {desc_info['description_length']} å­—ç¬¦")
            print(f"   V502å¢å¼º: {desc_info['v502_enhanced']}")
            
            if desc_info['v502_enhancement_timestamp']:
                timestamp = time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(desc_info['v502_enhancement_timestamp']))
                print(f"   å¢å¼ºæ—¶é—´: {timestamp}")
            
            # æ˜¾ç¤ºenhanced_descriptionå†…å®¹
            enhanced_desc = desc_info['enhanced_description']
            if enhanced_desc:
                print(f"   å¢å¼ºæè¿°:")
                # å¦‚æœæè¿°å¤ªé•¿ï¼Œåˆ†æ®µæ˜¾ç¤º
                if len(enhanced_desc) > 200:
                    print(f"      {enhanced_desc[:200]}...")
                    print(f"      ... (å®Œæ•´å†…å®¹è¯·æŸ¥çœ‹è¯¦ç»†ä¿¡æ¯)")
                else:
                    print(f"      {enhanced_desc}")
            else:
                print(f"   å¢å¼ºæè¿°: æ— ")
            
            # å¦‚æœéœ€è¦æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯
            if show_details:
                print(f"   è¯¦ç»†ä¿¡æ¯:")
                if desc_info.get('img_caption'):
                    print(f"     å›¾ç‰‡æ ‡é¢˜: {desc_info['img_caption']}")
                if desc_info.get('img_footnote'):
                    print(f"     å›¾ç‰‡è„šæ³¨: {desc_info['img_footnote']}")
                if desc_info.get('v502_layered_descriptions'):
                    print(f"     åˆ†å±‚æè¿°: {desc_info['v502_layered_descriptions']}")
                if desc_info.get('v502_structured_info'):
                    print(f"     ç»“æ„åŒ–ä¿¡æ¯: {desc_info['v502_structured_info']}")
            
            print("-" * 60)
        
        print(f"\nğŸ“ˆ ç»Ÿè®¡ä¿¡æ¯:")
        print(f"   æ€»æŸ¥è¯¢æ•°: {len(descriptions)}")
        print(f"   æœ‰V502å¢å¼º: {sum(1 for d in descriptions if d['v502_enhanced'])}")
        print(f"   æ— V502å¢å¼º: {sum(1 for d in descriptions if not d['v502_enhanced'])}")
        print(f"   å¹³å‡æè¿°é•¿åº¦: {sum(d['description_length'] for d in descriptions) / len(descriptions):.1f} å­—ç¬¦")


def main():
    """
    ä¸»å‡½æ•°
    """
    parser = argparse.ArgumentParser(description='V502å›¾åƒå¢å¼ºå™¨ - ä½¿ç”¨Qwen-VL-Plusæ¨¡å‹å¢å¼ºå›¾ç‰‡æè¿°')
    parser.add_argument('--skip_processed', action='store_true', default=True,
                       help='æ˜¯å¦è·³è¿‡å·²å¤„ç†çš„å›¾ç‰‡ï¼ˆé»˜è®¤ï¼šæ˜¯ï¼‰')
    parser.add_argument('--batch_size', type=int, default=10,
                       help='æ‰¹æ¬¡å¤§å°ï¼ˆé»˜è®¤ï¼š10ï¼‰')
    parser.add_argument('--config', type=str, default='config.json',
                       help='é…ç½®æ–‡ä»¶è·¯å¾„ï¼ˆé»˜è®¤ï¼šconfig.jsonï¼‰')
    
    # æ–°å¢æŸ¥è¯¢åŠŸèƒ½å‚æ•°
    parser.add_argument('--query', action='store_true',
                       help='æŸ¥è¯¢enhanced_descriptionå­—æ®µå†…å®¹')
    parser.add_argument('--limit', type=int, default=10,
                       help='æŸ¥è¯¢æ—¶é™åˆ¶è¿”å›çš„å›¾ç‰‡æ•°é‡ï¼ˆé»˜è®¤ï¼š10ï¼‰')
    parser.add_argument('--show_details', action='store_true',
                       help='æŸ¥è¯¢æ—¶æ˜¯å¦æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯')
    
    args = parser.parse_args()
    
    try:
        # åˆå§‹åŒ–å¢å¼ºå™¨
        enhancer = V502ImageEnhancer()
        
        # å¦‚æœæŒ‡å®šäº†æŸ¥è¯¢å‚æ•°ï¼Œæ‰§è¡ŒæŸ¥è¯¢åŠŸèƒ½
        if args.query:
            enhancer.print_enhanced_descriptions(limit=args.limit, show_details=args.show_details)
            return
        
        # å¦åˆ™æ‰§è¡Œå¢å¼ºåŠŸèƒ½
        results = enhancer.enhance_all_images(
            skip_processed=args.skip_processed,
            batch_size=args.batch_size
        )
        
        # è¾“å‡ºç»“æœ
        print(f"\nğŸ‰ V502å›¾åƒå¢å¼ºå®Œæˆï¼")
        print(f"ğŸ“Š æ€»å›¾ç‰‡æ•°: {results.total_images}")
        print(f"âœ… æˆåŠŸå¢å¼º: {results.enhanced_images}")
        print(f"âŒ å¤„ç†å¤±è´¥: {results.failed_images}")
        print(f"â±ï¸ å¤„ç†æ—¶é—´: {results.processing_time:.2f}ç§’")
        
        if results.enhanced_images > 0:
            print(f"ğŸ“ˆ æˆåŠŸç‡: {results.enhanced_images / results.total_images * 100:.1f}%")
        
    except Exception as e:
        logger.error(f"âŒ ç¨‹åºæ‰§è¡Œå¤±è´¥: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()
