#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æµ‹è¯•1ï¼šmultimodal-embedding-v1æ–‡æœ¬è¾“å…¥èƒ½åŠ›éªŒè¯

æµ‹è¯•ç›®æ ‡ï¼š
1. ç¡®è®¤multimodal-embedding-v1èƒ½å¦æ¥å—æ–‡æœ¬è¾“å…¥å¹¶ç”Ÿæˆå‘é‡
2. éªŒè¯è¿”å›å‘é‡çš„ç»´åº¦å’Œè´¨é‡
3. ä¸å·²çŸ¥å›¾ç‰‡å‘é‡è¿›è¡Œç›¸ä¼¼åº¦è®¡ç®—éªŒè¯
"""

import os
import sys
import time
import logging
from typing import List, Dict, Any

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.insert(0, project_root)

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def test_multimodal_text_input():
    """æµ‹è¯•multimodal-embedding-v1çš„æ–‡æœ¬è¾“å…¥èƒ½åŠ›"""
    print("="*60)
    print("ğŸ§ª æµ‹è¯•1ï¼šmultimodal-embedding-v1æ–‡æœ¬è¾“å…¥èƒ½åŠ›éªŒè¯")
    print("="*60)
    
    try:
        # 1. å¯¼å…¥å¿…è¦çš„æ¨¡å—
        print("ğŸ“¦ å¯¼å…¥å¿…è¦æ¨¡å—...")
        from langchain_community.vectorstores import FAISS
        import dashscope
        from config.api_key_manager import get_dashscope_api_key
        from config.settings import Settings
        
        print("âœ… æ¨¡å—å¯¼å…¥æˆåŠŸ")
        
        # 2. è·å–APIå¯†é’¥
        print("ğŸ”‘ è·å–APIå¯†é’¥...")
        config = Settings.load_from_file('config.json')
        api_key = get_dashscope_api_key(config.dashscope_api_key)
        
        if not api_key:
            print("âŒ æœªæ‰¾åˆ°æœ‰æ•ˆçš„DashScope APIå¯†é’¥")
            return False
        
        print("âœ… APIå¯†é’¥è·å–æˆåŠŸ")
        
        # 3. åˆå§‹åŒ–multimodal embeddings
        print("ğŸš€ åˆå§‹åŒ–multimodal embeddings...")
        dashscope.api_key = api_key
        print("âœ… multimodal embeddingsåˆå§‹åŒ–æˆåŠŸ")
        
        # 4. æµ‹è¯•æ–‡æœ¬è¾“å…¥
        print("ğŸ“ æµ‹è¯•æ–‡æœ¬è¾“å…¥...")
        test_queries = [
            "ä¸­èŠ¯å›½é™…çš„è´¢åŠ¡å›¾è¡¨",
            "åŠå¯¼ä½“åˆ¶é€ å·¥è‰ºæµç¨‹å›¾",
            "æ™¶åœ†ä»£å·¥äº§èƒ½åˆ©ç”¨ç‡å›¾è¡¨",
            "èŠ¯ç‰‡è‰¯ç‡ç»Ÿè®¡è¡¨"
        ]
        
        text_embeddings = []
        for i, query in enumerate(test_queries, 1):
            print(f"   å¤„ç†æŸ¥è¯¢ {i}: {query}")
            try:
                # ç”Ÿæˆæ–‡æœ¬å‘é‡
                from dashscope import MultiModalEmbedding
                result = MultiModalEmbedding.call(
                    model='multimodal-embedding-v1',
                    input=[{'text': query}]
                )
                if result.status_code == 200:
                    # ä»æ­£ç¡®çš„è·¯å¾„æå–å‘é‡
                    embedding = result.output['embeddings'][0]['embedding']
                else:
                    raise Exception(f"APIè°ƒç”¨å¤±è´¥: {result}")
                text_embeddings.append(embedding)
                
                print(f"   âœ… æŸ¥è¯¢ {i} å‘é‡ç”ŸæˆæˆåŠŸï¼Œç»´åº¦: {len(embedding)}")
                
                # æ£€æŸ¥å‘é‡è´¨é‡ï¼ˆä¸åº”è¯¥å…¨æ˜¯0æˆ–ç›¸åŒå€¼ï¼‰
                unique_values = len(set(embedding))
                embedding_sum = sum(embedding)
                embedding_norm = sum(x*x for x in embedding) ** 0.5
                
                print(f"   ğŸ“Š å‘é‡ç»Ÿè®¡: å”¯ä¸€å€¼={unique_values}, æ€»å’Œ={embedding_sum:.3f}, èŒƒæ•°={embedding_norm:.3f}")
                
                if unique_values < 10 or embedding_norm < 0.1:
                    print(f"   âš ï¸ è­¦å‘Šï¼šå‘é‡è´¨é‡å¯èƒ½æœ‰é—®é¢˜")
                
            except Exception as e:
                print(f"   âŒ æŸ¥è¯¢ {i} å‘é‡ç”Ÿæˆå¤±è´¥: {e}")
                return False
        
        print(f"âœ… æ‰€æœ‰ {len(test_queries)} ä¸ªæŸ¥è¯¢çš„å‘é‡ç”ŸæˆæˆåŠŸ")
        
        # 5. éªŒè¯å‘é‡ä¸€è‡´æ€§
        print("ğŸ” éªŒè¯å‘é‡ä¸€è‡´æ€§...")
        if len(text_embeddings) > 1:
            first_dim = len(text_embeddings[0])
            for i, embedding in enumerate(text_embeddings[1:], 2):
                if len(embedding) != first_dim:
                    print(f"   âŒ æŸ¥è¯¢ {i} å‘é‡ç»´åº¦ä¸ä¸€è‡´: {len(embedding)} vs {first_dim}")
                    return False
                else:
                    print(f"   âœ… æŸ¥è¯¢ {i} å‘é‡ç»´åº¦ä¸€è‡´: {len(embedding)}")
        
        print(f"âœ… æ‰€æœ‰å‘é‡ç»´åº¦ä¸€è‡´: {len(text_embeddings[0])}")
        
        # 6. æµ‹è¯•å‘é‡ç›¸ä¼¼åº¦è®¡ç®—
        print("ğŸ“Š æµ‹è¯•å‘é‡ç›¸ä¼¼åº¦è®¡ç®—...")
        if len(text_embeddings) >= 2:
            try:
                # æ£€æŸ¥numpyä¾èµ–
                try:
                    import numpy as np
                    print("   âœ… numpyå¯¼å…¥æˆåŠŸ")
                except ImportError:
                    print("   âŒ numpyæœªå®‰è£…ï¼Œè·³è¿‡ç›¸ä¼¼åº¦è®¡ç®—")
                    print("   è¯·è¿è¡Œ: pip install numpy")
                    return False
                
                # è®¡ç®—ç¬¬ä¸€ä¸ªæŸ¥è¯¢ä¸åç»­æŸ¥è¯¢çš„ç›¸ä¼¼åº¦
                query1_embedding = np.array(text_embeddings[0])
                
                for i in range(1, len(text_embeddings)):
                    query2_embedding = np.array(text_embeddings[i])
                    
                    # è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦
                    dot_product = np.dot(query1_embedding, query2_embedding)
                    norm1 = np.linalg.norm(query1_embedding)
                    norm2 = np.linalg.norm(query2_embedding)
                    
                    if norm1 > 0 and norm2 > 0:
                        similarity = dot_product / (norm1 * norm2)
                        print(f"   æŸ¥è¯¢1 vs æŸ¥è¯¢{i+1} ç›¸ä¼¼åº¦: {similarity:.4f}")
                        
                        # ç›¸ä¼¼åº¦åº”è¯¥åœ¨åˆç†èŒƒå›´å†…
                        if similarity < -1 or similarity > 1:
                            print(f"   âš ï¸ è­¦å‘Šï¼šç›¸ä¼¼åº¦è¶…å‡ºæ­£å¸¸èŒƒå›´")
                    else:
                        print(f"   âš ï¸ è­¦å‘Šï¼šå‘é‡èŒƒæ•°ä¸º0ï¼Œæ— æ³•è®¡ç®—ç›¸ä¼¼åº¦")
                
                print("âœ… å‘é‡ç›¸ä¼¼åº¦è®¡ç®—æˆåŠŸ")
                
            except Exception as e:
                print(f"   âŒ å‘é‡ç›¸ä¼¼åº¦è®¡ç®—å¤±è´¥: {e}")
                return False
        
        # 7. æµ‹è¯•ä¸å›¾ç‰‡å‘é‡çš„å…¼å®¹æ€§
        print("ï¿½ï¿½ï¸ æµ‹è¯•ä¸å›¾ç‰‡å‘é‡çš„å…¼å®¹æ€§...")
        try:
            # å°è¯•åŠ è½½å‘é‡æ•°æ®åº“
            vector_db_path = config.vector_db_dir
            if os.path.exists(vector_db_path):
                print(f"   å‘é‡æ•°æ®åº“è·¯å¾„: {vector_db_path}")
                
                # åŠ è½½å‘é‡å­˜å‚¨
                vector_store = FAISS.load_local(
                    vector_db_path, 
                    multimodal_embeddings,
                    allow_dangerous_deserialization=True
                )
                
                print("âœ… å‘é‡æ•°æ®åº“åŠ è½½æˆåŠŸ")
                
                # æ£€æŸ¥æ˜¯å¦æœ‰imageç±»å‹çš„chunks
                if hasattr(vector_store, 'docstore') and hasattr(vector_store.docstore, '_dict'):
                    image_chunks = []
                    for doc_id, doc in vector_store.docstore._dict.items():
                        metadata = doc.metadata if hasattr(doc, 'metadata') and doc.metadata else {}
                        if metadata.get('chunk_type') == 'image':
                            image_chunks.append(doc)
                    
                    print(f"   æ‰¾åˆ° {len(image_chunks)} ä¸ªimage chunks")
                    
                    if image_chunks:
                        # æµ‹è¯•æ–‡æœ¬å‘é‡ä¸å›¾ç‰‡å‘é‡çš„ç›¸ä¼¼åº¦è®¡ç®—
                        print("   ï¿½ï¿½ æµ‹è¯•æ–‡æœ¬å‘é‡ä¸å›¾ç‰‡å‘é‡çš„ç›¸ä¼¼åº¦...")
                        
                        # ä½¿ç”¨ç¬¬ä¸€ä¸ªæ–‡æœ¬æŸ¥è¯¢å‘é‡
                        test_text_embedding = text_embeddings[0]
                        
                        # å°è¯•è®¡ç®—ä¸ç¬¬ä¸€ä¸ªå›¾ç‰‡chunkçš„ç›¸ä¼¼åº¦
                        first_image_chunk = image_chunks[0]
                        if hasattr(first_image_chunk, 'embedding') or hasattr(first_image_chunk, 'vector'):
                            # è¿™é‡Œéœ€è¦æ ¹æ®å®é™…çš„chunkç»“æ„æ¥è·å–å‘é‡
                            print("   ğŸ“Š å›¾ç‰‡chunkç»“æ„åˆ†æ:")
                            print(f"      - ç±»å‹: {type(first_image_chunk)}")
                            print(f"      - å±æ€§: {dir(first_image_chunk)}")
                            print(f"      - metadata: {first_image_chunk.metadata if hasattr(first_image_chunk, 'metadata') else 'N/A'}")
                        
                        print("   âœ… å›¾ç‰‡chunkå…¼å®¹æ€§æ£€æŸ¥å®Œæˆ")
                    else:
                        print("   âš ï¸ æœªæ‰¾åˆ°image chunksï¼Œè·³è¿‡å…¼å®¹æ€§æµ‹è¯•")
                
            else:
                print(f"   âš ï¸ å‘é‡æ•°æ®åº“è·¯å¾„ä¸å­˜åœ¨: {vector_db_path}")
                
        except Exception as e:
            print(f"   âš ï¸ å›¾ç‰‡å‘é‡å…¼å®¹æ€§æµ‹è¯•å¤±è´¥: {e}")
            print("   è¿™ä¸ä¼šå½±å“åŸºæœ¬åŠŸèƒ½ï¼Œä½†å¯èƒ½å½±å“åç»­çš„è·¨æ¨¡æ€æœç´¢")
        
        print("\n" + "="*60)
        print("ğŸ‰ æµ‹è¯•1å®Œæˆï¼šmultimodal-embedding-v1æ–‡æœ¬è¾“å…¥èƒ½åŠ›éªŒè¯æˆåŠŸï¼")
        print("="*60)
        
        return True
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•1å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    success = test_multimodal_text_input()
    if success:
        print("\nâœ… æµ‹è¯•1é€šè¿‡ï¼šmultimodal-embedding-v1å¯ä»¥æ¥å—æ–‡æœ¬è¾“å…¥å¹¶ç”Ÿæˆå‘é‡")
    else:
        print("\nâŒ æµ‹è¯•1å¤±è´¥ï¼šéœ€è¦æ£€æŸ¥é…ç½®æˆ–APIå¯†é’¥")