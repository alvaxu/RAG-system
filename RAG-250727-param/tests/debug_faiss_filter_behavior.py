'''
ç¨‹åºè¯´æ˜ï¼š
## 1. æ·±å…¥åˆ†æFAISS filterçš„è¡Œä¸ºå·®å¼‚
## 2. å¯¹æ¯”filterç­–ç•¥å’Œpost-filterç­–ç•¥çš„ç»“æœå·®å¼‚
## 3. æ‰¾å‡ºä¸ºä»€ä¹ˆç›¸åŒé˜ˆå€¼ä¸‹filterç­–ç•¥å¤±è´¥è€Œpost-filteræˆåŠŸ
'''

import os
import sys
import logging

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.insert(0, project_root)

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')
logger = logging.getLogger(__name__)

def debug_faiss_filter_behavior():
    """æ·±å…¥åˆ†æFAISS filterçš„è¡Œä¸ºå·®å¼‚"""
    print("ğŸ” æ·±å…¥åˆ†æFAISS filterçš„è¡Œä¸ºå·®å¼‚")
    print("=" * 80)
    
    try:
        # 1. åŠ è½½å‘é‡æ•°æ®åº“
        from langchain_community.vectorstores import FAISS
        from langchain_community.embeddings import DashScopeEmbeddings
        from config.api_key_manager import get_dashscope_api_key
        
        # åˆå§‹åŒ–embeddings
        api_key = get_dashscope_api_key()
        embeddings = DashScopeEmbeddings(dashscope_api_key=api_key, model='text-embedding-v1')
        
        # åŠ è½½å‘é‡æ•°æ®åº“
        vector_db_path = "central/vector_db"
        vector_store = FAISS.load_local(vector_db_path, embeddings, allow_dangerous_deserialization=True)
        print("âœ… å‘é‡æ•°æ®åº“åŠ è½½æˆåŠŸ")
        
        # 2. æµ‹è¯•æŸ¥è¯¢
        test_query = "ä¸­èŠ¯å›½é™…çš„è¥ä¸šæ”¶å…¥ä»2017å¹´åˆ°2024å¹´çš„å˜åŒ–è¶‹åŠ¿ å¦‚ä½•ï¼Ÿ"
        print(f"æµ‹è¯•æŸ¥è¯¢: {test_query}")
        
        # 3. æµ‹è¯•ç­–ç•¥1ï¼šFAISS filter
        print("\nğŸ“‹ ç­–ç•¥1ï¼šFAISS filteræµ‹è¯•")
        print("-" * 40)
        
        try:
            # ä½¿ç”¨ä¸table_engineç›¸åŒçš„å‚æ•°
            filter_search_k = 200
            filter_results = vector_store.similarity_search(
                test_query, 
                k=filter_search_k,
                filter={'chunk_type': 'table'}
            )
            print(f"FAISS filterç»“æœæ•°é‡: {len(filter_results)}")
            
            if filter_results:
                print("FAISS filterç»“æœç¤ºä¾‹:")
                for i, doc in enumerate(filter_results[:3]):
                    chunk_type = doc.metadata.get('chunk_type', 'N/A') if hasattr(doc, 'metadata') and doc.metadata else 'N/A'
                    print(f"  ç»“æœ{i+1}: chunk_type={chunk_type}")
            else:
                print("âš ï¸ FAISS filterè¿”å›0ä¸ªç»“æœ")
                
        except Exception as e:
            print(f"FAISS filterå¤±è´¥: {e}")
        
        # 4. æµ‹è¯•ç­–ç•¥2ï¼šæ— filter + æ‰‹åŠ¨ç­›é€‰
        print("\nğŸ“‹ ç­–ç•¥2ï¼šæ— filter + æ‰‹åŠ¨ç­›é€‰æµ‹è¯•")
        print("-" * 40)
        
        try:
            search_k = 150
            all_candidates = vector_store.similarity_search(
                test_query, 
                k=search_k
            )
            print(f"æ— filteræœç´¢ç»“æœæ•°é‡: {len(all_candidates)}")
            
            # æ‰‹åŠ¨ç­›é€‰tableç±»å‹
            table_candidates = []
            for doc in all_candidates:
                if (hasattr(doc, 'metadata') and doc.metadata and 
                    doc.metadata.get('chunk_type') == 'table'):
                    table_candidates.append(doc)
            
            print(f"æ‰‹åŠ¨ç­›é€‰åtableæ–‡æ¡£æ•°é‡: {len(table_candidates)}")
            
            if table_candidates:
                print("æ‰‹åŠ¨ç­›é€‰ç»“æœç¤ºä¾‹:")
                for i, doc in enumerate(table_candidates[:3]):
                    chunk_type = doc.metadata.get('chunk_type', 'N/A')
                    print(f"  ç»“æœ{i+1}: chunk_type={chunk_type}")
                    
        except Exception as e:
            print(f"æ— filteræœç´¢å¤±è´¥: {e}")
        
        # 5. åˆ†æå·®å¼‚åŸå› 
        print("\nğŸ” åˆ†æå·®å¼‚åŸå› ")
        print("-" * 40)
        
        print("å¯èƒ½çš„åŸå› :")
        print("1. FAISS filterå¯èƒ½å¯¹å‘é‡ç›¸ä¼¼åº¦æœ‰é¢å¤–çš„é™åˆ¶")
        print("2. Filterå¯èƒ½åªè¿”å›ç›¸ä¼¼åº¦æœ€é«˜çš„ç»“æœï¼Œè€Œæˆ‘ä»¬çš„æŸ¥è¯¢ä¸tableæ–‡æ¡£ç›¸ä¼¼åº¦è¾ƒä½")
        print("3. FAISS filterçš„å®ç°å¯èƒ½ä¸é¢„æœŸä¸åŒ")
        print("4. å¯èƒ½å­˜åœ¨ç´¢å¼•é…ç½®é—®é¢˜")
        
        # 6. æµ‹è¯•ä¸åŒç›¸ä¼¼åº¦é˜ˆå€¼ä¸‹çš„filterè¡Œä¸º
        print("\nğŸ“‹ æµ‹è¯•ä¸åŒç›¸ä¼¼åº¦é˜ˆå€¼ä¸‹çš„filterè¡Œä¸º")
        print("-" * 40)
        
        # æ£€æŸ¥æ˜¯å¦æœ‰similarity_search_with_scoreæ–¹æ³•
        if hasattr(vector_store, 'similarity_search_with_score'):
            try:
                print("ä½¿ç”¨similarity_search_with_scoreåˆ†æç›¸ä¼¼åº¦åˆ†å¸ƒ...")
                docs_and_scores = vector_store.similarity_search_with_score(
                    test_query, 
                    k=50
                )
                
                # åˆ†æç›¸ä¼¼åº¦åˆ†å¸ƒ
                scores = [score for _, score in docs_and_scores]
                if scores:
                    min_score = min(scores)
                    max_score = max(scores)
                    avg_score = sum(scores) / len(scores)
                    print(f"ç›¸ä¼¼åº¦åˆ†å¸ƒ: æœ€å°={min_score:.4f}, æœ€å¤§={max_score:.4f}, å¹³å‡={avg_score:.4f}")
                    
                    # æ£€æŸ¥tableæ–‡æ¡£çš„ç›¸ä¼¼åº¦
                    table_scores = []
                    for doc, score in docs_and_scores:
                        if (hasattr(doc, 'metadata') and doc.metadata and 
                            doc.metadata.get('chunk_type') == 'table'):
                            table_scores.append(score)
                    
                    if table_scores:
                        table_min = min(table_scores)
                        table_max = max(table_scores)
                        table_avg = sum(table_scores) / len(table_scores)
                        print(f"Tableæ–‡æ¡£ç›¸ä¼¼åº¦: æœ€å°={table_min:.4f}, æœ€å¤§={table_max:.4f}, å¹³å‡={table_avg:.4f}")
                        
                        # æ£€æŸ¥æ˜¯å¦æœ‰tableæ–‡æ¡£çš„ç›¸ä¼¼åº¦è¶³å¤Ÿé«˜
                        high_similarity_table = [s for s in table_scores if s > 0.5]
                        print(f"ç›¸ä¼¼åº¦>0.5çš„tableæ–‡æ¡£æ•°é‡: {len(high_similarity_table)}")
                    else:
                        print("æ²¡æœ‰æ‰¾åˆ°tableæ–‡æ¡£")
                        
            except Exception as e:
                print(f"similarity_search_with_scoreå¤±è´¥: {e}")
        else:
            print("âŒ ä¸æ”¯æŒsimilarity_search_with_scoreæ–¹æ³•")
        
        # 7. ç»“è®ºå’Œå»ºè®®
        print("\nğŸ¯ ç»“è®ºå’Œå»ºè®®")
        print("-" * 40)
        
        print("åŸºäºæµ‹è¯•ç»“æœï¼Œå»ºè®®:")
        print("1. æ£€æŸ¥FAISS filterçš„å®ç°æœºåˆ¶")
        print("2. è€ƒè™‘è°ƒæ•´filterç­–ç•¥çš„æœç´¢å‚æ•°")
        print("3. å¯èƒ½éœ€è¦ç»“åˆfilterå’Œpost-filterçš„æ··åˆç­–ç•¥")
        print("4. è¿›ä¸€æ­¥åˆ†æå‘é‡ç›¸ä¼¼åº¦çš„åˆ†å¸ƒç‰¹å¾")
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    debug_faiss_filter_behavior()
