#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä¸“é—¨æµ‹è¯•image_textå’Œtable filteråŠŸèƒ½

ç›®æ ‡ï¼š
1. ä½¿ç”¨æ›´åˆé€‚çš„æŸ¥è¯¢ç¡®ä¿image_textå’Œtable filterèƒ½è¿”å›ç»“æœ
2. éªŒè¯Filteræ˜¯å¦çœŸçš„ç”Ÿæ•ˆ
3. åˆ†ææŸ¥è¯¢å’Œæ–‡æ¡£ç±»å‹çš„åŒ¹é…å…³ç³»
"""

import os
import sys
import json
from typing import List, Dict, Any

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.insert(0, project_root)

def test_image_text_table_filter():
    """ä¸“é—¨æµ‹è¯•image_textå’Œtable filteråŠŸèƒ½"""
    print("="*80)
    print("ä¸“é—¨æµ‹è¯•image_textå’Œtable filteråŠŸèƒ½")
    print("="*80)
    
    try:
        # 1. å¯¼å…¥å¿…è¦æ¨¡å—
        print("å¯¼å…¥å¿…è¦æ¨¡å—...")
        from langchain_community.vectorstores import FAISS
        from langchain_community.embeddings import DashScopeEmbeddings
        from config.api_key_manager import get_dashscope_api_key
        from config.settings import Settings
        
        print("âœ… æ¨¡å—å¯¼å…¥æˆåŠŸ")
        
        # 2. è·å–é…ç½®å’ŒAPIå¯†é’¥
        print("è·å–é…ç½®å’ŒAPIå¯†é’¥...")
        try:
            old_cwd = os.getcwd()
            os.chdir(project_root)
            config = Settings.load_from_file('config.json')
            os.chdir(old_cwd)
        except Exception as e:
            print(f"é…ç½®æ–‡ä»¶åŠ è½½å¤±è´¥: {e}")
            return False
        
        api_key = get_dashscope_api_key(config.dashscope_api_key)
        if not api_key:
            print("æœªæ‰¾åˆ°æœ‰æ•ˆçš„DashScope APIå¯†é’¥")
            return False
        
        print("âœ… é…ç½®å’ŒAPIå¯†é’¥è·å–æˆåŠŸ")
        
        # 3. åŠ è½½å‘é‡æ•°æ®åº“
        print("åŠ è½½å‘é‡æ•°æ®åº“...")
        try:
            text_embeddings = DashScopeEmbeddings(
                dashscope_api_key=api_key,
                model='text-embedding-v1'
            )
            
            vector_db_path = config.vector_db_dir
            vector_store = FAISS.load_local(
                vector_db_path, 
                text_embeddings,
                allow_dangerous_deserialization=True
            )
            print(f"âœ… å‘é‡æ•°æ®åº“åŠ è½½æˆåŠŸï¼ŒåŒ…å« {len(vector_store.docstore._dict)} ä¸ªæ–‡æ¡£")
            
        except Exception as e:
            print(f"âŒ å‘é‡æ•°æ®åº“åŠ è½½å¤±è´¥: {e}")
            return False
        
        # 4. åˆ†ææ–‡æ¡£ç±»å‹åˆ†å¸ƒ
        print("\nåˆ†ææ–‡æ¡£ç±»å‹åˆ†å¸ƒ...")
        chunk_type_stats = {}
        
        for doc_id, doc in vector_store.docstore._dict.items():
            if hasattr(doc, 'metadata') and doc.metadata:
                chunk_type = doc.metadata.get('chunk_type', 'unknown')
                chunk_type_stats[chunk_type] = chunk_type_stats.get(chunk_type, 0) + 1
        
        print("æ–‡æ¡£ç±»å‹åˆ†å¸ƒ:")
        for chunk_type, count in sorted(chunk_type_stats.items()):
            print(f"  {chunk_type}: {count} ä¸ª")
        
        # 5. ä¸“é—¨æµ‹è¯•image_textå’Œtableçš„æŸ¥è¯¢
        print("\nä¸“é—¨æµ‹è¯•image_textå’Œtable filter...")
        
        # é’ˆå¯¹tableçš„æŸ¥è¯¢
        table_queries = [
            "è¥ä¸šæ”¶å…¥",
            "å‡€åˆ©æ¶¦",
            "è´¢åŠ¡æ•°æ®",
            "å¸‚åœºæ•°æ®",
            "æ”¶ç›Šè¡¨ç°",
            "æ¸¯è‚¡æŒ‡æ ‡"
        ]
        
        # é’ˆå¯¹image_textçš„æŸ¥è¯¢
        image_text_queries = [
            "è‚¡ä»·èµ°åŠ¿",
            "äº§èƒ½åˆ©ç”¨ç‡",
            "æœˆäº§èƒ½",
            "å…¨çƒéƒ¨ç½²",
            "å­£åº¦ä¸šç»©",
            "å›¾è¡¨åˆ†æ"
        ]
        
        # æµ‹è¯•table filter
        print("\n" + "="*60)
        print("æµ‹è¯•Table Filter")
        print("="*60)
        
        for query in table_queries:
            print(f"\n--- æŸ¥è¯¢: {query} ---")
            
            # æ— filteræœç´¢
            try:
                no_filter_results = vector_store.similarity_search(query, k=20)
                print(f"  æ— filterç»“æœæ•°é‡: {len(no_filter_results)}")
                
                # åˆ†æç»“æœç±»å‹åˆ†å¸ƒ
                result_types = {}
                for doc in no_filter_results:
                    chunk_type = doc.metadata.get('chunk_type', 'unknown') if hasattr(doc, 'metadata') and doc.metadata else 'unknown'
                    result_types[chunk_type] = result_types.get(chunk_type, 0) + 1
                
                print(f"  æ— filterç»“æœç±»å‹åˆ†å¸ƒ: {result_types}")
                
            except Exception as e:
                print(f"  æ— filteræœç´¢å¤±è´¥: {e}")
                continue
            
            # æµ‹è¯•table filter
            try:
                table_filter_results = vector_store.similarity_search(query, k=20, filter={'chunk_type': 'table'})
                print(f"  table filterç»“æœæ•°é‡: {len(table_filter_results)}")
                
                if table_filter_results:
                    # éªŒè¯ç»“æœç±»å‹
                    all_table = True
                    for doc in table_filter_results:
                        chunk_type = doc.metadata.get('chunk_type', 'unknown') if hasattr(doc, 'metadata') and doc.metadata else 'unknown'
                        if chunk_type != 'table':
                            all_table = False
                            print(f"    âŒ å‘ç°étableç±»å‹: {chunk_type}")
                            break
                    
                    if all_table:
                        print(f"    âœ… æ‰€æœ‰ç»“æœéƒ½æ˜¯tableç±»å‹")
                    
                    # æ˜¾ç¤ºç¬¬ä¸€ä¸ªç»“æœ
                    first_doc = table_filter_results[0]
                    print(f"    ç¬¬ä¸€ä¸ªç»“æœ: {first_doc.page_content[:100]}...")
                    
                    # éªŒè¯filteræ˜¯å¦ç”Ÿæ•ˆ
                    if len(table_filter_results) < len(no_filter_results):
                        print(f"    âœ… Filterç”Ÿæ•ˆï¼šç»“æœæ•°é‡å‡å°‘ ({len(no_filter_results)} -> {len(table_filter_results)})")
                    else:
                        print(f"    âš ï¸ Filterå¯èƒ½æœªç”Ÿæ•ˆï¼šç»“æœæ•°é‡ç›¸åŒæˆ–å¢åŠ ")
                
            except Exception as e:
                print(f"  table filterå¤±è´¥: {e}")
        
        # æµ‹è¯•image_text filter
        print("\n" + "="*60)
        print("æµ‹è¯•Image_Text Filter")
        print("="*60)
        
        for query in image_text_queries:
            print(f"\n--- æŸ¥è¯¢: {query} ---")
            
            # æ— filteræœç´¢
            try:
                no_filter_results = vector_store.similarity_search(query, k=20)
                print(f"  æ— filterç»“æœæ•°é‡: {len(no_filter_results)}")
                
                # åˆ†æç»“æœç±»å‹åˆ†å¸ƒ
                result_types = {}
                for doc in no_filter_results:
                    chunk_type = doc.metadata.get('chunk_type', 'unknown') if hasattr(doc, 'metadata') and doc.metadata else 'unknown'
                    result_types[chunk_type] = result_types.get(chunk_type, 0) + 1
                
                print(f"  æ— filterç»“æœç±»å‹åˆ†å¸ƒ: {result_types}")
                
            except Exception as e:
                print(f"  æ— filteræœç´¢å¤±è´¥: {e}")
                continue
            
            # æµ‹è¯•image_text filter
            try:
                image_text_filter_results = vector_store.similarity_search(query, k=20, filter={'chunk_type': 'image_text'})
                print(f"  image_text filterç»“æœæ•°é‡: {len(image_text_filter_results)}")
                
                if image_text_filter_results:
                    # éªŒè¯ç»“æœç±»å‹
                    all_image_text = True
                    for doc in image_text_filter_results:
                        chunk_type = doc.metadata.get('chunk_type', 'unknown') if hasattr(doc, 'metadata') and doc.metadata else 'unknown'
                        if chunk_type != 'image_text':
                            all_image_text = False
                            print(f"    âŒ å‘ç°éimage_textç±»å‹: {chunk_type}")
                            break
                    
                    if all_image_text:
                        print(f"    âœ… æ‰€æœ‰ç»“æœéƒ½æ˜¯image_textç±»å‹")
                    
                    # æ˜¾ç¤ºç¬¬ä¸€ä¸ªç»“æœ
                    first_doc = image_text_filter_results[0]
                    print(f"    ç¬¬ä¸€ä¸ªç»“æœ: {first_doc.page_content[:100]}...")
                    
                    # éªŒè¯filteræ˜¯å¦ç”Ÿæ•ˆ
                    if len(image_text_filter_results) < len(no_filter_results):
                        print(f"    âœ… Filterç”Ÿæ•ˆï¼šç»“æœæ•°é‡å‡å°‘ ({len(no_filter_results)} -> {len(image_text_filter_results)})")
                    else:
                        print(f"    âš ï¸ Filterå¯èƒ½æœªç”Ÿæ•ˆï¼šç»“æœæ•°é‡ç›¸åŒæˆ–å¢åŠ ")
                
            except Exception as e:
                print(f"  image_text filterå¤±è´¥: {e}")
        
        # 6. æ€»ç»“åˆ†æ
        print("\n" + "="*80)
        print("Image_Textå’ŒTable Filteræµ‹è¯•æ€»ç»“")
        print("="*80)
        
        print("ğŸ” æµ‹è¯•ç»“æœ:")
        print(f"1. å‘é‡æ•°æ®åº“æ€»æ–‡æ¡£æ•°: {len(vector_store.docstore._dict)}")
        print(f"2. æ–‡æ¡£ç±»å‹åˆ†å¸ƒ: {chunk_type_stats}")
        
        print("\nğŸ’¡ FilteråŠŸèƒ½åˆ†æ:")
        print("  - å¦‚æœFilterèƒ½è¿”å›ç»“æœï¼Œè¯´æ˜FilteråŠŸèƒ½æ­£å¸¸")
        print("  - å¦‚æœFilterè¿”å›0ä¸ªç»“æœï¼Œå¯èƒ½æ˜¯æŸ¥è¯¢ä¸åŒ¹é…")
        print("  - éœ€è¦é€‰æ‹©åˆé€‚çš„æŸ¥è¯¢æ¥æµ‹è¯•FilteråŠŸèƒ½")
        
        return True
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    test_image_text_table_filter()
