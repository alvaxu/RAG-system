'''
ç¨‹åºè¯´æ˜ï¼š

## 1. æ£€æŸ¥å‘é‡æ•°æ®åº“ä¸­å›¾4çš„å®Œæ•´ä¿¡æ¯
## 2. éªŒè¯ä¸¤å¼ å›¾4æ˜¯å¦éƒ½æ­£ç¡®å­˜å‚¨åœ¨æ•°æ®åº“ä¸­
## 3. åˆ†ææ•°æ®åº“æ˜¯å¦æœ‰é—®é¢˜
'''

import os
import sys
import pickle
import json
from typing import List, Dict, Any

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from langchain_community.embeddings import DashScopeEmbeddings
from langchain_community.vectorstores import FAISS
from config.config_manager import ConfigManager

def check_figure4_in_vector_db():
    """æ£€æŸ¥å‘é‡æ•°æ®åº“ä¸­å›¾4çš„å®Œæ•´ä¿¡æ¯"""
    
    # åŠ è½½é…ç½®
    config = ConfigManager()
    
    # å‘é‡æ•°æ®åº“è·¯å¾„
    vector_db_path = config.settings.vector_db_dir
    
    print("ğŸ” æ£€æŸ¥å‘é‡æ•°æ®åº“ä¸­å›¾4çš„å®Œæ•´ä¿¡æ¯")
    print("=" * 60)
    
    # æ£€æŸ¥å‘é‡æ•°æ®åº“æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(vector_db_path):
        print(f"âŒ å‘é‡æ•°æ®åº“è·¯å¾„ä¸å­˜åœ¨: {vector_db_path}")
        return
    
    index_file = os.path.join(vector_db_path, "index.pkl")
    metadata_file = os.path.join(vector_db_path, "metadata.pkl")
    
    if not os.path.exists(index_file) or not os.path.exists(metadata_file):
        print(f"âŒ å‘é‡æ•°æ®åº“æ–‡ä»¶ä¸å®Œæ•´")
        print(f"   index.pkl: {'âœ…' if os.path.exists(index_file) else 'âŒ'}")
        print(f"   metadata.pkl: {'âœ…' if os.path.exists(metadata_file) else 'âŒ'}")
        return
    
    print("âœ… å‘é‡æ•°æ®åº“æ–‡ä»¶å­˜åœ¨")
    
    try:
        # åŠ è½½å‘é‡æ•°æ®åº“
        embeddings = DashScopeEmbeddings(
            dashscope_api_key=config.settings.dashscope_api_key, 
            model="text-embedding-v1"
        )
        vector_store = FAISS.load_local(
            vector_db_path, 
            embeddings, 
            allow_dangerous_deserialization=True
        )
        
        print(f"âœ… å‘é‡æ•°æ®åº“åŠ è½½æˆåŠŸ")
        print(f"ğŸ“Š æ€»æ–‡æ¡£æ•°: {len(vector_store.docstore._dict)}")
        print(f"ğŸ“Š ç´¢å¼•å¤§å°: {vector_store.index.ntotal}")
        
        # æŸ¥æ‰¾æ‰€æœ‰åŒ…å«"å›¾4"çš„æ–‡æ¡£
        print(f"\nğŸ” æŸ¥æ‰¾åŒ…å«'å›¾4'çš„æ–‡æ¡£...")
        print("-" * 40)
        
        figure4_docs = []
        for doc_id, doc in vector_store.docstore._dict.items():
            content = doc.page_content
            metadata = doc.metadata
            
            # æ£€æŸ¥å†…å®¹ä¸­æ˜¯å¦åŒ…å«"å›¾4"
            if "å›¾4" in content:
                figure4_docs.append({
                    'id': doc_id,
                    'content': content,
                    'metadata': metadata,
                    'document_name': metadata.get('document_name', 'æœªçŸ¥æ–‡æ¡£'),
                    'chunk_type': metadata.get('chunk_type', 'text'),
                    'img_caption': metadata.get('img_caption', []),
                    'page_number': metadata.get('page_number', 0)
                })
        
        print(f"ğŸ“‹ æ‰¾åˆ° {len(figure4_docs)} ä¸ªåŒ…å«'å›¾4'çš„æ–‡æ¡£")
        
        if figure4_docs:
            print(f"\nğŸ“„ å›¾4æ–‡æ¡£è¯¦æƒ…:")
            for i, doc in enumerate(figure4_docs, 1):
                print(f"\næ–‡æ¡£ {i}:")
                print(f"  ğŸ“„ æ–‡æ¡£åç§°: {doc['document_name']}")
                print(f"  ğŸ·ï¸ æ–‡æ¡£ç±»å‹: {doc['chunk_type']}")
                print(f"  ğŸ“ é¡µç : {doc['page_number']}")
                
                # æ˜¾ç¤ºå›¾ç‰‡æ ‡é¢˜
                if doc['img_caption']:
                    print(f"  ğŸ–¼ï¸ å›¾ç‰‡æ ‡é¢˜: {doc['img_caption']}")
                
                # æ˜¾ç¤ºå†…å®¹ç‰‡æ®µ
                content_preview = doc['content'][:200] + "..." if len(doc['content']) > 200 else doc['content']
                print(f"  ğŸ“ å†…å®¹é¢„è§ˆ: {content_preview}")
                
                # æ˜¾ç¤ºå®Œæ•´å…ƒæ•°æ®
                print(f"  ğŸ” å®Œæ•´å…ƒæ•°æ®: {json.dumps(doc['metadata'], ensure_ascii=False, indent=2)}")
        
        # ä¸“é—¨æŸ¥æ‰¾ä¸¤å¼ å›¾4
        print(f"\nğŸ¯ ä¸“é—¨æŸ¥æ‰¾ä¸¤å¼ å›¾4:")
        print("-" * 40)
        
        # å›¾4-1: ä¸­åŸè¯åˆ¸çš„å›¾4
        print(f"\n1ï¸âƒ£ æŸ¥æ‰¾ä¸­åŸè¯åˆ¸å›¾4: 'å…¬å¸25Q1ä¸‹æ¸¸åº”ç”¨é¢†åŸŸç»“æ„æƒ…å†µ'")
        zhongyuan_figure4 = []
        for doc in figure4_docs:
            if "å…¬å¸25Q1ä¸‹æ¸¸åº”ç”¨é¢†åŸŸç»“æ„æƒ…å†µ" in doc['content']:
                zhongyuan_figure4.append(doc)
        
        if zhongyuan_figure4:
            print(f"âœ… æ‰¾åˆ° {len(zhongyuan_figure4)} ä¸ªä¸­åŸè¯åˆ¸å›¾4")
            for doc in zhongyuan_figure4:
                print(f"   ğŸ“„ æ–‡æ¡£: {doc['document_name']}")
                print(f"   ğŸ·ï¸ ç±»å‹: {doc['chunk_type']}")
        else:
            print(f"âŒ æœªæ‰¾åˆ°ä¸­åŸè¯åˆ¸å›¾4")
        
        # å›¾4-2: ä¸Šæµ·è¯åˆ¸çš„å›¾4
        print(f"\n2ï¸âƒ£ æŸ¥æ‰¾ä¸Šæµ·è¯åˆ¸å›¾4: 'ä¸­èŠ¯å›½é™…å½’æ¯å‡€åˆ©æ¶¦æƒ…å†µæ¦‚è§ˆ'")
        shanghai_figure4 = []
        for doc in figure4_docs:
            if "ä¸­èŠ¯å›½é™…å½’æ¯å‡€åˆ©æ¶¦æƒ…å†µæ¦‚è§ˆ" in doc['content']:
                shanghai_figure4.append(doc)
        
        if shanghai_figure4:
            print(f"âœ… æ‰¾åˆ° {len(shanghai_figure4)} ä¸ªä¸Šæµ·è¯åˆ¸å›¾4")
            for doc in shanghai_figure4:
                print(f"   ğŸ“„ æ–‡æ¡£: {doc['document_name']}")
                print(f"   ğŸ·ï¸ ç±»å‹: {doc['chunk_type']}")
        else:
            print(f"âŒ æœªæ‰¾åˆ°ä¸Šæµ·è¯åˆ¸å›¾4")
        
        # æµ‹è¯•æ£€ç´¢åŠŸèƒ½
        print(f"\nğŸ§ª æµ‹è¯•æ£€ç´¢åŠŸèƒ½:")
        print("-" * 40)
        
        test_queries = [
            "å›¾4",
            "å…¬å¸25Q1ä¸‹æ¸¸åº”ç”¨é¢†åŸŸç»“æ„æƒ…å†µ",
            "ä¸­èŠ¯å›½é™…å½’æ¯å‡€åˆ©æ¶¦æƒ…å†µæ¦‚è§ˆ",
            "è¯·æ˜¾ç¤ºå›¾4"
        ]
        
        for query in test_queries:
            print(f"\nğŸ” æŸ¥è¯¢: '{query}'")
            try:
                results = vector_store.similarity_search(query, k=3)
                print(f"âœ… æ‰¾åˆ° {len(results)} ä¸ªç»“æœ")
                
                for j, result in enumerate(results, 1):
                    doc_name = result.metadata.get('document_name', 'æœªçŸ¥æ–‡æ¡£')
                    chunk_type = result.metadata.get('chunk_type', 'text')
                    img_caption = result.metadata.get('img_caption', [])
                    
                    print(f"   ç»“æœ {j}:")
                    print(f"     æ–‡æ¡£: {doc_name}")
                    print(f"     ç±»å‹: {chunk_type}")
                    if img_caption:
                        print(f"     å›¾ç‰‡æ ‡é¢˜: {img_caption}")
                    print(f"     å†…å®¹: {result.page_content[:100]}...")
                    
            except Exception as e:
                print(f"âŒ æ£€ç´¢å¤±è´¥: {e}")
        
        # æ£€æŸ¥å›¾ç‰‡ç±»å‹æ–‡æ¡£
        print(f"\nğŸ–¼ï¸ æ£€æŸ¥å›¾ç‰‡ç±»å‹æ–‡æ¡£:")
        print("-" * 40)
        
        image_docs = []
        for doc_id, doc in vector_store.docstore._dict.items():
            if doc.metadata.get('chunk_type') == 'image':
                image_docs.append({
                    'id': doc_id,
                    'content': doc.page_content,
                    'metadata': doc.metadata,
                    'document_name': doc.metadata.get('document_name', 'æœªçŸ¥æ–‡æ¡£'),
                    'img_caption': doc.metadata.get('img_caption', [])
                })
        
        print(f"ğŸ“Š æ€»å…±æœ‰ {len(image_docs)} ä¸ªå›¾ç‰‡æ–‡æ¡£")
        
        # æŸ¥æ‰¾å›¾ç‰‡æ–‡æ¡£ä¸­çš„å›¾4
        figure4_images = []
        for doc in image_docs:
            if doc['img_caption'] and any("å›¾4" in caption for caption in doc['img_caption']):
                figure4_images.append(doc)
        
        print(f"ğŸ–¼ï¸ æ‰¾åˆ° {len(figure4_images)} ä¸ªå›¾4å›¾ç‰‡æ–‡æ¡£")
        
        if figure4_images:
            for i, doc in enumerate(figure4_images, 1):
                print(f"\nå›¾ç‰‡ {i}:")
                print(f"  ğŸ“„ æ–‡æ¡£: {doc['document_name']}")
                print(f"  ğŸ–¼ï¸ æ ‡é¢˜: {doc['img_caption']}")
                print(f"  ğŸ“ æè¿°: {doc['content'][:200]}...")
        
        # æ€»ç»“
        print(f"\nğŸ“‹ æ£€æŸ¥æ€»ç»“:")
        print("-" * 40)
        print(f"âœ… å‘é‡æ•°æ®åº“çŠ¶æ€: æ­£å¸¸")
        print(f"ğŸ“Š æ€»æ–‡æ¡£æ•°: {len(vector_store.docstore._dict)}")
        print(f"ğŸ–¼ï¸ å›¾ç‰‡æ–‡æ¡£æ•°: {len(image_docs)}")
        print(f"ğŸ“„ åŒ…å«'å›¾4'çš„æ–‡æ¡£æ•°: {len(figure4_docs)}")
        print(f"ğŸ–¼ï¸ å›¾4å›¾ç‰‡æ–‡æ¡£æ•°: {len(figure4_images)}")
        
        # åˆ¤æ–­æ˜¯å¦æœ‰é—®é¢˜
        if len(figure4_docs) == 0:
            print(f"âŒ é—®é¢˜: æœªæ‰¾åˆ°ä»»ä½•åŒ…å«'å›¾4'çš„æ–‡æ¡£")
        elif len(figure4_images) == 0:
            print(f"âš ï¸ é—®é¢˜: æœªæ‰¾åˆ°å›¾4çš„å›¾ç‰‡æ–‡æ¡£")
        else:
            print(f"âœ… å›¾4æ–‡æ¡£å­˜åœ¨ï¼Œæ•°æ®åº“æ­£å¸¸")
        
    except Exception as e:
        print(f"âŒ åŠ è½½å‘é‡æ•°æ®åº“å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    check_figure4_in_vector_db()
