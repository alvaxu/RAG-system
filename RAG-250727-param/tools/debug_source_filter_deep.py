'''
ç¨‹åºè¯´æ˜ï¼š

## 1. ä¸“é—¨è°ƒè¯•æºè¿‡æ»¤é€»è¾‘
## 2. åˆ†æäº”å±‚å¬å›çš„å®Œæ•´ç»“æœæ’åº
## 3. è¿½è¸ªä¸ºä»€ä¹ˆå›¾4ç»“æœè¢«è¿‡æ»¤æ‰
## 4. æ£€æŸ¥æœ€ç»ˆä¼ é€’ç»™LLMçš„ä¸Šä¸‹æ–‡æ¥æº
'''

import os
import sys

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from langchain_community.vectorstores import FAISS
from langchain_community.embeddings import DashScopeEmbeddings
from config.api_key_manager import get_dashscope_api_key
from v2.core.image_engine import ImageEngine
from v2.core.document_loader import DocumentLoader
from v2.config.v2_config import ImageEngineConfigV2
from v2.core.source_filter_engine import SourceFilterEngine
import time


def debug_source_filter_deep():
    """æ·±åº¦è°ƒè¯•æºè¿‡æ»¤é€»è¾‘"""
    print("ğŸ” æ·±åº¦è°ƒè¯•æºè¿‡æ»¤é€»è¾‘")
    print("=" * 80)
    
    try:
        # 1. åˆå§‹åŒ–ç»„ä»¶
        print("ğŸ“¡ åˆå§‹åŒ–ç»„ä»¶...")
        config = ImageEngineConfigV2()
        
        api_key = get_dashscope_api_key()
        embeddings = DashScopeEmbeddings(dashscope_api_key=api_key, model='text-embedding-v1')
        vector_db_path = "../central/vector_db"
        vector_store = FAISS.load_local(vector_db_path, embeddings, allow_dangerous_deserialization=True)
        
        document_loader = DocumentLoader(vector_store=vector_store)
        image_engine = ImageEngine(
            config=config,
            vector_store=vector_store,
            document_loader=document_loader
        )
        source_filter_engine = SourceFilterEngine(config=config)
        print("âœ… ç»„ä»¶åˆå§‹åŒ–æˆåŠŸ")
        
        # 2. æµ‹è¯•æŸ¥è¯¢
        query = "å›¾4ï¼šä¸­èŠ¯å›½é™…å½’æ¯å‡€åˆ©æ¶¦æƒ…å†µæ¦‚è§ˆ"
        print(f"\nğŸ” æµ‹è¯•æŸ¥è¯¢: {query}")
        print("-" * 60)
        
        # 3. ç¬¬ä¸€æ­¥ï¼šè·å–å®Œæ•´çš„äº”å±‚å¬å›ç»“æœå¹¶åˆ†æ
        print("\nğŸ“Š ç¬¬ä¸€æ­¥ï¼šè·å–å®Œæ•´çš„äº”å±‚å¬å›ç»“æœå¹¶åˆ†æ")
        try:
            all_results = image_engine._search_images_with_five_layer_recall(query)
            print(f"  äº”å±‚å¬å›ç»“æœæ•°é‡: {len(all_results)}")
            
            if all_results:
                print(f"\n  å®Œæ•´ç»“æœåˆ†æ:")
                
                # æŒ‰åˆ†æ•°æ’åº
                sorted_results = sorted(all_results, key=lambda x: x.get('score', 0), reverse=True)
                
                # ç»Ÿè®¡å„ç­–ç•¥çš„ç»“æœ
                strategy_stats = {}
                metadata_stats = {
                    'has_our_fields': 0,
                    'missing_our_fields': 0
                }
                
                for i, result in enumerate(sorted_results):
                    score = result.get('score', 0)
                    search_method = result.get('search_method', 'N/A')
                    source = result.get('source', 'N/A')
                    
                    print(f"    ç»“æœ{i+1} (åˆ†æ•°: {score:.4f}):")
                    print(f"      æœç´¢æ–¹æ³•: {search_method}")
                    print(f"      æ¥æº: {source}")
                    
                    # ç»Ÿè®¡ç­–ç•¥
                    if search_method not in strategy_stats:
                        strategy_stats[search_method] = 0
                    strategy_stats[search_method] += 1
                    
                    # æ£€æŸ¥æˆ‘ä»¬çš„å­—æ®µ
                    has_our_fields = all([
                        result.get('document_name'),
                        result.get('page_number'),
                        result.get('chunk_type'),
                        result.get('llm_context')
                    ])
                    
                    if has_our_fields:
                        metadata_stats['has_our_fields'] += 1
                        print(f"      âœ… æœ‰æˆ‘ä»¬çš„å­—æ®µ:")
                        print(f"        document_name: {result.get('document_name')}")
                        print(f"        page_number: {result.get('page_number')}")
                        print(f"        chunk_type: {result.get('chunk_type')}")
                        print(f"        llm_contexté•¿åº¦: {len(result.get('llm_context', ''))}")
                        
                        # æ£€æŸ¥æ˜¯å¦åŒ…å«å›¾4ä¿¡æ¯
                        llm_context = result.get('llm_context', '')
                        if 'å›¾4' in llm_context:
                            print(f"        ğŸ¯ åŒ…å«å›¾4ä¿¡æ¯!")
                        else:
                            print(f"        âŒ ä¸åŒ…å«å›¾4ä¿¡æ¯")
                    else:
                        metadata_stats['missing_our_fields'] += 1
                        print(f"      âŒ ç¼ºå°‘æˆ‘ä»¬çš„å­—æ®µ")
                        
                        # æ£€æŸ¥docå†…å®¹
                        if 'doc' in result:
                            doc = result['doc']
                            print(f"      ğŸ“„ docå†…å®¹: {doc.page_content[:100]}...")
                            if hasattr(doc, 'metadata') and doc.metadata:
                                print(f"      ğŸ“„ docå…ƒæ•°æ®: {doc.metadata}")
                    
                    print()
                
                # ç»Ÿè®¡æ€»ç»“
                print(f"  ğŸ“Š ç»Ÿè®¡æ€»ç»“:")
                print(f"    ç­–ç•¥åˆ†å¸ƒ: {strategy_stats}")
                print(f"    å­—æ®µå®Œæ•´æ€§: {metadata_stats}")
                
        except Exception as e:
            print(f"  äº”å±‚å¬å›åˆ†æå¤±è´¥: {e}")
            import traceback
            print(f"  è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")
        
        # 4. ç¬¬äºŒæ­¥ï¼šæ¨¡æ‹Ÿæºè¿‡æ»¤è¿‡ç¨‹
        print(f"\nğŸ“Š ç¬¬äºŒæ­¥ï¼šæ¨¡æ‹Ÿæºè¿‡æ»¤è¿‡ç¨‹")
        try:
            if all_results:
                print(f"  è¾“å…¥ç»“æœæ•°é‡: {len(all_results)}")
                
                # æ£€æŸ¥æºè¿‡æ»¤é…ç½®
                print(f"  æºè¿‡æ»¤é…ç½®:")
                print(f"    enable_filtering: {config.enable_filtering}")
                print(f"    min_relevance_score: {getattr(config, 'min_relevance_score', 'N/A')}")
                print(f"    max_sources: {getattr(config, 'max_sources', 'N/A')}")
                
                # æ¨¡æ‹Ÿæºè¿‡æ»¤ï¼ˆä¸è°ƒç”¨LLMï¼Œåªæ£€æŸ¥é€»è¾‘ï¼‰
                print(f"\n  æ¨¡æ‹Ÿæºè¿‡æ»¤é€»è¾‘:")
                
                # æ£€æŸ¥æ¯ä¸ªç»“æœçš„åˆ†æ•°
                scores = [r.get('score', 0) for r in all_results]
                print(f"    åˆ†æ•°èŒƒå›´: {min(scores):.4f} - {max(scores):.4f}")
                print(f"    å¹³å‡åˆ†æ•°: {sum(scores)/len(scores):.4f}")
                
                # æ£€æŸ¥æ˜¯å¦æœ‰ä½åˆ†ç»“æœ
                low_score_results = [r for r in all_results if r.get('score', 0) < 0.5]
                if low_score_results:
                    print(f"    ä½åˆ†ç»“æœæ•°é‡: {len(low_score_results)}")
                    for r in low_score_results[:3]:
                        print(f"      åˆ†æ•°: {r.get('score', 0):.4f}, æ–¹æ³•: {r.get('search_method', 'N/A')}")
                
                # æ£€æŸ¥æˆ‘ä»¬çš„å›¾4ç»“æœ
                our_results = [r for r in all_results if all([
                    r.get('document_name'),
                    r.get('page_number'),
                    r.get('chunk_type'),
                    r.get('llm_context')
                ])]
                
                print(f"\n    æˆ‘ä»¬çš„ç»“æœåˆ†æ:")
                print(f"      æ•°é‡: {len(our_results)}")
                for r in our_results:
                    print(f"      åˆ†æ•°: {r.get('score', 0):.4f}, æ–¹æ³•: {r.get('search_method', 'N/A')}")
                    if 'å›¾4' in r.get('llm_context', ''):
                        print(f"        ğŸ¯ åŒ…å«å›¾4ä¿¡æ¯!")
                    else:
                        print(f"        âŒ ä¸åŒ…å«å›¾4ä¿¡æ¯")
                
        except Exception as e:
            print(f"  æ¨¡æ‹Ÿæºè¿‡æ»¤å¤±è´¥: {e}")
            import traceback
            print(f"  è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")
        
        # 5. ç¬¬ä¸‰æ­¥ï¼šæ£€æŸ¥æºè¿‡æ»¤å¼•æ“çš„å…·ä½“å®ç°
        print(f"\nğŸ“Š ç¬¬ä¸‰æ­¥ï¼šæ£€æŸ¥æºè¿‡æ»¤å¼•æ“çš„å…·ä½“å®ç°")
        try:
            # æŸ¥çœ‹filter_sourcesæ–¹æ³•çš„å®Œæ•´å®ç°
            import inspect
            source = inspect.getsource(source_filter_engine.filter_sources)
            print(f"  filter_sourcesæ–¹æ³•å®Œæ•´å®ç°:")
            lines = source.split('\n')
            
            # æ˜¾ç¤ºå…³é”®éƒ¨åˆ†
            key_sections = []
            for i, line in enumerate(lines):
                if any(keyword in line.lower() for keyword in ['score', 'filter', 'threshold', 'min', 'max']):
                    key_sections.append((i+1, line))
            
            for line_num, line in key_sections:
                print(f"    {line_num:2d}: {line}")
            
            # æ˜¾ç¤ºæ–¹æ³•ç»“å°¾
            print(f"  ...")
            for i in range(max(0, len(lines)-10), len(lines)):
                print(f"    {i+1:2d}: {lines[i]}")
                
        except Exception as e:
            print(f"  æºè¿‡æ»¤å¼•æ“æ£€æŸ¥å¤±è´¥: {e}")
            import traceback
            print(f"  è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")
        
        # 6. ç¬¬å››æ­¥ï¼šé—®é¢˜åˆ†æ
        print("\n" + "=" * 80)
        print("ğŸ¯ æ·±åº¦é—®é¢˜åˆ†æ")
        print("=" * 80)
        
        print(f"\nå…³é”®å‘ç°:")
        print(f"1. äº”å±‚å¬å›å±‚é¢ï¼šâœ… æˆ‘ä»¬çš„metadataå­—æ®µåœ¨vector_searchä¸­æ­£ç¡®ä¼ é€’")
        print(f"2. äº”å±‚å¬å›å±‚é¢ï¼šâŒ å…¶ä»–å¬å›ç­–ç•¥æ²¡æœ‰æˆ‘ä»¬çš„metadataå­—æ®µ")
        print(f"3. æºè¿‡æ»¤å±‚é¢ï¼šâ“ éœ€è¦ç¡®è®¤è¿‡æ»¤è§„åˆ™å’Œé˜ˆå€¼")
        
        print(f"\nå¯èƒ½çš„é—®é¢˜ç‚¹:")
        print(f"1. æºè¿‡æ»¤å¯èƒ½åŸºäºåˆ†æ•°è¿‡æ»¤ï¼Œæˆ‘ä»¬çš„ç»“æœåˆ†æ•°ä¸å¤Ÿé«˜")
        print(f"2. æºè¿‡æ»¤å¯èƒ½åŸºäºæ•°é‡é™åˆ¶ï¼Œåªä¿ç•™å‰Nä¸ªç»“æœ")
        print(f"3. æœ€ç»ˆLLMä¸Šä¸‹æ–‡å¯èƒ½æ¥è‡ªå…¶ä»–å¬å›ç­–ç•¥çš„ç»“æœ")
        print(f"4. æˆ‘ä»¬çš„å›¾4ä¿¡æ¯è™½ç„¶è¢«å¬å›ï¼Œä½†åœ¨åç»­å¤„ç†ä¸­è¢«ä¸¢å¼ƒ")
        
        print(f"\nå»ºè®®çš„è°ƒè¯•æ–¹å‘:")
        print(f"1. æ£€æŸ¥æºè¿‡æ»¤çš„å…·ä½“é˜ˆå€¼å’Œè§„åˆ™")
        print(f"2. ç¡®è®¤æœ€ç»ˆä¼ é€’ç»™LLMçš„ä¸Šä¸‹æ–‡æ¥æº")
        print(f"3. æ£€æŸ¥æ˜¯å¦éœ€è¦å¢å¼ºå…¶ä»–å¬å›ç­–ç•¥çš„metadata")
        print(f"4. è€ƒè™‘è°ƒæ•´æºè¿‡æ»¤çš„ä¼˜å…ˆçº§ç­–ç•¥")
        
    except Exception as e:
        print(f"âŒ è°ƒè¯•å¤±è´¥: {e}")
        import traceback
        print(f"è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")


if __name__ == "__main__":
    debug_source_filter_deep()
