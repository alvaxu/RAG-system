# RAGæ™ºèƒ½é—®ç­”ç³»ç»Ÿ - æŠ€æœ¯å®ç°è¯¦ç»†è¯´æ˜

## ğŸ“‹ æŠ€æœ¯æ¶æ„æ¦‚è¿°

### ç³»ç»ŸæŠ€æœ¯æ ˆ
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    æŠ€æœ¯æ ˆæ¶æ„å›¾                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ å‰ç«¯å±‚: HTML + JavaScript + Bootstrap                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ WebæœåŠ¡å±‚: Flask + RESTful API                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ åº”ç”¨å±‚: Python + LangChain + è‡ªå®šä¹‰æ¨¡å—                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ å‘é‡å­˜å‚¨å±‚: FAISS + å†…å­˜å­˜å‚¨                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ å¤§è¯­è¨€æ¨¡å‹: é€šä¹‰åƒé—® (DashScope API)                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ æ–‡æ¡£å¤„ç†å±‚: PDFå¤„ç† + Markdownè§£æ + å›¾ç‰‡æå–              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### æ ¸å¿ƒç»„ä»¶å…³ç³»
```
ç”¨æˆ·è¾“å…¥ â†’ Webç•Œé¢ â†’ Flaskè·¯ç”± â†’ QAç³»ç»Ÿ â†’ å‘é‡æ£€ç´¢ â†’ LLM â†’ ç­”æ¡ˆç”Ÿæˆ
    â†‘                                                      â†“
è®°å¿†ç®¡ç† â† å¯¹è¯å†å² â† ç»“æœå¤„ç† â† æ ¼å¼åŒ–è¾“å‡º â† å“åº”ç”Ÿæˆ
```

---

## ğŸ—ï¸ ç³»ç»Ÿæ¶æ„è¯¦è§£

### 1. æ–‡æ¡£å¤„ç†ç®¡é“ (Document Processing Pipeline)

#### 1.1 å¤„ç†æµç¨‹
```python
# æ ¸å¿ƒå¤„ç†æµç¨‹
def process_document_pipeline(document_path, config):
    """
    æ–‡æ¡£å¤„ç†ä¸»æµç¨‹
    """
    # 1. æ–‡æ¡£è§£æ
    if document_path.endswith('.pdf'):
        content = pdf_processor.extract_content(document_path)
    else:
        content = markdown_processor.extract_content(document_path)
    
    # 2. å›¾ç‰‡æå–
    images = image_extractor.extract_images(content)
    
    # 3. è¡¨æ ¼è¯†åˆ«
    tables = table_processor.extract_tables(content)
    
    # 4. æ–‡æ¡£åˆ†å—
    text_chunks = document_chunker.chunk_document(content)
    
    # 5. å‘é‡åŒ–å¤„ç†
    vector_store = vector_generator.create_vectors(
        text_chunks + images + tables
    )
    
    return vector_store
```

#### 1.2 PDFå¤„ç†æŠ€æœ¯
```python
class PDFProcessor:
    """
    PDFæ–‡æ¡£å¤„ç†å™¨
    """
    def extract_content(self, pdf_path):
        """
        æå–PDFå†…å®¹ï¼ŒåŒ…æ‹¬æ–‡æœ¬ã€å›¾ç‰‡ã€è¡¨æ ¼
        """
        # ä½¿ç”¨pdfplumberè¿›è¡Œæ–‡æœ¬æå–
        with pdfplumber.open(pdf_path) as pdf:
            pages = []
            for page_num, page in enumerate(pdf.pages):
                # æå–æ–‡æœ¬
                text = page.extract_text()
                
                # æå–å›¾ç‰‡
                images = page.images
                
                # æå–è¡¨æ ¼
                tables = page.extract_tables()
                
                pages.append({
                    'page_number': page_num + 1,
                    'text': text,
                    'images': images,
                    'tables': tables
                })
        
        return pages
```

#### 1.3 æ–‡æ¡£åˆ†å—ç®—æ³•
```python
class DocumentChunker:
    """
    æ–‡æ¡£åˆ†å—å¤„ç†å™¨
    """
    def chunk_document(self, content, chunk_size=1000, overlap=200):
        """
        æ™ºèƒ½æ–‡æ¡£åˆ†å—
        """
        chunks = []
        
        # æŒ‰æ®µè½åˆ†å‰²
        paragraphs = content.split('\n\n')
        
        current_chunk = ""
        for paragraph in paragraphs:
            if len(current_chunk) + len(paragraph) <= chunk_size:
                current_chunk += paragraph + "\n\n"
            else:
                if current_chunk:
                    chunks.append(current_chunk.strip())
                current_chunk = paragraph + "\n\n"
        
        # æ·»åŠ æœ€åä¸€ä¸ªå—
        if current_chunk:
            chunks.append(current_chunk.strip())
        
        # åº”ç”¨é‡å ç­–ç•¥
        overlapped_chunks = self._apply_overlap(chunks, overlap)
        
        return overlapped_chunks
```

### 2. å‘é‡æ•°æ®åº“æŠ€æœ¯ (Vector Database)

#### 2.1 FAISSå‘é‡å­˜å‚¨
```python
class VectorStore:
    """
    å‘é‡å­˜å‚¨ç®¡ç†å™¨
    """
    def __init__(self, embeddings_model):
        self.embeddings = embeddings_model
        self.index = None
        self.docstore = {}
        self.metadata = {}
    
    def add_documents(self, documents):
        """
        æ·»åŠ æ–‡æ¡£åˆ°å‘é‡å­˜å‚¨
        """
        # ç”Ÿæˆæ–‡æ¡£å‘é‡
        texts = [doc.page_content for doc in documents]
        embeddings = self.embeddings.embed_documents(texts)
        
        # åˆ›å»ºFAISSç´¢å¼•
        dimension = len(embeddings[0])
        self.index = faiss.IndexFlatIP(dimension)
        
        # æ·»åŠ å‘é‡åˆ°ç´¢å¼•
        embeddings_array = np.array(embeddings).astype('float32')
        self.index.add(embeddings_array)
        
        # å­˜å‚¨æ–‡æ¡£å’Œå…ƒæ•°æ®
        for i, doc in enumerate(documents):
            doc_id = f"doc_{i}"
            self.docstore[doc_id] = doc
            self.metadata[doc_id] = doc.metadata
    
    def similarity_search(self, query, k=5):
        """
        ç›¸ä¼¼æ€§æœç´¢
        """
        # æŸ¥è¯¢å‘é‡åŒ–
        query_embedding = self.embeddings.embed_query(query)
        
        # æ‰§è¡Œæœç´¢
        query_array = np.array([query_embedding]).astype('float32')
        scores, indices = self.index.search(query_array, k)
        
        # è¿”å›ç»“æœ
        results = []
        for idx in indices[0]:
            if idx < len(self.docstore):
                doc_id = f"doc_{idx}"
                results.append(self.docstore[doc_id])
        
        return results
```

#### 2.2 å›¾ç‰‡å‘é‡åŒ–æŠ€æœ¯
```python
class ImageVectorizer:
    """
    å›¾ç‰‡å‘é‡åŒ–å¤„ç†å™¨
    """
    def __init__(self, embeddings_model):
        self.embeddings = embeddings_model
    
    def vectorize_image(self, image_path):
        """
        å›¾ç‰‡å‘é‡åŒ–
        """
        # å›¾ç‰‡é¢„å¤„ç†
        image = self._preprocess_image(image_path)
        
        # ç”Ÿæˆå›¾ç‰‡æè¿°
        description = self._generate_image_description(image)
        
        # å°†æè¿°è½¬æ¢ä¸ºå‘é‡
        embedding = self.embeddings.embed_query(description)
        
        return embedding, description
    
    def _preprocess_image(self, image_path):
        """
        å›¾ç‰‡é¢„å¤„ç†
        """
        # å›¾ç‰‡åŠ è½½å’Œè°ƒæ•´
        image = Image.open(image_path)
        image = image.convert('RGB')
        image = image.resize((224, 224))  # æ ‡å‡†åŒ–å°ºå¯¸
        
        return image
    
    def _generate_image_description(self, image):
        """
        ç”Ÿæˆå›¾ç‰‡æè¿°
        """
        # ä½¿ç”¨OCRæŠ€æœ¯æå–æ–‡å­—
        text = pytesseract.image_to_string(image, lang='chi_sim+eng')
        
        # ç”Ÿæˆç»“æ„åŒ–æè¿°
        description = f"å›¾ç‰‡å†…å®¹: {text[:200]}..."
        
        return description
```

### 3. é—®ç­”ç³»ç»Ÿæ ¸å¿ƒ (QA System Core)

#### 3.1 æ£€ç´¢å¢å¼ºç”Ÿæˆ (RAG)
```python
class QASystem:
    """
    é—®ç­”ç³»ç»Ÿæ ¸å¿ƒ
    """
    def __init__(self, vector_store, llm_model, memory_manager):
        self.vector_store = vector_store
        self.llm = llm_model
        self.memory = memory_manager
        self.qa_chain = self._create_qa_chain()
    
    def _create_qa_chain(self):
        """
        åˆ›å»ºé—®ç­”é“¾
        """
        # å®šä¹‰æç¤ºæ¨¡æ¿
        prompt_template = """
        åŸºäºä»¥ä¸‹æ–‡æ¡£å†…å®¹å’Œå¯¹è¯å†å²å›ç­”é—®é¢˜ï¼š
        
        æ–‡æ¡£å†…å®¹ï¼š
        {context}
        
        å¯¹è¯å†å²ï¼š
        {chat_history}
        
        é—®é¢˜ï¼š{question}
        
        è¯·æ ¹æ®æ–‡æ¡£å†…å®¹æä¾›å‡†ç¡®ã€è¯¦ç»†çš„å›ç­”ã€‚å¦‚æœæ–‡æ¡£ä¸­æ²¡æœ‰ç›¸å…³ä¿¡æ¯ï¼Œè¯·æ˜ç¡®è¯´æ˜ã€‚
        """
        
        prompt = PromptTemplate(
            template=prompt_template,
            input_variables=["context", "chat_history", "question"]
        )
        
        # åˆ›å»ºé—®ç­”é“¾
        qa_chain = load_qa_chain(
            llm=self.llm,
            chain_type="stuff",
            prompt=prompt
        )
        
        return qa_chain
    
    def answer_question(self, question, k=5):
        """
        å›ç­”é—®é¢˜
        """
        # 1. æ£€ç´¢ç›¸å…³æ–‡æ¡£
        docs = self._retrieve_relevant_docs(question, k)
        
        # 2. è·å–å¯¹è¯å†å²
        chat_history = self.memory.get_chat_history()
        
        # 3. æ„å»ºä¸Šä¸‹æ–‡
        context = self._build_context(docs)
        
        # 4. ç”Ÿæˆå›ç­”
        response = self._generate_answer(question, context, chat_history)
        
        # 5. æ›´æ–°è®°å¿†
        self.memory.add_interaction(question, response)
        
        return response
    
    def _retrieve_relevant_docs(self, question, k):
        """
        æ£€ç´¢ç›¸å…³æ–‡æ¡£
        """
        # æ£€æŸ¥æ˜¯å¦ä¸ºå›¾ç‰‡ç›¸å…³é—®é¢˜
        image_keywords = ['å›¾ç‰‡', 'å›¾åƒ', 'ç…§ç‰‡', 'å›¾è¡¨', 'å›¾']
        is_image_question = any(keyword in question for keyword in image_keywords)
        
        if is_image_question:
            # ä¸“é—¨æœç´¢å›¾ç‰‡æ–‡æ¡£
            return self._search_images(k)
        else:
            # å¸¸è§„ç›¸ä¼¼æ€§æœç´¢
            return self.vector_store.similarity_search(question, k)
    
    def _search_images(self, k):
        """
        æœç´¢å›¾ç‰‡æ–‡æ¡£
        """
        image_docs = []
        
        # éå†æ‰€æœ‰æ–‡æ¡£ï¼Œç­›é€‰å›¾ç‰‡ç±»å‹
        for doc_id, doc in self.vector_store.docstore._dict.items():
            if doc.metadata.get('chunk_type') == 'image':
                image_docs.append(doc)
                if len(image_docs) >= k:
                    break
        
        return image_docs
```

#### 3.2 è®°å¿†ç®¡ç†ç³»ç»Ÿ
```python
class MemoryManager:
    """
    è®°å¿†ç®¡ç†å™¨
    """
    def __init__(self, memory_db_path):
        self.memory_db_path = memory_db_path
        self.session_memory = []
        self.user_memory = self._load_user_memory()
    
    def add_interaction(self, question, answer):
        """
        æ·»åŠ äº¤äº’åˆ°è®°å¿†
        """
        interaction = {
            'timestamp': datetime.now().isoformat(),
            'question': question,
            'answer': answer,
            'type': 'qa_interaction'
        }
        
        # æ·»åŠ åˆ°ä¼šè¯è®°å¿†
        self.session_memory.append(interaction)
        
        # é™åˆ¶ä¼šè¯è®°å¿†é•¿åº¦
        if len(self.session_memory) > 10:
            self.session_memory.pop(0)
    
    def get_chat_history(self):
        """
        è·å–å¯¹è¯å†å²
        """
        history = []
        for interaction in self.session_memory[-5:]:  # æœ€è¿‘5æ¬¡äº¤äº’
            history.append(f"ç”¨æˆ·: {interaction['question']}")
            history.append(f"åŠ©æ‰‹: {interaction['answer']}")
        
        return "\n".join(history)
    
    def _load_user_memory(self):
        """
        åŠ è½½ç”¨æˆ·è®°å¿†
        """
        try:
            with open(f"{self.memory_db_path}/user_memory.json", 'r', encoding='utf-8') as f:
                return json.load(f)
        except FileNotFoundError:
            return {}
    
    def save_user_memory(self):
        """
        ä¿å­˜ç”¨æˆ·è®°å¿†
        """
        os.makedirs(self.memory_db_path, exist_ok=True)
        with open(f"{self.memory_db_path}/user_memory.json", 'w', encoding='utf-8') as f:
            json.dump(self.user_memory, f, ensure_ascii=False, indent=2)
```

### 4. WebæœåŠ¡æ¶æ„ (Web Service Architecture)

#### 4.1 Flaskåº”ç”¨ç»“æ„
```python
# app.py
from flask import Flask, request, jsonify
from core.qa_system import QASystem
from core.memory_manager import MemoryManager

app = Flask(__name__)

# å…¨å±€å˜é‡
qa_system = None
memory_manager = None

@app.route('/api/ask', methods=['POST'])
def ask_question():
    """
    é—®ç­”APIç«¯ç‚¹
    """
    try:
        data = request.get_json()
        question = data.get('question', '')
        
        if not question:
            return jsonify({'error': 'é—®é¢˜ä¸èƒ½ä¸ºç©º'}), 400
        
        # è·å–å›ç­”
        result = qa_system.answer_question(question)
        
        return jsonify({
            'answer': result['answer'],
            'sources': result['sources'],
            'cost': result['cost']
        })
        
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/api/upload', methods=['POST'])
def upload_document():
    """
    æ–‡æ¡£ä¸Šä¼ APIç«¯ç‚¹
    """
    try:
        if 'file' not in request.files:
            return jsonify({'error': 'æ²¡æœ‰æ–‡ä»¶'}), 400
        
        file = request.files['file']
        if file.filename == '':
            return jsonify({'error': 'æ²¡æœ‰é€‰æ‹©æ–‡ä»¶'}), 400
        
        # ä¿å­˜æ–‡ä»¶
        filename = secure_filename(file.filename)
        file_path = os.path.join(app.config['UPLOAD_FOLDER'], filename)
        file.save(file_path)
        
        # å¤„ç†æ–‡æ¡£
        process_document(file_path)
        
        return jsonify({'message': 'æ–‡æ¡£ä¸Šä¼ å¹¶å¤„ç†æˆåŠŸ'})
        
    except Exception as e:
        return jsonify({'error': str(e)}), 500
```

#### 4.2 å‰ç«¯äº¤äº’
```javascript
// é—®ç­”åŠŸèƒ½
async function askQuestion() {
    const question = document.getElementById('question').value;
    
    if (!question.trim()) {
        alert('è¯·è¾“å…¥é—®é¢˜');
        return;
    }
    
    // æ˜¾ç¤ºåŠ è½½çŠ¶æ€
    showLoading();
    
    try {
        const response = await fetch('/api/ask', {
            method: 'POST',
            headers: {
                'Content-Type': 'application/json',
            },
            body: JSON.stringify({ question: question })
        });
        
        const data = await response.json();
        
        if (response.ok) {
            displayAnswer(data);
        } else {
            showError(data.error);
        }
        
    } catch (error) {
        showError('ç½‘ç»œé”™è¯¯: ' + error.message);
    } finally {
        hideLoading();
    }
}

// æ˜¾ç¤ºç­”æ¡ˆ
function displayAnswer(data) {
    const answerDiv = document.getElementById('answer');
    answerDiv.innerHTML = `
        <div class="answer-content">
            <h4>å›ç­”:</h4>
            <p>${data.answer}</p>
            
            <h4>æ¥æº:</h4>
            <ul>
                ${data.sources.map(source => 
                    `<li>${source.document_name} (ç¬¬${source.page_number}é¡µ)</li>`
                ).join('')}
            </ul>
            
            <small>æˆæœ¬: ${data.cost.toFixed(6)} å…ƒ</small>
        </div>
    `;
}
```

### 5. é…ç½®ç®¡ç†ç³»ç»Ÿ (Configuration Management)

#### 5.1 é…ç½®ç»“æ„
```python
# config/settings.py
class Settings:
    """
    ç³»ç»Ÿé…ç½®ç±»
    """
    def __init__(self):
        # APIé…ç½®
        self.dashscope_api_key = os.getenv('MY_DASHSCOPE_API_KEY', '')
        
        # è·¯å¾„é…ç½®
        self.pdf_dir = "./pdf_test"
        self.md_dir = "./md_test"
        self.output_dir = "./output"
        self.vector_db_dir = "./vector_db_test"
        self.memory_db_dir = "./memory_db"
        
        # å¤„ç†é…ç½®
        self.chunk_size = 1000
        self.chunk_overlap = 200
        self.max_tokens = 4000
        
        # æ¨¡å‹é…ç½®
        self.embedding_model = "text-embedding-v1"
        self.llm_model = "qwen-turbo"
        
        # æ—¥å¿—é…ç½®
        self.log_level = "INFO"
        self.log_file = "document_processing.log"
```

#### 5.2 é…ç½®éªŒè¯
```python
class ConfigValidator:
    """
    é…ç½®éªŒè¯å™¨
    """
    def validate_config(self, config):
        """
        éªŒè¯é…ç½®æœ‰æ•ˆæ€§
        """
        errors = []
        
        # æ£€æŸ¥APIå¯†é’¥
        if not config.dashscope_api_key:
            errors.append("æœªé…ç½®DashScope APIå¯†é’¥")
        
        # æ£€æŸ¥è·¯å¾„
        required_paths = [
            config.pdf_dir,
            config.md_dir,
            config.output_dir,
            config.vector_db_dir,
            config.memory_db_dir
        ]
        
        for path in required_paths:
            if not os.path.exists(path):
                try:
                    os.makedirs(path, exist_ok=True)
                except Exception as e:
                    errors.append(f"æ— æ³•åˆ›å»ºç›®å½• {path}: {e}")
        
        # æ£€æŸ¥æ¨¡å‹é…ç½®
        if config.chunk_size <= 0:
            errors.append("chunk_sizeå¿…é¡»å¤§äº0")
        
        if config.chunk_overlap < 0:
            errors.append("chunk_overlapä¸èƒ½ä¸ºè´Ÿæ•°")
        
        return errors
```

### 6. æ€§èƒ½ä¼˜åŒ–æŠ€æœ¯ (Performance Optimization)

#### 6.1 å‘é‡æ£€ç´¢ä¼˜åŒ–
```python
class OptimizedVectorStore:
    """
    ä¼˜åŒ–çš„å‘é‡å­˜å‚¨
    """
    def __init__(self, embeddings_model):
        self.embeddings = embeddings_model
        self.index = None
        self.docstore = {}
        self.cache = {}  # æŸ¥è¯¢ç¼“å­˜
    
    def similarity_search_with_cache(self, query, k=5):
        """
        å¸¦ç¼“å­˜çš„ç›¸ä¼¼æ€§æœç´¢
        """
        # ç”ŸæˆæŸ¥è¯¢å“ˆå¸Œ
        query_hash = hashlib.md5(query.encode()).hexdigest()
        
        # æ£€æŸ¥ç¼“å­˜
        if query_hash in self.cache:
            return self.cache[query_hash]
        
        # æ‰§è¡Œæœç´¢
        results = self.similarity_search(query, k)
        
        # ç¼“å­˜ç»“æœ
        self.cache[query_hash] = results
        
        # é™åˆ¶ç¼“å­˜å¤§å°
        if len(self.cache) > 1000:
            # åˆ é™¤æœ€æ—§çš„ç¼“å­˜é¡¹
            oldest_key = next(iter(self.cache))
            del self.cache[oldest_key]
        
        return results
```

#### 6.2 å¼‚æ­¥å¤„ç†
```python
import asyncio
from concurrent.futures import ThreadPoolExecutor

class AsyncDocumentProcessor:
    """
    å¼‚æ­¥æ–‡æ¡£å¤„ç†å™¨
    """
    def __init__(self):
        self.executor = ThreadPoolExecutor(max_workers=4)
    
    async def process_documents_async(self, document_paths):
        """
        å¼‚æ­¥å¤„ç†å¤šä¸ªæ–‡æ¡£
        """
        tasks = []
        
        for path in document_paths:
            task = asyncio.create_task(
                self._process_single_document(path)
            )
            tasks.append(task)
        
        # å¹¶å‘æ‰§è¡Œ
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        return results
    
    async def _process_single_document(self, path):
        """
        å¤„ç†å•ä¸ªæ–‡æ¡£
        """
        loop = asyncio.get_event_loop()
        
        # åœ¨çº¿ç¨‹æ± ä¸­æ‰§è¡ŒCPUå¯†é›†å‹ä»»åŠ¡
        result = await loop.run_in_executor(
            self.executor,
            self._process_document_sync,
            path
        )
        
        return result
    
    def _process_document_sync(self, path):
        """
        åŒæ­¥å¤„ç†æ–‡æ¡£
        """
        # å®é™…çš„æ–‡æ¡£å¤„ç†é€»è¾‘
        pass
```

### 7. é”™è¯¯å¤„ç†å’Œæ—¥å¿— (Error Handling & Logging)

#### 7.1 ç»Ÿä¸€é”™è¯¯å¤„ç†
```python
class ErrorHandler:
    """
    ç»Ÿä¸€é”™è¯¯å¤„ç†å™¨
    """
    def __init__(self, logger):
        self.logger = logger
    
    def handle_api_error(self, error, context=""):
        """
        å¤„ç†APIé”™è¯¯
        """
        error_info = {
            'error_type': type(error).__name__,
            'error_message': str(error),
            'context': context,
            'timestamp': datetime.now().isoformat()
        }
        
        # è®°å½•é”™è¯¯
        self.logger.error(f"APIé”™è¯¯: {error_info}")
        
        # æ ¹æ®é”™è¯¯ç±»å‹è¿”å›é€‚å½“çš„å“åº”
        if isinstance(error, ValueError):
            return {'error': 'å‚æ•°é”™è¯¯', 'details': str(error)}, 400
        elif isinstance(error, FileNotFoundError):
            return {'error': 'æ–‡ä»¶æœªæ‰¾åˆ°', 'details': str(error)}, 404
        else:
            return {'error': 'æœåŠ¡å™¨å†…éƒ¨é”™è¯¯', 'details': str(error)}, 500
    
    def handle_processing_error(self, error, document_path=""):
        """
        å¤„ç†æ–‡æ¡£å¤„ç†é”™è¯¯
        """
        error_info = {
            'error_type': type(error).__name__,
            'error_message': str(error),
            'document_path': document_path,
            'timestamp': datetime.now().isoformat()
        }
        
        self.logger.error(f"æ–‡æ¡£å¤„ç†é”™è¯¯: {error_info}")
        
        # è¿”å›å¤„ç†é”™è¯¯ä¿¡æ¯
        return {
            'status': 'error',
            'message': f'æ–‡æ¡£å¤„ç†å¤±è´¥: {str(error)}',
            'document': document_path
        }
```

#### 7.2 ç»“æ„åŒ–æ—¥å¿—
```python
import logging
import json
from datetime import datetime

class StructuredLogger:
    """
    ç»“æ„åŒ–æ—¥å¿—è®°å½•å™¨
    """
    def __init__(self, log_file):
        self.logger = logging.getLogger(__name__)
        self.logger.setLevel(logging.INFO)
        
        # æ–‡ä»¶å¤„ç†å™¨
        file_handler = logging.FileHandler(log_file, encoding='utf-8')
        file_handler.setLevel(logging.INFO)
        
        # æ ¼å¼åŒ–å™¨
        formatter = logging.Formatter(
            '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
        )
        file_handler.setFormatter(formatter)
        
        self.logger.addHandler(file_handler)
    
    def log_qa_interaction(self, question, answer, sources, cost):
        """
        è®°å½•é—®ç­”äº¤äº’
        """
        log_entry = {
            'event_type': 'qa_interaction',
            'timestamp': datetime.now().isoformat(),
            'question': question,
            'answer_length': len(answer),
            'sources_count': len(sources),
            'cost': cost
        }
        
        self.logger.info(json.dumps(log_entry, ensure_ascii=False))
    
    def log_document_processing(self, document_path, status, details):
        """
        è®°å½•æ–‡æ¡£å¤„ç†
        """
        log_entry = {
            'event_type': 'document_processing',
            'timestamp': datetime.now().isoformat(),
            'document_path': document_path,
            'status': status,
            'details': details
        }
        
        self.logger.info(json.dumps(log_entry, ensure_ascii=False))
```

---

## ğŸ”§ æŠ€æœ¯å®ç°ç»†èŠ‚

### 1. å‘é‡åŒ–ç®—æ³•
- **æ–‡æœ¬å‘é‡åŒ–**: ä½¿ç”¨DashScopeçš„text-embedding-v1æ¨¡å‹
- **å›¾ç‰‡å‘é‡åŒ–**: åŸºäºå›¾ç‰‡æè¿°æ–‡æœ¬çš„å‘é‡åŒ–
- **è¡¨æ ¼å‘é‡åŒ–**: ç»“æ„åŒ–è¡¨æ ¼æ•°æ®çš„æ–‡æœ¬è¡¨ç¤º

### 2. æ£€ç´¢ç®—æ³•
- **ç›¸ä¼¼æ€§æœç´¢**: FAISSçš„IndexFlatIPç´¢å¼•
- **æ··åˆæ£€ç´¢**: æ–‡æœ¬+å›¾ç‰‡+è¡¨æ ¼çš„å¤šæ¨¡æ€æ£€ç´¢
- **ç¼“å­˜æœºåˆ¶**: æŸ¥è¯¢ç»“æœç¼“å­˜ä¼˜åŒ–

### 3. ç”Ÿæˆç®—æ³•
- **æç¤ºå·¥ç¨‹**: ç»“æ„åŒ–çš„æç¤ºæ¨¡æ¿
- **ä¸Šä¸‹æ–‡ç®¡ç†**: åŠ¨æ€ä¸Šä¸‹æ–‡é•¿åº¦æ§åˆ¶
- **ç­”æ¡ˆä¼˜åŒ–**: åŸºäºæ£€ç´¢ç»“æœçš„ç­”æ¡ˆç”Ÿæˆ

### 4. æ•°æ®æµç¨‹
```
æ–‡æ¡£è¾“å…¥ â†’ é¢„å¤„ç† â†’ åˆ†å— â†’ å‘é‡åŒ– â†’ å­˜å‚¨ â†’ æ£€ç´¢ â†’ ç”Ÿæˆ â†’ è¾“å‡º
    â†“         â†“        â†“        â†“        â†“       â†“       â†“
  æ–‡ä»¶æ£€æŸ¥   æ ¼å¼è½¬æ¢  æ™ºèƒ½åˆ†å‰²  æ¨¡å‹è°ƒç”¨  ç´¢å¼•æ„å»º  ç›¸ä¼¼åŒ¹é…  LLMè°ƒç”¨
```

---

## ğŸ“Š æ€§èƒ½æŒ‡æ ‡

### 1. å¤„ç†æ€§èƒ½
- **PDFå¤„ç†é€Ÿåº¦**: ~2MB/åˆ†é’Ÿ
- **å‘é‡åŒ–é€Ÿåº¦**: ~1000æ–‡æ¡£/åˆ†é’Ÿ
- **æ£€ç´¢å“åº”æ—¶é—´**: <100ms

### 2. å†…å­˜ä½¿ç”¨
- **å‘é‡å­˜å‚¨**: ~1GB/10ä¸‡æ–‡æ¡£
- **ç¼“å­˜å¤§å°**: 1000ä¸ªæŸ¥è¯¢ç»“æœ
- **ä¼šè¯è®°å¿†**: æœ€è¿‘10æ¬¡äº¤äº’

### 3. å‡†ç¡®æ€§æŒ‡æ ‡
- **æ–‡æœ¬æ£€ç´¢å‡†ç¡®ç‡**: >85%
- **å›¾ç‰‡è¯†åˆ«å‡†ç¡®ç‡**: >70%
- **è¡¨æ ¼è¯†åˆ«å‡†ç¡®ç‡**: >90%

---

## ğŸ”„ æ‰©å±•æ€§è®¾è®¡

### 1. æ¨¡å—åŒ–æ¶æ„
- æ¯ä¸ªåŠŸèƒ½æ¨¡å—ç‹¬ç«‹å°è£…
- æ ‡å‡†åŒ–çš„æ¥å£è®¾è®¡
- æ’ä»¶å¼çš„æ‰©å±•æœºåˆ¶

### 2. é…ç½®é©±åŠ¨
- å¤–éƒ¨é…ç½®æ–‡ä»¶ç®¡ç†
- è¿è¡Œæ—¶å‚æ•°è°ƒæ•´
- ç¯å¢ƒå˜é‡æ”¯æŒ

### 3. å¤šæ¨¡å‹æ”¯æŒ
- å¯åˆ‡æ¢çš„LLMæ¨¡å‹
- å¯æ›¿æ¢çš„å‘é‡æ¨¡å‹
- å¯æ‰©å±•çš„å­˜å‚¨åç«¯

---

*æŠ€æœ¯å®ç°è¯¦ç»†è¯´æ˜ - ç‰ˆæœ¬ 1.0*
*æœ€åæ›´æ–°: 2024å¹´7æœˆ29æ—¥* 