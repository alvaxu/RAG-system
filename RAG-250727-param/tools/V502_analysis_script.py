#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è¯¦ç»†åˆ†æå›¾ç‰‡çš„enhanced_descriptionå†…å®¹ï¼ŒåŒºåˆ†åŸºç¡€å¤„ç†å’Œæ·±åº¦å¢å¼º
"""

import os
import sys
import json

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

def analyze_enhanced_descriptions():
    """è¯¦ç»†åˆ†æå›¾ç‰‡çš„enhanced_descriptionå†…å®¹"""
    
    try:
        from langchain_community.vectorstores import FAISS
        from langchain_community.embeddings import DashScopeEmbeddings
        from config.settings import Settings
        
        # åŠ è½½é…ç½®
        settings = Settings.load_from_file('config.json')
        
        # åŠ è½½å‘é‡æ•°æ®åº“
        embeddings = DashScopeEmbeddings(
            dashscope_api_key=settings.dashscope_api_key, 
            model='text-embedding-v1'
        )
        vector_store = FAISS.load_local(
            './central/vector_db', 
            embeddings, 
            allow_dangerous_deserialization=True
        )
        
        print("ğŸ” è¯¦ç»†åˆ†æå›¾ç‰‡çš„enhanced_descriptionå†…å®¹...")
        print("=" * 80)
        
        # è·å–æ‰€æœ‰å›¾ç‰‡æ–‡æ¡£
        image_docs = []
        for doc_id, doc in vector_store.docstore._dict.items():
            if doc.metadata.get('image_path'):
                image_docs.append((doc_id, doc.metadata))
        
        print(f"ğŸ“Š æ‰¾åˆ° {len(image_docs)} ä¸ªå›¾ç‰‡æ–‡æ¡£")
        print()
        
        # åˆ†æå‰å‡ ä¸ªå›¾ç‰‡çš„è¯¦ç»†å†…å®¹
        for i, (doc_id, metadata) in enumerate(image_docs[:5]):
            print(f"ğŸ“· å›¾ç‰‡ {i+1}: {metadata.get('image_path', 'Unknown')}")
            print(f"   ID: {doc_id}")
            
            # æ£€æŸ¥æ·±åº¦å¢å¼ºå­—æ®µ
            has_layered = 'layered_descriptions' in metadata
            has_structured = 'structured_info' in metadata
            has_timestamp = 'enhancement_timestamp' in metadata
            has_enabled = 'enhancement_enabled' in metadata
            
            print(f"   æ·±åº¦å¢å¼ºå­—æ®µ:")
            print(f"     layered_descriptions: {has_layered}")
            print(f"     structured_info: {has_structured}")
            print(f"     enhancement_timestamp: {has_timestamp}")
            print(f"     enhancement_enabled: {has_enabled}")
            
            # åˆ†æenhanced_descriptionå†…å®¹
            enhanced_desc = metadata.get('enhanced_description', '')
            if enhanced_desc:
                print(f"   enhanced_description é•¿åº¦: {len(enhanced_desc)}")
                print(f"   å†…å®¹é¢„è§ˆ: {enhanced_desc[:200]}...")
                
                # æ£€æŸ¥æ˜¯å¦åŒ…å«æ·±åº¦å¢å¼ºæ ‡è®°
                depth_markers = [
                    'åŸºç¡€è§†è§‰æè¿°:', 'å†…å®¹ç†è§£æè¿°:', 'æ•°æ®è¶‹åŠ¿æè¿°:', 
                    'è¯­ä¹‰ç‰¹å¾æè¿°:', 'æ•°æ®ç‚¹:', 'è¶‹åŠ¿åˆ†æ:', 'å…³é”®æ´å¯Ÿ:'
                ]
                
                found_markers = [marker for marker in depth_markers if marker in enhanced_desc]
                if found_markers:
                    print(f"   åŒ…å«çš„æ·±åº¦å¢å¼ºæ ‡è®°: {found_markers}")
                else:
                    print(f"   ä¸åŒ…å«æ·±åº¦å¢å¼ºæ ‡è®°")
            else:
                print(f"   æ²¡æœ‰enhanced_descriptionå­—æ®µ")
            
            print("-" * 60)
        
        # ç»Ÿè®¡åˆ†æ
        print("\nğŸ“Š ç»Ÿè®¡åˆ†æ:")
        print("=" * 60)
        
        depth_enhanced_count = 0
        basic_processed_count = 0
        no_description_count = 0
        
        for doc_id, metadata in image_docs:
            has_layered = 'layered_descriptions' in metadata
            has_structured = 'structured_info' in metadata
            enhanced_desc = metadata.get('enhanced_description', '')
            
            if has_layered and has_structured:
                depth_enhanced_count += 1
            elif enhanced_desc:
                basic_processed_count += 1
            else:
                no_description_count += 1
        
        print(f"æ·±åº¦å¢å¼ºå›¾ç‰‡: {depth_enhanced_count}")
        print(f"åŸºç¡€å¤„ç†å›¾ç‰‡: {basic_processed_count}")
        print(f"æ— æè¿°å›¾ç‰‡: {no_description_count}")
        print(f"æ€»è®¡: {len(image_docs)}")
        
    except Exception as e:
        print(f"âŒ åˆ†æå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    analyze_enhanced_descriptions()
