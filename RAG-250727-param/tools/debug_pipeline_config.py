'''
ç¨‹åºè¯´æ˜ï¼š
## 1. è°ƒè¯•Pipelineé…ç½®ä¼ é€’é—®é¢˜
## 2. æ£€æŸ¥pipeline_config.__dict__çš„å®é™…å†…å®¹
## 3. éªŒè¯é…ç½®æ˜¯å¦æ­£ç¡®ä¼ é€’åˆ°UnifiedPipeline
'''

import logging
import sys
import os

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)

logger = logging.getLogger(__name__)

def debug_pipeline_config():
    """è°ƒè¯•Pipelineé…ç½®ä¼ é€’é—®é¢˜"""
    
    logger.info("å¼€å§‹è°ƒè¯•Pipelineé…ç½®ä¼ é€’é—®é¢˜")
    
    try:
        # å¯¼å…¥å¿…è¦çš„æ¨¡å—
        from v2.config.v2_config import V2ConfigManager
        
        # åŠ è½½é…ç½®
        config_manager = V2ConfigManager()
        pipeline_config = config_manager.get_engine_config('unified_pipeline')
        
        if not pipeline_config:
            logger.error("âŒ æ— æ³•è·å–unified_pipelineé…ç½®")
            return False
        
        logger.info("âœ… é…ç½®åŠ è½½æˆåŠŸ")
        logger.info(f"é…ç½®å¯¹è±¡ç±»å‹: {type(pipeline_config)}")
        logger.info(f"é…ç½®å¯¹è±¡å±æ€§: {[attr for attr in dir(pipeline_config) if not attr.startswith('_')]}")
        
        # æ£€æŸ¥å…³é”®å­—æ®µ
        logger.info(f"\nğŸ” å…³é”®å­—æ®µæ£€æŸ¥:")
        logger.info(f"  enable_llm_generation: {pipeline_config.enable_llm_generation}")
        logger.info(f"  enable_source_filtering: {pipeline_config.enable_source_filtering}")
        logger.info(f"  max_context_results: {pipeline_config.max_context_results}")
        logger.info(f"  max_content_length: {pipeline_config.max_content_length}")
        
        # æ£€æŸ¥__dict__å†…å®¹
        logger.info(f"\nğŸ” __dict__å†…å®¹æ£€æŸ¥:")
        config_dict = pipeline_config.__dict__
        logger.info(f"  __dict__ç±»å‹: {type(config_dict)}")
        logger.info(f"  __dict__é”®: {list(config_dict.keys())}")
        
        for key, value in config_dict.items():
            logger.info(f"    {key}: {value} (ç±»å‹: {type(value)})")
        
        # æ£€æŸ¥enable_source_filteringå­—æ®µ
        if 'enable_source_filtering' in config_dict:
            logger.info(f"\nâœ… enable_source_filteringå­—æ®µå­˜åœ¨: {config_dict['enable_source_filtering']}")
        else:
            logger.error(f"\nâŒ enable_source_filteringå­—æ®µä¸å­˜åœ¨ï¼")
            
        # æ¨¡æ‹ŸUnifiedPipelineçš„config.getè°ƒç”¨
        logger.info(f"\nğŸ” æ¨¡æ‹ŸUnifiedPipelineçš„config.getè°ƒç”¨:")
        test_config = config_dict.copy()
        
        # æ¨¡æ‹ŸUnifiedPipelineçš„åˆå§‹åŒ–
        enable_source_filtering = test_config.get('enable_source_filtering', True)
        logger.info(f"  config.get('enable_source_filtering', True) = {enable_source_filtering}")
        
        if enable_source_filtering:
            logger.warning(f"âš ï¸ æºè¿‡æ»¤å°†è¢«å¯ç”¨ï¼")
        else:
            logger.info(f"âœ… æºè¿‡æ»¤å°†è¢«ç¦ç”¨")
            
        return True
        
    except Exception as e:
        logger.error(f"âŒ è°ƒè¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def main():
    """ä¸»å‡½æ•°"""
    logger.info("=== Pipelineé…ç½®è°ƒè¯•å·¥å…· ===")
    
    success = debug_pipeline_config()
    
    if success:
        logger.info("âœ… è°ƒè¯•å®Œæˆ")
    else:
        logger.error("âŒ è°ƒè¯•å¤±è´¥")

if __name__ == "__main__":
    main()
