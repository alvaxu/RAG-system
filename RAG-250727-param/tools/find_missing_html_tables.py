#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ‰¾å‡ºå‘é‡æ•°æ®åº“ä¸­ç¼ºå°‘HTMLå†…å®¹çš„è¡¨æ ¼
"""

import os
import sys
import pickle
import json
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

def find_missing_html_tables(vector_db_path):
    """
    æ‰¾å‡ºå‘é‡æ•°æ®åº“ä¸­ç¼ºå°‘HTMLå†…å®¹çš„è¡¨æ ¼
    
    :param vector_db_path: å‘é‡æ•°æ®åº“è·¯å¾„
    :return: ç¼ºå°‘HTMLå†…å®¹çš„è¡¨æ ¼åˆ—è¡¨
    """
    try:
        # åŠ è½½å…ƒæ•°æ®
        metadata_path = Path(vector_db_path) / "metadata.pkl"
        if not metadata_path.exists():
            print(f"âŒ å…ƒæ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {metadata_path}")
            return []
        
        with open(metadata_path, 'rb') as f:
            metadata = pickle.load(f)
        
        print(f"ğŸ“Š åŠ è½½äº† {len(metadata)} ä¸ªæ–‡æ¡£çš„å…ƒæ•°æ®")
        
        # æ‰¾å‡ºæ‰€æœ‰è¡¨æ ¼æ–‡æ¡£
        table_docs = []
        missing_html_tables = []
        
        for i, doc_metadata in enumerate(metadata):
            if doc_metadata.get('chunk_type') == 'table':
                table_docs.append({
                    'index': i,
                    'metadata': doc_metadata
                })
                
                # æ£€æŸ¥æ˜¯å¦ç¼ºå°‘HTMLå†…å®¹
                page_content = doc_metadata.get('page_content', '')
                if not page_content or page_content.strip() == '':
                    missing_html_tables.append({
                        'index': i,
                        'metadata': doc_metadata,
                        'reason': 'page_contentä¸ºç©ºæˆ–ä¸å­˜åœ¨'
                    })
                elif not page_content.strip().startswith('<table'):
                    missing_html_tables.append({
                        'index': i,
                        'metadata': doc_metadata,
                        'reason': 'page_contentä¸æ˜¯HTMLæ ¼å¼',
                        'content_preview': page_content[:100]
                    })
        
        print(f"ğŸ“‹ æ‰¾åˆ° {len(table_docs)} ä¸ªè¡¨æ ¼æ–‡æ¡£")
        print(f"âŒ å…¶ä¸­ {len(missing_html_tables)} ä¸ªç¼ºå°‘HTMLå†…å®¹")
        
        # æ˜¾ç¤ºç¼ºå°‘HTMLå†…å®¹çš„è¡¨æ ¼è¯¦æƒ…
        if missing_html_tables:
            print("\nğŸ” ç¼ºå°‘HTMLå†…å®¹çš„è¡¨æ ¼è¯¦æƒ…:")
            for i, missing_table in enumerate(missing_html_tables, 1):
                metadata = missing_table['metadata']
                print(f"\nè¡¨æ ¼ {i}:")
                print(f"  ç´¢å¼•: {missing_table['index']}")
                print(f"  è¡¨æ ¼ID: {metadata.get('table_id', 'N/A')}")
                print(f"  è¡¨æ ¼ç±»å‹: {metadata.get('table_type', 'N/A')}")
                print(f"  æ–‡æ¡£åç§°: {metadata.get('document_name', 'N/A')}")
                print(f"  é¡µç : {metadata.get('page_number', 'N/A')}")
                print(f"  åˆ†å—ç´¢å¼•: {metadata.get('chunk_index', 'N/A')}")
                print(f"  è¡Œæ•°: {metadata.get('table_row_count', 'N/A')}")
                print(f"  åˆ—æ•°: {metadata.get('table_column_count', 'N/A')}")
                print(f"  åŸå› : {missing_table['reason']}")
                
                if 'content_preview' in missing_table:
                    print(f"  å†…å®¹é¢„è§ˆ: {missing_table['content_preview']}")
                
                # æ£€æŸ¥processed_table_content
                processed_content = metadata.get('processed_table_content', '')
                if processed_content:
                    print(f"  å¤„ç†åå†…å®¹: {processed_content[:100]}...")
                else:
                    print(f"  å¤„ç†åå†…å®¹: æ— ")
        
        # åˆ†æåˆ†è¡¨æƒ…å†µ
        print(f"\nğŸ“Š åˆ†è¡¨åˆ†æ:")
        chunk_indices = [doc['metadata'].get('chunk_index', -1) for doc in table_docs]
        chunk_indices.sort()
        print(f"  åˆ†å—ç´¢å¼•èŒƒå›´: {min(chunk_indices)} - {max(chunk_indices)}")
        print(f"  åˆ†å—ç´¢å¼•åˆ—è¡¨: {chunk_indices}")
        
        # æŒ‰åˆ†å—ç´¢å¼•åˆ†ç»„
        chunk_groups = {}
        for doc in table_docs:
            chunk_index = doc['metadata'].get('chunk_index', -1)
            if chunk_index not in chunk_groups:
                chunk_groups[chunk_index] = []
            chunk_groups[chunk_index].append(doc)
        
        print(f"\nğŸ“‹ æŒ‰åˆ†å—ç´¢å¼•åˆ†ç»„çš„è¡¨æ ¼:")
        for chunk_index in sorted(chunk_groups.keys()):
            docs = chunk_groups[chunk_index]
            has_html_count = sum(1 for doc in docs if doc['metadata'].get('page_content', '').strip().startswith('<table'))
            total_count = len(docs)
            print(f"  åˆ†å— {chunk_index}: {total_count} ä¸ªè¡¨æ ¼ï¼Œ{has_html_count} ä¸ªæœ‰HTML")
        
        return missing_html_tables
        
    except Exception as e:
        print(f"âŒ åˆ†æå¤±è´¥: {e}")
        return []

def main():
    """ä¸»å‡½æ•°"""
    if len(sys.argv) != 2:
        print("ç”¨æ³•: python find_missing_html_tables.py <vector_db_path>")
        print("ç¤ºä¾‹: python find_missing_html_tables.py ./central/vector_db")
        sys.exit(1)
    
    vector_db_path = sys.argv[1]
    
    if not os.path.exists(vector_db_path):
        print(f"âŒ å‘é‡æ•°æ®åº“è·¯å¾„ä¸å­˜åœ¨: {vector_db_path}")
        sys.exit(1)
    
    print(f"ğŸ” å¼€å§‹åˆ†æå‘é‡æ•°æ®åº“: {vector_db_path}")
    missing_tables = find_missing_html_tables(vector_db_path)
    
    if missing_tables:
        print(f"\nâŒ å‘ç° {len(missing_tables)} ä¸ªç¼ºå°‘HTMLå†…å®¹çš„è¡¨æ ¼")
        print("å»ºè®®æ£€æŸ¥è¡¨æ ¼åˆ†å—å’ŒHTMLå†…å®¹ä¿å­˜é€»è¾‘")
    else:
        print("\nâœ… æ‰€æœ‰è¡¨æ ¼éƒ½æœ‰HTMLå†…å®¹")

if __name__ == "__main__":
    main()
