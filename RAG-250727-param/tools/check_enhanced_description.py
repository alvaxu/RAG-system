#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ£€æŸ¥å›¾ç‰‡æ–‡æ¡£ä¸­enhanced_descriptionå­—æ®µçš„å†…å®¹å’Œä½œç”¨

åˆ†æenhanced_descriptionåœ¨å›¾ç‰‡æŸ¥è¯¢ä¸­çš„å®é™…ä½¿ç”¨æƒ…å†µ
"""

import sys
import os
import json

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

def check_enhanced_description():
    """æ£€æŸ¥enhanced_descriptionå­—æ®µçš„å†…å®¹å’Œä½œç”¨"""
    print("ğŸ” æ£€æŸ¥å›¾ç‰‡æ–‡æ¡£ä¸­enhanced_descriptionå­—æ®µ")
    print("=" * 60)
    
    try:
        # å¯¼å…¥å¿…è¦çš„æ¨¡å—
        from v2.core.image_engine import ImageEngine
        from v2.config.v2_config import ImageEngineConfigV2
        from core.vector_store import VectorStoreManager  # ä¿®æ­£å¯¼å…¥è·¯å¾„å’Œç±»å
        
        print("ğŸ“š æ­£åœ¨åŠ è½½å‘é‡æ•°æ®åº“...")
        
        # åˆå§‹åŒ–å‘é‡å­˜å‚¨ç®¡ç†å™¨
        vector_store_manager = VectorStoreManager()
        
        # åŠ è½½å‘é‡å­˜å‚¨
        vector_store_path = "central/vector_db"
        vector_store = vector_store_manager.load_vector_store(vector_store_path)
        
        if not vector_store:
            print("âŒ æ— æ³•åŠ è½½å‘é‡æ•°æ®åº“")
            return
        
        print(f"âœ… å‘é‡æ•°æ®åº“åŠ è½½æˆåŠŸï¼Œæ–‡æ¡£æ€»æ•°: {len(vector_store.docstore._dict)}")
        
        # ç»Ÿè®¡å›¾ç‰‡æ–‡æ¡£
        image_docs = {}
        for doc_id, doc in vector_store.docstore._dict.items():
            chunk_type = doc.metadata.get('chunk_type', '')
            if chunk_type == 'image':
                image_docs[doc_id] = doc
        
        print(f"ğŸ“¸ æ‰¾åˆ°å›¾ç‰‡æ–‡æ¡£æ•°é‡: {len(image_docs)}")
        
        if not image_docs:
            print("âŒ æœªæ‰¾åˆ°å›¾ç‰‡æ–‡æ¡£")
            return
        
        # åˆ†æenhanced_descriptionå­—æ®µ
        print("\nğŸ“Š enhanced_descriptionå­—æ®µåˆ†æ:")
        print("-" * 50)
        
        enhanced_count = 0
        empty_count = 0
        sample_enhanced = []
        
        for doc_id, doc in image_docs.items():
            enhanced_desc = doc.metadata.get('enhanced_description', '')
            
            if enhanced_desc:
                enhanced_count += 1
                if len(sample_enhanced) < 3:  # åªæ˜¾ç¤ºå‰3ä¸ªæ ·æœ¬
                    sample_enhanced.append({
                        'doc_id': doc_id,
                        'enhanced_description': enhanced_desc[:100] + '...' if len(enhanced_desc) > 100 else enhanced_desc,
                        'caption': doc.metadata.get('img_caption', ''),
                        'title': doc.metadata.get('image_title', '')
                    })
            else:
                empty_count += 1
        
        print(f"âœ… æœ‰enhanced_descriptionçš„å›¾ç‰‡: {enhanced_count}")
        print(f"âŒ æ— enhanced_descriptionçš„å›¾ç‰‡: {empty_count}")
        print(f"ğŸ“ˆ è¦†ç›–ç‡: {enhanced_count/(enhanced_count+empty_count)*100:.1f}%")
        
        # æ˜¾ç¤ºæ ·æœ¬
        if sample_enhanced:
            print("\nğŸ“ enhanced_descriptionæ ·æœ¬:")
            for i, sample in enumerate(sample_enhanced, 1):
                print(f"\næ ·æœ¬ {i}:")
                print(f"  æ–‡æ¡£ID: {sample['doc_id']}")
                print(f"  å¢å¼ºæè¿°: {sample['enhanced_description']}")
                print(f"  åŸå§‹æ ‡é¢˜: {sample['caption']}")
                print(f"  å›¾ç‰‡æ ‡é¢˜: {sample['title']}")
        
        # æ£€æŸ¥å­—æ®µåœ¨æœç´¢ä¸­çš„ä½œç”¨
        print("\nğŸ” æ£€æŸ¥enhanced_descriptionåœ¨æœç´¢ä¸­çš„ä½œç”¨:")
        print("-" * 50)
        
        # æ¨¡æ‹Ÿä¸€ä¸ªæŸ¥è¯¢
        test_query = "ä¸­èŠ¯å›½é™…å‡€åˆ©æ¶¦"
        print(f"æµ‹è¯•æŸ¥è¯¢: {test_query}")
        
        # æ‰‹åŠ¨è®¡ç®—ç›¸ä¼¼åº¦åˆ†æ•°
        print("\næ‰‹åŠ¨è®¡ç®—ç›¸ä¼¼åº¦åˆ†æ•°ç¤ºä¾‹:")
        for i, (doc_id, doc) in enumerate(list(image_docs.items())[:2]):  # åªæµ‹è¯•å‰2ä¸ª
            print(f"\nå›¾ç‰‡ {i+1}:")
            
            caption = doc.metadata.get('img_caption', '')
            title = doc.metadata.get('image_title', '')
            enhanced_desc = doc.metadata.get('enhanced_description', '')
            
            print(f"  åŸå§‹æ ‡é¢˜: {caption}")
            print(f"  å›¾ç‰‡æ ‡é¢˜: {title}")
            print(f"  å¢å¼ºæè¿°: {enhanced_desc[:80] + '...' if enhanced_desc and len(enhanced_desc) > 80 else enhanced_desc}")
            
            # è®¡ç®—å„å­—æ®µçš„åŒ¹é…åˆ†æ•°
            caption_score = calculate_text_similarity(test_query, caption)
            title_score = calculate_text_similarity(test_query, title)
            enhanced_score = calculate_text_similarity(test_query, enhanced_desc)
            
            print(f"  æ ‡é¢˜åŒ¹é…åˆ†æ•°: {caption_score:.3f}")
            print(f"  å›¾ç‰‡æ ‡é¢˜åˆ†æ•°: {title_score:.3f}")
            print(f"  å¢å¼ºæè¿°åˆ†æ•°: {enhanced_score:.3f}")
            
            # è®¡ç®—ç»¼åˆåˆ†æ•°ï¼ˆä½¿ç”¨æƒé‡ï¼‰
            total_score = (caption_score * 0.2 + 
                          title_score * 0.5 + 
                          enhanced_score * 0.3)
            print(f"  ç»¼åˆåˆ†æ•°: {total_score:.3f}")
        
        print("\nğŸ’¡ åˆ†æç»“è®º:")
        print("1. enhanced_descriptionå­—æ®µæä¾›äº†AIç”Ÿæˆçš„è¯¦ç»†å›¾ç‰‡æè¿°")
        print("2. åœ¨ç›¸ä¼¼åº¦è®¡ç®—ä¸­ï¼Œenhanced_descriptionæƒé‡ä¸º30%")
        print("3. ç›¸æ¯”åŸå§‹æ ‡é¢˜ï¼Œenhanced_descriptioné€šå¸¸åŒ…å«æ›´å¤šè¯­ä¹‰ä¿¡æ¯")
        print("4. å¯¹äºå†…å®¹æŸ¥è¯¢ï¼Œenhanced_descriptionèƒ½æ˜¾è‘—æå‡åŒ¹é…ç²¾åº¦")
        
    except Exception as e:
        print(f"âŒ æ£€æŸ¥è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()

def calculate_text_similarity(query: str, text: str) -> float:
    """è®¡ç®—æ–‡æœ¬ç›¸ä¼¼åº¦ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼‰"""
    if not text or not query:
        return 0.0
    
    # ç¡®ä¿textæ˜¯å­—ç¬¦ä¸²ç±»å‹
    if isinstance(text, list):
        text = ' '.join([str(item) for item in text])
    elif not isinstance(text, str):
        text = str(text)
    
    # ç®€å•çš„è¯æ±‡é‡å è®¡ç®—
    query_words = set(query.lower().split())
    text_words = set(text.lower().split())
    
    if not query_words or not text_words:
        return 0.0
    
    intersection = query_words.intersection(text_words)
    union = query_words.union(text_words)
    
    if union:
        return len(intersection) / len(union)
    return 0.0

if __name__ == "__main__":
    print("ğŸš€ å¼€å§‹æ£€æŸ¥enhanced_descriptionå­—æ®µ")
    print("=" * 60)
    
    check_enhanced_description()
    
    print("\nğŸ‰ æ£€æŸ¥å®Œæˆï¼")
