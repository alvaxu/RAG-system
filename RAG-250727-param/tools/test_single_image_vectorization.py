#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æµ‹è¯•å•å¼ å›¾ç‰‡å‘é‡åŒ–åŠŸèƒ½

åŠŸèƒ½è¯´æ˜ï¼š
1. åªå¤„ç†ä¸€å¼ å›¾ç‰‡çš„enhanced_descriptionå‘é‡åŒ–
2. éªŒè¯metadata.pklæ˜¯å¦æ­£ç¡®ç»´æŠ¤
3. æµ‹è¯•ä¿®å¤åçš„vector_generatoråŠŸèƒ½
"""

import os
import sys
import logging
from typing import List, Dict, Any, Optional

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.insert(0, project_root)

try:
    from langchain_community.vectorstores import FAISS
    from langchain_community.embeddings import DashScopeEmbeddings
    from config.settings import Settings
    from document_processing.image_enhancer import ImageEnhancer
    from document_processing.vector_generator import VectorGenerator
    from document_processing.image_processor import ImageProcessor
except ImportError as e:
    print(f"âŒ ç¼ºå°‘å¿…è¦çš„ä¾èµ–åŒ…: {e}")
    print("è¯·ç¡®ä¿é¡¹ç›®ä¾èµ–å·²æ­£ç¡®å®‰è£…")
    sys.exit(1)

# å¯¼å…¥ç»Ÿä¸€çš„APIå¯†é’¥ç®¡ç†æ¨¡å—
from config.api_key_manager import get_dashscope_api_key

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class SingleImageTester:
    """
    å•å¼ å›¾ç‰‡å‘é‡åŒ–æµ‹è¯•å™¨
    """
    
    def __init__(self):
        """åˆå§‹åŒ–æµ‹è¯•å™¨"""
        try:
            # åŠ è½½é…ç½®
            self.config = Settings.load_from_file('config.json')
            
            # ä½¿ç”¨ç»Ÿä¸€çš„APIå¯†é’¥ç®¡ç†æ¨¡å—è·å–APIå¯†é’¥
            config_key = self.config.dashscope_api_key
            self.api_key = get_dashscope_api_key(config_key)
            
            if not self.api_key:
                logger.warning("æœªæ‰¾åˆ°æœ‰æ•ˆçš„DashScope APIå¯†é’¥")
            
            # åˆå§‹åŒ–å›¾åƒå¢å¼ºå™¨
            image_config = {
                'enable_enhancement': self.config.enable_enhancement,
                'enhancement_model': self.config.enhancement_model,
                'enhancement_max_tokens': self.config.enhancement_max_tokens,
                'enhancement_temperature': self.config.enhancement_temperature,
                'enhancement_batch_size': self.config.enhancement_batch_size,
                'enable_progress_logging': self.config.enable_progress_logging
            }
            self.image_enhancer = ImageEnhancer(
                api_key=self.api_key,
                config=image_config
            )
            
            # åˆå§‹åŒ–å‘é‡ç”Ÿæˆå™¨
            self.vector_generator = VectorGenerator(self.config.__dict__)
            
            # å‘é‡æ•°æ®åº“è·¯å¾„
            self.vector_db_path = self.config.vector_db_dir
            
            logger.info("å•å¼ å›¾ç‰‡æµ‹è¯•å™¨åˆå§‹åŒ–å®Œæˆ")
            
        except Exception as e:
            logger.error(f"åˆå§‹åŒ–å¤±è´¥: {e}")
            raise
    
    def load_vector_store(self) -> Optional[FAISS]:
        """åŠ è½½å‘é‡æ•°æ®åº“"""
        try:
            embedding_model = getattr(self.config, 'text_embedding_model', 'text-embedding-v1')
            embeddings = DashScopeEmbeddings(
                dashscope_api_key=self.api_key, 
                model=embedding_model
            )
            allow_dangerous_deserialization = getattr(self.config, 'allow_dangerous_deserialization', True)
            vector_store = FAISS.load_local(
                self.vector_db_path, 
                embeddings, 
                allow_dangerous_deserialization=allow_dangerous_deserialization
            )
            logger.info(f"å‘é‡æ•°æ®åº“åŠ è½½æˆåŠŸï¼ŒåŒ…å« {len(vector_store.docstore._dict)} ä¸ªæ–‡æ¡£")
            return vector_store
            
        except Exception as e:
            logger.error(f"åŠ è½½å‘é‡æ•°æ®åº“å¤±è´¥: {e}")
            return None
    
    def find_test_image(self) -> Optional[Dict[str, Any]]:
        """æ‰¾åˆ°ä¸€ä¸ªæµ‹è¯•ç”¨çš„å›¾ç‰‡"""
        vector_store = self.load_vector_store()
        if not vector_store:
            return None
        
        # æŸ¥æ‰¾ç¬¬ä¸€å¼ æœ‰enhanced_descriptionçš„å›¾ç‰‡
        for doc_id, doc in vector_store.docstore._dict.items():
            metadata = doc.metadata if hasattr(doc, 'metadata') and doc.metadata else {}
            if (metadata.get('chunk_type') == 'image' and 
                metadata.get('enhanced_description') and
                metadata.get('image_path') and
                os.path.exists(metadata.get('image_path'))):
                
                return {
                    'doc_id': doc_id,
                    'image_path': metadata.get('image_path'),
                    'document_name': metadata.get('document_name', 'æœªçŸ¥æ–‡æ¡£'),
                    'page_number': metadata.get('page_number', 1),
                    'image_id': metadata.get('image_id', 'unknown'),
                    'enhanced_description': metadata.get('enhanced_description', '')
                }
        
        return None
    
    def test_single_image_vectorization(self, image_info: Dict[str, Any]) -> bool:
        """æµ‹è¯•å•å¼ å›¾ç‰‡çš„å‘é‡åŒ–"""
        print(f"ğŸ§ª å¼€å§‹æµ‹è¯•å•å¼ å›¾ç‰‡å‘é‡åŒ–...")
        print(f"   æ–‡æ¡£: {image_info['document_name']}")
        print(f"   é¡µç : {image_info['page_number']}")
        print(f"   å›¾ç‰‡ID: {image_info['image_id']}")
        print(f"   å›¾ç‰‡è·¯å¾„: {image_info['image_path']}")
        
        # åŠ è½½å‘é‡æ•°æ®åº“
        vector_store = self.load_vector_store()
        if not vector_store:
            print("âŒ æ— æ³•åŠ è½½å‘é‡æ•°æ®åº“")
            return False
        
        # æ£€æŸ¥æ˜¯å¦å·²ç»å‘é‡åŒ–
        already_vectorized = False
        for doc_id, doc in vector_store.docstore._dict.items():
            metadata = doc.metadata if hasattr(doc, 'metadata') and doc.metadata else {}
            if (metadata.get('chunk_type') == 'image_text' and 
                metadata.get('related_image_id') == image_info['image_id']):
                already_vectorized = True
                break
        
        if already_vectorized:
            print(f"âš ï¸ å›¾ç‰‡ {image_info['image_id']} å·²ç»å‘é‡åŒ–è¿‡äº†")
            return True
        
        try:
            # åˆ›å»ºæ–°çš„image_text Documentå¯¹è±¡
            from langchain.schema import Document
            text_doc = Document(
                page_content=image_info["enhanced_description"],
                metadata={
                    "chunk_type": "image_text",
                    "source_type": "image_description",
                    "image_id": image_info['image_id'],
                    "document_name": image_info['document_name'],
                    "page_number": image_info['page_number'],
                    "enhanced_description": image_info["enhanced_description"],
                    "related_image_id": image_info['image_id'],
                    "page_idx": 0,
                    "img_caption": [],
                    "img_footnote": []
                }
            )
            
            print(f"âœ… åˆ›å»ºimage_text Documentå¯¹è±¡æˆåŠŸ")
            
            # ç”Ÿæˆæ–‡æœ¬å‘é‡
            print(f"ğŸ”¤ æ­£åœ¨ç”Ÿæˆæ–‡æœ¬å‘é‡...")
            text_embedding = self.vector_generator.embeddings.embed_documents([text_doc.page_content])[0]
            print(f"âœ… æ–‡æœ¬å‘é‡ç”ŸæˆæˆåŠŸï¼Œç»´åº¦: {len(text_embedding)}")
            
            # æ·»åŠ åˆ°å‘é‡å­˜å‚¨
            print(f"ğŸ“ æ­£åœ¨æ·»åŠ åˆ°FAISSç´¢å¼•...")
            vector_store.add_embeddings([(text_doc.page_content, text_embedding)], metadatas=[text_doc.metadata])
            print(f"âœ… æˆåŠŸæ·»åŠ åˆ°FAISSç´¢å¼•")
            
            # ä¿å­˜å‘é‡æ•°æ®åº“
            print(f"ğŸ’¾ æ­£åœ¨ä¿å­˜å‘é‡æ•°æ®åº“...")
            self.vector_generator._save_vector_store_with_metadata(vector_store, self.vector_db_path)
            print(f"âœ… å‘é‡æ•°æ®åº“ä¿å­˜æˆåŠŸ")
            
            # éªŒè¯ç»“æœ
            print(f"ğŸ” éªŒè¯ç»“æœ...")
            updated_vector_store = self.load_vector_store()
            if updated_vector_store:
                doc_count = len(updated_vector_store.docstore._dict)
                print(f"âœ… æ•°æ®åº“æ–‡æ¡£æ•°é‡: {doc_count}")
                
                # æ£€æŸ¥metadata.pkl
                metadata_path = os.path.join(self.vector_db_path, "metadata.pkl")
                if os.path.exists(metadata_path):
                    import pickle
                    with open(metadata_path, 'rb') as f:
                        metadata_list = pickle.load(f)
                    print(f"âœ… metadata.pklåŒ…å« {len(metadata_list)} ä¸ªå…ƒæ•°æ®")
                    
                    # ç»Ÿè®¡chunkç±»å‹
                    chunk_types = {}
                    for metadata in metadata_list:
                        chunk_type = metadata.get('chunk_type', 'unknown')
                        chunk_types[chunk_type] = chunk_types.get(chunk_type, 0) + 1
                    
                    print("ğŸ“Š å…ƒæ•°æ®ç»Ÿè®¡:")
                    for chunk_type, count in sorted(chunk_types.items()):
                        print(f"   {chunk_type}: {count} ä¸ª")
                else:
                    print(f"âŒ metadata.pklæ–‡ä»¶ä¸å­˜åœ¨")
            
            return True
            
        except Exception as e:
            print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
            logger.error(f"æµ‹è¯•å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return False
    
    def run_test(self):
        """è¿è¡Œæµ‹è¯•"""
        print("ğŸš€ å•å¼ å›¾ç‰‡å‘é‡åŒ–æµ‹è¯•å¯åŠ¨")
        print("="*50)
        
        # 1. æŸ¥æ‰¾æµ‹è¯•å›¾ç‰‡
        print("ğŸ” æ­£åœ¨æŸ¥æ‰¾æµ‹è¯•å›¾ç‰‡...")
        test_image = self.find_test_image()
        
        if not test_image:
            print("âŒ æ²¡æœ‰æ‰¾åˆ°åˆé€‚çš„æµ‹è¯•å›¾ç‰‡")
            print("è¯·ç¡®ä¿æ•°æ®åº“ä¸­æœ‰å›¾ç‰‡ä¸”åŒ…å«enhanced_description")
            return
        
        print(f"âœ… æ‰¾åˆ°æµ‹è¯•å›¾ç‰‡: {test_image['image_id']}")
        
        # 2. æ‰§è¡Œæµ‹è¯•
        print("\nğŸ§ª å¼€å§‹æ‰§è¡Œæµ‹è¯•...")
        success = self.test_single_image_vectorization(test_image)
        
        if success:
            print("\nğŸ‰ æµ‹è¯•æˆåŠŸï¼")
            print("metadata.pklç»´æŠ¤åŠŸèƒ½æ­£å¸¸å·¥ä½œ")
        else:
            print("\nâŒ æµ‹è¯•å¤±è´¥ï¼")
            print("è¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯")


def main():
    """ä¸»å‡½æ•°"""
    try:
        tester = SingleImageTester()
        tester.run_test()
    except Exception as e:
        print(f"âŒ æµ‹è¯•ç¨‹åºå¯åŠ¨å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()
