#!/usr/bin/env python3
# -*- coding: utf-8 -*-
'''
ç¨‹åºè¯´æ˜ï¼š
æ·±åº¦åˆ†æå‘é‡æ•°æ®åº“ï¼Œç‰¹åˆ«å…³æ³¨å›¾ç‰‡çš„è¯­ä¹‰æè¿°å­˜å‚¨æ–¹å¼
'''

import pickle
import os
import sys

def deep_analyze_vector_db():
    """æ·±åº¦åˆ†æå‘é‡æ•°æ®åº“ç»“æ„"""
    print("ğŸ” æ·±åº¦åˆ†æå‘é‡æ•°æ®åº“ç»“æ„...")
    print("=" * 60)
    
    # æ£€æŸ¥æ–‡ä»¶
    vector_db_dir = "central/vector_db"
    metadata_file = os.path.join(vector_db_dir, "metadata.pkl")
    index_file = os.path.join(vector_db_dir, "index.pkl")
    
    print("ğŸ“‹ åˆ†æmetadata.pklçš„è¯¦ç»†å†…å®¹:")
    try:
        with open(metadata_file, 'rb') as f:
            metadata = pickle.load(f)
        print(f"  å…ƒæ•°æ®æ€»æ•°é‡: {len(metadata)}")
        
        if len(metadata) > 0:
            first_doc = metadata[0]
            print(f"\n  ç¬¬ä¸€ä¸ªæ–‡æ¡£çš„è¯¦ç»†ä¿¡æ¯:")
            print(f"    chunk_type: {first_doc.get('chunk_type')}")
            print(f"    image_id: {first_doc.get('image_id')}")
            print(f"    img_caption: {first_doc.get('img_caption')}")
            print(f"    enhanced_description: {first_doc.get('enhanced_description', 'N/A')[:200]}...")
            print(f"    semantic_features: {first_doc.get('semantic_features')}")
            
            # æ£€æŸ¥æ˜¯å¦æœ‰å…¶ä»–å­—æ®µåŒ…å«è¯­ä¹‰ä¿¡æ¯
            print(f"\n  å…¶ä»–å¯èƒ½åŒ…å«è¯­ä¹‰ä¿¡æ¯çš„å­—æ®µ:")
            for key, value in first_doc.items():
                if isinstance(value, str) and len(value) > 50:
                    print(f"    {key}: {value[:100]}...")
                elif key not in ['image_id', 'image_path', 'image_filename', 'chunk_type', 'page_number', 'page_idx', 'extension', 'source_zip']:
                    print(f"    {key}: {value}")
    except Exception as e:
        print(f"  è¯»å–metadata.pklå¤±è´¥: {e}")
    
    print("\n" + "=" * 60)
    
    print("ğŸ“Š åˆ†æindex.pklçš„è¯¦ç»†å†…å®¹:")
    try:
        with open(index_file, 'rb') as f:
            index_data = pickle.load(f)
        print(f"  index.pklç±»å‹: {type(index_data)}")
        print(f"  index.pklé•¿åº¦: {len(index_data)}")
        
        if len(index_data) > 0:
            print(f"\n  ç¬¬ä¸€ä¸ªå…ƒç´ ç±»å‹: {type(index_data[0])}")
            if hasattr(index_data[0], '__dict__'):
                print(f"  ç¬¬ä¸€ä¸ªå…ƒç´ çš„å±æ€§: {list(index_data[0].__dict__.keys())}")
            
            if len(index_data) > 1:
                print(f"\n  ç¬¬äºŒä¸ªå…ƒç´ ç±»å‹: {type(index_data[1])}")
                if hasattr(index_data[1], '__dict__'):
                    print(f"  ç¬¬äºŒä¸ªå…ƒç´ çš„å±æ€§: {list(index_data[1].__dict__.keys())}")
                    
                    # å°è¯•è·å–æ–‡æ¡£å†…å®¹
                    if hasattr(index_data[1], 'page_content'):
                        content = index_data[1].page_content
                        print(f"  ç¬¬äºŒä¸ªå…ƒç´ çš„page_content: {content[:200] if content else 'N/A'}...")
                    
                    if hasattr(index_data[1], 'metadata'):
                        meta = index_data[1].metadata
                        print(f"  ç¬¬äºŒä¸ªå…ƒç´ çš„metadata: {meta}")
    except Exception as e:
        print(f"  è¯»å–index.pklå¤±è´¥: {e}")
    
    print("\n" + "=" * 60)
    
    print("ğŸ” åˆ†æFAISSç´¢å¼•çš„å‘é‡å†…å®¹:")
    try:
        import faiss
        faiss_file = os.path.join(vector_db_dir, "index.faiss")
        index = faiss.read_index(faiss_file)
        print(f"  FAISSç´¢å¼•ç±»å‹: {type(index)}")
        print(f"  å‘é‡ç»´åº¦: {index.d}")
        print(f"  å‘é‡æ•°é‡: {index.ntotal}")
        
        # å°è¯•è·å–å‰å‡ ä¸ªå‘é‡
        if index.ntotal > 0:
            vectors = index.reconstruct_n(0, min(3, index.ntotal))
            print(f"\n  å‰{min(3, index.ntotal)}ä¸ªå‘é‡çš„ç»Ÿè®¡ä¿¡æ¯:")
            for i in range(min(3, index.ntotal)):
                vector = vectors[i]
                print(f"    å‘é‡{i}: å½¢çŠ¶={vector.shape}, å‡å€¼={vector.mean():.6f}, æ ‡å‡†å·®={vector.std():.6f}")
    except ImportError:
        print("  FAISSæœªå®‰è£…ï¼Œæ— æ³•åˆ†æ")
    except Exception as e:
        print(f"  è¯»å–FAISSç´¢å¼•å¤±è´¥: {e}")

if __name__ == "__main__":
    deep_analyze_vector_db()
