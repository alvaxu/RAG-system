#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç¨‹åºè¯´æ˜ï¼š
## 1. æµ‹è¯•å›¾ç‰‡å‘é‡æœç´¢åŠŸèƒ½
## 2. éªŒè¯image_textå’Œimageä¸¤ç§æœç´¢ç­–ç•¥
## 3. æ£€æŸ¥å‘é‡æœç´¢APIæ˜¯å¦æ­£å¸¸å·¥ä½œ
"""

import sys
import os
import logging

# ä¿®å¤è·¯å¾„é—®é¢˜ï¼Œæ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from config.settings import Settings
from langchain_community.vectorstores import FAISS
from langchain_community.embeddings import DashScopeEmbeddings

# å¯¼å…¥ç»Ÿä¸€çš„APIå¯†é’¥ç®¡ç†æ¨¡å—
from config.api_key_manager import get_dashscope_api_key

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def test_image_vector_search():
    """æµ‹è¯•å›¾ç‰‡å‘é‡æœç´¢åŠŸèƒ½"""
    print("ğŸ” å¼€å§‹æµ‹è¯•å›¾ç‰‡å‘é‡æœç´¢åŠŸèƒ½")
    print("=" * 60)
    
    try:
        # åŠ è½½é…ç½®
        config = Settings.load_from_file('config.json')
        vector_db_path = config.vector_db_dir
        
        print(f"ğŸ“ å‘é‡æ•°æ®åº“è·¯å¾„: {vector_db_path}")
        
        # è·å–APIå¯†é’¥
        config_key = config.dashscope_api_key
        api_key = get_dashscope_api_key(config_key)
        
        if not api_key:
            print("âŒ æœªæ‰¾åˆ°æœ‰æ•ˆçš„DashScope APIå¯†é’¥")
            return
        
        # åˆå§‹åŒ–embeddings
        embeddings = DashScopeEmbeddings(dashscope_api_key=api_key, model='text-embedding-v1')
        print("âœ… DashScope embeddingsåˆå§‹åŒ–æˆåŠŸ")
        
        # åŠ è½½å‘é‡å­˜å‚¨
        vector_store = FAISS.load_local(vector_db_path, embeddings, allow_dangerous_deserialization=True)
        print(f"âœ… å‘é‡å­˜å‚¨åŠ è½½æˆåŠŸï¼ŒåŒ…å« {len(vector_store.docstore._dict)} ä¸ªæ–‡æ¡£")
        
        # æµ‹è¯•æŸ¥è¯¢
        test_query = "ä¸­èŠ¯å›½é™…å‡€åˆ©æ¶¦"
        print(f"\nğŸ” æµ‹è¯•æŸ¥è¯¢: {test_query}")
        
        # æµ‹è¯•1ï¼šæ— filterçš„å‘é‡æœç´¢
        print("\nğŸ“Š æµ‹è¯•1ï¼šæ— filterçš„å‘é‡æœç´¢")
        try:
            results = vector_store.similarity_search(test_query, k=5)
            print(f"âœ… æ— filteræœç´¢æˆåŠŸï¼Œè¿”å› {len(results)} ä¸ªç»“æœ")
            
            # æ˜¾ç¤ºå‰3ä¸ªç»“æœçš„chunk_type
            for i, doc in enumerate(results[:3]):
                chunk_type = doc.metadata.get('chunk_type', 'unknown') if hasattr(doc, 'metadata') else 'unknown'
                score = getattr(doc, 'score', 'N/A')
                print(f"  ç»“æœ{i+1}: chunk_type={chunk_type}, score={score}")
                
        except Exception as e:
            print(f"âŒ æ— filteræœç´¢å¤±è´¥: {e}")
        
        # æµ‹è¯•2ï¼šæœç´¢image_text chunks
        print("\nğŸ“Š æµ‹è¯•2ï¼šæœç´¢image_text chunks")
        try:
            image_text_results = vector_store.similarity_search(
                test_query, 
                k=10,
                filter={'chunk_type': 'image_text'}
            )
            print(f"âœ… image_textæœç´¢æˆåŠŸï¼Œè¿”å› {len(image_text_results)} ä¸ªç»“æœ")
            
            # æ˜¾ç¤ºç»“æœè¯¦æƒ…
            for i, doc in enumerate(image_text_results[:3]):
                if hasattr(doc, 'metadata') and doc.metadata:
                    chunk_type = doc.metadata.get('chunk_type', 'N/A')
                    score = getattr(doc, 'score', 'N/A')
                    enhanced_desc = doc.metadata.get('enhanced_description', '')[:100] + '...' if len(doc.metadata.get('enhanced_description', '')) > 100 else doc.metadata.get('enhanced_description', '')
                    print(f"  ç»“æœ{i+1}: chunk_type={chunk_type}, score={score}")
                    print(f"    æè¿°: {enhanced_desc}")
                else:
                    print(f"  ç»“æœ{i+1}: æ— metadata")
                    
        except Exception as e:
            print(f"âŒ image_textæœç´¢å¤±è´¥: {e}")
        
        # æµ‹è¯•3ï¼šæœç´¢image chunks
        print("\nğŸ“Š æµ‹è¯•3ï¼šæœç´¢image chunks")
        try:
            image_results = vector_store.similarity_search(
                test_query, 
                k=10,
                filter={'chunk_type': 'image'}
            )
            print(f"âœ… imageæœç´¢æˆåŠŸï¼Œè¿”å› {len(image_results)} ä¸ªç»“æœ")
            
            # æ˜¾ç¤ºç»“æœè¯¦æƒ…
            for i, doc in enumerate(image_results[:3]):
                if hasattr(doc, 'metadata') and doc.metadata:
                    chunk_type = doc.metadata.get('chunk_type', 'N/A')
                    score = getattr(doc, 'score', 'N/A')
                    img_caption = doc.metadata.get('img_caption', 'N/A')
                    print(f"  ç»“æœ{i+1}: chunk_type={chunk_type}, score={score}")
                    print(f"    æ ‡é¢˜: {img_caption}")
                else:
                    print(f"  ç»“æœ{i+1}: æ— metadata")
                    
        except Exception as e:
            print(f"âŒ imageæœç´¢å¤±è´¥: {e}")
        
        # æµ‹è¯•4ï¼šæ£€æŸ¥å‘é‡æ•°æ®
        print("\nğŸ“Š æµ‹è¯•4ï¼šæ£€æŸ¥å‘é‡æ•°æ®")
        try:
            # è·å–ä¸€ä¸ªimage_textæ–‡æ¡£
            docstore = vector_store.docstore._dict
            image_text_docs = []
            
            for doc_id, doc in docstore.items():
                if hasattr(doc, 'metadata') and doc.metadata and doc.metadata.get('chunk_type') == 'image_text':
                    image_text_docs.append(doc)
                    if len(image_text_docs) >= 3:
                        break
            
            print(f"æ‰¾åˆ° {len(image_text_docs)} ä¸ªimage_textæ–‡æ¡£")
            
            if image_text_docs:
                # æ£€æŸ¥ç¬¬ä¸€ä¸ªæ–‡æ¡£çš„å‘é‡
                doc = image_text_docs[0]
                print(f"ç¬¬ä¸€ä¸ªæ–‡æ¡£ID: {list(docstore.keys())[list(docstore.values()).index(doc)]}")
                print(f"æ–‡æ¡£ç±»å‹: {type(doc)}")
                print(f"æ˜¯å¦æœ‰page_content: {hasattr(doc, 'page_content')}")
                if hasattr(doc, 'page_content'):
                    print(f"page_contenté•¿åº¦: {len(doc.page_content)}")
                    print(f"page_contenté¢„è§ˆ: {doc.page_content[:100]}...")
                
                # æ£€æŸ¥metadata
                if hasattr(doc, 'metadata') and doc.metadata:
                    print(f"metadataå­—æ®µ: {list(doc.metadata.keys())}")
                    enhanced_desc = doc.metadata.get('enhanced_description', '')
                    print(f"enhanced_descriptioné•¿åº¦: {len(enhanced_desc)}")
                    print(f"enhanced_descriptioné¢„è§ˆ: {enhanced_desc[:100]}...")
                    
                    # æ£€æŸ¥semantic_features
                    semantic_features = doc.metadata.get('semantic_features', {})
                    if semantic_features:
                        print(f"semantic_features: {semantic_features}")
                    else:
                        print("âŒ æ²¡æœ‰semantic_features")
                else:
                    print("âŒ æ²¡æœ‰metadata")
                    
        except Exception as e:
            print(f"âŒ æ£€æŸ¥å‘é‡æ•°æ®å¤±è´¥: {e}")
        
        print("\nâœ… å›¾ç‰‡å‘é‡æœç´¢æµ‹è¯•å®Œæˆï¼")
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    test_image_vector_search()
