#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç›´æ¥æ£€æŸ¥è¡¨æ ¼æ–‡æ¡£å†…å®¹çš„è„šæœ¬
"""

import os
import sys
import pickle
import faiss
from pathlib import Path

def check_table_content_direct():
    """ç›´æ¥æ£€æŸ¥å‘é‡æ•°æ®åº“ä¸­çš„è¡¨æ ¼æ–‡æ¡£å†…å®¹"""
    
    # å‘é‡æ•°æ®åº“è·¯å¾„
    vector_db_path = "central/vector_db"
    
    if not os.path.exists(vector_db_path):
        print(f"âŒ å‘é‡æ•°æ®åº“è·¯å¾„ä¸å­˜åœ¨: {vector_db_path}")
        return
    
    # åŠ è½½FAISSç´¢å¼•
    try:
        index = faiss.read_index(os.path.join(vector_db_path, "index.faiss"))
        print(f"âœ… FAISSç´¢å¼•åŠ è½½æˆåŠŸï¼ŒåŒ…å« {index.ntotal} ä¸ªå‘é‡")
    except Exception as e:
        print(f"âŒ FAISSç´¢å¼•åŠ è½½å¤±è´¥: {e}")
        return
    
    # åŠ è½½ç´¢å¼•å…ƒæ•°æ®
    try:
        with open(os.path.join(vector_db_path, "index.pkl"), "rb") as f:
            index_data = pickle.load(f)
        print(f"âœ… ç´¢å¼•å…ƒæ•°æ®åŠ è½½æˆåŠŸ")
    except Exception as e:
        print(f"âŒ ç´¢å¼•å…ƒæ•°æ®åŠ è½½å¤±è´¥: {e}")
        return
    
    # æ£€æŸ¥ç´¢å¼•æ•°æ®ç»“æ„
    print(f"\nğŸ” ç´¢å¼•æ•°æ®ç»“æ„:")
    print(f"  ç±»å‹: {type(index_data)}")
    print(f"  é•¿åº¦: {len(index_data)}")
    
    if len(index_data) >= 2:
        docstore = index_data[0]
        id_mapping = index_data[1]
        
        print(f"  æ–‡æ¡£å­˜å‚¨ç±»å‹: {type(docstore)}")
        print(f"  IDæ˜ å°„ç±»å‹: {type(id_mapping)}")
        print(f"  IDæ˜ å°„é•¿åº¦: {len(id_mapping)}")
        
        # æŸ¥æ‰¾è¡¨æ ¼æ–‡æ¡£
        table_docs = []
        for doc_id, doc in docstore._dict.items():
            if hasattr(doc, 'metadata') and doc.metadata:
                chunk_type = doc.metadata.get('chunk_type', '')
                if chunk_type == 'table':
                    table_docs.append((doc_id, doc))
        
        print(f"\nğŸ“Š æ‰¾åˆ° {len(table_docs)} ä¸ªè¡¨æ ¼æ–‡æ¡£")
        
        if table_docs:
            print(f"\nğŸ” æ£€æŸ¥å‰3ä¸ªè¡¨æ ¼æ–‡æ¡£:")
            for i, (doc_id, doc) in enumerate(table_docs[:3]):
                print(f"\nğŸ“„ è¡¨æ ¼æ–‡æ¡£ {i+1}:")
                print(f"  æ–‡æ¡£ID: {doc_id}")
                print(f"  æ–‡æ¡£ç±»å‹: {type(doc)}")
                
                if hasattr(doc, 'metadata'):
                    metadata = doc.metadata
                    print(f"  å…ƒæ•°æ®ç±»å‹: {type(metadata)}")
                    print(f"  å…ƒæ•°æ®é”®: {list(metadata.keys())}")
                    
                    # æ£€æŸ¥å…³é”®å­—æ®µ
                    key_fields = ['document_name', 'page_number', 'chunk_type', 'table_id', 'table_type']
                    for field in key_fields:
                        value = metadata.get(field, 'NOT_FOUND')
                        print(f"    {field}: {value}")
                
                if hasattr(doc, 'page_content'):
                    page_content = doc.page_content
                    print(f"  page_contentç±»å‹: {type(page_content)}")
                    print(f"  page_contenté•¿åº¦: {len(str(page_content))}")
                    print(f"  page_contenté¢„è§ˆ: {str(page_content)[:200]}...")
                
                # æ£€æŸ¥æ˜¯å¦æœ‰å…¶ä»–å†…å®¹å­—æ®µ
                content_fields = ['content', 'processed_table_content', 'table_content']
                for field in content_fields:
                    if hasattr(doc, field):
                        value = getattr(doc, field)
                        print(f"  {field}: {type(value)}, é•¿åº¦: {len(str(value))}")
                        print(f"  {field}é¢„è§ˆ: {str(value)[:100]}...")
    
    else:
        print(f"âŒ ç´¢å¼•æ•°æ®ç»“æ„ä¸æ­£ç¡®ï¼ŒæœŸæœ›è‡³å°‘2ä¸ªå…ƒç´ ï¼Œå®é™…: {len(index_data)}")

if __name__ == "__main__":
    check_table_content_direct()
