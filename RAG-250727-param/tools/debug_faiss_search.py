'''
ç¨‹åºè¯´æ˜ï¼š
## 1. ä¸“é—¨è°ƒè¯•FAISSæœç´¢é—®é¢˜
## 2. æŸ¥çœ‹"å›¾4ï¼šä¸­èŠ¯å›½é™…å½’æ¯å‡€åˆ©æ¶¦æƒ…å†µæ¦‚è§ˆ"æ˜¯å¦åœ¨FAISSæœç´¢ç»“æœä¸­
## 3. åˆ†æFAISSæœç´¢çš„åŸå§‹ç»“æœ
'''

import os
import sys

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from langchain_community.vectorstores import FAISS
from langchain_community.embeddings import DashScopeEmbeddings
from config.api_key_manager import get_dashscope_api_key


def debug_faiss_search():
    """è°ƒè¯•FAISSæœç´¢é—®é¢˜"""
    print("ğŸ” è°ƒè¯•FAISSæœç´¢é—®é¢˜")
    print("=" * 80)
    
    try:
        # 1. åˆå§‹åŒ–
        api_key = get_dashscope_api_key()
        embeddings = DashScopeEmbeddings(dashscope_api_key=api_key, model='text-embedding-v1')
        vector_db_path = "../central/vector_db"
        vector_store = FAISS.load_local(vector_db_path, embeddings, allow_dangerous_deserialization=True)
        
        print("âœ… å‘é‡æ•°æ®åº“åŠ è½½æˆåŠŸ")
        
        # 2. æµ‹è¯•æŸ¥è¯¢
        query = "å›¾4ï¼šä¸­èŠ¯å›½é™…å½’æ¯å‡€åˆ©æ¶¦æƒ…å†µæ¦‚è§ˆ"
        print(f"\nğŸ” æµ‹è¯•æŸ¥è¯¢: '{query}'")
        
        # 3. åŸå§‹FAISSæœç´¢ï¼ˆä¸ä½¿ç”¨filterï¼‰
        print("\nğŸ“‹ æ­¥éª¤1ï¼šåŸå§‹FAISSæœç´¢ï¼ˆk=100ï¼Œæ— filterï¼‰")
        all_results = vector_store.similarity_search(query, k=100)
        print(f"æœç´¢åˆ° {len(all_results)} ä¸ªç»“æœ")
        
        # æŸ¥æ‰¾ç›®æ ‡æ–‡æ¡£
        target_found = False
        target_position = -1
        
        for i, doc in enumerate(all_results):
            if "å›¾4ï¼šä¸­èŠ¯å›½é™…å½’æ¯å‡€åˆ©æ¶¦æƒ…å†µæ¦‚è§ˆ" in doc.page_content:
                target_found = True
                target_position = i + 1
                print(f"âœ… æ‰¾åˆ°ç›®æ ‡æ–‡æ¡£ï¼ä½ç½®: ç¬¬{target_position}ä½")
                print(f"   å†…å®¹: {doc.page_content[:200]}...")
                print(f"   ç±»å‹: {doc.metadata.get('chunk_type', 'unknown')}")
                break
        
        if not target_found:
            print("âŒ åœ¨å‰100ä¸ªç»“æœä¸­æ²¡æœ‰æ‰¾åˆ°ç›®æ ‡æ–‡æ¡£")
            
            # æœç´¢æ›´å¤šç»“æœ
            print("\nğŸ“‹ æ­¥éª¤2ï¼šæ‰©å¤§æœç´¢èŒƒå›´ï¼ˆk=300ï¼‰")
            more_results = vector_store.similarity_search(query, k=300)
            print(f"æœç´¢åˆ° {len(more_results)} ä¸ªç»“æœ")
            
            for i, doc in enumerate(more_results):
                if "å›¾4ï¼šä¸­èŠ¯å›½é™…å½’æ¯å‡€åˆ©æ¶¦æƒ…å†µæ¦‚è§ˆ" in doc.page_content:
                    target_found = True
                    target_position = i + 1
                    print(f"âœ… æ‰¾åˆ°ç›®æ ‡æ–‡æ¡£ï¼ä½ç½®: ç¬¬{target_position}ä½")
                    print(f"   å†…å®¹: {doc.page_content[:200]}...")
                    print(f"   ç±»å‹: {doc.metadata.get('chunk_type', 'unknown')}")
                    break
        
        # 4. ä½¿ç”¨filteræœç´¢image_text
        print(f"\nğŸ“‹ æ­¥éª¤3ï¼šä½¿ç”¨filteræœç´¢image_textï¼ˆk=100ï¼‰")
        try:
            image_text_results = vector_store.similarity_search(
                query, 
                k=100,
                filter={'chunk_type': 'image_text'}
            )
            print(f"filteræœç´¢åˆ° {len(image_text_results)} ä¸ªimage_textç»“æœ")
            
            # æŸ¥æ‰¾ç›®æ ‡æ–‡æ¡£
            for i, doc in enumerate(image_text_results):
                if "å›¾4ï¼šä¸­èŠ¯å›½é™…å½’æ¯å‡€åˆ©æ¶¦æƒ…å†µæ¦‚è§ˆ" in doc.page_content:
                    print(f"âœ… åœ¨filterç»“æœä¸­æ‰¾åˆ°ç›®æ ‡æ–‡æ¡£ï¼ä½ç½®: ç¬¬{i+1}ä½")
                    print(f"   å†…å®¹: {doc.page_content[:200]}...")
                    break
            else:
                print("âŒ åœ¨filterç»“æœä¸­æ²¡æœ‰æ‰¾åˆ°ç›®æ ‡æ–‡æ¡£")
                
        except Exception as e:
            print(f"âŒ filteræœç´¢å¤±è´¥: {e}")
        
        # 5. æ£€æŸ¥æ–‡æ¡£æ˜¯å¦å­˜åœ¨äºæ•°æ®åº“ä¸­
        print(f"\nğŸ“‹ æ­¥éª¤4ï¼šæ£€æŸ¥ç›®æ ‡æ–‡æ¡£æ˜¯å¦å­˜åœ¨äºæ•°æ®åº“ä¸­")
        if hasattr(vector_store, 'docstore') and hasattr(vector_store.docstore, '_dict'):
            docs = vector_store.docstore._dict
            found_in_db = False
            
            for doc_id, doc in docs.items():
                if "å›¾4ï¼šä¸­èŠ¯å›½é™…å½’æ¯å‡€åˆ©æ¶¦æƒ…å†µæ¦‚è§ˆ" in doc.page_content:
                    found_in_db = True
                    print(f"âœ… ç›®æ ‡æ–‡æ¡£å­˜åœ¨äºæ•°æ®åº“ä¸­")
                    print(f"   æ–‡æ¡£ID: {doc_id}")
                    print(f"   ç±»å‹: {doc.metadata.get('chunk_type', 'unknown')}")
                    print(f"   å†…å®¹: {doc.page_content[:200]}...")
                    break
            
            if not found_in_db:
                print("âŒ ç›®æ ‡æ–‡æ¡£ä¸å­˜åœ¨äºæ•°æ®åº“ä¸­")
        
        print("\n" + "=" * 80)
        print("ğŸ¯ è°ƒè¯•æ€»ç»“")
        print("=" * 80)
        
        if target_found:
            print(f"âœ… ç›®æ ‡æ–‡æ¡£å­˜åœ¨ï¼Œæ’å: ç¬¬{target_position}ä½")
            if target_position > 60:  # max_results * 2 = 30 * 2 = 60
                print("âš ï¸ é—®é¢˜ï¼šç›®æ ‡æ–‡æ¡£æ’åå¤ªé åï¼Œéœ€è¦å¢åŠ æœç´¢æ•°é‡")
            else:
                print("âš ï¸ é—®é¢˜ï¼šç›®æ ‡æ–‡æ¡£æ’ååˆç†ï¼Œé—®é¢˜å¯èƒ½åœ¨å…¶ä»–åœ°æ–¹")
        else:
            print("âŒ ç›®æ ‡æ–‡æ¡£ä¸å­˜åœ¨æˆ–FAISSæœç´¢æœ‰é—®é¢˜")
            
    except Exception as e:
        print(f"âŒ è°ƒè¯•å¤±è´¥: {e}")
        import traceback
        print(f"è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")


if __name__ == "__main__":
    debug_faiss_search()
