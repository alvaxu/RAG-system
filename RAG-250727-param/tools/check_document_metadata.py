#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ£€æŸ¥index.pklä¸­å­˜å‚¨çš„æ–‡æ¡£å…ƒæ•°æ®
"""

import pickle
from pathlib import Path

def check_document_metadata():
    """æ£€æŸ¥index.pklä¸­çš„æ–‡æ¡£å…ƒæ•°æ®"""
    index_path = Path('central/vector_db/index.pkl')
    
    if not index_path.exists():
        print(f"âŒ ç´¢å¼•æ–‡ä»¶ä¸å­˜åœ¨: {index_path}")
        return
    
    try:
        with open(index_path, 'rb') as f:
            index_data = pickle.load(f)
        
        print(f"ğŸ“Š æ–‡æ¡£å…ƒæ•°æ®åˆ†æ")
        print(f"æ–‡ä»¶è·¯å¾„: {index_path.absolute()}")
        print(f"æ•°æ®ç±»å‹: {type(index_data)}")
        print(f"æ•°æ®é•¿åº¦: {len(index_data)}")
        print()
        
        # ç¬¬2ä¸ªå…ƒç´ åº”è¯¥æ˜¯æ–‡æ¡£å…ƒæ•°æ®å­—å…¸
        if len(index_data) >= 2 and isinstance(index_data[1], dict):
            metadata_dict = index_data[1]
            print(f"ğŸ“‹ æ–‡æ¡£å…ƒæ•°æ®å­—å…¸:")
            print(f"  é”®æ•°é‡: {len(metadata_dict)}")
            print(f"  é”®èŒƒå›´: {min(metadata_dict.keys())} - {max(metadata_dict.keys())}")
            print()
            
            # æ£€æŸ¥å‰å‡ ä¸ªæ–‡æ¡£çš„å…ƒæ•°æ®
            print("ğŸ” å‰5ä¸ªæ–‡æ¡£çš„å…ƒæ•°æ®:")
            for i in range(min(5, len(metadata_dict))):
                if i in metadata_dict:
                    doc = metadata_dict[i]
                    print(f"  æ–‡æ¡£ {i}:")
                    if isinstance(doc, dict):
                        for key, value in doc.items():
                            if key == 'page_content':
                                content_preview = str(value)[:100] + '...' if len(str(value)) > 100 else str(value)
                                print(f"    {key}: {content_preview}")
                            else:
                                print(f"    {key}: {value}")
                    else:
                        print(f"    ç±»å‹: {type(doc)}")
                    print()
            
            # ç»Ÿè®¡chunk_typeåˆ†å¸ƒ
            print("ğŸ“Š Chunkç±»å‹åˆ†å¸ƒ:")
            chunk_types = {}
            for i, doc in metadata_dict.items():
                if isinstance(doc, dict) and 'chunk_type' in doc:
                    chunk_type = doc['chunk_type']
                    chunk_types[chunk_type] = chunk_types.get(chunk_type, 0) + 1
            
            for chunk_type, count in sorted(chunk_types.items()):
                print(f"  {chunk_type}: {count}")
            
            # æ£€æŸ¥å…³é”®å­—æ®µ
            print("\nğŸ¯ å…³é”®å­—æ®µæ£€æŸ¥:")
            key_fields = ['document_name', 'page_number', 'chunk_type', 'source', 'title']
            for field in key_fields:
                field_values = set()
                for doc in metadata_dict.values():
                    if isinstance(doc, dict) and field in doc:
                        field_values.add(doc[field])
                
                if field_values:
                    print(f"  {field}: {len(field_values)} ä¸ªå”¯ä¸€å€¼")
                    if len(field_values) <= 3:
                        print(f"    å€¼: {list(field_values)}")
                    else:
                        print(f"    å‰3ä¸ªå€¼: {list(field_values)[:3]}")
                else:
                    print(f"  {field}: æœªæ‰¾åˆ°")
            
            # æ˜¾ç¤ºä¸€äº›ç¤ºä¾‹æ–‡æ¡£
            print("\nğŸ“ ç¤ºä¾‹æ–‡æ¡£:")
            sample_count = 0
            for i, doc in metadata_dict.items():
                if sample_count >= 3:
                    break
                if isinstance(doc, dict) and 'document_name' in doc:
                    print(f"  [{i}] {doc.get('chunk_type', 'N/A')}: {doc.get('document_name', 'N/A')} (p.{doc.get('page_number', 'N/A')})")
                    sample_count += 1
        
    except Exception as e:
        print(f"âŒ åˆ†æå¤±è´¥: {e}")

if __name__ == "__main__":
    check_document_metadata()
