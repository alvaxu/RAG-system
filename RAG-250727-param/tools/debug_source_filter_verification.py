'''
ç¨‹åºè¯´æ˜ï¼š

## 1. éªŒè¯æºè¿‡æ»¤æ˜¯å¦çœŸçš„æŠŠå›¾4ç»“æœè¿‡æ»¤æ‰äº†
## 2. æµ‹è¯•å¢åŠ æºæ•°é‡çš„æ•ˆæœ
## 3. ä¸ºå¢å¼ºå…¶ä»–å¬å›ç­–ç•¥çš„metadataå­—æ®µåšå‡†å¤‡
'''

import os
import sys

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from langchain_community.vectorstores import FAISS
from langchain_community.embeddings import DashScopeEmbeddings
from config.api_key_manager import get_dashscope_api_key
from v2.core.image_engine import ImageEngine
from v2.core.document_loader import DocumentLoader
from v2.config.v2_config import ImageEngineConfigV2
from v2.core.source_filter_engine import SourceFilterEngine
import time


def debug_source_filter_verification():
    """éªŒè¯æºè¿‡æ»¤è¡Œä¸º"""
    print("ğŸ” éªŒè¯æºè¿‡æ»¤è¡Œä¸º")
    print("=" * 80)
    
    try:
        # 1. åˆå§‹åŒ–ç»„ä»¶
        print("ğŸ“¡ åˆå§‹åŒ–ç»„ä»¶...")
        config = ImageEngineConfigV2()
        
        api_key = get_dashscope_api_key()
        embeddings = DashScopeEmbeddings(dashscope_api_key=api_key, model='text-embedding-v1')
        vector_db_path = "../central/vector_db"
        vector_store = FAISS.load_local(vector_db_path, embeddings, allow_dangerous_deserialization=True)
        
        document_loader = DocumentLoader(vector_store=vector_store)
        image_engine = ImageEngine(
            config=config,
            vector_store=vector_store,
            document_loader=document_loader
        )
        source_filter_engine = SourceFilterEngine(config=config)
        print("âœ… ç»„ä»¶åˆå§‹åŒ–æˆåŠŸ")
        
        # 2. æµ‹è¯•æŸ¥è¯¢
        query = "å›¾4ï¼šä¸­èŠ¯å›½é™…å½’æ¯å‡€åˆ©æ¶¦æƒ…å†µæ¦‚è§ˆ"
        print(f"\nğŸ” æµ‹è¯•æŸ¥è¯¢: {query}")
        print("-" * 60)
        
        # 3. ç¬¬ä¸€æ­¥ï¼šè·å–äº”å±‚å¬å›ç»“æœ
        print("\nğŸ“Š ç¬¬ä¸€æ­¥ï¼šè·å–äº”å±‚å¬å›ç»“æœ")
        all_results = image_engine._search_images_with_five_layer_recall(query)
        print(f"  äº”å±‚å¬å›ç»“æœæ•°é‡: {len(all_results)}")
        
        # 4. ç¬¬äºŒæ­¥ï¼šåˆ†æç»“æœä¸­çš„å›¾4ä¿¡æ¯
        print(f"\nğŸ“Š ç¬¬äºŒæ­¥ï¼šåˆ†æç»“æœä¸­çš„å›¾4ä¿¡æ¯")
        our_results = []
        other_results = []
        
        for i, result in enumerate(all_results):
            score = result.get('score', 0)
            search_method = result.get('search_method', 'N/A')
            source = result.get('source', 'N/A')
            
            # æ£€æŸ¥æ˜¯å¦æœ‰æˆ‘ä»¬çš„å­—æ®µ
            has_our_fields = all([
                result.get('document_name'),
                result.get('page_number'),
                result.get('chunk_type'),
                result.get('llm_context')
            ])
            
            if has_our_fields:
                our_results.append(result)
                print(f"  âœ… ç»“æœ{i+1}: {search_method} (åˆ†æ•°: {score:.4f}) - æœ‰æˆ‘ä»¬çš„å­—æ®µ")
                
                # æ£€æŸ¥æ˜¯å¦åŒ…å«å›¾4ä¿¡æ¯
                llm_context = result.get('llm_context', '')
                if 'å›¾4' in llm_context:
                    print(f"    ğŸ¯ åŒ…å«å›¾4ä¿¡æ¯!")
                    print(f"    ğŸ“‹ document_name: {result.get('document_name')}")
                    print(f"    ğŸ“‹ page_number: {result.get('page_number')}")
                    print(f"    ğŸ“‹ llm_contexté•¿åº¦: {len(llm_context)}")
                else:
                    print(f"    âŒ ä¸åŒ…å«å›¾4ä¿¡æ¯")
            else:
                other_results.append(result)
                print(f"  âŒ ç»“æœ{i+1}: {search_method} (åˆ†æ•°: {score:.4f}) - ç¼ºå°‘æˆ‘ä»¬çš„å­—æ®µ")
        
        print(f"\n  ç»Ÿè®¡:")
        print(f"    æœ‰æˆ‘ä»¬å­—æ®µçš„ç»“æœ: {len(our_results)}")
        print(f"    ç¼ºå°‘æˆ‘ä»¬å­—æ®µçš„ç»“æœ: {len(other_results)}")
        
        # 5. ç¬¬ä¸‰æ­¥ï¼šæ¨¡æ‹Ÿæºè¿‡æ»¤è¿‡ç¨‹
        print(f"\nğŸ“Š ç¬¬ä¸‰æ­¥ï¼šæ¨¡æ‹Ÿæºè¿‡æ»¤è¿‡ç¨‹")
        
        # æ£€æŸ¥æºè¿‡æ»¤é…ç½®
        print(f"  æºè¿‡æ»¤é…ç½®æ£€æŸ¥:")
        config_attrs = dir(config)
        filter_attrs = [attr for attr in config_attrs if 'filter' in attr.lower() or 'source' in attr.lower()]
        print(f"    ç›¸å…³é…ç½®å±æ€§: {filter_attrs}")
        
        # å°è¯•è·å–é…ç½®å€¼
        for attr in filter_attrs:
            try:
                value = getattr(config, attr)
                print(f"    {attr}: {value}")
            except:
                print(f"    {attr}: æ— æ³•è·å–")
        
        # 6. ç¬¬å››æ­¥ï¼šæµ‹è¯•å¢åŠ æºæ•°é‡çš„æ•ˆæœ
        print(f"\nğŸ“Š ç¬¬å››æ­¥ï¼šæµ‹è¯•å¢åŠ æºæ•°é‡çš„æ•ˆæœ")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰max_sourcesé…ç½®
        if hasattr(config, 'max_sources'):
            max_sources = config.max_sources
            print(f"    å½“å‰max_sourcesé…ç½®: {max_sources}")
            
            # å»ºè®®å¢åŠ æºæ•°é‡
            if max_sources and max_sources < 10:
                print(f"    ğŸ’¡ å»ºè®®å¢åŠ max_sourcesåˆ°10æˆ–æ›´å¤š")
        else:
            print(f"    â“ æ²¡æœ‰æ‰¾åˆ°max_sourcesé…ç½®")
        
        # 7. ç¬¬äº”æ­¥ï¼šåˆ†æå…¶ä»–å¬å›ç­–ç•¥
        print(f"\nğŸ“Š ç¬¬äº”æ­¥ï¼šåˆ†æå…¶ä»–å¬å›ç­–ç•¥")
        
        # ç»Ÿè®¡å„ç­–ç•¥çš„ç»“æœ
        strategy_stats = {}
        for result in all_results:
            search_method = result.get('search_method', 'N/A')
            if search_method not in strategy_stats:
                strategy_stats[search_method] = []
            strategy_stats[search_method].append(result)
        
        print(f"  å„ç­–ç•¥ç»“æœç»Ÿè®¡:")
        for strategy, results in strategy_stats.items():
            print(f"    {strategy}: {len(results)} ä¸ªç»“æœ")
            
            # æ£€æŸ¥è¯¥ç­–ç•¥æ˜¯å¦æœ‰æˆ‘ä»¬çš„å­—æ®µ
            has_fields_count = sum(1 for r in results if all([
                r.get('document_name'),
                r.get('page_number'),
                r.get('chunk_type'),
                r.get('llm_context')
            ]))
            print(f"      æœ‰æˆ‘ä»¬å­—æ®µçš„ç»“æœ: {has_fields_count}/{len(results)}")
        
        # 8. ç¬¬å…­æ­¥ï¼šé—®é¢˜åˆ†æå’Œå»ºè®®
        print("\n" + "=" * 80)
        print("ğŸ¯ é—®é¢˜åˆ†æå’Œå»ºè®®")
        print("=" * 80)
        
        print(f"\nå…³é”®å‘ç°:")
        print(f"1. äº”å±‚å¬å›å±‚é¢ï¼šâœ… æˆ‘ä»¬çš„metadataå­—æ®µåœ¨vector_searchä¸­æ­£ç¡®ä¼ é€’")
        print(f"2. äº”å±‚å¬å›å±‚é¢ï¼šâŒ å…¶ä»–å¬å›ç­–ç•¥æ²¡æœ‰æˆ‘ä»¬çš„metadataå­—æ®µ")
        print(f"3. æºè¿‡æ»¤å±‚é¢ï¼šâ“ éœ€è¦ç¡®è®¤å…·ä½“é…ç½®å’Œè¿‡æ»¤é€»è¾‘")
        
        print(f"\nå¯èƒ½çš„é—®é¢˜ç‚¹:")
        print(f"1. æºè¿‡æ»¤å¯èƒ½åŸºäºæ•°é‡é™åˆ¶ï¼Œåªä¿ç•™å‰Nä¸ªç»“æœ")
        print(f"2. æºè¿‡æ»¤å¯èƒ½åŸºäºåˆ†æ•°é˜ˆå€¼è¿‡æ»¤")
        print(f"3. å…¶ä»–å¬å›ç­–ç•¥çš„ç»“æœæ²¡æœ‰æˆ‘ä»¬çš„metadataï¼Œå¯¼è‡´ä¿¡æ¯ä¸¢å¤±")
        
        print(f"\nå»ºè®®çš„è§£å†³æ–¹æ¡ˆ:")
        print(f"1. å¢åŠ max_sourcesé…ç½®ï¼Œç¡®ä¿æ›´å¤šç»“æœè¢«ä¿ç•™")
        print(f"2. å¢å¼ºå…¶ä»–å¬å›ç­–ç•¥çš„metadataå­—æ®µ")
        print(f"3. è°ƒæ•´æºè¿‡æ»¤çš„ä¼˜å…ˆçº§ç­–ç•¥ï¼Œä¼˜å…ˆä¿ç•™æœ‰å®Œæ•´metadataçš„ç»“æœ")
        
        print(f"\nä¸‹ä¸€æ­¥è¡ŒåŠ¨:")
        print(f"1. æ£€æŸ¥å¹¶è°ƒæ•´æºè¿‡æ»¤é…ç½®")
        print(f"2. å¢å¼ºå…¶ä»–å¬å›ç­–ç•¥çš„metadataå­—æ®µ")
        print(f"3. æµ‹è¯•è°ƒæ•´åçš„æ•ˆæœ")
        
    except Exception as e:
        print(f"âŒ è°ƒè¯•å¤±è´¥: {e}")
        import traceback
        print(f"è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")


if __name__ == "__main__":
    debug_source_filter_verification()
