#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç¨‹åºè¯´æ˜ï¼š
## 1. æµ‹è¯•ä¿®å¤åçš„ImageEngine
## 2. éªŒè¯post-filteringç­–ç•¥æ˜¯å¦æ­£å¸¸å·¥ä½œ
## 3. æ£€æŸ¥ç¬¬ä¸€å±‚å‘é‡æœç´¢æ˜¯å¦èƒ½è¿”å›ç»“æœ
"""

import sys
import os
import logging

# ä¿®å¤è·¯å¾„é—®é¢˜ï¼Œæ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from config.settings import Settings
from v2.core.image_engine import ImageEngine
from v2.config.v2_config import ImageEngineConfigV2

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def test_fixed_image_engine():
    """æµ‹è¯•ä¿®å¤åçš„ImageEngine"""
    print("ğŸ” æµ‹è¯•ä¿®å¤åçš„ImageEngine")
    print("=" * 60)
    
    try:
        # åŠ è½½é…ç½®
        config = Settings.load_from_file('config.json')
        
        # åˆ›å»ºImageEngineé…ç½®
        image_config = ImageEngineConfigV2(
            enabled=True,
            max_results=20,
            image_similarity_threshold=0.05,
            enable_vector_search=True,
            enable_keyword_search=True,
            max_recall_results=150,
            use_new_pipeline=False,  # æš‚æ—¶å…³é—­æ–°pipelineï¼Œä¸“æ³¨æµ‹è¯•å¬å›
            enable_enhanced_reranking=False
        )
        
        print("âœ… ImageEngineé…ç½®åˆ›å»ºæˆåŠŸ")
        
        # åŠ è½½å‘é‡æ•°æ®åº“
        print("ğŸ“š æ­£åœ¨åŠ è½½å‘é‡æ•°æ®åº“...")
        from langchain_community.vectorstores import FAISS
        from langchain_community.embeddings import DashScopeEmbeddings
        from config.api_key_manager import get_dashscope_api_key
        
        # è·å–APIå¯†é’¥
        config_key = config.dashscope_api_key
        api_key = get_dashscope_api_key(config_key)
        
        if not api_key:
            print("âŒ æœªæ‰¾åˆ°æœ‰æ•ˆçš„DashScope APIå¯†é’¥")
            return
        
        # åˆå§‹åŒ–embeddings
        embeddings = DashScopeEmbeddings(dashscope_api_key=api_key, model='text-embedding-v1')
        vector_db_path = config.vector_db_dir
        vector_store = FAISS.load_local(vector_db_path, embeddings, allow_dangerous_deserialization=True)
        print(f"âœ… å‘é‡æ•°æ®åº“åŠ è½½æˆåŠŸï¼ŒåŒ…å« {len(vector_store.docstore._dict)} ä¸ªæ–‡æ¡£")
        
        # åˆ›å»ºImageEngineå®ä¾‹
        image_engine = ImageEngine(
            config=image_config,
            vector_store=vector_store,
            skip_initial_load=True  # è·³è¿‡åˆå§‹åŠ è½½ï¼Œæ‰‹åŠ¨åŠ è½½
        )
        
        print("âœ… ImageEngineå®ä¾‹åˆ›å»ºæˆåŠŸ")
        
        # æ‰‹åŠ¨åŠ è½½æ–‡æ¡£
        print("ğŸ“š æ­£åœ¨åŠ è½½æ–‡æ¡£...")
        image_engine._load_from_vector_store()
        
        if not image_engine.image_docs:
            print("âŒ æ²¡æœ‰åŠ è½½åˆ°å›¾ç‰‡æ–‡æ¡£")
            return
        
        print(f"âœ… æˆåŠŸåŠ è½½ {len(image_engine.image_docs)} ä¸ªå›¾ç‰‡æ–‡æ¡£")
        
        # æµ‹è¯•æŸ¥è¯¢
        test_query = "ä¸­èŠ¯å›½é™…å‡€åˆ©æ¶¦"
        print(f"\nğŸ” æµ‹è¯•æŸ¥è¯¢: {test_query}")
        
        # æµ‹è¯•ç¬¬ä¸€å±‚å‘é‡æœç´¢
        print("\nğŸ“Š æµ‹è¯•ç¬¬ä¸€å±‚å‘é‡æœç´¢")
        try:
            vector_results = image_engine._vector_search(test_query, max_results=10)
            print(f"âœ… ç¬¬ä¸€å±‚å‘é‡æœç´¢æˆåŠŸï¼Œè¿”å› {len(vector_results)} ä¸ªç»“æœ")
            
            if vector_results:
                print("ğŸ“‹ ç»“æœè¯¦æƒ…:")
                for i, result in enumerate(vector_results[:3]):
                    doc = result['doc']
                    metadata = doc.metadata if hasattr(doc, 'metadata') else {}
                    chunk_type = metadata.get('chunk_type', 'N/A')
                    score = result.get('score', 'N/A')
                    search_method = result.get('search_method', 'N/A')
                    
                    print(f"  ç»“æœ{i+1}:")
                    print(f"    chunk_type: {chunk_type}")
                    print(f"    score: {score}")
                    print(f"    search_method: {search_method}")
                    
                    if chunk_type == 'image':
                        img_caption = metadata.get('img_caption', 'N/A')
                        print(f"    img_caption: {img_caption}")
                    elif chunk_type == 'image_text':
                        enhanced_desc = metadata.get('enhanced_description', '')[:100] + '...' if len(metadata.get('enhanced_description', '')) > 100 else metadata.get('enhanced_description', '')
                        print(f"    enhanced_description: {enhanced_desc}")
            else:
                print("âš ï¸ ç¬¬ä¸€å±‚å‘é‡æœç´¢æ²¡æœ‰è¿”å›ç»“æœ")
                
        except Exception as e:
            print(f"âŒ ç¬¬ä¸€å±‚å‘é‡æœç´¢å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
        
        # æµ‹è¯•äº”å±‚å¬å›ç­–ç•¥
        print("\nğŸ“Š æµ‹è¯•äº”å±‚å¬å›ç­–ç•¥")
        try:
            recall_results = image_engine._search_images_with_five_layer_recall(test_query)
            print(f"âœ… äº”å±‚å¬å›ç­–ç•¥æˆåŠŸï¼Œè¿”å› {len(recall_results)} ä¸ªç»“æœ")
            
            if recall_results:
                print("ğŸ“‹ å¬å›ç»“æœç»Ÿè®¡:")
                layer_counts = {}
                for result in recall_results:
                    layer = result.get('layer', 'unknown')
                    layer_counts[layer] = layer_counts.get(layer, 0) + 1
                
                for layer, count in sorted(layer_counts.items()):
                    print(f"  ç¬¬{layer}å±‚: {count} ä¸ªç»“æœ")
            else:
                print("âš ï¸ äº”å±‚å¬å›ç­–ç•¥æ²¡æœ‰è¿”å›ç»“æœ")
                
        except Exception as e:
            print(f"âŒ äº”å±‚å¬å›ç­–ç•¥å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
        
        print("\nâœ… ImageEngineæµ‹è¯•å®Œæˆï¼")
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    test_fixed_image_engine()
