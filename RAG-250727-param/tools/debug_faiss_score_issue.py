#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç¨‹åºè¯´æ˜ï¼š
## 1. ä¸“é—¨è°ƒè¯•FAISSä¸è¿”å›scoreçš„é—®é¢˜
## 2. æµ‹è¯•å¤šç§FAISSæœç´¢æ–¹æ³•
## 3. æ£€æŸ¥FAISSé…ç½®å’Œç‰ˆæœ¬ä¿¡æ¯
## 4. æ‰¾å‡ºscoreç¼ºå¤±çš„æ ¹æœ¬åŸå› 
"""

import sys
import os
import logging
import json
from typing import List, Dict, Any

# ä¿®å¤è·¯å¾„é—®é¢˜ï¼Œæ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from config.settings import Settings
from langchain_community.vectorstores import FAISS
from langchain_community.embeddings import DashScopeEmbeddings
from config.api_key_manager import get_dashscope_api_key

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def debug_faiss_methods(vector_store, query: str, max_results: int = 10):
    """
    è°ƒè¯•FAISSçš„å„ç§æœç´¢æ–¹æ³•ï¼Œæ‰¾å‡ºscoreç¼ºå¤±çš„åŸå› 
    
    :param vector_store: FAISSå‘é‡æ•°æ®åº“
    :param query: æŸ¥è¯¢æ–‡æœ¬
    :param max_results: æœ€å¤§ç»“æœæ•°
    :return: è°ƒè¯•ç»“æœ
    """
    print(f"\nğŸ” è°ƒè¯•æŸ¥è¯¢: {query}")
    print("=" * 80)
    
    results = {
        'query': query,
        'max_results': max_results,
        'methods_tested': [],
        'faiss_info': {},
        'search_results': {},
        'recommendations': []
    }
    
    try:
        # 1. æ£€æŸ¥FAISSåŸºæœ¬ä¿¡æ¯
        print("ğŸ“‹ 1. æ£€æŸ¥FAISSåŸºæœ¬ä¿¡æ¯")
        print("-" * 50)
        
        faiss_info = {
            'vector_store_type': type(vector_store).__name__,
            'has_index': hasattr(vector_store, 'index'),
            'has_docstore': hasattr(vector_store, 'docstore'),
            'has_embedding_function': hasattr(vector_store, 'embedding_function'),
            'docstore_size': len(vector_store.docstore._dict) if hasattr(vector_store, 'docstore') else 0
        }
        
        if hasattr(vector_store, 'index'):
            index = vector_store.index
            faiss_info.update({
                'index_type': type(index).__name__,
                'index_ntotal': getattr(index, 'ntotal', 'N/A'),
                'index_d': getattr(index, 'd', 'N/A'),
                'index_metric_type': getattr(index, 'metric_type', 'N/A'),
                'index_is_trained': getattr(index, 'is_trained', 'N/A')
            })
        
        results['faiss_info'] = faiss_info
        
        for key, value in faiss_info.items():
            print(f"  {key}: {value}")
        
        # 2. æ£€æŸ¥å¯ç”¨çš„æœç´¢æ–¹æ³•
        print(f"\nğŸ“‹ 2. æ£€æŸ¥å¯ç”¨çš„æœç´¢æ–¹æ³•")
        print("-" * 50)
        
        available_methods = []
        for method_name in dir(vector_store):
            if 'search' in method_name.lower() and callable(getattr(vector_store, method_name)):
                available_methods.append(method_name)
        
        print(f"å¯ç”¨çš„æœç´¢æ–¹æ³•: {available_methods}")
        results['available_methods'] = available_methods
        
        # 3. æµ‹è¯•æ–¹æ³•1: similarity_search (å½“å‰ä½¿ç”¨çš„æ–¹æ³•)
        print(f"\nğŸ“‹ 3. æµ‹è¯•æ–¹æ³•1: similarity_search")
        print("-" * 50)
        
        try:
            candidates = vector_store.similarity_search(
                query, 
                k=max_results,
                filter={'chunk_type': 'image_text'}
            )
            
            print(f"âœ… similarity_searchæˆåŠŸï¼Œè¿”å› {len(candidates)} ä¸ªç»“æœ")
            
            # æ£€æŸ¥ç¬¬ä¸€ä¸ªç»“æœçš„å±æ€§
            if candidates:
                first_doc = candidates[0]
                print(f"\nç¬¬ä¸€ä¸ªæ–‡æ¡£çš„å±æ€§åˆ†æ:")
                print(f"  - ç±»å‹: {type(first_doc)}")
                print(f"  - æ‰€æœ‰å±æ€§: {[attr for attr in dir(first_doc) if not attr.startswith('_')]}")
                print(f"  - æ˜¯å¦æœ‰score: {hasattr(first_doc, 'score')}")
                print(f"  - æ˜¯å¦æœ‰metadata: {hasattr(first_doc, 'metadata')}")
                
                if hasattr(first_doc, 'metadata'):
                    print(f"  - metadataå†…å®¹: {first_doc.metadata}")
                
                # å°è¯•è·å–score
                score = getattr(first_doc, 'score', None)
                print(f"  - getattr(doc, 'score', None): {score}")
                
                # å°è¯•ä»metadataè·å–score
                if hasattr(first_doc, 'metadata') and first_doc.metadata:
                    metadata_score = first_doc.metadata.get('score', None)
                    print(f"  - doc.metadata.get('score'): {metadata_score}")
                
                results['search_results']['similarity_search'] = {
                    'success': True,
                    'count': len(candidates),
                    'first_doc_analysis': {
                        'has_score': hasattr(first_doc, 'score'),
                        'score_value': score,
                        'metadata_score': metadata_score if 'metadata_score' in locals() else None,
                        'attributes': [attr for attr in dir(first_doc) if not attr.startswith('_')]
                    }
                }
            else:
                print("âš ï¸ æ²¡æœ‰è¿”å›ç»“æœ")
                results['search_results']['similarity_search'] = {
                    'success': True,
                    'count': 0,
                    'first_doc_analysis': None
                }
                
        except Exception as e:
            print(f"âŒ similarity_searchå¤±è´¥: {e}")
            results['search_results']['similarity_search'] = {
                'success': False,
                'error': str(e)
            }
        
        # 4. æµ‹è¯•æ–¹æ³•2: similarity_search_with_score
        print(f"\nğŸ“‹ 4. æµ‹è¯•æ–¹æ³•2: similarity_search_with_score")
        print("-" * 50)
        
        try:
            if hasattr(vector_store, 'similarity_search_with_score'):
                docs_and_scores = vector_store.similarity_search_with_score(
                    query, 
                    k=max_results,
                    filter={'chunk_type': 'image_text'}
                )
                
                print(f"âœ… similarity_search_with_scoreæˆåŠŸï¼Œè¿”å› {len(docs_and_scores)} ä¸ªç»“æœ")
                
                if docs_and_scores:
                    first_result = docs_and_scores[0]
                    print(f"\nç¬¬ä¸€ä¸ªç»“æœåˆ†æ:")
                    print(f"  - ç±»å‹: {type(first_result)}")
                    print(f"  - é•¿åº¦: {len(first_result)}")
                    print(f"  - å†…å®¹: {first_result}")
                    
                    if len(first_result) == 2:
                        doc, score = first_result
                        print(f"  - æ–‡æ¡£ç±»å‹: {type(doc)}")
                        print(f"  - åˆ†æ•°ç±»å‹: {type(score)}")
                        print(f"  - åˆ†æ•°å€¼: {score}")
                        
                        # æ£€æŸ¥æ–‡æ¡£æ˜¯å¦æœ‰scoreå±æ€§
                        print(f"  - doc.score: {getattr(doc, 'score', 'ä¸å­˜åœ¨')}")
                
                results['search_results']['similarity_search_with_score'] = {
                    'success': True,
                    'count': len(docs_and_scores),
                    'first_result_analysis': {
                        'type': type(docs_and_scores[0]) if docs_and_scores else None,
                        'length': len(docs_and_scores[0]) if docs_and_scores else None,
                        'has_score': len(docs_and_scores[0]) == 2 if docs_and_scores else False
                    }
                }
            else:
                print("âŒ ä¸æ”¯æŒsimilarity_search_with_scoreæ–¹æ³•")
                results['search_results']['similarity_search_with_score'] = {
                    'success': False,
                    'error': 'æ–¹æ³•ä¸å­˜åœ¨'
                }
                
        except Exception as e:
            print(f"âŒ similarity_search_with_scoreå¤±è´¥: {e}")
            results['search_results']['similarity_search_with_score'] = {
                'success': False,
                'error': str(e)
            }
        
        # 5. æµ‹è¯•æ–¹æ³•3: ç›´æ¥è°ƒç”¨FAISSç´¢å¼•
        print(f"\nğŸ“‹ 5. æµ‹è¯•æ–¹æ³•3: ç›´æ¥è°ƒç”¨FAISSç´¢å¼•")
        print("-" * 50)
        
        try:
            if hasattr(vector_store, 'index') and hasattr(vector_store, 'embedding_function'):
                # è·å–æŸ¥è¯¢å‘é‡
                query_embedding = vector_store.embedding_function.embed_query(query)
                print(f"âœ… æŸ¥è¯¢å‘é‡ç”ŸæˆæˆåŠŸï¼Œç»´åº¦: {len(query_embedding)}")
                
                # ç›´æ¥è°ƒç”¨FAISSç´¢å¼•æœç´¢
                if hasattr(vector_store.index, 'search'):
                    # æœç´¢æœ€è¿‘çš„å‘é‡
                    distances, indices = vector_store.index.search(
                        [query_embedding], 
                        max_results
                    )
                    
                    print(f"âœ… ç›´æ¥FAISSæœç´¢æˆåŠŸ")
                    print(f"  - è·ç¦»: {distances[0]}")
                    print(f"  - ç´¢å¼•: {indices[0]}")
                    print(f"  - è·ç¦»ç±»å‹: {type(distances[0][0])}")
                    print(f"  - è·ç¦»èŒƒå›´: {distances[0].min():.4f} - {distances[0].max():.4f}")
                    
                    # æ£€æŸ¥è·ç¦»æ˜¯å¦åˆç†
                    if distances[0].min() < 0.1:
                        print(f"  - ğŸš¨ è·ç¦»å€¼è¿‡å°ï¼Œå¯èƒ½æ˜¯ç›¸ä¼¼åº¦åˆ†æ•°")
                    elif distances[0].max() > 10:
                        print(f"  - ğŸš¨ è·ç¦»å€¼è¿‡å¤§ï¼Œå¯èƒ½éœ€è¦è½¬æ¢")
                    else:
                        print(f"  - âœ… è·ç¦»å€¼åœ¨åˆç†èŒƒå›´å†…")
                    
                    results['search_results']['direct_faiss_search'] = {
                        'success': True,
                        'distances': distances[0].tolist(),
                        'indices': indices[0].tolist(),
                        'distance_range': f"{distances[0].min():.4f} - {distances[0].max():.4f}"
                    }
                else:
                    print("âŒ FAISSç´¢å¼•ä¸æ”¯æŒsearchæ–¹æ³•")
                    results['search_results']['direct_faiss_search'] = {
                        'success': False,
                        'error': 'ç´¢å¼•ä¸æ”¯æŒsearchæ–¹æ³•'
                    }
            else:
                print("âŒ æ— æ³•ç›´æ¥è°ƒç”¨FAISSç´¢å¼•")
                results['search_results']['direct_faiss_search'] = {
                    'success': False,
                    'error': 'ç¼ºå°‘å¿…è¦çš„å±æ€§'
                }
                
        except Exception as e:
            print(f"âŒ ç›´æ¥FAISSæœç´¢å¤±è´¥: {e}")
            results['search_results']['direct_faiss_search'] = {
                'success': False,
                'error': str(e)
            }
        
        # 6. æµ‹è¯•æ–¹æ³•4: æ£€æŸ¥æ–‡æ¡£å­˜å‚¨
        print(f"\nğŸ“‹ 6. æµ‹è¯•æ–¹æ³•4: æ£€æŸ¥æ–‡æ¡£å­˜å‚¨")
        print("-" * 50)
        
        try:
            if hasattr(vector_store, 'docstore') and hasattr(vector_store.docstore, '_dict'):
                docstore = vector_store.docstore._dict
                print(f"âœ… æ–‡æ¡£å­˜å‚¨æ£€æŸ¥æˆåŠŸ")
                print(f"  - æ–‡æ¡£æ€»æ•°: {len(docstore)}")
                
                # æ£€æŸ¥å‰å‡ ä¸ªæ–‡æ¡£
                sample_docs = list(docstore.values())[:3]
                for i, doc in enumerate(sample_docs):
                    print(f"\n  æ ·æœ¬æ–‡æ¡£ {i+1}:")
                    print(f"    - ç±»å‹: {type(doc)}")
                    print(f"    - å±æ€§: {[attr for attr in dir(doc) if not attr.startswith('_')]}")
                    print(f"    - æ˜¯å¦æœ‰score: {hasattr(doc, 'score')}")
                    
                    if hasattr(doc, 'metadata'):
                        print(f"    - metadata keys: {list(doc.metadata.keys())}")
                        if 'score' in doc.metadata:
                            print(f"    - metadata.score: {doc.metadata['score']}")
                
                results['search_results']['docstore_check'] = {
                    'success': True,
                    'total_docs': len(docstore),
                    'sample_docs_analysis': [
                        {
                            'has_score': hasattr(doc, 'score'),
                            'metadata_keys': list(doc.metadata.keys()) if hasattr(doc, 'metadata') else []
                        }
                        for doc in sample_docs
                    ]
                }
            else:
                print("âŒ æ— æ³•æ£€æŸ¥æ–‡æ¡£å­˜å‚¨")
                results['search_results']['docstore_check'] = {
                    'success': False,
                    'error': 'ç¼ºå°‘docstoreå±æ€§'
                }
                
        except Exception as e:
            print(f"âŒ æ–‡æ¡£å­˜å‚¨æ£€æŸ¥å¤±è´¥: {e}")
            results['search_results']['docstore_check'] = {
                'success': False,
                'error': str(e)
            }
        
        # 7. ç”Ÿæˆè¯Šæ–­å»ºè®®
        print(f"\nğŸ“‹ 7. è¯Šæ–­å»ºè®®")
        print("-" * 50)
        
        # åˆ†æé—®é¢˜
        if results['search_results'].get('similarity_search_with_score', {}).get('success'):
            results['recommendations'].append("âœ… å»ºè®®ä½¿ç”¨similarity_search_with_scoreæ–¹æ³•ï¼Œå®ƒä¼šè¿”å›åˆ†æ•°")
        else:
            results['recommendations'].append("âŒ similarity_search_with_scoreä¸å¯ç”¨ï¼Œéœ€è¦å…¶ä»–è§£å†³æ–¹æ¡ˆ")
        
        if results['search_results'].get('direct_faiss_search', {}).get('success'):
            distances = results['search_results']['direct_faiss_search'].get('distances', [])
            if distances:
                min_dist = min(distances)
                max_dist = max(distances)
                if min_dist < 0.1:
                    results['recommendations'].append("ğŸš¨ FAISSè¿”å›çš„æ˜¯ç›¸ä¼¼åº¦åˆ†æ•°ï¼Œä¸æ˜¯è·ç¦»")
                elif max_dist > 10:
                    results['recommendations'].append("ğŸš¨ FAISSè¿”å›çš„è·ç¦»å€¼è¿‡å¤§ï¼Œéœ€è¦è½¬æ¢")
                else:
                    results['recommendations'].append("âœ… FAISSè¿”å›çš„è·ç¦»å€¼åœ¨åˆç†èŒƒå›´å†…")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰scoreå±æ€§
        similarity_search_result = results['search_results'].get('similarity_search', {})
        if similarity_search_result.get('success') and similarity_search_result.get('first_doc_analysis'):
            if not similarity_search_result['first_doc_analysis']['has_score']:
                results['recommendations'].append("âŒ similarity_searchä¸è¿”å›scoreå±æ€§ï¼Œè¿™æ˜¯é—®é¢˜çš„æ ¹æº")
        
        # è¾“å‡ºå»ºè®®
        for i, rec in enumerate(results['recommendations'], 1):
            print(f"  {i}. {rec}")
            
    except Exception as e:
        print(f"âŒ è°ƒè¯•è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        results['error'] = str(e)
    
    return results

def test_faiss_score_issue():
    """æµ‹è¯•FAISS scoreé—®é¢˜"""
    print("ğŸ” è°ƒè¯•FAISS Scoreç¼ºå¤±é—®é¢˜")
    print("=" * 80)
    
    try:
        # åŠ è½½é…ç½®
        config = Settings.load_from_file('config.json')
        
        # åŠ è½½å‘é‡æ•°æ®åº“
        print("ğŸ“š æ­£åœ¨åŠ è½½å‘é‡æ•°æ®åº“...")
        
        # è·å–APIå¯†é’¥
        config_key = config.dashscope_api_key
        api_key = get_dashscope_api_key(config_key)
        
        if not api_key:
            print("âŒ æœªæ‰¾åˆ°æœ‰æ•ˆçš„DashScope APIå¯†é’¥")
            return
        
        # åˆå§‹åŒ–embeddings
        embeddings = DashScopeEmbeddings(dashscope_api_key=api_key, model='text-embedding-v1')
        vector_db_path = config.vector_db_dir
        vector_store = FAISS.load_local(vector_db_path, embeddings, allow_dangerous_deserialization=True)
        
        print(f"âœ… å‘é‡æ•°æ®åº“åŠ è½½æˆåŠŸ")
        
        # æµ‹è¯•æŸ¥è¯¢
        test_queries = [
            "å›¾4ï¼šä¸­èŠ¯å›½é™…å½’æ¯å‡€åˆ©æ¶¦æƒ…å†µæ¦‚è§ˆ",  # æ§åˆ¶å°è¾“å‡ºä¸­çš„å®é™…æŸ¥è¯¢
            "ä¸­èŠ¯å›½é™…å‡€åˆ©æ¶¦"
        ]
        
        all_results = []
        
        for test_query in test_queries:
            result = debug_faiss_methods(vector_store, test_query, 10)
            all_results.append(result)
        
        # ä¿å­˜è°ƒè¯•ç»“æœ
        output_file = "faiss_score_debug_results.json"
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(all_results, f, ensure_ascii=False, indent=2, default=str)
        
        print(f"\nğŸ’¾ è°ƒè¯•ç»“æœå·²ä¿å­˜åˆ°: {output_file}")
        
        # ç”Ÿæˆæ€»ç»“æŠ¥å‘Š
        print(f"\nğŸ“‹ æ€»ç»“æŠ¥å‘Š:")
        print("=" * 60)
        
        # åˆ†æä¸»è¦å‘ç°
        for result in all_results:
            if 'search_results' in result:
                print(f"\næŸ¥è¯¢: {result['query']}")
                
                # æ£€æŸ¥similarity_search_with_score
                with_score_result = result['search_results'].get('similarity_search_with_score', {})
                if with_score_result.get('success'):
                    print(f"  âœ… similarity_search_with_scoreå¯ç”¨")
                else:
                    print(f"  âŒ similarity_search_with_scoreä¸å¯ç”¨")
                
                # æ£€æŸ¥ç›´æ¥FAISSæœç´¢
                direct_result = result['search_results'].get('direct_faiss_search', {})
                if direct_result.get('success'):
                    print(f"  âœ… ç›´æ¥FAISSæœç´¢å¯ç”¨")
                else:
                    print(f"  âŒ ç›´æ¥FAISSæœç´¢ä¸å¯ç”¨")
        
        print(f"\nğŸ¯ ä¸»è¦å‘ç°:")
        print("-" * 40)
        
        # æ£€æŸ¥æ˜¯å¦æœ‰å¯ç”¨çš„è§£å†³æ–¹æ¡ˆ
        has_solution = False
        for result in all_results:
            if result['search_results'].get('similarity_search_with_score', {}).get('success'):
                has_solution = True
                break
        
        if has_solution:
            print("  âœ… æ‰¾åˆ°è§£å†³æ–¹æ¡ˆï¼šä½¿ç”¨similarity_search_with_score")
        else:
            print("  âŒ æ²¡æœ‰æ‰¾åˆ°ç›´æ¥è§£å†³æ–¹æ¡ˆï¼Œéœ€è¦æ‰‹åŠ¨è®¡ç®—ç›¸ä¼¼åº¦")
        
        print(f"\nğŸ“– è¯¦ç»†è°ƒè¯•ç»“æœè¯·æŸ¥çœ‹: {output_file}")
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    test_faiss_score_issue()
