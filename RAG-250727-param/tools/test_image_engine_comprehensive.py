#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç¨‹åºè¯´æ˜ï¼š
## 1. å…¨é¢æµ‹è¯•ImageEngineçš„FAISS filteråŠŸèƒ½
## 2. æµ‹è¯•ä¸åŒæŸ¥è¯¢ç±»å‹çš„è¡¨ç°
## 3. éªŒè¯å‘é‡æœç´¢çš„å®Œæ•´æ€§å’Œå‡†ç¡®æ€§
## 4. åˆ†ææŸ¥è¯¢ç»“æœçš„è´¨é‡å’Œç›¸å…³æ€§
"""

import sys
import os
import logging

# ä¿®å¤è·¯å¾„é—®é¢˜ï¼Œæ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from config.settings import Settings
from v2.core.image_engine import ImageEngine
from v2.config.v2_config import ImageEngineConfigV2

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def test_image_engine_comprehensive():
    """å…¨é¢æµ‹è¯•ImageEngineçš„FAISS filteråŠŸèƒ½"""
    print("ğŸ” å…¨é¢æµ‹è¯•ImageEngineçš„FAISS filteråŠŸèƒ½")
    print("=" * 60)
    
    try:
        # åŠ è½½é…ç½®
        config = Settings.load_from_file('config.json')
        
        # åˆ›å»ºImageEngineé…ç½®
        image_config = ImageEngineConfigV2(
            enabled=True,
            max_results=20,
            image_similarity_threshold=0.01,  # é™ä½é˜ˆå€¼ï¼Œè·å–æ›´å¤šç»“æœ
            enable_vector_search=True,
            enable_keyword_search=True,
            max_recall_results=150,
            use_new_pipeline=False,
            enable_enhanced_reranking=False
        )
        
        print("âœ… ImageEngineé…ç½®åˆ›å»ºæˆåŠŸ")
        
        # åŠ è½½å‘é‡æ•°æ®åº“
        print("ğŸ“š æ­£åœ¨åŠ è½½å‘é‡æ•°æ®åº“...")
        from langchain_community.vectorstores import FAISS
        from langchain_community.embeddings import DashScopeEmbeddings
        from config.api_key_manager import get_dashscope_api_key
        
        # è·å–APIå¯†é’¥
        config_key = config.dashscope_api_key
        api_key = get_dashscope_api_key(config_key)
        
        if not api_key:
            print("âŒ æœªæ‰¾åˆ°æœ‰æ•ˆçš„DashScope APIå¯†é’¥")
            return
        
        # åˆå§‹åŒ–embeddings
        embeddings = DashScopeEmbeddings(dashscope_api_key=api_key, model='text-embedding-v1')
        vector_db_path = config.vector_db_dir
        vector_store = FAISS.load_local(vector_db_path, embeddings, allow_dangerous_deserialization=True)
        print(f"âœ… å‘é‡æ•°æ®åº“åŠ è½½æˆåŠŸï¼ŒåŒ…å« {len(vector_store.docstore._dict)} ä¸ªæ–‡æ¡£")
        
        # åˆ›å»ºImageEngineå®ä¾‹
        image_engine = ImageEngine(
            config=image_config,
            vector_store=vector_store,
            skip_initial_load=True
        )
        
        print("âœ… ImageEngineå®ä¾‹åˆ›å»ºæˆåŠŸ")
        
        # æ‰‹åŠ¨åŠ è½½æ–‡æ¡£
        print("ğŸ“š æ­£åœ¨åŠ è½½æ–‡æ¡£...")
        image_engine._load_from_vector_store()
        
        if not image_engine.image_docs:
            print("âŒ æ²¡æœ‰åŠ è½½åˆ°å›¾ç‰‡æ–‡æ¡£")
            return
        
        print(f"âœ… æˆåŠŸåŠ è½½ {len(image_engine.image_docs)} ä¸ªå›¾ç‰‡æ–‡æ¡£")
        
        # æµ‹è¯•ä¸åŒç±»å‹çš„æŸ¥è¯¢
        test_queries = [
            # è´¢åŠ¡ç›¸å…³æŸ¥è¯¢
            "ä¸­èŠ¯å›½é™…å‡€åˆ©æ¶¦",
            "è´¢åŠ¡æ•°æ®",
            "è¥æ”¶æƒ…å†µ",
            "åˆ©æ¶¦åˆ†æ",
            
            # å›¾è¡¨ç›¸å…³æŸ¥è¯¢
            "å›¾è¡¨æ•°æ®",
            "æ•°æ®å›¾è¡¨",
            "ç»Ÿè®¡å›¾è¡¨",
            "è¶‹åŠ¿å›¾",
            
            # æŠ€æœ¯ç›¸å…³æŸ¥è¯¢
            "æŠ€æœ¯æŒ‡æ ‡",
            "å·¥è‰ºæ°´å¹³",
            "åˆ¶ç¨‹æŠ€æœ¯",
            "è‰¯ç‡æ•°æ®",
            
            # é€šç”¨æŸ¥è¯¢
            "ä¸­èŠ¯å›½é™…",
            "åŠå¯¼ä½“",
            "èŠ¯ç‰‡åˆ¶é€ ",
            "æ™¶åœ†ä»£å·¥"
        ]
        
        # ç»Ÿè®¡ç»“æœ
        total_queries = len(test_queries)
        successful_queries = 0
        query_results = {}
        
        for test_query in test_queries:
            print(f"\nğŸ” æµ‹è¯•æŸ¥è¯¢: {test_query}")
            print("-" * 50)
            
            try:
                # æµ‹è¯•ç¬¬ä¸€å±‚å‘é‡æœç´¢
                vector_results = image_engine._vector_search(test_query, max_results=15)
                print(f"âœ… ç¬¬ä¸€å±‚å‘é‡æœç´¢æˆåŠŸï¼Œè¿”å› {len(vector_results)} ä¸ªç»“æœ")
                
                # è®°å½•æŸ¥è¯¢ç»“æœ
                query_results[test_query] = {
                    'total_results': len(vector_results),
                    'semantic_results': len([r for r in vector_results if 'semantic' in r.get('search_method', '')]),
                    'visual_results': len([r for r in vector_results if 'visual' in r.get('search_method', '')]),
                    'results': vector_results[:5]  # åªè®°å½•å‰5ä¸ªç»“æœ
                }
                
                if vector_results:
                    successful_queries += 1
                    print("ğŸ“‹ ç»“æœè¯¦æƒ…:")
                    
                    # ç»Ÿè®¡ä¸åŒæœç´¢æ–¹æ³•çš„ç»“æœ
                    semantic_count = 0
                    visual_count = 0
                    
                    for i, result in enumerate(vector_results[:5]):
                        doc = result['doc']
                        metadata = doc.metadata if hasattr(doc, 'metadata') else {}
                        chunk_type = metadata.get('chunk_type', 'N/A')
                        score = result.get('score', 'N/A')
                        search_method = result.get('search_method', 'N/A')
                        source = result.get('source', 'N/A')
                        
                        print(f"  ç»“æœ{i+1}:")
                        print(f"    chunk_type: {chunk_type}")
                        print(f"    score: {score}")
                        print(f"    search_method: {search_method}")
                        print(f"    source: {source}")
                        
                        if chunk_type == 'image':
                            img_caption = metadata.get('img_caption', 'N/A')
                            print(f"    img_caption: {img_caption}")
                            visual_count += 1
                        elif chunk_type == 'image_text':
                            enhanced_desc = metadata.get('enhanced_description', '')[:100] + '...' if len(metadata.get('enhanced_description', '')) > 100 else metadata.get('enhanced_description', '')
                            print(f"    enhanced_description: {enhanced_desc}")
                            semantic_count += 1
                    
                    print(f"  ğŸ“Š ç»“æœç»Ÿè®¡: è¯­ä¹‰ç›¸ä¼¼åº¦ {semantic_count} ä¸ª, è§†è§‰ç›¸ä¼¼åº¦ {visual_count} ä¸ª")
                else:
                    print("âš ï¸ ç¬¬ä¸€å±‚å‘é‡æœç´¢æ²¡æœ‰è¿”å›ç»“æœ")
                    
            except Exception as e:
                print(f"âŒ ç¬¬ä¸€å±‚å‘é‡æœç´¢å¤±è´¥: {e}")
                query_results[test_query] = {
                    'error': str(e),
                    'total_results': 0
                }
        
        # è¾“å‡ºæµ‹è¯•æ€»ç»“
        print("\n" + "=" * 60)
        print("ğŸ“Š æµ‹è¯•æ€»ç»“")
        print("=" * 60)
        print(f"æ€»æŸ¥è¯¢æ•°: {total_queries}")
        print(f"æˆåŠŸæŸ¥è¯¢æ•°: {successful_queries}")
        print(f"æˆåŠŸç‡: {successful_queries/total_queries*100:.1f}%")
        
        # åˆ†ææŸ¥è¯¢ç±»å‹è¡¨ç°
        print("\nğŸ” æŸ¥è¯¢ç±»å‹è¡¨ç°åˆ†æ:")
        print("-" * 40)
        
        query_categories = {
            'è´¢åŠ¡ç›¸å…³': ['ä¸­èŠ¯å›½é™…å‡€åˆ©æ¶¦', 'è´¢åŠ¡æ•°æ®', 'è¥æ”¶æƒ…å†µ', 'åˆ©æ¶¦åˆ†æ'],
            'å›¾è¡¨ç›¸å…³': ['å›¾è¡¨æ•°æ®', 'æ•°æ®å›¾è¡¨', 'ç»Ÿè®¡å›¾è¡¨', 'è¶‹åŠ¿å›¾'],
            'æŠ€æœ¯ç›¸å…³': ['æŠ€æœ¯æŒ‡æ ‡', 'å·¥è‰ºæ°´å¹³', 'åˆ¶ç¨‹æŠ€æœ¯', 'è‰¯ç‡æ•°æ®'],
            'é€šç”¨æŸ¥è¯¢': ['ä¸­èŠ¯å›½é™…', 'åŠå¯¼ä½“', 'èŠ¯ç‰‡åˆ¶é€ ', 'æ™¶åœ†ä»£å·¥']
        }
        
        for category, queries in query_categories.items():
            category_results = [query_results.get(q, {}) for q in queries if q in query_results]
            if category_results:
                avg_results = sum(r.get('total_results', 0) for r in category_results) / len(category_results)
                avg_semantic = sum(r.get('semantic_results', 0) for r in category_results) / len(category_results)
                avg_visual = sum(r.get('visual_results', 0) for r in category_results) / len(category_results)
                
                print(f"{category}:")
                print(f"  å¹³å‡ç»“æœæ•°: {avg_results:.1f}")
                print(f"  å¹³å‡è¯­ä¹‰ç»“æœ: {avg_semantic:.1f}")
                print(f"  å¹³å‡è§†è§‰ç»“æœ: {avg_visual:.1f}")
        
        print("\nâœ… å…¨é¢æµ‹è¯•å®Œæˆï¼")
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    test_image_engine_comprehensive()
