'''
ç¨‹åºè¯´æ˜ï¼š

## 1. æµ‹è¯•ä¿®æ”¹åçš„metadataä¼ é€’åŠŸèƒ½
## 2. éªŒè¯æ–°å¢å­—æ®µæ˜¯å¦æ­£ç¡®ä¼ é€’
## 3. æ£€æŸ¥LLMä¸Šä¸‹æ–‡æ˜¯å¦å®Œæ•´
## 4. éªŒè¯æ¥æºä¿¡æ¯æ˜¯å¦å®Œæ•´
'''

import os
import sys

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from langchain_community.vectorstores import FAISS
from langchain_community.embeddings import DashScopeEmbeddings
from config.api_key_manager import get_dashscope_api_key
from v2.core.image_engine import ImageEngine
from v2.core.document_loader import DocumentLoader
from v2.config.v2_config import ImageEngineConfigV2
import time


def test_enhanced_metadata():
    """æµ‹è¯•ä¿®æ”¹åçš„metadataä¼ é€’åŠŸèƒ½"""
    print("ğŸ§ª æµ‹è¯•ä¿®æ”¹åçš„metadataä¼ é€’åŠŸèƒ½")
    print("=" * 80)
    
    try:
        # 1. åˆå§‹åŒ–ç»„ä»¶
        print("ğŸ“¡ åˆå§‹åŒ–ç»„ä»¶...")
        config = ImageEngineConfigV2()
        
        api_key = get_dashscope_api_key()
        embeddings = DashScopeEmbeddings(dashscope_api_key=api_key, model='text-embedding-v1')
        vector_db_path = "../central/vector_db"
        vector_store = FAISS.load_local(vector_db_path, embeddings, allow_dangerous_deserialization=True)
        
        document_loader = DocumentLoader(vector_store=vector_store)
        image_engine = ImageEngine(
            config=config,
            vector_store=vector_store,
            document_loader=document_loader
        )
        print("âœ… ç»„ä»¶åˆå§‹åŒ–æˆåŠŸ")
        
        # 2. æµ‹è¯•æŸ¥è¯¢
        query = "å›¾4ï¼šä¸­èŠ¯å›½é™…å½’æ¯å‡€åˆ©æ¶¦æƒ…å†µæ¦‚è§ˆ"
        print(f"\nğŸ” æµ‹è¯•æŸ¥è¯¢: {query}")
        print("-" * 60)
        
        # 3. æ£€æŸ¥å‘é‡æœç´¢ç»“æœ
        print("\nğŸ“Š æ£€æŸ¥å‘é‡æœç´¢è¯¦ç»†ç»“æœ")
        vector_results = image_engine._vector_search(query, max_results=50)
        print(f"  å‘é‡æœç´¢ç»“æœæ•°é‡: {len(vector_results)}")
        
        if vector_results:
            for i, result in enumerate(vector_results):
                print(f"\n  ç»“æœ {i+1}:")
                print(f"    åˆ†æ•°: {result.get('score', 'N/A'):.4f}")
                print(f"    æœç´¢æ–¹æ³•: {result.get('search_method', 'N/A')}")
                print(f"    æ¥æº: {result.get('source', 'N/A')}")
                print(f"    å±‚çº§: {result.get('layer', 'N/A')}")
                
                # æ£€æŸ¥æ–°å¢çš„metadataå­—æ®µ
                print(f"    ğŸ“‹ æ–°å¢metadataå­—æ®µ:")
                print(f"      document_name: {result.get('document_name', 'N/A')}")
                print(f"      page_number: {result.get('page_number', 'N/A')}")
                print(f"      chunk_type: {result.get('chunk_type', 'N/A')}")
                print(f"      enhanced_description: {result.get('enhanced_description', 'N/A')[:100]}...")
                print(f"      llm_context: {result.get('llm_context', 'N/A')[:100]}...")
                
                # æ£€æŸ¥æ–‡æ¡£ç±»å‹
                if hasattr(result['doc'], 'metadata') and result['doc'].metadata:
                    chunk_type = result['doc'].metadata.get('chunk_type', 'unknown')
                    document_name = result['doc'].metadata.get('document_name', 'unknown')
                    page_number = result['doc'].metadata.get('page_number', 'unknown')
                    print(f"    ğŸ“„ æ–‡æ¡£ä¿¡æ¯:")
                    print(f"      æ–‡æ¡£ç±»å‹: {chunk_type}")
                    print(f"      æ–‡æ¡£åç§°: {document_name}")
                    print(f"      é¡µç : {page_number}")
                
                # æ£€æŸ¥æ–‡æ¡£å†…å®¹
                content = result['doc'].page_content
                print(f"    å†…å®¹é•¿åº¦: {len(content)} å­—ç¬¦")
                
                # é‡ç‚¹æ£€æŸ¥æ˜¯å¦åŒ…å«å›¾4å®Œæ•´ä¿¡æ¯
                if 'å›¾4ï¼šä¸­èŠ¯å›½é™…å½’æ¯å‡€åˆ©æ¶¦æƒ…å†µæ¦‚è§ˆ' in content:
                    print("    âœ… åŒ…å«å®Œæ•´çš„å›¾4æ ‡é¢˜!")
                elif 'å›¾4' in content and 'ä¸­èŠ¯å›½é™…' in content and 'å‡€åˆ©æ¶¦' in content:
                    print("    âš ï¸  åŒ…å«å›¾4ç›¸å…³ä¿¡æ¯ï¼Œä½†å¯èƒ½ä¸å®Œæ•´")
                else:
                    print("    âŒ ä¸åŒ…å«å›¾4ç›¸å…³ä¿¡æ¯")
                
                # æ˜¾ç¤ºå†…å®¹å‰200å­—ç¬¦
                print(f"    å†…å®¹é¢„è§ˆ: {content[:200]}...")
        
        # 4. éªŒè¯LLMä¸Šä¸‹æ–‡å®Œæ•´æ€§
        print(f"\nğŸ“Š éªŒè¯LLMä¸Šä¸‹æ–‡å®Œæ•´æ€§")
        if vector_results:
            first_result = vector_results[0]
            llm_context = first_result.get('llm_context', '')
            
            if llm_context:
                print(f"  LLMä¸Šä¸‹æ–‡é•¿åº¦: {len(llm_context)} å­—ç¬¦")
                print(f"  åŒ…å«å›¾4æ ‡é¢˜: {'å›¾4ï¼šä¸­èŠ¯å›½é™…å½’æ¯å‡€åˆ©æ¶¦æƒ…å†µæ¦‚è§ˆ' in llm_context}")
                print(f"  åŒ…å«å›¾4å…³é”®è¯: {'å›¾4' in llm_context and 'ä¸­èŠ¯å›½é™…' in llm_context and 'å‡€åˆ©æ¶¦' in llm_context}")
                
                # æ£€æŸ¥enhanced_descriptionæ˜¯å¦åŒ…å«åœ¨ä¸Šä¸‹æ–‡ä¸­
                enhanced_desc = first_result.get('enhanced_description', '')
                if enhanced_desc and enhanced_desc in llm_context:
                    print("  âœ… enhanced_descriptionå·²æ­£ç¡®åŒ…å«åœ¨LLMä¸Šä¸‹æ–‡ä¸­")
                else:
                    print("  âŒ enhanced_descriptionæœªåŒ…å«åœ¨LLMä¸Šä¸‹æ–‡ä¸­")
                
                print(f"\n  LLMä¸Šä¸‹æ–‡å†…å®¹é¢„è§ˆ:")
                print(f"  {llm_context[:500]}...")
            else:
                print("  âŒ æ²¡æœ‰æ‰¾åˆ°llm_contextå­—æ®µ")
        
        # 5. éªŒè¯æ¥æºä¿¡æ¯å®Œæ•´æ€§
        print(f"\nğŸ“Š éªŒè¯æ¥æºä¿¡æ¯å®Œæ•´æ€§")
        if vector_results:
            first_result = vector_results[0]
            
            required_fields = ['document_name', 'page_number', 'chunk_type']
            missing_fields = []
            
            for field in required_fields:
                value = first_result.get(field, '')
                if value:
                    print(f"  âœ… {field}: {value}")
                else:
                    print(f"  âŒ {field}: ç¼ºå¤±")
                    missing_fields.append(field)
            
            if not missing_fields:
                print("  âœ… æ‰€æœ‰å¿…éœ€çš„æ¥æºä¿¡æ¯å­—æ®µéƒ½å·²æ­£ç¡®ä¼ é€’")
            else:
                print(f"  âŒ ç¼ºå¤±çš„å­—æ®µ: {missing_fields}")
        
        # 6. æ€»ç»“
        print("\n" + "=" * 80)
        print("ğŸ¯ æµ‹è¯•æ€»ç»“")
        print("=" * 80)
        
        if vector_results:
            first_result = vector_results[0]
            
            print(f"\nä¿®æ”¹æ•ˆæœéªŒè¯:")
            print(f"âœ… æ–°å¢metadataå­—æ®µä¼ é€’: {'document_name' in first_result and 'page_number' in first_result}")
            print(f"âœ… LLMä¸Šä¸‹æ–‡å®Œæ•´æ€§: {'llm_context' in first_result and first_result['llm_context']}")
            print(f"âœ… æ¥æºä¿¡æ¯å®Œæ•´æ€§: {first_result.get('document_name') and first_result.get('page_number')}")
            
            print(f"\né¢„æœŸæ•ˆæœ:")
            print(f"1. å‰ç«¯èƒ½æ­£ç¡®æ˜¾ç¤ºæ¥æºä¿¡æ¯ï¼ˆä¸å†æ˜¾ç¤º'æœªçŸ¥æ–‡æ¡£'ï¼‰")
            print(f"2. LLMèƒ½è·å¾—å®Œæ•´çš„å›¾4ä¸Šä¸‹æ–‡ä¿¡æ¯")
            print(f"3. èƒ½ç”Ÿæˆå‡†ç¡®çš„ç­”æ¡ˆè€Œä¸æ˜¯'æ²¡æœ‰å…³äºå›¾4çš„ä¿¡æ¯'")
        else:
            print(f"âŒ æ²¡æœ‰æ‰¾åˆ°å‘é‡æœç´¢ç»“æœï¼Œéœ€è¦æ£€æŸ¥åè¿‡æ»¤å®ç°")
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        print(f"è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")


if __name__ == "__main__":
    test_enhanced_metadata()
