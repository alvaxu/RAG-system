'''
ç¨‹åºè¯´æ˜ï¼š
## 1. æŸ¥çœ‹å‘é‡æ•°æ®åº“ä¸­å›¾ç‰‡çš„å…·ä½“æè¿°ä¿¡æ¯
## 2. æ˜¾ç¤ºå›¾ç‰‡çš„å…ƒæ•°æ®ã€å¢å¼ºæè¿°ã€è¯­ä¹‰ç‰¹å¾ç­‰è¯¦ç»†ä¿¡æ¯
## 3. æ”¯æŒæŒ‰å›¾ç‰‡ç±»å‹ã€æ–‡æ¡£åç§°ç­‰æ¡ä»¶ç­›é€‰
## 4. æä¾›å‹å¥½çš„æ˜¾ç¤ºæ ¼å¼
'''

import sys
import os
# ä¿®å¤è·¯å¾„é—®é¢˜ï¼Œæ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from config.settings import Settings
from langchain_community.vectorstores import FAISS
from langchain_community.embeddings import DashScopeEmbeddings
import logging
import json
from pathlib import Path

# å¯¼å…¥ç»Ÿä¸€çš„APIå¯†é’¥ç®¡ç†æ¨¡å—
from config.api_key_manager import get_dashscope_api_key

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def load_vector_store(vector_db_path):
    """åŠ è½½å‘é‡å­˜å‚¨"""
    try:
        config = Settings.load_from_file('config.json')
        
        # ä½¿ç”¨ç»Ÿä¸€çš„APIå¯†é’¥ç®¡ç†æ¨¡å—è·å–APIå¯†é’¥
        config_key = config.dashscope_api_key
        api_key = get_dashscope_api_key(config_key)
        
        if not api_key:
            logger.warning("æœªæ‰¾åˆ°æœ‰æ•ˆçš„DashScope APIå¯†é’¥")
            return None
        
        embeddings = DashScopeEmbeddings(dashscope_api_key=api_key, model="text-embedding-v1")
        vector_store = FAISS.load_local(vector_db_path, embeddings, allow_dangerous_deserialization=True)
        logger.info(f"å‘é‡å­˜å‚¨åŠ è½½æˆåŠŸï¼ŒåŒ…å« {len(vector_store.docstore._dict)} ä¸ªæ–‡æ¡£")
        return vector_store
    except Exception as e:
        logger.error(f"åŠ è½½å‘é‡å­˜å‚¨å¤±è´¥: {e}")
        return None

def extract_image_descriptions(vector_store):
    """æå–å›¾ç‰‡æè¿°ä¿¡æ¯"""
    image_descriptions = []
    try:
        for doc_id, doc in vector_store.docstore._dict.items():
            metadata = doc.metadata if hasattr(doc, 'metadata') and doc.metadata else {}
            if metadata.get('chunk_type') == 'image':
                image_info = {
                    'doc_id': doc_id,
                    'content': doc.page_content,
                    'metadata': metadata,
                    'image_id': metadata.get('image_id', 'unknown'),
                    'image_path': metadata.get('image_path', ''),
                    'document_name': metadata.get('document_name', 'æœªçŸ¥æ–‡æ¡£'),
                    'page_number': metadata.get('page_number', 1),
                    'img_caption': metadata.get('img_caption', []),
                    'img_footnote': metadata.get('img_footnote', []),
                    'enhanced_description': metadata.get('enhanced_description', ''),
                    'image_type': metadata.get('image_type', 'general'),
                    'semantic_features': metadata.get('semantic_features', {}),
                    'image_filename': metadata.get('image_filename', ''),
                    'extension': metadata.get('extension', ''),
                    'source_zip': metadata.get('source_zip', '')
                }
                image_descriptions.append(image_info)
        logger.info(f"æå–äº† {len(image_descriptions)} å¼ å›¾ç‰‡çš„æè¿°ä¿¡æ¯")
        return image_descriptions
    except Exception as e:
        logger.error(f"æå–å›¾ç‰‡æè¿°å¤±è´¥: {e}")
        return []

def display_image_descriptions(image_descriptions, filter_type=None, filter_document=None):
    """æ˜¾ç¤ºå›¾ç‰‡æè¿°ä¿¡æ¯"""
    print("="*80)
    print("ğŸ–¼ï¸  å‘é‡æ•°æ®åº“ä¸­çš„å›¾ç‰‡æè¿°ä¿¡æ¯")
    print("="*80)
    
    filtered_descriptions = image_descriptions
    
    if filter_type:
        filtered_descriptions = [desc for desc in filtered_descriptions if desc['image_type'] == filter_type]
        print(f"ğŸ“Š ç­›é€‰æ¡ä»¶: å›¾ç‰‡ç±»å‹ = {filter_type}")
    
    if filter_document:
        filtered_descriptions = [desc for desc in filtered_descriptions if filter_document.lower() in desc['document_name'].lower()]
        print(f"ğŸ“Š ç­›é€‰æ¡ä»¶: æ–‡æ¡£åç§°åŒ…å« = {filter_document}")
    
    print(f"ğŸ“Š æ‰¾åˆ° {len(filtered_descriptions)} å¼ å›¾ç‰‡")
    print("="*80)
    
    for i, desc in enumerate(filtered_descriptions, 1):
        print(f"\nğŸ–¼ï¸  å›¾ç‰‡ {i}:")
        print(f"   ğŸ“„ æ–‡æ¡£åç§°: {desc['document_name']}")
        print(f"   ğŸ“– é¡µç : {desc['page_number']}")
        print(f"   ğŸ†” å›¾ç‰‡ID: {desc['image_id']}")
        print(f"   ğŸ“ å›¾ç‰‡è·¯å¾„: {desc['image_path']}")
        print(f"   ğŸ“ æ–‡ä»¶å: {desc['image_filename']}")
        print(f"   ğŸ”§ æ‰©å±•å: {desc['extension']}")
        print(f"   ğŸ“¦ æ¥æº: {desc['source_zip']}")
        print(f"   ğŸ·ï¸  å›¾ç‰‡ç±»å‹: {desc['image_type']}")
        
        if desc['img_caption']:
            print(f"   ğŸ“‹ å›¾ç‰‡æ ‡é¢˜: {' | '.join(desc['img_caption'])}")
        
        if desc['img_footnote']:
            print(f"   ğŸ“ å›¾ç‰‡è„šæ³¨: {' | '.join(desc['img_footnote'])}")
        
        if desc['enhanced_description']:
            print(f"   ğŸ¯ å¢å¼ºæè¿°: {desc['enhanced_description']}")
        
        if desc['content']:
            print(f"   ğŸ“„ åŸå§‹å†…å®¹: {desc['content']}")
        
        if desc['semantic_features']:
            print(f"   ğŸ§  è¯­ä¹‰ç‰¹å¾:")
            for key, value in desc['semantic_features'].items():
                if isinstance(value, float):
                    print(f"      {key}: {value:.4f}")
                else:
                    print(f"      {key}: {value}")
        
        print("-" * 60)

def show_statistics(image_descriptions):
    """æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯"""
    print("\n" + "="*80)
    print("ğŸ“Š å›¾ç‰‡ä¿¡æ¯ç»Ÿè®¡")
    print("="*80)
    
    doc_stats = {}
    for desc in image_descriptions:
        doc_name = desc['document_name']
        doc_stats[doc_name] = doc_stats.get(doc_name, 0) + 1
    
    print("ğŸ“„ æŒ‰æ–‡æ¡£ç»Ÿè®¡:")
    for doc_name, count in sorted(doc_stats.items()):
        print(f"   {doc_name}: {count} å¼ å›¾ç‰‡")
    
    type_stats = {}
    for desc in image_descriptions:
        img_type = desc['image_type']
        type_stats[img_type] = type_stats.get(img_type, 0) + 1
    
    print("\nğŸ·ï¸  æŒ‰å›¾ç‰‡ç±»å‹ç»Ÿè®¡:")
    for img_type, count in sorted(type_stats.items()):
        print(f"   {img_type}: {count} å¼ å›¾ç‰‡")
    
    ext_stats = {}
    for desc in image_descriptions:
        ext = desc['extension']
        if ext:
            ext_stats[ext] = ext_stats.get(ext, 0) + 1
    
    print("\nğŸ“ æŒ‰æ‰©å±•åç»Ÿè®¡:")
    for ext, count in sorted(ext_stats.items()):
        print(f"   {ext}: {count} å¼ å›¾ç‰‡")
    
    with_caption = sum(1 for desc in image_descriptions if desc['img_caption'])
    with_footnote = sum(1 for desc in image_descriptions if desc['img_footnote'])
    
    print(f"\nğŸ“‹ æœ‰å›¾ç‰‡æ ‡é¢˜: {with_caption} å¼ ")
    print(f"ğŸ“ æœ‰å›¾ç‰‡è„šæ³¨: {with_footnote} å¼ ")
    print(f"ğŸ¯ æœ‰å¢å¼ºæè¿°: {sum(1 for desc in image_descriptions if desc['enhanced_description'])} å¼ ")

def save_descriptions_to_file(image_descriptions, output_file: str):
    """ä¿å­˜æè¿°ä¿¡æ¯åˆ°æ–‡ä»¶"""
    try:
        serializable_descriptions = []
        for desc in image_descriptions:
            serializable_desc = {
                'doc_id': str(desc['doc_id']),
                'content': desc['content'],
                'image_id': desc['image_id'],
                'image_path': desc['image_path'],
                'document_name': desc['document_name'],
                'page_number': desc['page_number'],
                'img_caption': desc['img_caption'],
                'img_footnote': desc['img_footnote'],
                'enhanced_description': desc['enhanced_description'],
                'image_type': desc['image_type'],
                'semantic_features': desc['semantic_features'],
                'image_filename': desc['image_filename'],
                'extension': desc['extension'],
                'source_zip': desc['source_zip']
            }
            serializable_descriptions.append(serializable_desc)
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(serializable_descriptions, f, ensure_ascii=False, indent=2)
        
        print(f"\nğŸ’¾ æè¿°ä¿¡æ¯å·²ä¿å­˜åˆ°: {output_file}")
        
    except Exception as e:
        logger.error(f"ä¿å­˜æè¿°ä¿¡æ¯å¤±è´¥: {e}")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ” å‘é‡æ•°æ®åº“å›¾ç‰‡æè¿°æŸ¥çœ‹å™¨")
    print("="*60)
    
    try:
        config = Settings.load_from_file('config.json')
        vector_db_path = config.vector_db_dir
        
        print(f"ğŸ“ å‘é‡æ•°æ®åº“è·¯å¾„: {vector_db_path}")
        
        # æ£€æŸ¥è·¯å¾„æ˜¯å¦å­˜åœ¨ï¼Œå¦‚æœä¸å­˜åœ¨å°è¯•å…¶ä»–å¯èƒ½çš„è·¯å¾„
        if not os.path.exists(vector_db_path):
            # å°è¯•å…¶ä»–å¯èƒ½çš„è·¯å¾„
            possible_paths = [
                "./central/vector_db",
                "./vector_db",
                "./central/vector_db_test",
                "./vector_db_test"
            ]
            
            for path in possible_paths:
                if os.path.exists(path):
                    vector_db_path = path
                    print(f"âœ… æ‰¾åˆ°å‘é‡æ•°æ®åº“è·¯å¾„: {vector_db_path}")
                    break
            else:
                print(f"âŒ å‘é‡æ•°æ®åº“è·¯å¾„ä¸å­˜åœ¨ï¼Œå°è¯•è¿‡çš„è·¯å¾„:")
                for path in possible_paths:
                    print(f"   - {path}")
                return
        
        vector_store = load_vector_store(vector_db_path)
        if not vector_store:
            print("âŒ æ— æ³•åŠ è½½å‘é‡å­˜å‚¨")
            return
        
        image_descriptions = extract_image_descriptions(vector_store)
        
        if not image_descriptions:
            print("âŒ æ²¡æœ‰æ‰¾åˆ°å›¾ç‰‡ä¿¡æ¯")
            return
        
        show_statistics(image_descriptions)
        
        print("\n" + "="*60)
        print("ğŸ” ç­›é€‰é€‰é¡¹:")
        print("1. æ˜¾ç¤ºæ‰€æœ‰å›¾ç‰‡")
        print("2. æŒ‰å›¾ç‰‡ç±»å‹ç­›é€‰")
        print("3. æŒ‰æ–‡æ¡£åç§°ç­›é€‰")
        print("4. ç»„åˆç­›é€‰")
        
        choice = input("\nè¯·é€‰æ‹©ç­›é€‰æ–¹å¼ (1-4): ").strip()
        
        filter_type = None
        filter_document = None
        
        if choice == "2":
            types = set(desc['image_type'] for desc in image_descriptions)
            print("\nå¯ç”¨çš„å›¾ç‰‡ç±»å‹:")
            for t in sorted(types):
                print(f"   - {t}")
            filter_type = input("è¯·è¾“å…¥å›¾ç‰‡ç±»å‹: ").strip()
            
        elif choice == "3":
            docs = set(desc['document_name'] for desc in image_descriptions)
            print("\nå¯ç”¨çš„æ–‡æ¡£åç§°:")
            for doc in sorted(docs):
                print(f"   - {doc}")
            filter_document = input("è¯·è¾“å…¥æ–‡æ¡£åç§°å…³é”®è¯: ").strip()
            
        elif choice == "4":
            types = set(desc['image_type'] for desc in image_descriptions)
            print("\nå¯ç”¨çš„å›¾ç‰‡ç±»å‹:")
            for t in sorted(types):
                print(f"   - {t}")
            filter_type = input("è¯·è¾“å…¥å›¾ç‰‡ç±»å‹: ").strip()
            
            docs = set(desc['document_name'] for desc in image_descriptions)
            print("\nå¯ç”¨çš„æ–‡æ¡£åç§°:")
            for doc in sorted(docs):
                print(f"   - {doc}")
            filter_document = input("è¯·è¾“å…¥æ–‡æ¡£åç§°å…³é”®è¯: ").strip()
        
        display_image_descriptions(image_descriptions, filter_type, filter_document)
        
        save_choice = input("\næ˜¯å¦ä¿å­˜æè¿°ä¿¡æ¯åˆ°æ–‡ä»¶? (y/n): ").strip().lower()
        if save_choice == 'y':
            output_file = "image_descriptions.json"
            save_descriptions_to_file(image_descriptions, output_file)
        
        print("\nâœ… å›¾ç‰‡æè¿°æŸ¥çœ‹å®Œæˆï¼")
        
    except Exception as e:
        logger.error(f"ç¨‹åºæ‰§è¡Œå¤±è´¥: {e}")
        print(f"âŒ ç¨‹åºæ‰§è¡Œå¤±è´¥: {e}")

if __name__ == "__main__":
    main()
