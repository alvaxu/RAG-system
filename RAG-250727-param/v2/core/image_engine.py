'''
ç¨‹åºè¯´æ˜ï¼š
## 1. å›¾ç‰‡å¼•æ“ - ä¸“é—¨å¤„ç†å›¾ç‰‡æŸ¥è¯¢
## 2. æ”¯æŒå›¾ç‰‡æ ‡é¢˜ã€æè¿°ã€å…³é”®è¯åŒ¹é…
## 3. æ™ºèƒ½å›¾ç‰‡é€‰æ‹©å’Œæ’åº
## 4. å‘åå…¼å®¹ç°æœ‰å›¾ç‰‡æŸ¥è¯¢åŠŸèƒ½
'''

import logging
import time
from typing import Dict, Any, List, Optional, Union
from .base_engine import BaseEngine, QueryType, QueryResult, EngineConfig, EngineStatus


logger = logging.getLogger(__name__)


class ImageEngineConfig(EngineConfig):
    """å›¾ç‰‡å¼•æ“ä¸“ç”¨é…ç½®"""
    
    def __init__(self, **kwargs):
        super().__init__(**kwargs)
        self.name = "image_engine"
        self.max_results = 20  # å›¾ç‰‡æŸ¥è¯¢å¯ä»¥è¿”å›æ›´å¤šç»“æœ
        self.image_similarity_threshold = 0.6  # å›¾ç‰‡ç›¸ä¼¼åº¦é˜ˆå€¼
        self.keyword_weight = 0.4  # å…³é”®è¯æƒé‡
        self.caption_weight = 0.3  # æ ‡é¢˜æƒé‡
        self.description_weight = 0.3  # æè¿°æƒé‡
        self.enable_fuzzy_match = True  # å¯ç”¨æ¨¡ç³ŠåŒ¹é…
        self.enable_semantic_search = True  # å¯ç”¨è¯­ä¹‰æœç´¢


class ImageEngine(BaseEngine):
    """
    å›¾ç‰‡å¼•æ“
    
    ä¸“é—¨å¤„ç†å›¾ç‰‡æŸ¥è¯¢ï¼Œæ”¯æŒå¤šç§åŒ¹é…ç­–ç•¥
    """
    
    def __init__(self, config: ImageEngineConfig, vector_store=None, document_loader=None, skip_initial_load=False):
        """
        åˆå§‹åŒ–å›¾ç‰‡å¼•æ“
        
        :param config: å›¾ç‰‡å¼•æ“é…ç½®
        :param vector_store: å‘é‡æ•°æ®åº“
        :param document_loader: ç»Ÿä¸€æ–‡æ¡£åŠ è½½å™¨
        :param skip_initial_load: æ˜¯å¦è·³è¿‡åˆå§‹åŠ è½½
        """
        super().__init__(config)
        self.vector_store = vector_store
        self.document_loader = document_loader
        self.image_docs = {}  # ç¼“å­˜çš„å›¾ç‰‡æ–‡æ¡£
        self._docs_loaded = False
        
        # åœ¨è®¾ç½®å®Œvector_storeåè°ƒç”¨_initialize
        self._initialize()
        
        # æ ¹æ®å‚æ•°å†³å®šæ˜¯å¦åŠ è½½æ–‡æ¡£
        if not skip_initial_load:
            if document_loader:
                self._load_from_document_loader()
            else:
                self._load_image_documents()
    
    def _setup_components(self):
        """è®¾ç½®å›¾ç‰‡å¼•æ“ç»„ä»¶"""
        if not self.vector_store:
            raise ValueError("å‘é‡æ•°æ®åº“æœªæä¾›")
        
        # åˆå§‹åŒ–å›¾ç‰‡æ–‡æ¡£ç¼“å­˜
        self._load_image_documents()
        
        # è®¾ç½®å›¾ç‰‡å¤„ç†ç»„ä»¶
        self._setup_image_processors()
    
    def _setup_image_processors(self):
        """è®¾ç½®å›¾ç‰‡å¤„ç†å™¨"""
        # è¿™é‡Œå¯ä»¥æ·»åŠ å›¾ç‰‡é¢„å¤„ç†ã€ç‰¹å¾æå–ç­‰ç»„ä»¶
        pass
    
    def _validate_config(self):
        """éªŒè¯å›¾ç‰‡å¼•æ“é…ç½®"""
        # æ”¯æŒä¸¤ç§é…ç½®ç±»å‹ï¼šImageEngineConfig å’Œ ImageEngineConfigV2
        from ..config.v2_config import ImageEngineConfigV2
        
        if not isinstance(self.config, (ImageEngineConfig, ImageEngineConfigV2)):
            raise ValueError("é…ç½®å¿…é¡»æ˜¯ImageEngineConfigæˆ–ImageEngineConfigV2ç±»å‹")
        
        # è·å–ç›¸ä¼¼åº¦é˜ˆå€¼ï¼Œæ”¯æŒä¸¤ç§é…ç½®ç±»å‹
        threshold = getattr(self.config, 'image_similarity_threshold', 0.6)
        if threshold < 0 or threshold > 1:
            raise ValueError("å›¾ç‰‡ç›¸ä¼¼åº¦é˜ˆå€¼å¿…é¡»åœ¨0-1ä¹‹é—´")
    
    def _load_from_document_loader(self):
        """ä»ç»Ÿä¸€æ–‡æ¡£åŠ è½½å™¨è·å–å›¾ç‰‡æ–‡æ¡£"""
        if self.document_loader:
            try:
                self.image_docs = self.document_loader.get_documents_by_type('image')
                self._docs_loaded = True
                self.logger.info(f"ä»ç»Ÿä¸€åŠ è½½å™¨è·å–å›¾ç‰‡æ–‡æ¡£: {len(self.image_docs)} ä¸ª")
            except Exception as e:
                self.logger.error(f"ä»ç»Ÿä¸€åŠ è½½å™¨è·å–å›¾ç‰‡æ–‡æ¡£å¤±è´¥: {e}")
                # é™çº§åˆ°ä¼ ç»ŸåŠ è½½æ–¹å¼
                self._load_image_documents()
        else:
            self.logger.warning("æ–‡æ¡£åŠ è½½å™¨æœªæä¾›ï¼Œä½¿ç”¨ä¼ ç»ŸåŠ è½½æ–¹å¼")
            self._load_image_documents()
    
    def clear_cache(self):
        """æ¸…ç†å›¾ç‰‡å¼•æ“ç¼“å­˜"""
        try:
            total_docs = len(self.image_docs)
            self.image_docs = {}
            self._docs_loaded = False
            
            self.logger.info(f"å›¾ç‰‡å¼•æ“ç¼“å­˜æ¸…ç†å®Œæˆï¼Œå…±æ¸…ç† {total_docs} ä¸ªæ–‡æ¡£")
            return total_docs
            
        except Exception as e:
            self.logger.error(f"æ¸…ç†å›¾ç‰‡å¼•æ“ç¼“å­˜å¤±è´¥: {e}")
            return 0
    
    def _ensure_docs_loaded(self):
        """ç¡®ä¿æ–‡æ¡£å·²åŠ è½½ï¼ˆå»¶è¿ŸåŠ è½½ï¼‰"""
        if not self._docs_loaded:
            if self.document_loader:
                self._load_from_document_loader()
            else:
                self._load_image_documents()
                self._docs_loaded = True
    
    def _load_image_documents(self):
        """åŠ è½½å›¾ç‰‡æ–‡æ¡£åˆ°ç¼“å­˜"""
        if not self.vector_store or not hasattr(self.vector_store, 'docstore'):
            self.logger.warning("âŒ å‘é‡æ•°æ®åº“æœªæä¾›æˆ–æ²¡æœ‰docstoreå±æ€§")
            return
        
        try:
            self.logger.info(f"ğŸ“š å¼€å§‹åŠ è½½å›¾ç‰‡æ–‡æ¡£...")
            self.logger.info(f"å‘é‡æ•°æ®åº“æ–‡æ¡£æ€»æ•°: {len(self.vector_store.docstore._dict)}")
            
            # ç»Ÿè®¡æ‰€æœ‰æ–‡æ¡£çš„ç±»å‹
            doc_types = {}
            for doc_id, doc in self.vector_store.docstore._dict.items():
                chunk_type = doc.metadata.get('chunk_type', '')
                if chunk_type not in doc_types:
                    doc_types[chunk_type] = 0
                doc_types[chunk_type] += 1
            
            self.logger.info(f"ğŸ“Š æ–‡æ¡£ç±»å‹ç»Ÿè®¡: {doc_types}")
            
            # ä»å‘é‡æ•°æ®åº“åŠ è½½æ‰€æœ‰å›¾ç‰‡æ–‡æ¡£
            for doc_id, doc in self.vector_store.docstore._dict.items():
                # æ£€æŸ¥å¤šç§å¯èƒ½çš„å›¾ç‰‡æ ‡è¯†
                chunk_type = doc.metadata.get('chunk_type', '')
                content_type = doc.metadata.get('content_type', '')
                doc_type = doc.metadata.get('doc_type', '')
                
                # åˆ¤æ–­æ˜¯å¦ä¸ºå›¾ç‰‡æ–‡æ¡£ - ç®€åŒ–åˆ¤æ–­é€»è¾‘
                is_image = chunk_type == 'image'
                
                if is_image:
                    self.image_docs[doc_id] = doc
                    self.logger.debug(f"âœ… åŠ è½½å›¾ç‰‡æ–‡æ¡£: {doc_id}")
                    self.logger.debug(f"  å…ƒæ•°æ®å­—æ®µ: {list(doc.metadata.keys())}")
            
            self.logger.info(f"ğŸ¯ æˆåŠŸåŠ è½½ {len(self.image_docs)} ä¸ªå›¾ç‰‡æ–‡æ¡£")
            
            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°å›¾ç‰‡æ–‡æ¡£ï¼Œå°è¯•å…¶ä»–æ–¹æ³•
            if not self.image_docs:
                self.logger.warning("âš ï¸ æœªæ‰¾åˆ°å›¾ç‰‡æ–‡æ¡£ï¼Œå°è¯•æœç´¢æ‰€æœ‰æ–‡æ¡£...")
                self._search_all_documents_for_images()
                
        except Exception as e:
            self.logger.error(f"âŒ åŠ è½½å›¾ç‰‡æ–‡æ¡£å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            self.image_docs = {}
    
    def _search_all_documents_for_images(self):
        """æœç´¢æ‰€æœ‰æ–‡æ¡£ä¸­çš„å›¾ç‰‡å†…å®¹"""
        try:
            for doc_id, doc in self.vector_store.docstore._dict.items():
                # æ£€æŸ¥æ–‡æ¡£å†…å®¹æ˜¯å¦åŒ…å«å›¾ç‰‡ç›¸å…³ä¿¡æ¯
                content = doc.metadata.get('content', '')
                if isinstance(content, str) and any(keyword in content.lower() for keyword in ['å›¾', 'å›¾ç‰‡', 'chart', 'figure']):
                    self.image_docs[doc_id] = doc
                    self.logger.debug(f"é€šè¿‡å†…å®¹è¯†åˆ«å›¾ç‰‡æ–‡æ¡£: {doc_id}")
        except Exception as e:
            self.logger.error(f"æœç´¢å›¾ç‰‡æ–‡æ¡£å¤±è´¥: {e}")
    
    def process_query(self, query: str, **kwargs) -> QueryResult:
        """
        å¤„ç†å›¾ç‰‡æŸ¥è¯¢
        
        :param query: æŸ¥è¯¢æ–‡æœ¬
        :param kwargs: é¢å¤–å‚æ•°
        :return: æŸ¥è¯¢ç»“æœ
        """
        if not self.is_enabled():
            return QueryResult(
                success=False,
                query=query,
                query_type=QueryType.IMAGE,
                results=[],
                total_count=0,
                processing_time=0.0,
                engine_name=self.name,
                metadata={},
                error_message="å›¾ç‰‡å¼•æ“æœªå¯ç”¨"
            )
        
        # ç¡®ä¿æ–‡æ¡£å·²åŠ è½½
        self._ensure_docs_loaded()
        
        start_time = time.time()
        
        try:
            # åˆ†ææŸ¥è¯¢æ„å›¾
            intent = self._analyze_image_intent(query)
            
            # æ‰§è¡Œå›¾ç‰‡æœç´¢
            results = self._search_images(query, intent, **kwargs)
            
            # æ™ºèƒ½æ’åº
            sorted_results = self._rank_image_results(results, query, intent)
            
            processing_time = time.time() - start_time
            
            return QueryResult(
                success=True,
                query=query,
                query_type=QueryType.IMAGE,
                results=sorted_results,
                total_count=len(sorted_results),
                processing_time=processing_time,
                engine_name=self.name,
                metadata={'intent': intent, 'total_images': len(self.image_docs)}
            )
            
        except Exception as e:
            processing_time = time.time() - start_time
            self.logger.error(f"å›¾ç‰‡æŸ¥è¯¢å¤±è´¥: {e}")
            
            return QueryResult(
                success=False,
                query=query,
                query_type=QueryType.IMAGE,
                results=[],
                total_count=0,
                processing_time=processing_time,
                engine_name=self.name,
                metadata={},
                error_message=str(e)
            )
    
    def _analyze_image_intent(self, query: str) -> Dict[str, Any]:
        """
        åˆ†æå›¾ç‰‡æŸ¥è¯¢æ„å›¾
        
        :param query: æŸ¥è¯¢æ–‡æœ¬
        :return: æ„å›¾åˆ†æç»“æœ
        """
        intent = {
            'type': 'general',  # general, specific, very_specific
            'keywords': [],
            'figure_numbers': [],
            'content_types': [],
            'confidence': 0.0,
            'requested_count': None,  # æ–°å¢ï¼šç”¨æˆ·è¯·æ±‚çš„æ•°é‡
            'show_all': False  # æ–°å¢ï¼šæ˜¯å¦æ˜¾ç¤ºæ‰€æœ‰
        }
        
        # æ£€æµ‹"æ‰€æœ‰"ã€"å…¨éƒ¨"ç­‰å…³é”®è¯
        all_keywords = ['æ‰€æœ‰', 'å…¨éƒ¨', 'æ¯ä¸€ä¸ª', 'æ¯å¼ ', 'æ¯å¹…', 'æ¯å¼ å›¾', 'æ¯å¹…å›¾']
        if any(keyword in query for keyword in all_keywords):
            intent['show_all'] = True
            self.logger.debug(f"æ£€æµ‹åˆ°'æ˜¾ç¤ºæ‰€æœ‰'è¦æ±‚: {query}")
        
        # æ£€æµ‹æ•°é‡è¦æ±‚ï¼ˆå¦‚"ä¸¤å¼ "ã€"3ä¸ª"ã€"5å¹…"ï¼‰
        import re
        count_matches = re.findall(r'(\d+)å¼ |(\d+)ä¸ª|(\d+)å¹…|(\d+)å¼ å›¾|(\d+)ä¸ªå›¾|(\d+)å¹…å›¾', query)
        if count_matches:
            for match in count_matches:
                if any(match):
                    intent['requested_count'] = int([x for x in match if x][0])
                    self.logger.debug(f"æ£€æµ‹åˆ°æ•°é‡è¦æ±‚: {intent['requested_count']}")
                    break
        
        # æå–å…³é”®è¯
        keywords = self._extract_keywords(query)
        intent['keywords'] = keywords
        
        # æ£€æµ‹å›¾è¡¨ç¼–å·
        figure_matches = re.findall(r'å›¾(\d+)', query)
        if figure_matches:
            intent['figure_numbers'] = [int(x) for x in figure_matches]
            intent['type'] = 'very_specific'
            intent['confidence'] = 0.9
        
        # æ£€æµ‹å†…å®¹ç±»å‹
        content_keywords = {
            'è¥æ”¶': 'financial',
            'åˆ©æ¶¦': 'financial', 
            'å­£åº¦': 'temporal',
            'å¹´åº¦': 'temporal',
            'å¢é•¿': 'trend',
            'ä¸‹é™': 'trend',
            'å¯¹æ¯”': 'comparison',
            'åˆ†æ': 'analysis'
        }
        
        for keyword, content_type in content_keywords.items():
            if keyword in query:
                intent['content_types'].append(content_type)
        
        # æ ¹æ®å…³é”®è¯æ•°é‡åˆ¤æ–­å…·ä½“ç¨‹åº¦
        if len(keywords) >= 3:
            intent['type'] = 'specific'
            intent['confidence'] = 0.7
        elif len(keywords) >= 1:
            intent['type'] = 'general'
            intent['confidence'] = 0.5
        
        self.logger.debug(f"æŸ¥è¯¢æ„å›¾åˆ†æç»“æœ: {intent}")
        return intent
    
    def _extract_keywords(self, query: str) -> List[str]:
        """æå–æŸ¥è¯¢å…³é”®è¯"""
        # ç®€å•çš„å…³é”®è¯æå–ï¼Œå¯ä»¥åç»­ä¼˜åŒ–
        stop_words = {'çš„', 'æ˜¯', 'åœ¨', 'æœ‰', 'å’Œ', 'ä¸', 'æˆ–', 'ä½†', 'è€Œ', 'äº†', 'å—', 'å‘¢', 'å•Š'}
        
        # ç§»é™¤æ ‡ç‚¹ç¬¦å·
        import re
        clean_query = re.sub(r'[^\w\s]', '', query)
        
        # åˆ†è¯å¹¶è¿‡æ»¤åœç”¨è¯
        words = clean_query.split()
        keywords = [word for word in words if word not in stop_words and len(word) > 1]
        
        return keywords
    
    def _search_images(self, query: str, intent: Dict[str, Any], **kwargs) -> List[Any]:
        """
        æ™ºèƒ½å›¾ç‰‡æœç´¢ - æ”¯æŒå›¾å·è¿‡æ»¤å’Œå†…å®¹ç²¾ç¡®åŒ¹é…
        
        :param query: æŸ¥è¯¢æ–‡æœ¬
        :param intent: æŸ¥è¯¢æ„å›¾
        :param kwargs: å…¶ä»–å‚æ•°
        :return: åŒ¹é…çš„å›¾ç‰‡åˆ—è¡¨
        """
        results = []
        self.logger.info(f"ğŸ” å¼€å§‹æ™ºèƒ½å›¾ç‰‡æœç´¢")
        self.logger.info(f"æŸ¥è¯¢: {query}")
        self.logger.info(f"æ„å›¾: {intent}")
        self.logger.info(f"å¯ç”¨å›¾ç‰‡æ–‡æ¡£æ•°é‡: {len(self.image_docs)}")
        
        # æ˜¾ç¤ºå‰å‡ ä¸ªå›¾ç‰‡æ–‡æ¡£çš„å…ƒæ•°æ®ï¼Œå¸®åŠ©è°ƒè¯•
        if self.image_docs:
            self.logger.info("ğŸ“¸ å‰3ä¸ªå›¾ç‰‡æ–‡æ¡£çš„å…ƒæ•°æ®:")
            for i, (doc_id, doc) in enumerate(list(self.image_docs.items())[:3]):
                self.logger.info(f"å›¾ç‰‡ {i+1}:")
                self.logger.info(f"  - æ–‡æ¡£ID: {doc_id}")
                self.logger.info(f"  - chunk_type: {doc.metadata.get('chunk_type', 'N/A')}")
                self.logger.info(f"  - img_caption: {doc.metadata.get('img_caption', 'N/A')}")
                self.logger.info(f"  - image_title: {doc.metadata.get('image_title', 'N/A')}")
                self.logger.info(f"  - enhanced_description: {doc.metadata.get('enhanced_description', 'N/A')[:50] if doc.metadata.get('enhanced_description') else 'N/A'}...")

        # ç¬¬ä¸€æ­¥ï¼šå›¾å·è¿‡æ»¤ï¼ˆå¦‚æœç”¨æˆ·æåˆ°äº†å›¾å·ï¼‰
        if intent['figure_numbers']:
            self.logger.info(f"ğŸ¯ æ£€æµ‹åˆ°å›¾å·æŸ¥è¯¢ï¼Œå›¾å·: {intent['figure_numbers']}")
            filtered_by_number = self._filter_by_figure_number(intent['figure_numbers'])
            
            if filtered_by_number:
                self.logger.info(f"âœ… å›¾å·è¿‡æ»¤åå‰©ä½™å›¾ç‰‡æ•°é‡: {len(filtered_by_number)}")
                # åœ¨è¿‡æ»¤åçš„å›¾ç‰‡ä¸­è¿›è¡Œå†…å®¹ç²¾ç¡®åŒ¹é…
                results = self._content_precise_match(query, filtered_by_number, intent)
                self.logger.info(f"âœ… å†…å®¹ç²¾ç¡®åŒ¹é…åç»“æœæ•°é‡: {len(results)}")
                # å›¾å·æŸ¥è¯¢è¿”å›æ‰€æœ‰åŒ¹é…çš„ç»“æœï¼Œä¸é™åˆ¶æ•°é‡
                return results
            else:
                self.logger.warning(f"âŒ æœªæ‰¾åˆ°å›¾å· {intent['figure_numbers']} å¯¹åº”çš„å›¾ç‰‡")
                return []
        
        # ç¬¬äºŒæ­¥ï¼šä¸€èˆ¬å†…å®¹æœç´¢ï¼ˆç”¨æˆ·æ²¡æœ‰æåˆ°å›¾å·ï¼‰
        self.logger.info("ğŸ” æ‰§è¡Œä¸€èˆ¬å†…å®¹æœç´¢")
        results = self._general_content_search(query, intent)
        self.logger.info(f"âœ… ä¸€èˆ¬å†…å®¹æœç´¢ç»“æœæ•°é‡: {len(results)}")
        if results:
            self.logger.info(f"ğŸ“¸ å‰3ä¸ªç»“æœé¢„è§ˆ:")
            for i, result in enumerate(results[:3]):
                self.logger.info(f"  ç»“æœ {i+1}: {result.get('caption', 'N/A')} (åˆ†æ•°: {result.get('score', 0):.3f})")
        else:
            self.logger.warning("âš ï¸ æ²¡æœ‰æ‰¾åˆ°åŒ¹é…çš„å›¾ç‰‡ï¼Œå¯èƒ½çš„åŸå› :")
            self.logger.warning("   - ç›¸ä¼¼åº¦é˜ˆå€¼è¿‡é«˜")
            self.logger.warning("   - å…³é”®è¯åŒ¹é…å¤±è´¥")
            self.logger.warning("   - å›¾ç‰‡å…ƒæ•°æ®ä¸å®Œæ•´")
        
        # æ ¹æ®æŸ¥è¯¢ç±»å‹è°ƒæ•´ç»“æœæ•°é‡
        max_results = self._adjust_result_count(intent)
        self.logger.info(f"ğŸ“Š è°ƒæ•´åçš„æœ€å¤§ç»“æœæ•°é‡: {max_results}")
        final_results = results[:max_results]
        self.logger.info(f"ğŸ¯ æœ€ç»ˆè¿”å›ç»“æœæ•°é‡: {len(final_results)}")
        return final_results

    def _filter_by_figure_number(self, figure_numbers: List[int]) -> List[Any]:
        """
        æ ¹æ®å›¾å·è¿›è¡Œç¬¬ä¸€å±‚è¿‡æ»¤
        
        :param figure_numbers: å›¾å·åˆ—è¡¨
        :return: è¿‡æ»¤åçš„å›¾ç‰‡åˆ—è¡¨
        """
        filtered_images = []
        self.logger.info(f"ğŸ” å¼€å§‹å›¾å·è¿‡æ»¤ï¼ŒæŸ¥æ‰¾å›¾å·: {figure_numbers}")
        
        for doc_id, doc in self.image_docs.items():
            # è·å–å›¾ç‰‡æ ‡é¢˜å’Œæè¿°
            caption = doc.metadata.get('img_caption', '')
            title = doc.metadata.get('image_title', '')
            
            self.logger.debug(f"æ£€æŸ¥æ–‡æ¡£ {doc_id}:")
            self.logger.debug(f"  - caption: {caption}")
            self.logger.debug(f"  - title: {title}")
            
            # æ£€æŸ¥å›¾ç‰‡æ ‡é¢˜æˆ–æè¿°ä¸­æ˜¯å¦åŒ…å«æŒ‡å®šçš„å›¾å·
            for fig_num in figure_numbers:
                caption_match = f'å›¾{fig_num}' in str(caption)
                title_match = f'å›¾{fig_num}' in str(title)
                
                if caption_match or title_match:
                    self.logger.info(f"âœ… æ‰¾åˆ°åŒ¹é…çš„å›¾å· {fig_num} åœ¨æ–‡æ¡£ {doc_id}")
                    self.logger.info(f"  - captionåŒ¹é…: {caption_match}")
                    self.logger.info(f"  - titleåŒ¹é…: {title_match}")
                    filtered_images.append(doc)
                    break
        
        self.logger.info(f"ğŸ¯ å›¾å·è¿‡æ»¤ç»“æœ: æ‰¾åˆ° {len(filtered_images)} å¼ å›¾ç‰‡")
        return filtered_images

    def _content_precise_match(self, query: str, filtered_images: List[Any], intent: Dict[str, Any]) -> List[Any]:
        """
        åœ¨è¿‡æ»¤åçš„å›¾ç‰‡ä¸­è¿›è¡Œå†…å®¹ç²¾ç¡®åŒ¹é…
        
        :param query: æŸ¥è¯¢æ–‡æœ¬
        :param filtered_images: è¿‡æ»¤åçš„å›¾ç‰‡åˆ—è¡¨
        :param intent: æŸ¥è¯¢æ„å›¾
        :return: ç²¾ç¡®åŒ¹é…çš„å›¾ç‰‡åˆ—è¡¨
        """
        if not filtered_images:
            return []
        
        # æå–å†…å®¹å…³é”®è¯ï¼ˆæ’é™¤å›¾å·éƒ¨åˆ†ï¼‰
        content_query = self._extract_content_query(query)
        content_keywords = self._extract_keywords(content_query)
        
        self.logger.debug(f"å†…å®¹æŸ¥è¯¢: {content_query}, å…³é”®è¯: {content_keywords}")
        
        # è®¡ç®—æ¯å¼ å›¾ç‰‡çš„å†…å®¹åŒ¹é…åˆ†æ•°
        scored_images = []
        for doc in filtered_images:
            score = self._calculate_content_similarity(query, doc, content_keywords)
            # å¯¹äºå›¾å·æŸ¥è¯¢ï¼Œå³ä½¿åˆ†æ•°ä¸º0ä¹Ÿè¦è¿”å›ï¼Œå› ä¸ºå›¾å·å·²ç»åŒ¹é…äº†
            if intent.get('figure_numbers'):
                # å›¾å·æŸ¥è¯¢ï¼šç¡®ä¿æœ€ä½åˆ†æ•°ï¼Œè®©æ‰€æœ‰åŒ¹é…çš„å›¾ç‰‡éƒ½èƒ½è¿”å›
                score = max(score, 0.1)  # è®¾ç½®æœ€ä½åˆ†æ•°ä¸º0.1
            
            scored_images.append((doc, score))
            self.logger.debug(f"å›¾ç‰‡ {doc.metadata.get('doc_id', 'unknown')} åˆ†æ•°: {score}")
        
        # æŒ‰åˆ†æ•°æ’åº
        scored_images.sort(key=lambda x: x[1], reverse=True)
        
        # æ„å»ºç»“æœ
        results = []
        for doc, score in scored_images:
            # å¯¹äºå›¾å·æŸ¥è¯¢ï¼Œè¿”å›æ‰€æœ‰åŒ¹é…çš„å›¾ç‰‡
            if intent.get('figure_numbers') or score > 0:
                # æ„å»ºcontentå­—æ®µï¼Œä¼˜å…ˆçº§ï¼šå¢å¼ºæè¿° > å›¾ç‰‡æ ‡é¢˜ > å›¾ç‰‡ID
                enhanced_desc = doc.metadata.get('enhanced_description', '')
                caption = doc.metadata.get('img_caption', '')
                content = enhanced_desc or caption or f"å›¾ç‰‡ID: {doc.metadata.get('doc_id', 'unknown')}"
                
                results.append({
                    'doc_id': doc.metadata.get('doc_id', 'unknown'),
                    'image_path': doc.metadata.get('image_path', ''),
                    'enhanced_description': enhanced_desc,
                    'caption': caption,
                    'title': doc.metadata.get('image_title', ''),
                    'content': content,
                    'score': score,
                    'match_type': 'content_precise_match',
                    'document_name': doc.metadata.get('document_name', 'æœªçŸ¥æ–‡æ¡£'),
                    'page_number': doc.metadata.get('page_number', 'N/A')
                })
        
        self.logger.info(f"å†…å®¹ç²¾ç¡®åŒ¹é…ç»“æœ: {len(results)} å¼ å›¾ç‰‡")
        return results

    def _extract_content_query(self, query: str) -> str:
        """
        æå–å†…å®¹æŸ¥è¯¢éƒ¨åˆ†ï¼Œæ’é™¤å›¾å·
        
        :param query: åŸå§‹æŸ¥è¯¢
        :return: å†…å®¹æŸ¥è¯¢éƒ¨åˆ†
        """
        import re
        # ç§»é™¤"å›¾Xï¼š"éƒ¨åˆ†ï¼Œä¿ç•™åé¢çš„å†…å®¹
        content_query = re.sub(r'å›¾\d+[ï¼š:]\s*', '', query)
        return content_query.strip()

    def _calculate_content_similarity(self, query: str, doc: Any, content_keywords: List[str]) -> float:
        """
        è®¡ç®—å†…å®¹ç›¸ä¼¼åº¦åˆ†æ•°
        
        :param query: æŸ¥è¯¢æ–‡æœ¬
        :param doc: æ–‡æ¡£å¯¹è±¡
        :param content_keywords: å†…å®¹å…³é”®è¯
        :return: ç›¸ä¼¼åº¦åˆ†æ•° (0-1)
        """
        score = 0.0
        
        # è·å–å›¾ç‰‡å…ƒæ•°æ®
        caption = doc.metadata.get('img_caption', '')
        title = doc.metadata.get('image_title', '')
        description = doc.metadata.get('enhanced_description', '')
        
        self.logger.debug(f"è®¡ç®—ç›¸ä¼¼åº¦ - caption: {caption}, title: {title}, description: {description[:50] if description else 'N/A'}")
        
        # æ ‡é¢˜åŒ¹é…åˆ†æ•°ï¼ˆæƒé‡æœ€é«˜ï¼‰
        if title and title != 'N/A' and title != 'æ— æ ‡é¢˜':
            title_score = self._calculate_text_similarity(query, title)
            score += title_score * 0.5  # æ ‡é¢˜æƒé‡50%
            self.logger.debug(f"æ ‡é¢˜åŒ¹é…åˆ†æ•°: {title_score} * 0.5 = {title_score * 0.5}")
        
        # æè¿°åŒ¹é…åˆ†æ•°
        if description:
            desc_score = self._calculate_text_similarity(query, description)
            score += desc_score * 0.3  # æè¿°æƒé‡30%
            self.logger.debug(f"æè¿°åŒ¹é…åˆ†æ•°: {desc_score} * 0.3 = {desc_score * 0.3}")
        
        # æ ‡é¢˜åŒ¹é…åˆ†æ•°
        if caption:
            caption_score = self._calculate_text_similarity(query, caption)
            score += caption_score * 0.2  # æ ‡é¢˜æƒé‡20%
            self.logger.debug(f"æ ‡é¢˜åŒ¹é…åˆ†æ•°: {caption_score} * 0.2 = {caption_score * 0.2}")
        
        # å…³é”®è¯åŒ¹é…åŠ åˆ†
        if content_keywords:
            keyword_score = self._calculate_keyword_match(doc, content_keywords)
            score += keyword_score * 0.1  # å…³é”®è¯æƒé‡10%
            self.logger.debug(f"å…³é”®è¯åŒ¹é…åˆ†æ•°: {keyword_score} * 0.1 = {keyword_score * 0.1}")
        
        final_score = min(score, 1.0)
        self.logger.debug(f"æœ€ç»ˆç›¸ä¼¼åº¦åˆ†æ•°: {final_score}")
        return final_score

    def _general_content_search(self, query: str, intent: Dict[str, Any]) -> List[Any]:
        """
        ä¸€èˆ¬å†…å®¹æœç´¢ï¼ˆç”¨æˆ·æ²¡æœ‰æåˆ°å›¾å·ï¼‰
        
        :param query: æŸ¥è¯¢æ–‡æœ¬
        :param intent: æŸ¥è¯¢æ„å›¾
        :return: æœç´¢ç»“æœåˆ—è¡¨
        """
        results = []
        
        # å…³é”®è¯åŒ¹é…
        if intent['keywords']:
            for doc_id, doc in self.image_docs.items():
                try:
                    score = self._calculate_image_score(doc, query, intent)
                    # é™ä½é˜ˆå€¼ï¼Œç¡®ä¿æ›´å¤šå›¾ç‰‡èƒ½è¢«åŒ¹é…åˆ°
                    if score >= 0.05:  # ä½¿ç”¨æ›´ä½çš„é˜ˆå€¼
                        # æ„å»ºcontentå­—æ®µ
                        enhanced_desc = doc.metadata.get('enhanced_description', '')
                        caption = doc.metadata.get('img_caption', '')
                        content = enhanced_desc or caption or f"å›¾ç‰‡ID: {doc_id}"
                        
                        results.append({
                            'doc_id': doc_id,
                            'image_path': doc.metadata.get('image_path', ''),
                            'enhanced_description': enhanced_desc,
                            'caption': caption,
                            'title': doc.metadata.get('image_title', ''),
                            'content': content,
                            'score': score,
                            'match_type': 'keyword_match',
                            'document_name': doc.metadata.get('document_name', 'æœªçŸ¥æ–‡æ¡£'),
                            'page_number': doc.metadata.get('page_number', 'N/A')
                        })
                        
                        self.logger.debug(f"å›¾ç‰‡ {doc_id} åŒ¹é…æˆåŠŸï¼Œåˆ†æ•°: {score}, æ ‡é¢˜: {caption}")
                except Exception as e:
                    self.logger.warning(f"è®¡ç®—å›¾ç‰‡åˆ†æ•°å¤±è´¥ {doc_id}: {e}")
                    continue
        
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ç»“æœï¼Œå°è¯•æ¨¡ç³ŠåŒ¹é…
        if not results and self.config.enable_fuzzy_match:
            fuzzy_results = self._fuzzy_image_search(query, intent)
            # è¡¥å……å­—æ®µ
            for item in fuzzy_results:
                doc = item.get('doc')
                if doc:
                    enhanced_desc = doc.metadata.get('enhanced_description', '')
                    caption = doc.metadata.get('img_caption', '')
                    content = enhanced_desc or caption or f"å›¾ç‰‡ID: {item.get('doc_id', 'unknown')}"
                    
                    item['image_path'] = doc.metadata.get('image_path', '')
                    item['enhanced_description'] = enhanced_desc
                    item['caption'] = caption
                    item['title'] = doc.metadata.get('image_title', '')
                    item['content'] = content
                    item['document_name'] = doc.metadata.get('document_name', 'æœªçŸ¥æ–‡æ¡£')
                    item['page_number'] = doc.metadata.get('page_number', 'N/A')
            results = fuzzy_results
        
        return results

    def _adjust_result_count(self, intent: Dict[str, Any]) -> int:
        """
        æ ¹æ®æŸ¥è¯¢æ„å›¾è°ƒæ•´ç»“æœæ•°é‡
        
        :param intent: æŸ¥è¯¢æ„å›¾
        :return: ç»“æœæ•°é‡
        """
        # å¦‚æœç”¨æˆ·è¦æ±‚æ˜¾ç¤ºæ‰€æœ‰ï¼Œè¿”å›ä¸€ä¸ªå¾ˆå¤§çš„æ•°å­—
        if intent.get('show_all'):
            self.logger.info("ç”¨æˆ·è¦æ±‚æ˜¾ç¤ºæ‰€æœ‰å›¾ç‰‡ï¼Œè¿”å›æœ€å¤§æ•°é‡")
            return 999  # æˆ–è€…ä½¿ç”¨ len(self.image_docs) è·å–å®é™…å›¾ç‰‡æ€»æ•°
        
        # å¦‚æœç”¨æˆ·æ˜ç¡®è¦æ±‚äº†æ•°é‡ï¼Œä¼˜å…ˆä½¿ç”¨ç”¨æˆ·çš„è¦æ±‚
        if intent.get('requested_count'):
            self.logger.info(f"ç”¨æˆ·è¦æ±‚æ˜¾ç¤º {intent['requested_count']} å¼ å›¾ç‰‡")
            return intent['requested_count']
        
        # å¦åˆ™ä½¿ç”¨é»˜è®¤é€»è¾‘
        if intent['type'] == 'very_specific':
            return 10  # éå¸¸å…·ä½“çš„æŸ¥è¯¢ï¼ˆåŒ…å«å›¾å·ï¼‰ï¼Œè¿”å›æœ€å¤š10ä¸ªç»“æœï¼Œç¡®ä¿èƒ½çœ‹åˆ°æ‰€æœ‰å›¾å·
        elif intent['type'] == 'specific':
            return 5  # å…·ä½“æŸ¥è¯¢ï¼Œè¿”å›5ä¸ªç»“æœ
        else:
            return 3  # ä¸€èˆ¬æŸ¥è¯¢ï¼Œè¿”å›3ä¸ªç»“æœ
    
    def _calculate_image_score(self, doc: Any, query: str, intent: Dict[str, Any]) -> float:
        """
        è®¡ç®—å›¾ç‰‡åŒ¹é…åˆ†æ•°
        
        :param doc: æ–‡æ¡£å¯¹è±¡
        :param query: æŸ¥è¯¢æ–‡æœ¬
        :param intent: æŸ¥è¯¢æ„å›¾
        :return: åŒ¹é…åˆ†æ•° (0-1)
        """
        score = 0.0
        
        # è·å–å›¾ç‰‡å…ƒæ•°æ®ï¼Œç¡®ä¿ç±»å‹å®‰å…¨
        caption = doc.metadata.get('img_caption', '')
        title = doc.metadata.get('image_title', '')
        description = doc.metadata.get('enhanced_description', '')
        content = doc.metadata.get('content', '')
        
        # æ ‡é¢˜åŒ¹é…åˆ†æ•°
        if title and title != 'æ— æ ‡é¢˜':
            title_score = self._calculate_text_similarity(query, title)
            score += title_score * self.config.caption_weight
        
        # æ ‡é¢˜åŒ¹é…åˆ†æ•°
        if caption:
            caption_score = self._calculate_text_similarity(query, caption)
            score += caption_score * self.config.caption_weight
        
        # æè¿°åŒ¹é…åˆ†æ•°
        if description:
            desc_score = self._calculate_text_similarity(query, description)
            score += desc_score * self.config.description_weight
        
        # å†…å®¹åŒ¹é…åˆ†æ•°
        if content:
            content_score = self._calculate_text_similarity(query, content)
            score += content_score * self.config.description_weight
        
        # å…³é”®è¯åŒ¹é…åˆ†æ•°
        if intent['keywords']:
            keyword_score = self._calculate_keyword_match(doc, intent['keywords'])
            score += keyword_score * self.config.keyword_weight
        
        return min(score, 1.0)
    
    def _calculate_text_similarity(self, query: str, text: str) -> float:
        """è®¡ç®—æ–‡æœ¬ç›¸ä¼¼åº¦"""
        if not text or not query:
            return 0.0
        
        # ç¡®ä¿textæ˜¯å­—ç¬¦ä¸²ç±»å‹
        if isinstance(text, list):
            text = ' '.join([str(item) for item in text])
        elif not isinstance(text, str):
            text = str(text)
        
        self.logger.debug(f"è®¡ç®—æ–‡æœ¬ç›¸ä¼¼åº¦ - query: '{query}', text: '{text}'")
        
        # æ”¹è¿›çš„ç›¸ä¼¼åº¦è®¡ç®—ï¼šç»“åˆè¯æ±‡é‡å å’Œè¯­ä¹‰åŒ¹é…
        query_words = set(query.lower().split())
        text_words = set(text.lower().split())
        
        if not query_words or not text_words:
            self.logger.debug(f"è¯æ±‡ä¸ºç©º - query_words: {query_words}, text_words: {text_words}")
            return 0.0
        
        # 1. è¯æ±‡é‡å åˆ†æ•°
        intersection = query_words.intersection(text_words)
        union = query_words.union(text_words)
        
        if union:
            overlap_similarity = len(intersection) / len(union)
        else:
            overlap_similarity = 0.0
        
        # 2. å…³é”®è¯å¯†åº¦åˆ†æ•°
        matched_keywords = 0
        for keyword in query_words:
            if keyword in text.lower():
                matched_keywords += 1
        
        keyword_density = matched_keywords / len(query_words) if query_words else 0.0
        
        # 3. é•¿åº¦åŒ¹é…åˆ†æ•°ï¼ˆçŸ­æŸ¥è¯¢åŒ¹é…é•¿æ–‡æœ¬æ—¶ç»™äºˆåŠ åˆ†ï¼‰
        length_ratio = min(len(query) / max(len(text), 1), 1.0)
        length_score = 1.0 - abs(0.5 - length_ratio) * 0.5  # 0.5æ—¶æœ€é«˜åˆ†
        
        # 4. ç»¼åˆåˆ†æ•°
        final_similarity = (
            overlap_similarity * 0.4 +      # è¯æ±‡é‡å æƒé‡40%
            keyword_density * 0.4 +         # å…³é”®è¯å¯†åº¦æƒé‡40%
            length_score * 0.2              # é•¿åº¦åŒ¹é…æƒé‡20%
        )
        
        # ç¡®ä¿åˆ†æ•°åœ¨åˆç†èŒƒå›´å†…ï¼Œé¿å…è¿‡ä½
        final_similarity = max(final_similarity, 0.1)  # æœ€ä½åˆ†æ•°0.1
        
        self.logger.debug(f"ç›¸ä¼¼åº¦è®¡ç®— - é‡å : {overlap_similarity:.3f}, å¯†åº¦: {keyword_density:.3f}, é•¿åº¦: {length_score:.3f}, æœ€ç»ˆ: {final_similarity:.3f}")
        return final_similarity
    
    def _calculate_keyword_match(self, doc: Any, keywords: List[str]) -> float:
        """è®¡ç®—å…³é”®è¯åŒ¹é…åˆ†æ•°"""
        if not keywords:
            return 0.0
        
        # è·å–æ‰€æœ‰æ–‡æœ¬å­—æ®µï¼Œç¡®ä¿ç±»å‹å®‰å…¨
        text_fields = []
        
        # å®‰å…¨è·å–å…ƒæ•°æ®å­—æ®µ
        caption = doc.metadata.get('img_caption', '')
        if isinstance(caption, list):
            caption = ' '.join([str(item) for item in caption])
        elif not isinstance(caption, str):
            caption = str(caption) if caption else ''
        text_fields.append(caption)
        
        title = doc.metadata.get('image_title', '')
        if isinstance(title, list):
            title = ' '.join([str(item) for item in title])
        elif not isinstance(title, str):
            title = str(title) if title else ''
        text_fields.append(title)
        
        description = doc.metadata.get('enhanced_description', '')
        if isinstance(description, list):
            description = ' '.join([str(item) for item in description])
        elif not isinstance(description, str):
            description = str(description) if description else ''
        text_fields.append(description)
        
        # æ·»åŠ å…¶ä»–å¯èƒ½çš„æ–‡æœ¬å­—æ®µ
        content = doc.metadata.get('content', '')
        if isinstance(content, list):
            content = ' '.join([str(item) for item in content])
        elif not isinstance(content, str):
            content = str(content) if content else ''
        text_fields.append(content)
        
        total_score = 0.0
        for keyword in keywords:
            for field in text_fields:
                if field and keyword in field:
                    total_score += 1.0
                    break
        
        return min(total_score / len(keywords), 1.0)
    
    def _fuzzy_image_search(self, query: str, intent: Dict[str, Any]) -> List[Any]:
        """æ¨¡ç³Šå›¾ç‰‡æœç´¢"""
        results = []
        
        # ä½¿ç”¨å‘é‡ç›¸ä¼¼åº¦æœç´¢
        if hasattr(self.vector_store, 'similarity_search'):
            try:
                # æœç´¢ç›¸ä¼¼æ–‡æ¡£
                similar_docs = self.vector_store.similarity_search(
                    query, 
                    k=min(10, self.config.max_results)
                )
                
                # è¿‡æ»¤å‡ºå›¾ç‰‡æ–‡æ¡£
                for doc in similar_docs:
                    if doc.metadata.get('chunk_type') == 'image':
                        results.append({
                            'doc_id': doc.metadata.get('doc_id', 'unknown'),
                            'doc': doc,
                            'score': 0.5,  # æ¨¡ç³ŠåŒ¹é…çš„é»˜è®¤åˆ†æ•°
                            'match_type': 'fuzzy_search'
                        })
            except Exception as e:
                self.logger.warning(f"æ¨¡ç³Šæœç´¢å¤±è´¥: {e}")
        
        return results
    
    def _rank_image_results(self, results: List[Any], query: str, intent: Dict[str, Any]) -> List[Any]:
        """
        å¯¹å›¾ç‰‡ç»“æœè¿›è¡Œæ™ºèƒ½æ’åº
        
        :param results: æœç´¢ç»“æœ
        :param query: æŸ¥è¯¢æ–‡æœ¬
        :param intent: æŸ¥è¯¢æ„å›¾
        :return: æ’åºåçš„ç»“æœ
        """
        if not results:
            return []
        
        # æŒ‰åˆ†æ•°æ’åº
        sorted_results = sorted(results, key=lambda x: x['score'], reverse=True)
        
        # é™åˆ¶ç»“æœæ•°é‡
        return sorted_results[:self.config.max_results]
    
    def get_image_by_id(self, image_id: str) -> Optional[Any]:
        """æ ¹æ®IDè·å–å›¾ç‰‡"""
        return self.image_docs.get(image_id)
    
    def get_all_images(self) -> List[Any]:
        """è·å–æ‰€æœ‰å›¾ç‰‡"""
        return list(self.image_docs.values())
    
    def refresh_image_cache(self):
        """åˆ·æ–°å›¾ç‰‡ç¼“å­˜"""
        self._load_image_documents()
        self.logger.info("å›¾ç‰‡ç¼“å­˜å·²åˆ·æ–°")
    
    def get_image_statistics(self) -> Dict[str, Any]:
        """è·å–å›¾ç‰‡ç»Ÿè®¡ä¿¡æ¯"""
        return {
            'total_images': len(self.image_docs),
            'with_caption': len([d for d in self.image_docs.values() 
                               if d.metadata.get('img_caption')]),
            'with_title': len([d for d in self.image_docs.values() 
                             if d.metadata.get('image_title') and d.metadata.get('image_title') != 'æ— æ ‡é¢˜']),
            'with_description': len([d for d in self.image_docs.values() 
                                   if d.metadata.get('enhanced_description')])
        }
