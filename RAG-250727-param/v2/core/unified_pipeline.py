'''
ç¨‹åºè¯´æ˜ï¼š
## 1. ç»Ÿä¸€Pipelineæ¨¡å— - åŸºäºè€çš„æˆç†Ÿå®ç°
## 2. ä¸“é—¨ä¸ºTextEngineæœåŠ¡ï¼Œå…¶ä»–å¼•æ“ç»§ç»­ä½¿ç”¨è€Pipeline
## 3. ç®€åŒ–æµç¨‹ï¼šåªä¿ç•™LLMç”Ÿæˆå’Œæºè¿‡æ»¤
## 4. é€‚é…TextEngineçš„è¾“å‡ºæ ¼å¼
## 5. é‡æ„å­—æ®µæå–é€»è¾‘ï¼Œä½¿ç”¨æ˜ç¡®çš„å­—æ®µæ˜ å°„å…³ç³»

## ä¸»è¦åŠŸèƒ½ï¼š
- LLMç”Ÿæˆç­”æ¡ˆï¼šåŸºäºé‡æ’åºåçš„æ–‡æ¡£ç”Ÿæˆç­”æ¡ˆ
- æºè¿‡æ»¤ï¼šåŸºäºLLMç­”æ¡ˆå†…å®¹è¿‡æ»¤æœ€ç»ˆæº
- æ˜ç¡®çš„å­—æ®µæ˜ å°„ï¼šé¿å…çŒœæµ‹å¼å­—æ®µæå–
- ä¿æŒè€çš„æˆç†Ÿé€»è¾‘ï¼Œç¡®ä¿åŠŸèƒ½ç¨³å®š
'''

import logging
import time
from typing import List, Dict, Any, Optional
from dataclasses import dataclass

# æ˜ç¡®çš„å­—æ®µæ˜ å°„è¡¨
FIELD_MAPPING = {
    # é€šç”¨å­—æ®µ
    'document_name': 'document_name',      # æ–‡æ¡£åç§°
    'page_number': 'page_number',          # é¡µç 
    'chunk_type': 'chunk_type',            # å†…å®¹ç±»å‹
    
    # å›¾ç‰‡å­—æ®µ
    'caption': 'img_caption',              # å›¾ç‰‡æ ‡é¢˜ï¼ˆä»img_captionè·å–ï¼‰
    'footnote': 'img_footnote',            # å›¾ç‰‡è„šæ³¨ï¼ˆä»img_footnoteè·å–ï¼‰
    'enhanced_description': 'enhanced_description',  # å¢å¼ºæè¿°
    'image_id': 'image_id',                # å›¾ç‰‡ID
    'image_path': 'image_path',            # å›¾ç‰‡è·¯å¾„
    'image_filename': 'image_filename',    # å›¾ç‰‡æ–‡ä»¶å
    'image_type': 'image_type',            # å›¾ç‰‡ç±»å‹
    'extension': 'extension',              # æ–‡ä»¶æ‰©å±•å
    
    # è¡¨æ ¼å­—æ®µ
    'table_id': 'table_id',                # è¡¨æ ¼ID
    'table_type': 'table_type',            # è¡¨æ ¼ç±»å‹
    'table_title': 'table_title',          # è¡¨æ ¼æ ‡é¢˜
    'table_summary': 'table_summary',      # è¡¨æ ¼æ‘˜è¦
    'table_headers': 'table_headers',      # è¡¨æ ¼è¡¨å¤´
    'table_row_count': 'table_row_count',  # è¡¨æ ¼è¡Œæ•°
    'table_column_count': 'table_column_count',  # è¡¨æ ¼åˆ—æ•°
    'html_content': 'page_content',        # HTMLæ ¼å¼å†…å®¹
    'processed_content': 'processed_table_content',  # è¯­ä¹‰åŒ–å†…å®¹
    
    # æ–‡æœ¬å­—æ®µ
    'content': 'page_content',             # æ–‡æœ¬å†…å®¹
    'content_preview': 'page_content',     # å†…å®¹é¢„è§ˆ
    'chunk_index': 'chunk_index'           # åˆ†å—ç´¢å¼•
}

@dataclass
class UnifiedPipelineResult:
    """ç»Ÿä¸€Pipelineç»“æœ"""
    llm_answer: str
    filtered_sources: List[Dict[str, Any]]
    pipeline_metrics: Dict[str, Any]
    success: bool
    error_message: str = ""

class UnifiedPipeline:
    """ç»Ÿä¸€Pipeline - ä¸“é—¨ä¸ºTextEngineæœåŠ¡ï¼Œåªä¿ç•™LLMç”Ÿæˆå’Œæºè¿‡æ»¤"""
    
    def __init__(self, config: Dict[str, Any], llm_engine, source_filter_engine):
        """
        åˆå§‹åŒ–ç»Ÿä¸€Pipeline
        
        :param config: Pipelineé…ç½®
        :param llm_engine: LLMå¼•æ“
        :param source_filter_engine: æºè¿‡æ»¤å¼•æ“
        """
        self.config = config
        self.llm_engine = llm_engine
        self.source_filter_engine = source_filter_engine
        
        self.logger = logging.getLogger(__name__)
        self.logger.info("ç»Ÿä¸€Pipelineåˆå§‹åŒ–å®Œæˆ")
        
        # é…ç½®å‚æ•°
        self.enable_llm_generation = config.get('enable_llm_generation', True)
        self.enable_source_filtering = config.get('enable_source_filtering', True)
        self.max_context_results = config.get('max_context_results', 10)  # æ”¹è¿›ï¼šä»5å¢åŠ åˆ°10
        self.max_content_length = config.get('max_content_length', 1000)  # æ”¹è¿›ï¼šä»500å¢åŠ åˆ°1000
        
        # å­—æ®µæ˜ å°„é…ç½®
        self.field_mapping = FIELD_MAPPING
    
    def process(self, query: str, reranked_results: List[Dict[str, Any]], query_type: str = None, **kwargs) -> Dict[str, Any]:
        """
        æ‰§è¡Œç»Ÿä¸€çš„Pipelineæµç¨‹ - è¾“å‡ºå‰ç«¯æœŸæœ›çš„å®Œæ•´æ ¼å¼
        
        :param query: æŸ¥è¯¢æ–‡æœ¬
        :param reranked_results: é‡æ’åºåçš„ç»“æœï¼ˆæ¥è‡ªTextEngineï¼‰
        :param query_type: æŸ¥è¯¢ç±»å‹ï¼ˆtext/image/table/hybrid/smartï¼‰
        :param kwargs: å…¶ä»–å‚æ•°
        :return: å‰ç«¯æœŸæœ›çš„å®Œæ•´å­—å…¸æ ¼å¼
        """
        start_time = time.time()
        pipeline_metrics = {}
        
        try:
            self.logger.info(f"å¼€å§‹ç»Ÿä¸€Pipelineå¤„ç†ï¼Œè¾“å…¥ç»“æœæ•°é‡: {len(reranked_results)}")
            if query_type:
                self.logger.info(f"æŸ¥è¯¢ç±»å‹: {query_type}")
            
            # 1. LLMç”Ÿæˆç­”æ¡ˆï¼ˆå¦‚æœå¯ç”¨ï¼‰
            llm_answer = ""
            if self.enable_llm_generation and self.llm_engine:
                llm_start = time.time()
                llm_answer = self._generate_llm_answer(query, reranked_results)
                llm_time = time.time() - llm_start
                pipeline_metrics['llm_time'] = llm_time
                pipeline_metrics['llm_answer_length'] = len(llm_answer)
                self.logger.info(f"LLMç­”æ¡ˆç”Ÿæˆå®Œæˆï¼Œè€—æ—¶: {llm_time:.2f}ç§’")
            else:
                self.logger.warning("LLMç”Ÿæˆæœªå¯ç”¨æˆ–å¼•æ“ä¸å¯ç”¨")
                llm_answer = "æŠ±æ­‰ï¼ŒLLMç”ŸæˆåŠŸèƒ½å½“å‰ä¸å¯ç”¨ã€‚"
            
            # 2. æºè¿‡æ»¤ï¼ˆå¦‚æœå¯ç”¨ï¼‰
            filtered_sources = reranked_results
            if self.enable_source_filtering and self.source_filter_engine and llm_answer:
                source_filter_start = time.time()
                self.logger.info(f"å¼€å§‹æºè¿‡æ»¤ï¼Œè¾“å…¥ç»“æœæ•°é‡: {len(reranked_results)}")
                filtered_sources = self._filter_sources(llm_answer, reranked_results, query, query_type)
                source_filter_time = time.time() - source_filter_start
                pipeline_metrics['source_filter_time'] = source_filter_time
                pipeline_metrics['source_filter_count'] = len(filtered_sources)
                self.logger.info(f"æºè¿‡æ»¤å®Œæˆï¼Œè€—æ—¶: {source_filter_time:.2f}ç§’ï¼Œè¿‡æ»¤åæ•°é‡: {len(filtered_sources)}")
            else:
                self.logger.warning("æºè¿‡æ»¤æœªå¯ç”¨æˆ–å¼•æ“ä¸å¯ç”¨ï¼Œä½¿ç”¨åŸå§‹ç»“æœ")
                filtered_sources = reranked_results
            
            # è®¡ç®—æ€»è€—æ—¶
            total_time = time.time() - start_time
            pipeline_metrics['total_time'] = total_time
            
            # 3. æå–æ¥æºä¿¡æ¯ï¼ˆé‡æ„åçš„æ–¹æ³•ï¼‰
            extracted_sources = self._extract_sources(filtered_sources)
            
            # 4. æ„å»ºUnifiedPipelineResultå¯¹è±¡
            self.logger.info(f"ç»Ÿä¸€Pipelineå¤„ç†å®Œæˆï¼Œæ€»è€—æ—¶: {total_time:.2f}ç§’")
            self.logger.info(f"LLMç­”æ¡ˆé•¿åº¦: {len(llm_answer)}, è¿‡æ»¤åæºæ•°é‡: {len(filtered_sources)}")
            
            return UnifiedPipelineResult(
                llm_answer=llm_answer,
                filtered_sources=filtered_sources,
                pipeline_metrics=pipeline_metrics,
                success=True
            )
            
        except Exception as e:
            error_msg = f"ç»Ÿä¸€Pipelineå¤„ç†å¤±è´¥: {str(e)}"
            self.logger.error(error_msg)
            return UnifiedPipelineResult(
                llm_answer='æŠ±æ­‰ï¼Œå¤„ç†è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯ã€‚',
                filtered_sources=[],
                pipeline_metrics={'error': error_msg, 'processing_time': time.time() - start_time},
                success=False,
                error_message=error_msg
            )
    
    def _extract_sources(self, retrieved_docs: List[Any]) -> List[Dict[str, Any]]:
        """
        æå–æ¥æºä¿¡æ¯ - æ™ºèƒ½å¤„ç†ä¸‰ç§ä¸åŒå¼•æ“çš„è¾“å‡ºæ ¼å¼
        
        :param retrieved_docs: æ£€ç´¢åˆ°çš„æ–‡æ¡£åˆ—è¡¨
        :return: æå–çš„æºä¿¡æ¯åˆ—è¡¨
        """
        sources = []
        
        for doc in retrieved_docs:
            # è·³è¿‡æ— æ•ˆçš„æ–‡æ¡£
            if not doc:
                self.logger.warning("è·³è¿‡ç©ºæ–‡æ¡£")
                continue
            
            # æ™ºèƒ½è¯†åˆ«å¹¶å¤„ç†ä¸‰ç§ä¸åŒçš„æ•°æ®æ ¼å¼
            doc_metadata = self._extract_metadata_from_doc(doc)
            if not doc_metadata:
                continue
            
            # æ„å»ºç»Ÿä¸€çš„æºä¿¡æ¯
            source_info = self._build_unified_source_info(doc, doc_metadata)
            if source_info:
                sources.append(source_info)
                self.logger.debug(f"æ·»åŠ æœ‰æ•ˆæºä¿¡æ¯: {source_info.get('document_name', 'N/A')} - {source_info.get('chunk_type', 'N/A')}")
        
        self.logger.info(f"æºä¿¡æ¯æå–å®Œæˆï¼Œæœ‰æ•ˆæºæ•°é‡: {len(sources)}")
        return sources
    
    def _extract_metadata_from_doc(self, doc: Any) -> Optional[Dict[str, Any]]:
        """
        ä»æ–‡æ¡£å¯¹è±¡ä¸­æå–metadata - æ™ºèƒ½è¯†åˆ«ä¸åŒå¼•æ“çš„è¾“å‡ºæ ¼å¼
        
        :param doc: æ–‡æ¡£å¯¹è±¡
        :return: æå–çš„metadataå­—å…¸ï¼Œå¦‚æœå¤±è´¥è¿”å›None
        """
        try:
            # æ ¼å¼1ï¼šTableEngineæ ¼å¼ - å¤„ç†åçš„å­—æ®µ
            # æ£€æŸ¥æ˜¯å¦åŒ…å«è¡¨æ ¼ç›¸å…³å­—æ®µï¼Œè¿™äº›å­—æ®µæ˜ç¡®è¡¨ç¤ºè¿™æ˜¯TableEngineçš„ç»“æœ
            if isinstance(doc, dict) and any(key in doc for key in ['chunk_type', 'table_id', 'table_type', 'html_content']):
                self.logger.debug("æ£€æµ‹åˆ°TableEngineæ ¼å¼ï¼ˆå¤„ç†åå­—æ®µï¼‰")
                
                # ä¼˜å…ˆä½¿ç”¨metadataå­—æ®µ
                if 'metadata' in doc and doc['metadata']:
                    self.logger.debug("TableEngineæ ¼å¼ï¼šä½¿ç”¨metadataå­—æ®µ")
                    return doc['metadata']
                
                # å¦‚æœæ²¡æœ‰metadataå­—æ®µï¼Œä»docæœ¬èº«æ„å»ºmetadata
                metadata = {}
                # æå–é€šç”¨å­—æ®µ
                for key in ['document_name', 'page_number', 'chunk_type', 'table_type', 'doc_id']:
                    if key in doc and doc[key]:
                        metadata[key] = doc[key]
                
                # æå–è¡¨æ ¼ç‰¹å®šå­—æ®µ
                for key in ['table_id', 'table_title', 'html_content', 'content', 'page_content']:
                    if key in doc and doc[key]:
                        metadata[key] = doc[key]
                
                # å¦‚æœæ„å»ºçš„metadataä¸ä¸ºç©ºï¼Œè¿”å›
                if metadata:
                    self.logger.debug(f"TableEngineæ ¼å¼ï¼šæ„å»ºmetadataæˆåŠŸï¼ŒåŒ…å«å­—æ®µ: {list(metadata.keys())}")
                    return metadata
                else:
                    self.logger.warning("TableEngineæ ¼å¼æ— æ³•æå–æœ‰æ•ˆmetadata")
                    return None
            
            # æ ¼å¼2ï¼šTextEngineæ ¼å¼ - åŒ…å« 'doc' é”®ï¼Œä½†ä¸åŒ…å«è¡¨æ ¼ç›¸å…³å­—æ®µ
            elif isinstance(doc, dict) and 'doc' in doc and not any(key in doc for key in ['chunk_type', 'table_id', 'table_type', 'html_content']):
                self.logger.debug("æ£€æµ‹åˆ°TextEngineæ ¼å¼ï¼ˆåŒ…å«docé”®ï¼Œä¸”ä¸åŒ…å«è¡¨æ ¼å­—æ®µï¼‰")
                nested_doc = doc['doc']
                
                # å¤„ç†åµŒå¥—çš„docé”®ç»“æ„
                if isinstance(nested_doc, dict) and 'doc' in nested_doc:
                    # å¦‚æœnested_docæœ¬èº«ä¹ŸåŒ…å«docé”®ï¼Œç»§ç»­æ·±å…¥
                    actual_doc = nested_doc['doc']
                    if hasattr(actual_doc, 'metadata') and actual_doc.metadata:
                        self.logger.debug("æ£€æµ‹åˆ°åµŒå¥—TextEngineæ ¼å¼ï¼ŒæˆåŠŸæå–metadata")
                        return actual_doc.metadata
                    else:
                        self.logger.warning("åµŒå¥—TextEngineæ ¼å¼ä¸­doc.doc.metadataä¸ºç©º")
                        return None
                else:
                    # ç›´æ¥å¤„ç†nested_doc
                    if hasattr(nested_doc, 'metadata') and nested_doc.metadata:
                        return nested_doc.metadata
                    else:
                        self.logger.warning("TextEngineæ ¼å¼ä¸­doc.metadataä¸ºç©º")
                        return None
            
            # æ ¼å¼3ï¼šImageEngineæ ¼å¼ - ç›´æ¥å±•å¼€çš„å­—æ®µ
            elif isinstance(doc, dict) and 'document_name' in doc:
                self.logger.debug("æ£€æµ‹åˆ°ImageEngineæ ¼å¼ï¼ˆç›´æ¥å±•å¼€å­—æ®µï¼‰")
                # å°†æ•´ä¸ªdocä½œä¸ºmetadataå¤„ç†
                return doc
            
            # æ ¼å¼4ï¼šæ ‡å‡†Documentå¯¹è±¡
            elif hasattr(doc, 'metadata') and doc.metadata:
                self.logger.debug("æ£€æµ‹åˆ°æ ‡å‡†Documentå¯¹è±¡æ ¼å¼")
                return doc.metadata
            
            # æ ¼å¼5ï¼šçº¯å­—å…¸æ ¼å¼ï¼ˆå¯èƒ½æ˜¯å…¶ä»–å¼•æ“çš„å˜ä½“ï¼‰
            elif isinstance(doc, dict):
                self.logger.debug("æ£€æµ‹åˆ°çº¯å­—å…¸æ ¼å¼")
                # æ£€æŸ¥æ˜¯å¦åŒ…å«å¿…è¦çš„å­—æ®µ
                if any(key in doc for key in ['document_name', 'chunk_type', 'page_content', 'content']):
                    return doc
                else:
                    self.logger.warning("çº¯å­—å…¸æ ¼å¼ç¼ºå°‘å¿…è¦å­—æ®µ")
                    return None
            
            else:
                self.logger.warning(f"æ— æ³•è¯†åˆ«çš„æ–‡æ¡£æ ¼å¼: {type(doc)}")
                return None
                
        except Exception as e:
            self.logger.error(f"æå–metadataæ—¶å‡ºé”™: {e}")
            return None
    
    def _build_unified_source_info(self, doc: Any, doc_metadata: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """
        æ„å»ºç»Ÿä¸€çš„æºä¿¡æ¯ - è¾“å‡ºå‰ç«¯æœŸæœ›çš„sourcesæ ¼å¼
        
        :param doc: åŸå§‹æ–‡æ¡£å¯¹è±¡
        :param doc_metadata: æå–çš„metadata
        :return: ç»Ÿä¸€çš„æºä¿¡æ¯å­—å…¸ï¼Œå¦‚æœå¤±è´¥è¿”å›None
        """
        try:
            # æ„å»ºå‰ç«¯æœŸæœ›çš„sourcesæ ¼å¼
            source_info = {
                'title': f"{doc_metadata.get('document_name', 'æœªçŸ¥æ–‡æ¡£')} - ç¬¬{doc_metadata.get('page_number', 'æœªçŸ¥é¡µ')}é¡µ",
                'document_name': doc_metadata.get('document_name', 'æœªçŸ¥æ–‡æ¡£'),
                'page_number': doc_metadata.get('page_number', 'æœªçŸ¥é¡µ'),
                'source_type': self._convert_chunk_type(doc_metadata.get('chunk_type', 'æœªçŸ¥ç±»å‹')),
                'score': self._extract_score(doc),
                'content_preview': self._build_content_preview(doc, doc_metadata),
                'formatted_source': self._generate_formatted_source({
                    'document_name': doc_metadata.get('document_name', 'æœªçŸ¥æ–‡æ¡£'),
                    'page_number': doc_metadata.get('page_number', 'æœªçŸ¥é¡µ'),
                    'chunk_type': doc_metadata.get('chunk_type', 'æœªçŸ¥ç±»å‹')
                })
            }
            
            # éªŒè¯æºä¿¡æ¯æ˜¯å¦æœ‰æ•ˆ
            if source_info and len(source_info) > 0:
                return source_info
            else:
                self.logger.warning("æ„å»ºçš„æºä¿¡æ¯ä¸ºç©º")
                return None
                
        except Exception as e:
            self.logger.error(f"æ„å»ºæºä¿¡æ¯æ—¶å‡ºé”™: {e}")
            return None
    

    
    def _extract_content_from_doc(self, doc: Any) -> str:
        """
        ä»æ–‡æ¡£å¯¹è±¡ä¸­æå–å†…å®¹ - ç®€åŒ–ç‰ˆæœ¬ï¼Œä¸»è¦ç”¨äºæ„å»ºcontent_preview
        
        :param doc: æ–‡æ¡£å¯¹è±¡
        :return: æå–çš„å†…å®¹å­—ç¬¦ä¸²
        """
        try:
            # ä¼˜å…ˆçº§1ï¼šä»Documentå¯¹è±¡è·å–page_content
            if hasattr(doc, 'page_content') and doc.page_content:
                return doc.page_content
            
            # ä¼˜å…ˆçº§2ï¼šä»TextEngineæ ¼å¼çš„åµŒå¥—docè·å–page_content
            elif isinstance(doc, dict) and 'doc' in doc:
                nested_doc = doc['doc']
                if hasattr(nested_doc, 'page_content') and nested_doc.page_content:
                    return nested_doc.page_content
            
            # ä¼˜å…ˆçº§3ï¼šä»å­—å…¸æ ¼å¼çš„page_contentè·å–
            elif isinstance(doc, dict) and 'page_content' in doc:
                return doc['page_content']
            
            # ä¼˜å…ˆçº§4ï¼šä»TextEngineçš„contentå­—æ®µè·å–
            elif isinstance(doc, dict) and 'content' in doc:
                return doc['content']
            
            return ""
            
        except Exception as e:
            self.logger.warning(f"æå–æ–‡æ¡£å†…å®¹æ—¶å‡ºé”™: {e}")
            return ""
    
    def _generate_formatted_source(self, source_info: Dict[str, Any]) -> str:
        """
        ç”Ÿæˆæ ¼å¼åŒ–çš„æºä¿¡æ¯æ˜¾ç¤º
        
        :param source_info: æºä¿¡æ¯å­—å…¸
        :return: æ ¼å¼åŒ–çš„æºä¿¡æ¯å­—ç¬¦ä¸²
        """
        try:
            from ..api.v2_routes import _format_source_display
            return _format_source_display(
                source_info.get('document_name', 'æœªçŸ¥æ–‡æ¡£'),
                source_info.get('llm_context', ''),
                source_info.get('page_number', 'æœªçŸ¥é¡µ'),
                source_info.get('chunk_type', 'æœªçŸ¥ç±»å‹')
            )
        except ImportError:
            # å¦‚æœæ— æ³•å¯¼å…¥ï¼Œç”Ÿæˆç®€å•çš„æ ¼å¼åŒ–å­—ç¬¦ä¸²
            return f"{source_info.get('document_name', 'æœªçŸ¥æ–‡æ¡£')} - ç¬¬{source_info.get('page_number', 'æœªçŸ¥é¡µ')}é¡µ"
    
    def _convert_chunk_type(self, chunk_type: str) -> str:
        """è½¬æ¢chunk_typeä¸ºä¸­æ–‡æ˜¾ç¤º"""
        type_mapping = {
            'image': 'å›¾ç‰‡',
            'image_text': 'å›¾ç‰‡æ–‡æœ¬',
            'table': 'è¡¨æ ¼',
            'text': 'æ–‡æœ¬'
        }
        return type_mapping.get(chunk_type, chunk_type)
    
    def _extract_score(self, doc: Any) -> float:
        """æå–æ–‡æ¡£çš„ç›¸å…³æ€§åˆ†æ•°"""
        try:
            if isinstance(doc, dict):
                return doc.get('score', doc.get('vector_score', 0.0))
            elif hasattr(doc, 'score'):
                return getattr(doc, 'score', 0.0)
            return 0.0
        except Exception:
            return 0.0
    
    def _build_content_preview(self, doc: Any, doc_metadata: Dict[str, Any]) -> str:
        """æ„å»ºå†…å®¹é¢„è§ˆ"""
        try:
            content = self._extract_content_from_doc(doc)
            if not content:
                content = doc_metadata.get('page_content', doc_metadata.get('content', ''))
            
            if content:
                return content[:200] + '...' if len(content) > 200 else content
            return ''
        except Exception:
            return ''
    
    def _generate_llm_answer(self, query: str, reranked_results: List[Dict[str, Any]]) -> str:
        """
        ç”ŸæˆLLMç­”æ¡ˆ
        
        :param query: ç”¨æˆ·æŸ¥è¯¢
        :param reranked_results: é‡æ’åºåçš„ç»“æœ
        :return: LLMç”Ÿæˆçš„ç­”æ¡ˆ
        """
        try:
            # æ„å»ºä¸Šä¸‹æ–‡
            context = self._build_context_for_llm(reranked_results)
            
            # è°ƒç”¨LLMå¼•æ“
            if hasattr(self.llm_engine, 'generate_answer'):
                answer = self.llm_engine.generate_answer(query, context)
            else:
                # å…¼å®¹æ—§çš„æ¥å£
                answer = self.llm_engine(query, context)
            
            self.logger.info(f"LLMå¼•æ“è¿”å›ç»“æœé•¿åº¦: {len(answer)}")
            return answer
            
        except Exception as e:
            self.logger.error(f"LLMç­”æ¡ˆç”Ÿæˆå¤±è´¥: {e}")
            return f"æŠ±æ­‰ï¼Œç”Ÿæˆç­”æ¡ˆæ—¶å‡ºç°é”™è¯¯: {str(e)}"
    
    def _build_context_for_llm(self, reranked_results: List[Dict[str, Any]]) -> str:
        """
        ä¸ºLLMæ„å»ºä¸Šä¸‹æ–‡
        
        :param reranked_results: é‡æ’åºåçš„ç»“æœ
        :return: æ„å»ºçš„ä¸Šä¸‹æ–‡å­—ç¬¦ä¸²
        """
        context_parts = []
        
        for i, result in enumerate(reranked_results[:self.max_context_results]):
            if isinstance(result, dict) and 'doc' in result:
                doc = result['doc']
                
                # ğŸ”‘ ä¿®å¤ï¼šå¤„ç†ä¸åŒçš„docæ ¼å¼
                if isinstance(doc, dict):
                    # docæ˜¯å­—å…¸æ ¼å¼ï¼Œç›´æ¥æå–contentå­—æ®µ
                    content = doc.get('content', '')
                    if content:
                        context_parts.append(f"æ–‡æ¡£{i+1}: {content[:self.max_content_length]}")
                        
                elif hasattr(doc, 'page_content') and doc.page_content:
                    # docæ˜¯Documentå¯¹è±¡æ ¼å¼ï¼Œä½¿ç”¨åŸæœ‰é€»è¾‘
                    content = doc.page_content[:self.max_content_length]
                    context_parts.append(f"æ–‡æ¡£{i+1}: {content}")
        
        return "\n\n".join(context_parts)
    
    def _filter_sources(self, llm_answer: str, reranked_results: List[Dict[str, Any]], query: str, query_type: str = None) -> List[Dict[str, Any]]:
        """
        è¿‡æ»¤æº
        
        :param llm_answer: LLMç”Ÿæˆçš„ç­”æ¡ˆ
        :param reranked_results: é‡æ’åºåçš„ç»“æœ
        :param query: åŸå§‹æŸ¥è¯¢
        :param query_type: æŸ¥è¯¢ç±»å‹
        :return: è¿‡æ»¤åçš„ç»“æœ
        """
        try:
            if hasattr(self.source_filter_engine, 'filter_sources'):
                filtered = self.source_filter_engine.filter_sources(
                    llm_answer, reranked_results, query, query_type
                )
                return filtered[:self.max_context_results]
            else:
                # å…¼å®¹æ—§çš„æ¥å£
                return reranked_results[:self.max_context_results]
            
        except Exception as e:
            self.logger.error(f"æºè¿‡æ»¤å¤±è´¥: {e}")
            return reranked_results[:self.max_context_results]
    
    def _build_frontend_format(self, query: str, llm_answer: str, sources: List[Dict[str, Any]], 
                              original_results: List[Dict[str, Any]], query_type: str = None, 
                              pipeline_metrics: Dict[str, Any] = None) -> Dict[str, Any]:
        """
        æ„å»ºå‰ç«¯æœŸæœ›çš„å®Œæ•´æ ¼å¼
        
        :param query: æŸ¥è¯¢æ–‡æœ¬
        :param llm_answer: LLMç”Ÿæˆçš„ç­”æ¡ˆ
        :param sources: æå–çš„æºä¿¡æ¯
        :param original_results: åŸå§‹æ£€ç´¢ç»“æœ
        :param query_type: æŸ¥è¯¢ç±»å‹
        :param pipeline_metrics: Pipelineå¤„ç†æŒ‡æ ‡
        :return: å‰ç«¯æœŸæœ›çš„å®Œæ•´å­—å…¸æ ¼å¼
        """
        try:
            # æ„å»ºåŸºç¡€å“åº”
            response = {
                'success': True,
                'query': query,
                'query_type': query_type or 'text',
                'answer': llm_answer,
                'processing_time': pipeline_metrics.get('total_time', 0) if pipeline_metrics else 0,
                'timestamp': time.time(),
                'total_count': len(original_results)
            }
            
            # æ·»åŠ sources
            response['sources'] = sources
            
            # æŒ‰ç±»å‹åˆ†ç±»åŸå§‹ç»“æœ
            image_results = []
            table_results = []
            text_results = []
            
            for result in original_results:
                chunk_type = self._get_chunk_type(result)
                
                if chunk_type == 'image':
                    image_result = self._build_image_result(result)
                    if image_result:
                        image_results.append(image_result)
                elif chunk_type == 'table':
                    table_result = self._build_table_result(result)
                    if table_result:
                        table_results.append(table_result)
                elif chunk_type == 'text':
                    text_result = self._build_text_result(result)
                    if text_result:
                        text_results.append(text_result)
            
            # æ·»åŠ åˆ†ç±»ç»“æœ
            response['image_results'] = image_results
            response['table_results'] = table_results
            response['text_results'] = text_results
            
            # æ·»åŠ Pipelineå…ƒæ•°æ®
            if pipeline_metrics:
                response['pipeline_metrics'] = pipeline_metrics
            
            self.logger.info(f"å‰ç«¯æ ¼å¼æ„å»ºå®Œæˆï¼ŒåŒ…å«å­—æ®µ: {list(response.keys())}")
            self.logger.info(f"ç»“æœç»Ÿè®¡: sources={len(sources)}, images={len(image_results)}, tables={len(table_results)}, texts={len(text_results)}")
            
            return response
            
        except Exception as e:
            self.logger.error(f"æ„å»ºå‰ç«¯æ ¼å¼å¤±è´¥: {e}")
            return {
                'success': False,
                'error_message': f'æ„å»ºå‰ç«¯æ ¼å¼å¤±è´¥: {str(e)}',
                'answer': 'æŠ±æ­‰ï¼Œæ ¼å¼åŒ–ç»“æœæ—¶å‡ºç°é”™è¯¯ã€‚',
                'sources': [],
                'image_results': [],
                'table_results': [],
                'text_results': [],
                'processing_time': 0
            }
    
    def _get_chunk_type(self, result: Any) -> str:
        """è·å–ç»“æœçš„å†…å®¹ç±»å‹"""
        try:
            if isinstance(result, dict):
                if 'chunk_type' in result:
                    return result['chunk_type']
                elif 'doc' in result and hasattr(result['doc'], 'metadata'):
                    return result['doc'].metadata.get('chunk_type', 'text')
            elif hasattr(result, 'metadata'):
                return result.metadata.get('chunk_type', 'text')
            return 'text'
        except Exception:
            return 'text'
    
    def _build_image_result(self, result: Any) -> Optional[Dict[str, Any]]:
        """æ„å»ºå›¾ç‰‡ç»“æœæ ¼å¼"""
        try:
            if isinstance(result, dict):
                return {
                    'id': result.get('image_id', result.get('doc_id', 'unknown')),
                    'image_path': result.get('image_path', ''),
                    'caption': result.get('caption', result.get('img_caption', 'æ— æ ‡é¢˜')),
                    'document_name': result.get('document_name', 'æœªçŸ¥æ–‡æ¡£'),
                    'page_number': result.get('page_number', 'N/A'),
                    'score': result.get('score', result.get('vector_score', 0.0))
                }
            elif hasattr(result, 'metadata'):
                metadata = result.metadata
                return {
                    'id': getattr(result, 'doc_id', 'unknown'),
                    'image_path': metadata.get('image_path', ''),
                    'caption': metadata.get('img_caption', 'æ— æ ‡é¢˜'),
                    'document_name': metadata.get('document_name', 'æœªçŸ¥æ–‡æ¡£'),
                    'page_number': metadata.get('page_number', 'N/A'),
                    'score': getattr(result, 'score', 0.0)
                }
            return None
        except Exception as e:
            self.logger.warning(f"æ„å»ºå›¾ç‰‡ç»“æœå¤±è´¥: {e}")
            return None
    
    def _build_table_result(self, result: Any) -> Optional[Dict[str, Any]]:
        """æ„å»ºè¡¨æ ¼ç»“æœæ ¼å¼"""
        try:
            if isinstance(result, dict):
                return {
                    'id': result.get('table_id', result.get('doc_id', 'unknown')),
                    'table_html': result.get('html_content', result.get('table_html', '')),
                    'table_content': result.get('processed_content', result.get('table_content', '')),
                    'document_name': result.get('document_name', 'æœªçŸ¥æ–‡æ¡£'),
                    'page_number': result.get('page_number', 'N/A'),
                    'score': result.get('score', result.get('vector_score', 0.0))
                }
            elif hasattr(result, 'metadata'):
                metadata = result.metadata
                return {
                    'id': getattr(result, 'doc_id', 'unknown'),
                    'table_html': getattr(result, 'page_content', ''),
                    'table_content': metadata.get('processed_table_content', ''),
                    'document_name': metadata.get('document_name', 'æœªçŸ¥æ–‡æ¡£'),
                    'page_number': metadata.get('page_number', 'N/A'),
                    'score': getattr(result, 'score', 0.0)
                }
            return None
        except Exception as e:
            self.logger.warning(f"æ„å»ºè¡¨æ ¼ç»“æœå¤±è´¥: {e}")
            return None
    
    def _build_text_result(self, result: Any) -> Optional[Dict[str, Any]]:
        """æ„å»ºæ–‡æœ¬ç»“æœæ ¼å¼"""
        try:
            if isinstance(result, dict):
                return {
                    'id': result.get('doc_id', 'unknown'),
                    'content': result.get('content', ''),
                    'document_name': result.get('document_name', 'æœªçŸ¥æ–‡æ¡£'),
                    'page_number': result.get('page_number', 'N/A'),
                    'score': result.get('score', result.get('vector_score', 0.0))
                }
            elif hasattr(result, 'metadata'):
                metadata = result.metadata
                return {
                    'id': getattr(result, 'doc_id', 'unknown'),
                    'content': getattr(result, 'page_content', ''),
                    'document_name': metadata.get('document_name', 'æœªçŸ¥æ–‡æ¡£'),
                    'page_number': metadata.get('page_number', 'N/A'),
                    'score': getattr(result, 'score', 0.0)
                }
            return None
        except Exception as e:
            self.logger.warning(f"æ„å»ºæ–‡æœ¬ç»“æœå¤±è´¥: {e}")
            return None