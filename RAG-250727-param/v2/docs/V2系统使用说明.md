# V2 RAG系统使用说明

## 系统概述

V2 RAG系统是一个基于检索增强生成（Retrieval-Augmented Generation）的智能问答系统，集成了多引擎检索、智能过滤、LLM生成和答案验证等先进功能。

### 主要特性

- **多引擎检索**：支持文本、图像、表格等多种内容类型的智能检索
- **优化管道**：集成重排序、智能过滤、LLM生成、源过滤等优化步骤
- **智能记忆管理**：基于相关性的对话记忆和上下文管理
- **配置化管理**：灵活的引擎配置和参数调整
- **前后端分离**：现代化的Web界面和RESTful API

## 系统架构

```
用户界面 (Web) ←→ API服务 (Flask) ←→ 混合引擎 (Hybrid Engine)
                                    ↓
                    优化管道 (Optimization Pipeline)
                                    ↓
        重排序引擎 ← 智能过滤引擎 ← LLM引擎 ← 源过滤引擎
```

## 安装和配置

### 环境要求

- Python 3.8+
- 必要的Python包：dashscope, flask, numpy, jieba等

### 配置步骤

1. **API密钥配置**
   - 在 `v2/config/v2_config.json` 中配置DashScope API密钥
   - 确保所有引擎的API密钥都已正确设置

2. **系统配置**
   - 检查 `v2_config.json` 中的引擎启用状态
   - 根据需要调整优化管道的配置参数

3. **启动系统**
   ```bash
   python v2/V800_v2_main.py
   ```

## 基本使用流程

### 1. 系统启动

启动后系统会自动：
- 加载配置文件
- 初始化所有引擎
- 启动Web服务（默认端口5000）

### 2. 查询处理

用户可以通过以下方式提交查询：

- **Web界面**：访问 `http://localhost:5000`
- **API接口**：使用 `/api/v2/query/optimized` 端点

### 3. 优化查询

启用优化查询后，系统会执行完整的优化管道：

1. **检索阶段**：根据查询类型选择相应的检索引擎
2. **重排序阶段**：使用BGE-reranker-v2-m3模型重新排序结果
3. **智能过滤阶段**：基于内容质量、关键词匹配等过滤文档
4. **LLM生成阶段**：使用通义千问生成答案
5. **源过滤阶段**：智能过滤和验证信息源

### 4. 结果展示

系统会返回：
- 生成的答案
- 相关的文档片段
- 优化管道的执行详情
- 置信度评分

## 高级功能

### 记忆管理

- 系统会自动记录对话历史
- 基于相关性进行上下文管理
- 支持长期记忆和短期记忆

### 引擎状态监控

- 实时监控各引擎的运行状态
- 支持动态启用/禁用优化功能
- 提供性能指标和错误日志

### 配置管理

- 支持运行时配置更新
- 提供配置验证和错误检查
- 支持配置备份和恢复

## 故障排除

### 常见问题

1. **API密钥错误**
   - 检查配置文件中的API密钥是否正确
   - 确认API密钥是否有效且未过期

2. **引擎初始化失败**
   - 检查网络连接
   - 验证依赖包是否正确安装
   - 查看错误日志获取详细信息

3. **查询响应慢**
   - 检查优化管道的配置
   - 考虑禁用某些优化步骤以提高速度
   - 监控系统资源使用情况

### 调试模式

启用调试模式可以获取更详细的执行信息：

```python
# 在配置文件中设置
"debug_mode": true
```

## 性能优化建议

1. **合理配置重排序阈值**
2. **根据需求调整智能过滤参数**
3. **优化LLM模型的调用频率**
4. **合理设置记忆管理的相关阈值**

## 联系和支持

如遇到问题，请：
1. 查看系统日志
2. 检查配置文件
3. 参考技术文档
4. 联系技术支持团队
