# 文本引擎技术实现深度剖析

## 程序说明

### 1. 文本引擎 - 专门处理文本查询
### 2. 支持关键词、语义、向量相似度搜索
### 3. 智能文本排序和相关性计算
### 4. 向后兼容现有文本查询功能

---

## 目录

1. [架构概述](#架构概述)
2. [核心组件](#核心组件)
3. [配置管理](#配置管理)
4. [搜索策略](#搜索策略)
5. [系统集成](#系统集成)
6. [API接口](#api接口)
7. [前端展示](#前端展示)
8. [性能优化](#性能优化)
9. [使用示例](#使用示例)
10. [故障排查](#故障排查)

---

## 架构概述

### 设计理念

`TextEngine` 是 V2 RAG 系统的核心组件之一，专门负责处理纯文本查询。它采用了多策略搜索架构，结合了传统的关键词匹配、语义相似度计算和向量搜索技术，为用户提供准确、相关的文本检索结果。

### 核心特性

- **多策略搜索**: 关键词搜索、语义搜索、向量搜索
- **智能过滤**: 严格的文档类型过滤，只处理 `chunk_type='text'` 的文档
- **自适应阈值**: 动态调整相似度阈值，确保结果质量
- **缓存机制**: 文本文档缓存，提高查询性能
- **相关性评分**: 综合多种因素计算文档相关性

---

## 核心组件

### TextEngineConfig 配置类

```python
@dataclass
class TextEngineConfigV2(EngineConfigV2):
    name: str = "text_engine"
    max_results: int = 10
    text_similarity_threshold: float = 0.7
    keyword_weight: float = 0.3
    semantic_weight: float = 0.4
    vector_weight: float = 0.3
    enable_semantic_search: bool = True
    enable_vector_search: bool = True
```

**配置参数说明**:
- `max_results`: 最大返回结果数量
- `text_similarity_threshold`: 文本相似度阈值（0.7）
- `keyword_weight`: 关键词匹配权重（0.3）
- `semantic_weight`: 语义相似度权重（0.4）
- `vector_weight`: 向量相似度权重（0.3）

### TextEngine 主类

继承自 `BaseEngine`，实现了完整的文本查询功能：

```python
class TextEngine(BaseEngine):
    def __init__(self, config: TextEngineConfig, vector_store=None):
        super().__init__(config)
        self.vector_store = vector_store
        self.text_docs = {}  # 缓存的文本文档
        self._initialize()
        self._load_text_documents()
```

---

## 配置管理

### 配置文件位置

文本引擎的配置通过 `v2/config/v2_config.py` 中的 `TextEngineConfigV2` 类管理，配置数据存储在 `v2/config/v2_config.json` 文件中。

### 配置加载流程

1. **V2ConfigManager** 加载配置文件
2. **V800_v2_main.py** 创建 TextEngine 实例时传入配置
3. **HybridEngine** 集成 TextEngine 并管理其生命周期

### 配置示例

```json
{
  "text_engine": {
    "enabled": true,
    "name": "text_engine",
    "max_results": 10,
    "text_similarity_threshold": 0.7,
    "keyword_weight": 0.3,
    "semantic_weight": 0.4,
    "vector_weight": 0.3,
    "enable_semantic_search": true,
    "enable_vector_search": true
  }
}
```

---

## 搜索策略

### 1. 文本文档缓存搜索

```python
def _search_texts(self, query: str, **kwargs) -> List[Any]:
    # 策略1: 优先使用已加载的文本文档进行搜索
    if self.text_docs:
        for doc_id, doc in self.text_docs.items():
            score = self._calculate_text_score(doc, query)
            if score >= self.config.text_similarity_threshold:
                results.append({
                    'doc_id': doc_id,
                    'doc': doc,
                    'score': score,
                    'match_type': 'text_doc_search'
                })
```

**优势**: 快速响应，减少向量数据库查询开销

### 2. 向量存储搜索（类型过滤）

```python
# 策略2: 向量存储搜索，但严格过滤文档类型
similar_docs = self.vector_store.similarity_search(query, k=50)
for doc in similar_docs:
    chunk_type = doc.metadata.get('chunk_type', '')
    # 只处理文本文档，排除图片和表格
    if chunk_type == 'text':
        score = self._calculate_text_score(doc, query)
        if score >= self.config.text_similarity_threshold:
            results.append({...})
```

**特点**: 严格的类型过滤，确保结果质量

### 3. 关键词搜索

```python
def _keyword_search(self, query: str) -> List[Any]:
    keywords = self._extract_keywords(query)
    for doc_id, doc in self.text_docs.items():
        score = self._calculate_keyword_score(doc, keywords)
        if score >= self.config.text_similarity_threshold:
            results.append({...})
```

**功能**: 基于关键词的精确匹配

### 4. 智能模糊搜索

```python
def _fuzzy_search(self, query: str) -> List[Any]:
    # 分析查询意图，判断是否与中芯国际相关
    smic_keywords = ['中芯国际', '中芯', '晶圆', '芯片', '半导体', '集成电路', 'IC', '代工']
    query_has_smic_context = any(keyword in query_lower for keyword in smic_keywords)
    
    # 如果查询与中芯国际无关，不启用模糊搜索
    if not query_has_smic_context:
        return results
```

**智能特性**: 基于业务领域的智能模糊匹配

### 5. 自适应阈值搜索

```python
# 策略5: 降低阈值重新搜索（保持类型过滤）
if not results and self.config.text_similarity_threshold > 0.05:
    original_threshold = self.config.text_similarity_threshold
    self.config.text_similarity_threshold = 0.05
    
    # 重新执行向量搜索，但严格过滤类型
    # ... 搜索逻辑
    
    # 恢复原始阈值
    self.config.text_similarity_threshold = original_threshold
```

**自适应机制**: 动态调整阈值，平衡结果数量和质量

---

## 相关性评分算法

### 综合评分公式

```python
def _calculate_text_score(self, doc: Any, query: str) -> float:
    score = 0.0
    
    # 1. 语义相似度分数（核心指标）
    semantic_score = self._calculate_text_similarity(query, content)
    score += semantic_score * self.config.semantic_weight
    
    # 2. 关键词匹配分数（严格匹配）
    keywords = self._extract_keywords(query)
    if keywords:
        keyword_score = self._calculate_keyword_score(doc, keywords)
        if keyword_score > 0.3:  # 至少30%的关键词匹配
            score += keyword_score * self.config.keyword_weight
        else:
            score *= 0.3  # 关键词匹配不足，大幅降低分数
    
    # 3. 向量相似度分数
    if hasattr(doc, 'metadata') and 'semantic_features' in doc.metadata:
        vector_score = 0.3
        score += vector_score * self.config.vector_weight
    
    # 4. 文档类型匹配奖励
    if doc.metadata.get('chunk_type') == 'text':
        score += 0.05
    
    # 5. 内容长度奖励
    if len(content) > 100:
        score += 0.02
    
    # 6. 相关性惩罚机制
    if semantic_score < 0.1:
        score *= 0.5
    
    return min(score, 1.0)
```

### 评分权重分配

- **语义相似度**: 40% - 核心相关性指标
- **关键词匹配**: 30% - 精确匹配度
- **向量相似度**: 30% - 语义特征匹配

---

## 系统集成

### 1. 在 V800_v2_main.py 中的初始化

```python
# 创建文本引擎
text_engine = TextEngine(
    config=self.v2_config.text_engine,
    vector_store=vector_store
)

# 集成到混合引擎
self.hybrid_engine = HybridEngine(
    config=self.v2_config.hybrid_engine,
    image_engine=image_engine,
    text_engine=text_engine,  # 文本引擎集成
    table_engine=table_engine,
    # ... 其他引擎
)
```

### 2. 在 HybridEngine 中的使用

```python
class HybridEngine(BaseEngine):
    def __init__(self, config, text_engine: TextEngine = None, ...):
        self.text_engine = text_engine
    
    def process_query(self, query: str, **kwargs) -> QueryResult:
        # 根据查询类型路由到相应引擎
        if query_type == 'text':
            return self.text_engine.process_query(query, **kwargs)
        elif query_type == 'hybrid':
            # 混合查询：同时调用多个引擎
            text_results = self.text_engine.process_query(query, **kwargs)
            # ... 融合结果
```

### 3. 优化管道集成

文本引擎的结果会进入优化管道进行进一步处理：

1. **重排序**: 基于语义相似度重新排序
2. **智能过滤**: 过滤低质量或重复内容
3. **LLM生成**: 基于检索结果生成答案
4. **源过滤**: 选择最相关的来源

---

## API接口

### 1. 直接文本查询接口

```python
@v2_api_bp.route('/query/text', methods=['POST'])
def query_text():
    """纯文本查询接口"""
    data = request.get_json()
    query = data.get('query', '').strip()
    
    # 调用文本引擎
    result = hybrid_engine.text_engine.process_query(query)
    
    return jsonify({
        'success': True,
        'query': query,
        'query_type': 'text',
        'results': result.results,
        'total_count': result.total_count,
        'processing_time': result.processing_time
    })
```

### 2. 混合查询接口

```python
@v2_api_bp.route('/ask', methods=['POST'])
def v2_ask_question():
    """混合查询接口"""
    data = request.get_json()
    question = data.get('question', '').strip()
    query_type = data.get('query_type', 'hybrid')
    
    if query_type == 'text':
        # 纯文本查询
        result = hybrid_engine.text_engine.process_query(question)
    elif query_type == 'hybrid':
        # 混合查询
        result = hybrid_engine.process_query(question)
    
    # 格式化响应
    response = _format_query_response(result, question)
    return jsonify(response)
```

### 3. 查询结果格式

```python
def _extract_sources_from_result(result, result_type='text'):
    """提取来源信息"""
    sources = []
    
    if result_type == 'text':
        for doc in result.results:
            if 'content' in doc:
                sources.append({
                    'title': doc.get('title', '文档'),
                    'page_number': doc.get('page_number', 'N/A'),
                    'document_name': doc.get('document_name', 'N/A'),
                    'source_type': doc.get('chunk_type', 'text'),
                    'score': doc.get('score', 0.0),
                    'content_preview': doc.get('content', '')[:200] + '...'
                })
    
    return sources
```

---

## 前端展示

### 1. 查询类型选择

```html
<!-- 查询类型选择器 -->
<div class="query-type-selector">
    <label>
        <input type="radio" name="query_type" value="text" checked>
        文本查询
    </label>
    <label>
        <input type="radio" name="query_type" value="image">
        图片查询
    </label>
    <label>
        <input type="radio" name="query_type" value="table">
        表格查询
    </label>
    <label>
        <input type="radio" name="query_type" value="hybrid">
        混合查询
    </label>
</div>
```

### 2. 结果展示

```javascript
// 处理文本查询结果
function displayTextResults(data) {
    let messageContent = `<div class="message-text">${data.answer}</div>`;
    
    // 添加来源详情显示
    if (data.sources && data.sources.length > 0) {
        messageContent += `
            <div class="sources-section">
                <div class="sources-header">
                    <h4>来源详情</h4>
                </div>
                <div class="sources-list">
                    ${data.sources.map((source, index) => `
                        <div class="source-item">
                            <span class="source-number">${index + 1}.</span>
                            <span class="source-content">${source.formatted_source || '未知来源'}</span>
                        </div>
                    `).join('')}
                </div>
            </div>
        `;
    }
    
    return messageContent;
}
```

### 3. 来源格式化

```python
def _format_source_display(document_name, page_number, chunk_type, content_preview):
    """格式化来源显示"""
    document_name = document_name.replace('【', '').replace('】', '').strip()
    
    if chunk_type == 'text':
        # 文本：文档名 - 第X页 (文本)
        return f"{document_name} - 第{page_number}页 (文本)"
    elif chunk_type == 'image':
        # 图片：文档名 - 图片标题 - 第X页 (图片)
        lines = content_preview.split('\n')
        image_title = lines[0].strip() if lines else content_preview[:50]
        return f"{document_name} - {image_title} - 第{page_number}页 (图片)"
    elif chunk_type == 'table':
        # 表格：文档名 - 表格标题 - 第X页 (表格)
        lines = content_preview.split('\n')
        table_title = lines[0].strip() if lines else content_preview[:50]
        return f"{document_name} - {table_title} - 第{page_number}页 (表格)"
    else:
        return f"{document_name} - 第{page_number}页"
```

---

## 性能优化

### 1. 文档缓存机制

```python
def _load_text_documents(self):
    """加载文本文档到缓存"""
    for doc_id, doc in self.vector_store.docstore._dict.items():
        chunk_type = doc.metadata.get('chunk_type', '')
        if chunk_type == 'text':
            self.text_docs[doc_id] = doc
    
    self.logger.info(f"成功加载 {len(self.text_docs)} 个文本文档")
```

**优化效果**: 减少重复的向量数据库查询，提高响应速度

### 2. 智能搜索策略

- **优先级排序**: 缓存搜索 → 向量搜索 → 关键词搜索 → 模糊搜索
- **类型过滤**: 严格过滤非文本文档，减少无效计算
- **阈值自适应**: 动态调整相似度阈值，平衡结果数量和质量

### 3. 并发处理

```python
# 在混合查询中，文本引擎可以与其他引擎并行执行
with ThreadPoolExecutor(max_workers=3) as executor:
    text_future = executor.submit(self.text_engine.process_query, query)
    image_future = executor.submit(self.image_engine.process_query, query)
    table_future = executor.submit(self.table_engine.process_query, query)
    
    # 等待所有结果
    text_results = text_future.result()
    image_results = image_future.result()
    table_results = table_future.result()
```

---

## 使用示例

### 1. 命令行使用

```bash
# 启动V2系统
python V800_v2_main.py --mode web

# 纯文本查询
curl -X POST http://localhost:5000/api/v2/query/text \
  -H "Content-Type: application/json" \
  -d '{"query": "中芯国际的技术发展情况"}'

# 混合查询（包含文本）
curl -X POST http://localhost:5000/api/v2/ask \
  -H "Content-Type: application/json" \
  -d '{"question": "中芯国际的技术发展情况", "query_type": "hybrid"}'
```

### 2. Python API 使用

```python
from v2.core.text_engine import TextEngine
from v2.config.v2_config import TextEngineConfigV2

# 创建配置
config = TextEngineConfigV2(
    max_results=15,
    text_similarity_threshold=0.6,
    keyword_weight=0.4,
    semantic_weight=0.4,
    vector_weight=0.2
)

# 创建文本引擎
text_engine = TextEngine(config, vector_store)

# 执行查询
result = text_engine.process_query("中芯国际的技术发展情况")

# 处理结果
for doc in result.results:
    print(f"文档: {doc['document_name']}")
    print(f"页码: {doc['page_number']}")
    print(f"分数: {doc['score']}")
    print(f"内容: {doc['content'][:100]}...")
    print("---")
```

### 3. 前端界面使用

1. 在Web界面选择"文本查询"类型
2. 输入查询问题
3. 点击"发送"按钮
4. 查看文本检索结果和来源信息

---

## 故障排查

### 1. 常见问题

#### 问题1: 文本引擎未找到文本文档

**症状**: 日志显示"未找到文本文档"
**原因**: 向量数据库中文档的 `chunk_type` 字段设置不正确
**解决方案**: 检查文档处理管道，确保文本文档的 `chunk_type` 设置为 `'text'`

#### 问题2: 搜索结果相关性低

**症状**: 返回结果与查询问题相关性不高
**原因**: 相似度阈值设置过低或评分算法权重配置不当
**解决方案**: 调整 `text_similarity_threshold` 和权重配置

#### 问题3: 查询响应慢

**症状**: 文本查询响应时间过长
**原因**: 向量数据库查询开销大或缓存未生效
**解决方案**: 检查向量数据库性能，确保文档缓存正常工作

### 2. 调试工具

#### 检查文本引擎状态

```python
# 获取文本引擎统计信息
stats = text_engine.get_text_statistics()
print(f"文本文档总数: {stats['total_texts']}")
print(f"总字符数: {stats['total_chars']}")

# 检查缓存状态
print(f"缓存文档数: {len(text_engine.text_docs)}")
```

#### 检查向量数据库结构

```python
# 检查文档类型分布
from tools.check_db_structure import check_document_types
check_document_types('central/vector_db')

# 检查特定文档的元数据
for doc_id, doc in vector_store.docstore._dict.items():
    if doc.metadata.get('chunk_type') == 'text':
        print(f"文本文档: {doc_id}")
        print(f"元数据: {doc.metadata}")
        break
```

### 3. 日志分析

启用详细日志记录：

```python
import logging
logging.getLogger('v2.core.text_engine').setLevel(logging.DEBUG)
```

关键日志信息：
- 文档加载状态
- 搜索策略执行情况
- 相关性评分计算
- 结果过滤和排序

---

## 总结

`TextEngine` 是 V2 RAG 系统的核心组件，通过多策略搜索、智能过滤和缓存机制，为用户提供高效、准确的文本检索服务。它与整个系统深度集成，支持从命令行到Web界面的多种使用方式，并通过优化管道实现结果质量的进一步提升。

### 核心优势

1. **多策略搜索**: 结合关键词、语义和向量搜索
2. **智能过滤**: 严格的文档类型过滤
3. **自适应机制**: 动态调整搜索参数
4. **高性能**: 文档缓存和并发处理
5. **易集成**: 与混合引擎和优化管道无缝集成

### 适用场景

- 纯文本内容查询
- 基于关键词的精确搜索
- 语义相似度搜索
- 混合查询中的文本部分
- 需要高质量文本检索的应用

通过合理配置和优化，`TextEngine` 能够为各种文本检索需求提供稳定、高效的服务支持。
