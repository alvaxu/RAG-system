"""
ç¬¬ä¸€é˜¶æ®µLangChainæ”¹é€ æµ‹è¯•ç¨‹åº

æµ‹è¯•æ–°åˆ›å»ºçš„LangChainç»„ä»¶ï¼š
1. LangChainVectorStoreManager
2. LangChainTextVectorizer  
3. LangChainModelCaller

ç¡®ä¿è¿™äº›ç»„ä»¶èƒ½å¤Ÿæ­£å¸¸å·¥ä½œå¹¶æ›¿ä»£åŸæœ‰åŠŸèƒ½ã€‚
"""

import os
import sys
import logging
import time
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

# æ·»åŠ å½“å‰ç›®å½•åˆ°Pythonè·¯å¾„
current_dir = Path(__file__).parent
sys.path.insert(0, str(current_dir))

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)

def test_langchain_components():
    """æµ‹è¯•LangChainç»„ä»¶"""
    print("ğŸš€ å¼€å§‹ç¬¬ä¸€é˜¶æ®µLangChainæ”¹é€ æµ‹è¯•")
    print("=" * 60)
    
    try:
        # æµ‹è¯•1: é…ç½®ç®¡ç†å™¨
        print("\nğŸ“‹ æµ‹è¯•1: é…ç½®ç®¡ç†å™¨")
        from config.config_manager import ConfigManager
        
        # è®¾ç½®æµ‹è¯•ä¸“ç”¨çš„å‘é‡æ•°æ®åº“è·¯å¾„
        test_vector_db_dir = str(Path(__file__).parent.parent / "central" / "vector_db")
        print(f"ğŸ“ æµ‹è¯•å‘é‡æ•°æ®åº“è·¯å¾„: {test_vector_db_dir}")
        
        config_manager = ConfigManager()
        
        # åŠ¨æ€æ›´æ–°å‘é‡æ•°æ®åº“è·¯å¾„é…ç½®
        if hasattr(config_manager, 'config_data'):
            config_manager.config_data['paths'] = config_manager.config_data.get('paths', {})
            config_manager.config_data['paths']['vector_db_dir'] = test_vector_db_dir
        
        print("âœ… é…ç½®ç®¡ç†å™¨åˆå§‹åŒ–æˆåŠŸ")
        
        # æµ‹è¯•2: LangChainæ¨¡å‹è°ƒç”¨å™¨
        print("\nğŸ¤– æµ‹è¯•2: LangChainæ¨¡å‹è°ƒç”¨å™¨")
        from core.model_caller import LangChainModelCaller
        
        model_caller = LangChainModelCaller(config_manager)
        print("âœ… LangChainæ¨¡å‹è°ƒç”¨å™¨åˆå§‹åŒ–æˆåŠŸ")
        
        # æµ‹è¯•æ¨¡å‹ä¿¡æ¯
        model_info = model_caller.get_model_info()
        print(f"ğŸ“Š æ¨¡å‹ä¿¡æ¯: {model_info}")
        
        # æµ‹è¯•3: LangChainæ–‡æœ¬å‘é‡åŒ–å™¨
        print("\nğŸ“ æµ‹è¯•3: LangChainæ–‡æœ¬å‘é‡åŒ–å™¨")
        from vectorization.text_vectorizer import LangChainTextVectorizer
        
        text_vectorizer = LangChainTextVectorizer(config_manager)
        print("âœ… LangChainæ–‡æœ¬å‘é‡åŒ–å™¨åˆå§‹åŒ–æˆåŠŸ")
        
        # æµ‹è¯•æ–‡æœ¬åˆ†å‰²
        test_text = "è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•æ–‡æœ¬ã€‚å®ƒåŒ…å«å¤šä¸ªå¥å­ã€‚æˆ‘ä»¬å°†æµ‹è¯•æ–‡æœ¬åˆ†å‰²åŠŸèƒ½ã€‚"
        chunks = text_vectorizer.split_text(test_text, chunk_size=20, chunk_overlap=5)
        print(f"ğŸ“„ æ–‡æœ¬åˆ†å‰²æµ‹è¯•: åŸæ–‡æœ¬é•¿åº¦ {len(test_text)}ï¼Œåˆ†å‰²å {len(chunks)} ä¸ªå—")
        for i, chunk in enumerate(chunks):
            print(f"   å— {i+1}: {chunk}")
        
        # æµ‹è¯•4: LangChainå‘é‡å­˜å‚¨ç®¡ç†å™¨
        print("\nğŸ—„ï¸ æµ‹è¯•4: LangChainå‘é‡å­˜å‚¨ç®¡ç†å™¨")
        from core.vector_store_manager import LangChainVectorStoreManager
        
        vector_store_manager = LangChainVectorStoreManager(config_manager)
        print("âœ… LangChainå‘é‡å­˜å‚¨ç®¡ç†å™¨åˆå§‹åŒ–æˆåŠŸ")
        
        # æµ‹è¯•å‘é‡å­˜å‚¨åˆ›å»º
        success = vector_store_manager.create_vector_store()
        if success:
            print("âœ… å‘é‡å­˜å‚¨åˆ›å»ºæˆåŠŸ")
        else:
            print("âŒ å‘é‡å­˜å‚¨åˆ›å»ºå¤±è´¥")
            return False
        
        # æµ‹è¯•çŠ¶æ€è·å–
        status = vector_store_manager.get_status()
        print(f"ğŸ“Š å‘é‡å­˜å‚¨çŠ¶æ€: {status}")
        
        # æµ‹è¯•5: é›†æˆæµ‹è¯•
        print("\nğŸ”— æµ‹è¯•5: é›†æˆæµ‹è¯•")
        
        # æµ‹è¯•æ–‡æœ¬å‘é‡åŒ–
        test_texts = [
            "äººå·¥æ™ºèƒ½æ˜¯è®¡ç®—æœºç§‘å­¦çš„ä¸€ä¸ªåˆ†æ”¯",
            "æœºå™¨å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½çš„é‡è¦æŠ€æœ¯",
            "æ·±åº¦å­¦ä¹ æ˜¯æœºå™¨å­¦ä¹ çš„ä¸€ä¸ªå­é¢†åŸŸ"
        ]
        
        print("ğŸ“ å¼€å§‹æ–‡æœ¬å‘é‡åŒ–æµ‹è¯•...")
        for i, text in enumerate(test_texts):
            result = text_vectorizer.vectorize(text, {'source': f'test_{i}'})
            if result['vectorization_status'] == 'success':
                print(f"âœ… æ–‡æœ¬ {i+1} å‘é‡åŒ–æˆåŠŸ: {len(result['text_embedding'])} ç»´")
            else:
                print(f"âŒ æ–‡æœ¬ {i+1} å‘é‡åŒ–å¤±è´¥: {result.get('error_message', 'æœªçŸ¥é”™è¯¯')}")
        
        # æµ‹è¯•å‘é‡å­˜å‚¨
        print("\nğŸ—„ï¸ å¼€å§‹å‘é‡å­˜å‚¨æµ‹è¯•...")
        
        # æ·»åŠ æ–‡æœ¬åˆ°å‘é‡å­˜å‚¨
        for i, text in enumerate(test_texts):
            success = vector_store_manager.add_texts(
                [text], 
                [{'source': f'test_{i}', 'timestamp': time.time()}]
            )
            if success:
                print(f"âœ… æ–‡æœ¬ {i+1} æ·»åŠ åˆ°å‘é‡å­˜å‚¨æˆåŠŸ")
            else:
                print(f"âŒ æ–‡æœ¬ {i+1} æ·»åŠ åˆ°å‘é‡å­˜å‚¨å¤±è´¥")
        
        # æµ‹è¯•ç›¸ä¼¼æ€§æœç´¢
        print("\nğŸ” å¼€å§‹ç›¸ä¼¼æ€§æœç´¢æµ‹è¯•...")
        query = "äººå·¥æ™ºèƒ½æŠ€æœ¯"
        search_results = vector_store_manager.similarity_search(query, k=3)
        print(f"ğŸ” æŸ¥è¯¢: '{query}'")
        print(f"ğŸ“Š æœç´¢ç»“æœæ•°é‡: {len(search_results)}")
        
        for i, result in enumerate(search_results):
            print(f"   ç»“æœ {i+1}: {result.page_content[:50]}...")
            print(f"   å…ƒæ•°æ®: {result.metadata}")
        
        # æµ‹è¯•ä¿å­˜å’ŒåŠ è½½
        print("\nğŸ’¾ å¼€å§‹ä¿å­˜å’ŒåŠ è½½æµ‹è¯•...")
        
        # ä¿å­˜å‘é‡å­˜å‚¨
        save_success = vector_store_manager.save()
        if save_success:
            print("âœ… å‘é‡å­˜å‚¨ä¿å­˜æˆåŠŸ")
        else:
            print("âŒ å‘é‡å­˜å‚¨ä¿å­˜å¤±è´¥")
        
        # æ¸…ç©ºå½“å‰å‘é‡å­˜å‚¨
        vector_store_manager.clear()
        print("ğŸ—‘ï¸ å‘é‡å­˜å‚¨å·²æ¸…ç©º")
        
        # é‡æ–°åŠ è½½å‘é‡å­˜å‚¨
        load_success = vector_store_manager.load()
        if load_success:
            print("âœ… å‘é‡å­˜å‚¨åŠ è½½æˆåŠŸ")
            
            # éªŒè¯æ•°æ®æ˜¯å¦æ¢å¤
            status_after_load = vector_store_manager.get_status()
            print(f"ğŸ“Š åŠ è½½åçŠ¶æ€: {status_after_load}")
        else:
            print("âŒ å‘é‡å­˜å‚¨åŠ è½½å¤±è´¥")
        
        print("\nğŸ‰ ç¬¬ä¸€é˜¶æ®µæµ‹è¯•å®Œæˆï¼")
        return True
        
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        logging.error(f"æµ‹è¯•é”™è¯¯: {e}", exc_info=True)
        return False

def test_performance_comparison():
    """æµ‹è¯•æ€§èƒ½å¯¹æ¯”"""
    print("\nâš¡ æ€§èƒ½å¯¹æ¯”æµ‹è¯•")
    print("=" * 40)
    
    try:
        from config.config_manager import ConfigManager
        from core.model_caller import LangChainModelCaller
        from vectorization.text_vectorizer import LangChainTextVectorizer
        
        config_manager = ConfigManager()
        model_caller = LangChainModelCaller(config_manager)
        text_vectorizer = LangChainTextVectorizer(config_manager)
        
        # æµ‹è¯•æ–‡æœ¬
        test_text = "è¿™æ˜¯ä¸€ä¸ªç”¨äºæ€§èƒ½æµ‹è¯•çš„æ–‡æœ¬ã€‚" * 100
        
        # æµ‹è¯•æ–‡æœ¬åˆ†å‰²æ€§èƒ½
        print("ğŸ“ æµ‹è¯•æ–‡æœ¬åˆ†å‰²æ€§èƒ½...")
        start_time = time.time()
        chunks = text_vectorizer.split_text(test_text, chunk_size=500, chunk_overlap=50)
        split_time = time.time() - start_time
        print(f"â±ï¸ æ–‡æœ¬åˆ†å‰²è€—æ—¶: {split_time:.3f}ç§’ï¼Œç”Ÿæˆäº† {len(chunks)} ä¸ªå—")
        
        # æµ‹è¯•å‘é‡åŒ–æ€§èƒ½
        print("\nğŸ¤– æµ‹è¯•å‘é‡åŒ–æ€§èƒ½...")
        start_time = time.time()
        result = text_vectorizer.vectorize(test_text[:1000])
        vectorize_time = time.time() - start_time
        print(f"â±ï¸ å‘é‡åŒ–è€—æ—¶: {vectorize_time:.3f}ç§’")
        
        # æµ‹è¯•æ‰¹é‡å¤„ç†æ€§èƒ½
        print("\nğŸ“¦ æµ‹è¯•æ‰¹é‡å¤„ç†æ€§èƒ½...")
        test_texts = [f"æµ‹è¯•æ–‡æœ¬ {i}" * 20 for i in range(10)]
        
        start_time = time.time()
        results = text_vectorizer.vectorize_batch(test_texts)
        batch_time = time.time() - start_time
        
        success_count = len([r for r in results if r['vectorization_status'] == 'success'])
        print(f"â±ï¸ æ‰¹é‡å¤„ç†è€—æ—¶: {batch_time:.3f}ç§’ï¼ŒæˆåŠŸç‡: {success_count}/{len(test_texts)}")
        
        print("\nâœ… æ€§èƒ½æµ‹è¯•å®Œæˆ")
        
    except Exception as e:
        print(f"âŒ æ€§èƒ½æµ‹è¯•å¤±è´¥: {e}")
        logging.error(f"æ€§èƒ½æµ‹è¯•é”™è¯¯: {e}", exc_info=True)

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ”§ LangChainæ”¹é€ ç¬¬ä¸€é˜¶æ®µæµ‹è¯•ç¨‹åº")
    print("=" * 60)
    
    # æ£€æŸ¥ä¾èµ–
    print("ğŸ“‹ æ£€æŸ¥ä¾èµ–åŒ…...")
    try:
        import langchain
        print(f"âœ… LangChainç‰ˆæœ¬: {langchain.__version__}")
    except ImportError:
        print("âŒ LangChainæœªå®‰è£…ï¼Œè¯·å…ˆå®‰è£…: pip install langchain")
        return
    
    try:
        import faiss
        print(f"âœ… FAISSç‰ˆæœ¬: {faiss.__version__}")
    except ImportError:
        print("âŒ FAISSæœªå®‰è£…ï¼Œè¯·å…ˆå®‰è£…: pip install faiss-cpu")
        return
    
    try:
        import dashscope
        print(f"âœ… DashScopeå·²å®‰è£…")
    except ImportError:
        print("âŒ DashScopeæœªå®‰è£…ï¼Œè¯·å…ˆå®‰è£…: pip install dashscope")
        return
    
    print("âœ… æ‰€æœ‰ä¾èµ–åŒ…æ£€æŸ¥å®Œæˆ")
    
    # è¿è¡ŒåŠŸèƒ½æµ‹è¯•
    if test_langchain_components():
        print("\nğŸ¯ åŠŸèƒ½æµ‹è¯•é€šè¿‡ï¼Œå¼€å§‹æ€§èƒ½æµ‹è¯•...")
        test_performance_comparison()
        
        print("\n" + "=" * 60)
        print("ğŸ‰ ç¬¬ä¸€é˜¶æ®µæ”¹é€ æµ‹è¯•å…¨éƒ¨å®Œæˆï¼")
        print("âœ… LangChainç»„ä»¶åŠŸèƒ½æ­£å¸¸")
        print("âœ… å‘é‡å­˜å‚¨ç®¡ç†æ­£å¸¸")
        print("âœ… æ–‡æœ¬å¤„ç†æµç¨‹æ­£å¸¸")
        print("âœ… æ€§èƒ½è¡¨ç°è‰¯å¥½")
        print("\nğŸš€ å¯ä»¥è¿›å…¥ç¬¬äºŒé˜¶æ®µæ”¹é€ ")
    else:
        print("\nâŒ åŠŸèƒ½æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯")
        print("ğŸ”§ éœ€è¦ä¿®å¤é—®é¢˜åé‡æ–°æµ‹è¯•")

if __name__ == "__main__":
    main()
