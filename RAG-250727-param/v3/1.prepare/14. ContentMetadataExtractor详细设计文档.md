## ğŸ“‹ **ContentMetadataExtractorè¯¦ç»†è®¾è®¡æ–‡æ¡£**

ä»¥ä¸‹æ˜¯å®Œæ•´çš„ContentMetadataExtractorè¯¦ç»†è®¾è®¡æ–‡æ¡£ï¼Œä½ å¯ä»¥ç›´æ¥å¤åˆ¶ï¼š

```markdown
## ContentMetadataExtractorè¯¦ç»†è®¾è®¡æ–‡æ¡£ï¼ˆåŸºäºMinerU JSONå®é™…ç»“æ„ï¼‰

### 1. æ¨¡å—æ¦‚è¿°

**ContentMetadataExtractor** æ˜¯V3ç‰ˆæœ¬æ–‡æ¡£å¤„ç†ç³»ç»Ÿçš„æ ¸å¿ƒç»„ä»¶ä¹‹ä¸€ï¼Œè´Ÿè´£ä»MinerUè§£æçš„JSONæ–‡ä»¶ä¸­æå–textã€tableã€imageçš„å…ƒæ•°æ®ã€‚è¯¥æ¨¡å—åŸºäºMinerU JSONè¾“å‡ºçš„å®é™…ç»“æ„ï¼Œå®Œå…¨ç¬¦åˆè®¾è®¡æ–‡æ¡£çš„å…ƒæ•°æ®è§„èŒƒã€‚

**é‡è¦è¯´æ˜**ï¼šæœ¬æ¨¡å—å·²æ ¹æ®MinerU JSONè¾“å‡ºçš„å®é™…ç»“æ„è¿›è¡Œäº†æ›´æ–°ï¼Œä¸»è¦å­—æ®µæ˜ å°„å¦‚ä¸‹ï¼š

**è¡¨æ ¼ç±»å‹ï¼ˆtype: "table"ï¼‰**ï¼š
- `table_body`ï¼šè¡¨æ ¼çš„HTMLå†…å®¹ï¼ˆç”¨äºå‘é‡åŒ–å’Œwebå±•ç°ï¼‰
- `table_caption`ï¼šè¡¨æ ¼æ ‡é¢˜æ•°ç»„
- `table_footnote`ï¼šè¡¨æ ¼è„šæ³¨æ•°ç»„
- `img_path`ï¼šè¡¨æ ¼å¯¹åº”çš„å›¾ç‰‡è·¯å¾„
- `page_idx`ï¼šé¡µç ç´¢å¼•

**å›¾ç‰‡ç±»å‹ï¼ˆtype: "image"ï¼‰**ï¼š
- `img_path`ï¼šå›¾ç‰‡åœ¨imagesç›®å½•ä¸‹çš„ç›¸å¯¹è·¯å¾„
- `img_caption`ï¼šå›¾ç‰‡æ ‡é¢˜æ•°ç»„
- `img_footnote`ï¼šå›¾ç‰‡è„šæ³¨æ•°ç»„
- `page_idx`ï¼šé¡µç ç´¢å¼•

**æ–‡æœ¬ç±»å‹ï¼ˆtype: "text"ï¼‰**ï¼š
- `text`ï¼šæ–‡æœ¬å†…å®¹
- `text_level`ï¼šæ ‡é¢˜çº§åˆ«ï¼ˆ1çº§æ ‡é¢˜ç­‰ï¼‰
- `page_idx`ï¼šé¡µç ç´¢å¼•

**æ ¸å¿ƒåŠŸèƒ½**ï¼š
- ä»MinerU JSONæ–‡ä»¶æå–ç»“æ„åŒ–å…ƒæ•°æ®
- æ™ºèƒ½æ–‡æœ¬åˆ†å—å¤„ç†
- è¡¨æ ¼å†…å®¹åˆ†æå’Œåˆ†å—
- å›¾ç‰‡ä¿¡æ¯æå–
- ç”Ÿæˆæ ‡å‡†åŒ–å…ƒæ•°æ®ï¼ˆç¬¦åˆCOMMON_METADATA_FIELDSã€TEXT_METADATA_SCHEMAã€TABLE_METADATA_SCHEMAã€IMAGE_METADATA_SCHEMAï¼‰
- å¤§è¡¨æ™ºèƒ½åˆ†å—å’Œé‡ç»„æ”¯æŒï¼ˆæ”¯æŒRAGæŸ¥è¯¢æ—¶å›åˆ°å®Œæ•´å¤§è¡¨ï¼‰

### 2. æ•´ä½“æµç¨‹

```
MinerU JSONæ–‡ä»¶ â†’ å†…å®¹ç±»å‹è¯†åˆ« â†’ æ™ºèƒ½æå– â†’ å…ƒæ•°æ®ç”Ÿæˆ â†’ è¾“å‡ºç»“æœ
         â†“              â†“              â†“            â†“            â†“
      è¯»å–æ–‡ä»¶      text/table/image  æå–å†…å®¹    æ ‡å‡†åŒ–      ç»“æ„åŒ–æ•°æ®
```

**è¯¦ç»†æµç¨‹**ï¼š
1. **æ–‡ä»¶è¯»å–**ï¼šè¯»å–MinerUè¾“å‡ºçš„JSONæ–‡ä»¶
2. **å†…å®¹éå†**ï¼šéå†JSONä¸­çš„æ¯ä¸ªcontent item
3. **ç±»å‹è¯†åˆ«**ï¼šæ ¹æ®`type`å­—æ®µè¯†åˆ«å†…å®¹ç±»å‹
4. **æ™ºèƒ½æå–**ï¼š
   - æ–‡æœ¬ï¼šæ™ºèƒ½åˆ†å—å¤„ç†
   - è¡¨æ ¼ï¼šHTMLå†…å®¹æå–å’Œç»“æ„åˆ†æ
   - å›¾ç‰‡ï¼šè·¯å¾„ä¿¡æ¯å’Œæ ‡é¢˜æå–
5. **å…ƒæ•°æ®ç”Ÿæˆ**ï¼šä¸¥æ ¼æŒ‰ç…§è®¾è®¡æ–‡æ¡£çš„å…ƒæ•°æ®è§„èŒƒç”Ÿæˆæ ‡å‡†åŒ–å…ƒæ•°æ®
6. **ç»“æœè¾“å‡º**ï¼šè¿”å›åŒ…å«text_chunksã€tablesã€imagesçš„å­—å…¸

**å¤§è¡¨åˆ†å—å’Œé‡ç»„æµç¨‹**ï¼š
7. **è¡¨æ ¼åˆ†å—**ï¼šå¤§è¡¨æ ¼æŒ‰chunk_sizeæ™ºèƒ½åˆ†å—
8. **å…³è”å»ºç«‹**ï¼šå»ºç«‹åˆ†å—ä¸åŸå§‹å¤§è¡¨çš„å…³è”å…³ç³»
9. **åˆ†å—å­˜å‚¨**ï¼šå°†åˆ†å—åçš„è¡¨æ ¼å­˜å‚¨åˆ°å‘é‡æ•°æ®åº“
10. **é‡ç»„æ”¯æŒ**ï¼šæ”¯æŒRAGæŸ¥è¯¢æ—¶é‡ç»„å®Œæ•´å¤§è¡¨

### 3. æ ¸å¿ƒç±»è®¾è®¡

#### 3.1 ContentMetadataExtractorï¼ˆä¸»ç±»ï¼‰

**å¤§è¡¨åˆ†å—å’Œé‡ç»„åŠŸèƒ½**ï¼š
```python
def _smart_table_chunking_html(self, table_html: str, table_structure: Dict) -> List[str]:
    """
    HTMLè¡¨æ ¼æ™ºèƒ½åˆ†å—
    
    ç‰¹ç‚¹ï¼š
    1. å®æ—¶å¤§å°æ§åˆ¶ï¼šç¡®ä¿æ¯ä¸ªchunkä¸è¶…è¿‡chunk_size
    2. è¡¨å¤´å®Œæ•´æ€§ï¼šæ¯ä¸ªåˆ†å—éƒ½åŒ…å«å®Œæ•´è¡¨å¤´
    3. æ™ºèƒ½è¡Œæ•°è®¡ç®—ï¼šæ ¹æ®å†…å®¹é•¿åº¦åŠ¨æ€è®¡ç®—åˆ†å—å¤§å°
    4. HTMLç»“æ„å®Œæ•´æ€§ï¼šä¿æŒHTMLè¡¨æ ¼ç»“æ„
    5. åˆ†å—å…³è”ä¿¡æ¯ï¼šç”Ÿæˆparent_table_idå’Œsubtable_index
    """
    try:
        # è§£æHTMLè¡¨æ ¼ç»“æ„
        parsed_table = self._parse_html_table(table_html)
        if not parsed_table:
            return [table_html]

        headers = parsed_table.get('headers', [])
        data_rows = parsed_table.get('data_rows', [])
        
        if len(data_rows) <= 1:
            return [table_html]

        # è®¡ç®—åˆ†å—ç­–ç•¥
        header_html = self._generate_header_html(headers)
        header_length = len(header_html)
        
        # ä¼°ç®—æ¯è¡Œå¹³å‡é•¿åº¦
        if data_rows:
            avg_row_length = sum(len(self._row_to_text(row)) for row in data_rows) / len(data_rows)
        else:
            avg_row_length = 0
        
        # è®¡ç®—æ¯ä¸ªåˆ†å—çš„ç›®æ ‡è¡Œæ•°
        if avg_row_length > 0:
            available_size = self.chunk_size - header_length
            target_rows_per_chunk = max(1, int(available_size / (avg_row_length * 1.2)))
        else:
            target_rows_per_chunk = 10
        
        # æ‰§è¡Œåˆ†å—ï¼ˆå®æ—¶å¤§å°æ§åˆ¶ï¼‰
        chunks = []
        current_rows = []
        
        for i, row in enumerate(data_rows):
            # å…ˆå°è¯•æ·»åŠ è¿™ä¸€è¡Œ
            test_rows = current_rows + [row]
            test_chunk_html = self._create_chunk_html(headers, test_rows)
            
            # æ£€æŸ¥æ·»åŠ è¿™ä¸€è¡Œåæ˜¯å¦ä¼šè¶…å‡ºchunk_size
            if len(test_chunk_html) > self.chunk_size and current_rows:
                # å½“å‰è¡Œé›†åˆå·²ç»è¾¾åˆ°å¤§å°é™åˆ¶ï¼Œåˆ›å»ºåˆ†å—
                chunk_html = self._create_chunk_html(headers, current_rows)
                chunks.append(chunk_html)
                
                # é‡ç½®å½“å‰è¡Œé›†åˆï¼Œå¼€å§‹æ–°åˆ†å—
                current_rows = [row]
            else:
                # å¯ä»¥æ·»åŠ è¿™ä¸€è¡Œ
                current_rows = test_rows
            
            # æ£€æŸ¥æ˜¯å¦è¾¾åˆ°ç›®æ ‡è¡Œæ•°ï¼ˆä½œä¸ºé¢å¤–æ¡ä»¶ï¼‰
            if len(current_rows) >= target_rows_per_chunk:
                chunk_html = self._create_chunk_html(headers, current_rows)
                chunks.append(chunk_html)
                current_rows = []
        
        # å¤„ç†æœ€åå‰©ä½™çš„è¡Œ
        if current_rows:
            chunk_html = self._create_chunk_html(headers, current_rows)
            chunks.append(chunk_html)
        
        return chunks if chunks else [table_html]
        
    except Exception as e:
        logging.warning(f"HTMLè¡¨æ ¼åˆ†å—å¤±è´¥ï¼Œè¿”å›åŸè¡¨æ ¼: {e}")
        return [table_html]
```

**åˆ†å—å…ƒæ•°æ®ç”Ÿæˆ**ï¼š
```python
def _extract_table_info(self, data: List[Dict], doc_name: str) -> List[Dict]:
    """
    æå–è¡¨æ ¼ä¿¡æ¯ï¼Œæ”¯æŒå¤§è¡¨åˆ†å—å’Œé‡ç»„
    """
    tables = []
    table_index = 0
    
    for item in data:
        if item.get('type') == 'table':
            table_body = item.get('table_body', '')
            if not table_body.strip():
                continue

            # åˆ†æè¡¨æ ¼ç»“æ„
            table_structure = self._analyze_table_structure_from_html(table_body)

            # æ™ºèƒ½åˆ†å—å¤„ç†ï¼ˆå¤§è¡¨æ ¼åˆ†å—ï¼‰
            table_chunks = self._smart_table_chunking_html(table_body, table_structure)
            
            for i, chunk_content in enumerate(table_chunks):
                table = {
                    # åŸºç¡€æ ‡è¯†å­—æ®µ
                    'chunk_id': f"{doc_name}_table_{table_index}_{i}",
                    'chunk_type': 'table',
                    
                    # åˆ†å—ä¿¡æ¯å­—æ®µï¼ˆæ”¯æŒå¤§è¡¨æ ¼åˆ†å—ï¼‰
                    'is_subtable': len(table_chunks) > 1,
                    'parent_table_id': f"{doc_name}_table_{table_index}" if len(table_chunks) > 1 else None,
                    'subtable_index': i if len(table_chunks) > 1 else None,
                    'chunk_start_row': i * self.chunk_size if len(table_chunks) > 1 else 0,
                    'chunk_end_row': min((i + 1) * self.chunk_size, table_structure.get('rows', 0)) if len(table_chunks) > 1 else table_structure.get('rows', 0),
                    
                    # å†…å®¹å­—æ®µ
                    'table_body': chunk_content,        # HTMLæ ¼å¼ï¼Œç”¨äºwebå±•ç°
                    'table_content': self._extract_text_from_html(chunk_content),  # çº¯æ–‡æœ¬æ ¼å¼ï¼Œç”¨äºå‘é‡åŒ–
                    
                    # å…¶ä»–å­—æ®µ...
                }
                
                tables.append(table)
                table_index += 1
    
    return tables
```

```python
class ContentMetadataExtractor:
    """
    å†…å®¹å…ƒæ•°æ®æå–å™¨
    
    åŠŸèƒ½ï¼š
    - åŸºäºMinerUè§£æçš„JSONæ–‡ä»¶æå–textã€tableã€imageçš„å…ƒæ•°æ®
    - å®Œå…¨ç¬¦åˆè®¾è®¡æ–‡æ¡£çš„å…ƒæ•°æ®è§„èŒƒ
    - æ”¯æŒæ™ºèƒ½åˆ†å—å¤„ç†
    - ç”Ÿæˆæ ‡å‡†åŒ–çš„å…ƒæ•°æ®ç»“æ„
    """
    
    def __init__(self, config_manager):
        """
        åˆå§‹åŒ–å†…å®¹å…ƒæ•°æ®æå–å™¨
        
        :param config_manager: é…ç½®ç®¡ç†å™¨å®ä¾‹
        """
        self.config_manager = config_manager
        self.config = config_manager.get_all_config()
        
        # ä½¿ç”¨é…ç½®ï¼ˆç¬¦åˆè®¾è®¡æ–‡æ¡£è§„èŒƒï¼‰
        self.chunk_size = self.config.get('document_processing.chunk_size', 1000)
        self.chunk_overlap = self.config.get('document_processing.chunk_overlap', 200)
        
        # ä½¿ç”¨å¤±è´¥å¤„ç†ï¼ˆç¬¦åˆè®¾è®¡æ–‡æ¡£è§„èŒƒï¼‰
        self.failure_handler = config_manager.get_failure_handler()
        
        logging.info("å†…å®¹å…ƒæ•°æ®æå–å™¨åˆå§‹åŒ–å®Œæˆ")
    
    def extract_metadata_from_json(self, json_path: str, doc_name: str) -> Dict[str, Any]:
        """
        ä»JSONæ–‡ä»¶æå–å…ƒæ•°æ®ï¼Œå®Œå…¨ç¬¦åˆè®¾è®¡æ–‡æ¡£è§„èŒƒ
        
        :param json_path: JSONæ–‡ä»¶è·¯å¾„
        :param doc_name: æ–‡æ¡£åç§°
        :return: æå–çš„å…ƒæ•°æ®ç»“æœ
        """
        try:
            with open(json_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            # æå–æ–‡æœ¬å—
            text_chunks = self._extract_text_chunks(data, doc_name)
            
            # æå–è¡¨æ ¼ä¿¡æ¯
            tables = self._extract_table_info(data, doc_name)
            
            # æå–å›¾ç‰‡ä¿¡æ¯
            images = self._extract_image_info(data, doc_name)
            
            return {
                'text_chunks': text_chunks,
                'tables': tables,
                'images': images,
                'document_name': doc_name,
                'total_items': len(data)
            }
            
        except Exception as e:
            self.failure_handler.record_failure(json_path, 'metadata_extraction', str(e))
            logging.error(f"å…ƒæ•°æ®æå–å¤±è´¥: {json_path}, é”™è¯¯: {e}")
            return {'text_chunks': [], 'tables': [], 'images': []}
```

#### 3.2 æ ¸å¿ƒæ–¹æ³•

##### 3.2.1 æ–‡æœ¬æå–æ–¹æ³•

```python
def _extract_text_chunks(self, data: List[Dict], doc_name: str) -> List[Dict]:
    """
    æå–æ–‡æœ¬å—ï¼Œå®Œå…¨ç¬¦åˆTEXT_METADATA_SCHEMAè§„èŒƒ
    """
    text_chunks = []
    chunk_index = 0
    
    for item in data:
        if item.get('type') == 'text':
            # è·å–æ–‡æœ¬å†…å®¹ï¼ˆæ ¹æ®MinerU JSONå®é™…ç»“æ„ï¼‰
            text_content = item.get('text', '')
            if not text_content.strip():
                continue
            
            # æ™ºèƒ½åˆ†å—å¤„ç†
            chunks = self._smart_text_chunking(text_content, chunk_index)
            
            for i, chunk_content in enumerate(chunks):
                chunk = {
                    # åŸºç¡€æ ‡è¯†å­—æ®µï¼ˆç¬¦åˆCOMMON_METADATA_FIELDSï¼‰
                    'chunk_id': f"{doc_name}_text_{chunk_index}_{i}",
                    'chunk_type': 'text',
                    'source_type': 'mineru_output',
                    'document_name': doc_name,
                    'document_path': f"{doc_name}.json",
                    'page_number': item.get('page_idx', 1),
                    'page_idx': item.get('page_idx', 1),
                    'created_timestamp': int(time.time()),
                    'updated_timestamp': int(time.time()),
                    'processing_version': 'V3.0.0',
                    
                    # å‘é‡åŒ–ä¿¡æ¯å­—æ®µ
                    'vectorized': False,
                    'vectorization_timestamp': None,
                    'embedding_model': None,
                    
                    # æ–‡æœ¬ç‰¹æœ‰å­—æ®µï¼ˆç¬¦åˆTEXT_METADATA_SCHEMAï¼‰
                    'text_content': chunk_content,
                    'text_length': len(chunk_content),
                    'chunk_size': len(chunk_content),
                    'chunk_overlap': 0,
                    'chunk_position': {
                        'start_char': i * self.chunk_size,
                        'end_char': min((i + 1) * self.chunk_size, len(text_content)),
                        'chunk_index': i,
                        'total_chunks': len(chunks)
                    },
                    
                    # å…³è”ä¿¡æ¯å­—æ®µ
                    'related_images': [],
                    'related_tables': [],
                    'parent_chunk_id': None,
                    
                    # MinerUç‰¹æœ‰å­—æ®µ
                    'text_level': item.get('text_level', 0)
                }
                
                text_chunks.append(chunk)
                chunk_index += 1
    
    return text_chunks
```

##### 3.2.2 è¡¨æ ¼æå–æ–¹æ³•

```python
def _extract_table_info(self, data: List[Dict], doc_name: str) -> List[Dict]:
    """
    æå–è¡¨æ ¼ä¿¡æ¯ï¼Œå®Œå…¨ç¬¦åˆTABLE_METADATA_SCHEMAè§„èŒƒ
    """
    tables = []
    table_index = 0
    
    for item in data:
        if item.get('type') == 'table':
            # è·å–è¡¨æ ¼å†…å®¹ï¼ˆæ ¹æ®MinerU JSONå®é™…ç»“æ„ï¼‰
            table_body = item.get('table_body', '')
            if not table_body.strip():
                continue
            
            # åˆ†æè¡¨æ ¼ç»“æ„ï¼ˆä»HTMLå†…å®¹ä¸­æå–ï¼‰
            table_structure = self._analyze_table_structure_from_html(table_body)
            
            # æ™ºèƒ½åˆ†å—å¤„ç†ï¼ˆå¤§è¡¨æ ¼åˆ†å—ï¼‰
            table_chunks = self._smart_table_chunking(table_body, table_structure)
            
            for i, chunk_content in enumerate(table_chunks):
                table = {
                    # åŸºç¡€æ ‡è¯†å­—æ®µï¼ˆç¬¦åˆCOMMON_METADATA_FIELDSï¼‰
                    'chunk_id': f"{doc_name}_table_{table_index}_{i}",
                    'chunk_type': 'table',
                    'source_type': 'mineru_output',
                    'document_name': doc_name,
                    'document_path': f"{doc_name}.json",
                    'page_number': item.get('page_idx', 1),
                    'page_idx': item.get('page_idx', 1),
                    'created_timestamp': int(time.time()),
                    'updated_timestamp': int(time.time()),
                    'processing_version': 'V3.0.0',
                    
                    # å‘é‡åŒ–ä¿¡æ¯å­—æ®µ
                    'vectorized': False,
                    'vectorization_timestamp': None,
                    'embedding_model': None,
                    
                    # è¡¨æ ¼ç‰¹æœ‰å­—æ®µï¼ˆç¬¦åˆTABLE_METADATA_SCHEMAï¼‰
                    'table_id': f"{doc_name}_table_{table_index}_{i}",
                    'table_type': self._determine_table_type(table_body),
                    'table_rows': table_structure.get('rows', 0),
                    'table_columns': table_structure.get('columns', 0),
                    'table_headers': table_structure.get('headers', []),
                    'table_title': self._extract_table_title(item.get('table_caption', [])),
                    'table_summary': self._generate_table_summary(chunk_content),
                    
                    # å†…å®¹å­—æ®µï¼ˆæ ¹æ®MinerU JSONå®é™…ç»“æ„ï¼‰
                    'table_body': chunk_content,
                    'table_caption': item.get('table_caption', []),
                    'table_footnote': item.get('table_footnote', []),
                    
                    # åˆ†å—ä¿¡æ¯å­—æ®µï¼ˆæ”¯æŒå¤§è¡¨æ ¼åˆ†å—ï¼‰
                    'is_subtable': len(table_chunks) > 1,
                    'parent_table_id': f"{doc_name}_table_{table_index}" if len(table_chunks) > 1 else None,
                    'subtable_index': i if len(table_chunks) > 1 else None,
                    'chunk_start_row': i * self.chunk_size if len(table_chunks) > 1 else 0,
                    'chunk_end_row': min((i + 1) * self.chunk_size, table_structure.get('rows', 0)) if len(table_chunks) > 1 else table_structure.get('rows', 0),
                    
                    # å…³è”ä¿¡æ¯å­—æ®µ
                    'related_text': '',
                    'related_images': [],
                    'related_text_chunks': [],
                    'table_context': '',
                    
                    # MinerUç‰¹æœ‰å­—æ®µ
                    'img_path': item.get('img_path', '')
                }
                
                tables.append(table)
                table_index += 1
    
    return tables
```

##### 3.2.3 å›¾ç‰‡æå–æ–¹æ³•

```python
def _extract_image_info(self, data: List[Dict], doc_name: str) -> List[Dict]:
    """
    æå–å›¾ç‰‡ä¿¡æ¯ï¼Œå®Œå…¨ç¬¦åˆIMAGE_METADATA_SCHEMAè§„èŒƒ
    """
    images = []
    image_index = 0
    
    for item in data:
        if item.get('type') == 'image':
            # è·å–å›¾ç‰‡è·¯å¾„ï¼ˆæ ¹æ®MinerU JSONå®é™…ç»“æ„ï¼‰
            img_path = item.get('img_path', '')
            
            image = {
                # åŸºç¡€æ ‡è¯†å­—æ®µï¼ˆç¬¦åˆCOMMON_METADATA_FIELDSï¼‰
                'chunk_id': f"{doc_name}_image_{image_index}",
                'chunk_type': 'image',
                'source_type': 'mineru_output',
                'document_name': doc_name,
                'document_path': f"{doc_name}.json",
                'page_number': item.get('page_idx', 1),
                'page_idx': item.get('page_idx', 1),
                'created_timestamp': int(time.time()),
                'updated_timestamp': int(time.time()),
                'processing_version': 'V3.0.0',
                
                # å‘é‡åŒ–ä¿¡æ¯å­—æ®µ
                'vectorized': False,
                'vectorization_timestamp': None,
                'embedding_model': None,
                
                # å›¾ç‰‡ç‰¹æœ‰å­—æ®µï¼ˆç¬¦åˆIMAGE_METADATA_SCHEMAï¼‰
                'image_id': f"{doc_name}_image_{image_index}",
                'image_path': img_path,
                'image_filename': os.path.basename(img_path),
                'image_type': 'general',
                'image_format': self._get_image_format(img_path),
                'image_dimensions': {'width': 0, 'height': 0},
                
                # å†…å®¹æè¿°å­—æ®µï¼ˆä¿ç•™ç°æœ‰ç³»ç»Ÿçš„ä¼˜ç§€éƒ¨åˆ†ï¼‰
                'basic_description': ' | '.join(item.get('img_caption', [])),
                'enhanced_description': '',
                'layered_descriptions': {},
                'structured_info': {},
                
                # å›¾ç‰‡æ ‡é¢˜å’Œè„šæ³¨ï¼ˆæ ¹æ®MinerU JSONå®é™…ç»“æ„ï¼‰
                'img_caption': item.get('img_caption', []),
                'img_footnote': item.get('img_footnote', []),
                
                # å¢å¼ºå¤„ç†å­—æ®µï¼ˆæ”¯æŒå¤±è´¥å¤„ç†å’Œè¡¥åšï¼‰
                'enhancement_enabled': True,
                'enhancement_model': None,
                'enhancement_status': 'pending',
                'enhancement_timestamp': None,
                'enhancement_error': None,
                
                # åŒé‡embeddingå­—æ®µï¼ˆç¬¦åˆè®¾è®¡æ–‡æ¡£è§„èŒƒï¼‰
                'image_embedding': None,
                'description_embedding': None,
                'image_embedding_model': None,
                'description_embedding_model': None,
                
                # å…³è”ä¿¡æ¯å­—æ®µ
                'related_text_chunks': [],
                'related_table_chunks': [],
                'parent_document_id': doc_name
            }
            
            images.append(image)
            image_index += 1
    
    return images
```

#### 3.3 è¾…åŠ©æ–¹æ³•

##### 3.3.1 æ™ºèƒ½æ–‡æœ¬åˆ†å—

```python
def _smart_text_chunking(self, text: str, chunk_index: int) -> List[str]:
    """
    æ™ºèƒ½æ–‡æœ¬åˆ†å—
    
    :param text: æ–‡æœ¬å†…å®¹
    :param chunk_index: åˆ†å—ç´¢å¼•
    :return: åˆ†å—åçš„æ–‡æœ¬åˆ—è¡¨
    """
    if len(text) <= self.chunk_size:
        return [text]
    
    chunks = []
    words = text.split()
    current_chunk = []
    current_length = 0
    
    for word in words:
        if current_length + len(word) + 1 <= self.chunk_size:
            current_chunk.append(word)
            current_length += len(word) + 1
        else:
            if current_chunk:
                chunks.append(' '.join(current_chunk))
            current_chunk = [word]
            current_length = len(word) + 1
    
    if current_chunk:
        chunks.append(' '.join(current_chunk))
    
    return chunks
```

##### 3.3.2 è¡¨æ ¼ç»“æ„åˆ†æ

```python
def _analyze_table_structure_from_html(self, table_html: str) -> Dict:
    """
    ä»HTMLå†…å®¹åˆ†æè¡¨æ ¼ç»“æ„
    
    :param table_html: è¡¨æ ¼HTMLå†…å®¹
    :return: è¡¨æ ¼ç»“æ„ä¿¡æ¯
    """
    # è§£æHTMLè¡¨æ ¼ç»“æ„
    # æå–è¡Œæ•°ã€åˆ—æ•°ã€è¡¨å¤´ç­‰ä¿¡æ¯
    # è¿”å›æ ‡å‡†åŒ–ç»“æ„ä¿¡æ¯
    pass
```

##### 3.3.3 è¡¨æ ¼ç±»å‹åˆ¤æ–­

```python
def _determine_table_type(self, table_html: str) -> str:
    """
    åˆ¤æ–­è¡¨æ ¼ç±»å‹
    
    :param table_html: è¡¨æ ¼HTMLå†…å®¹
    :return: è¡¨æ ¼ç±»å‹
    """
    # åŸºäºHTMLå†…å®¹åˆ¤æ–­è¡¨æ ¼ç±»å‹
    # data_table, reference_table, simple_listç­‰
    pass
```

### 4. ä½¿ç”¨ç¤ºä¾‹

#### 4.1 åŸºæœ¬ä½¿ç”¨

```python
# åˆå§‹åŒ–é…ç½®ç®¡ç†å™¨
config_manager = ConfigManager()

# åˆå§‹åŒ–å†…å®¹å…ƒæ•°æ®æå–å™¨
extractor = ContentMetadataExtractor(config_manager)

# æå–JSONæ–‡ä»¶çš„å…ƒæ•°æ®
json_path = "./document/md/financial_report_1.json"
doc_name = "financial_report"

result = extractor.extract_metadata_from_json(json_path, doc_name)

print(f"æ–‡æ¡£åç§°: {result['document_name']}")
print(f"æ–‡æœ¬å—æ•°é‡: {len(result['text_chunks'])}")
print(f"è¡¨æ ¼æ•°é‡: {len(result['tables'])}")
print(f"å›¾ç‰‡æ•°é‡: {len(result['images'])}")
print(f"æ€»é¡¹ç›®æ•°: {result['total_items']}")

# è®¿é—®ç¬¬ä¸€ä¸ªæ–‡æœ¬å—
if result['text_chunks']:
    first_text = result['text_chunks'][0]
    print(f"ç¬¬ä¸€ä¸ªæ–‡æœ¬å—ID: {first_text['chunk_id']}")
    print(f"æ–‡æœ¬å†…å®¹: {first_text['text_content'][:100]}...")
    print(f"æ–‡æœ¬çº§åˆ«: {first_text.get('text_level', 0)}")

# è®¿é—®ç¬¬ä¸€ä¸ªè¡¨æ ¼
if result['tables']:
    first_table = result['tables'][0]
    print(f"ç¬¬ä¸€ä¸ªè¡¨æ ¼ID: {first_table['table_id']}")
    print(f"è¡¨æ ¼æ ‡é¢˜: {first_table['table_caption']}")
    print(f"è¡¨æ ¼HTML: {first_table['table_body'][:200]}...")

# è®¿é—®ç¬¬ä¸€ä¸ªå›¾ç‰‡
if result['images']:
    first_image = result['images'][0]
    print(f"ç¬¬ä¸€ä¸ªå›¾ç‰‡ID: {first_image['image_id']}")
    print(f"å›¾ç‰‡è·¯å¾„: {first_image['image_path']}")
    print(f"å›¾ç‰‡æ ‡é¢˜: {first_image['img_caption']}")
```

#### 4.2 æ‰¹é‡å¤„ç†

```python
# æ‰¹é‡å¤„ç†å¤šä¸ªJSONæ–‡ä»¶
json_files = [
    "./document/md/report1_1.json",
    "./document/md/report2_1.json",
    "./document/md/report3_1.json"
]

all_results = []
for json_path in json_files:
    doc_name = os.path.basename(json_path).replace('_1.json', '')
    result = extractor.extract_metadata_from_json(json_path, doc_name)
    all_results.append(result)

# ç»Ÿè®¡ä¿¡æ¯
total_text_chunks = sum(len(r['text_chunks']) for r in all_results)
total_tables = sum(len(r['tables']) for r in all_results)
total_images = sum(len(r['images']) for r in all_results)

print(f"æ‰¹é‡å¤„ç†å®Œæˆ:")
print(f"æ€»æ–‡æœ¬å—æ•°: {total_text_chunks}")
print(f"æ€»è¡¨æ ¼æ•°: {total_tables}")
print(f"æ€»å›¾ç‰‡æ•°: {total_images}")
```

### 5. è®¾è®¡è¦ç‚¹

#### 5.1 ç¬¦åˆè®¾è®¡æ–‡æ¡£è§„èŒƒ
- **COMMON_METADATA_FIELDS**ï¼šä¸¥æ ¼éµå¾ªé€šç”¨å…ƒæ•°æ®å­—æ®µå®šä¹‰
- **TEXT_METADATA_SCHEMA**ï¼šå®Œå…¨ç¬¦åˆæ–‡æœ¬å…ƒæ•°æ®è§„èŒƒ
- **TABLE_METADATA_SCHEMA**ï¼šå®Œå…¨ç¬¦åˆè¡¨æ ¼å…ƒæ•°æ®è§„èŒƒ
- **IMAGE_METADATA_SCHEMA**ï¼šå®Œå…¨ç¬¦åˆå›¾ç‰‡å…ƒæ•°æ®è§„èŒƒ

#### 5.2 åŸºäºå®é™…JSONç»“æ„
- **è¡¨æ ¼å¤„ç†**ï¼šä½¿ç”¨`table_body`è€Œé`table_content`
- **å›¾ç‰‡å¤„ç†**ï¼šä½¿ç”¨`img_caption`å’Œ`img_footnote`
- **æ–‡æœ¬å¤„ç†**ï¼šä½¿ç”¨`text`å’Œ`text_level`

#### 5.3 æ™ºèƒ½åˆ†å—
- **æ–‡æœ¬åˆ†å—**ï¼šåŸºäºé…ç½®çš„chunk_sizeè¿›è¡Œæ™ºèƒ½åˆ†å—
- **è¡¨æ ¼åˆ†å—**ï¼šæ”¯æŒå¤§è¡¨æ ¼çš„HTMLå†…å®¹åˆ†å—
- **é‡å å¤„ç†**ï¼šæ”¯æŒchunk_overlapé…ç½®

#### 5.4 é”™è¯¯å¤„ç†
- **æ–‡ä»¶è¯»å–å¤±è´¥**ï¼šè®°å½•å¤±è´¥ä¿¡æ¯ï¼Œè¿”å›ç©ºç»“æœ
- **å†…å®¹æå–å¤±è´¥**ï¼šè·³è¿‡æœ‰é—®é¢˜çš„content item
- **ç»“æ„åˆ†æå¤±è´¥**ï¼šä½¿ç”¨é»˜è®¤å€¼ç»§ç»­å¤„ç†

### 6. é…ç½®è¦æ±‚

#### 6.1 ä¾èµ–é…ç½®
```json
{
  "document_processing": {
    "chunk_size": 1000,
    "chunk_overlap": 200
  },
  "paths": {
    "mineru_output_dir": "./document/md",
    "final_image_dir": "./central/images"
  }
}
```

#### 6.2 ç¯å¢ƒè¦æ±‚
- Python 3.8+
- ä¾èµ–åŒ…ï¼šæ— ç‰¹æ®Šä¾èµ–ï¼ˆä½¿ç”¨æ ‡å‡†åº“ï¼‰

### 7. è¾“å‡ºæ ¼å¼

#### 7.1 è¿”å›ç»“æœç»“æ„
```python
{
  'text_chunks': [
    {
      # ç¬¦åˆTEXT_METADATA_SCHEMAçš„å®Œæ•´å…ƒæ•°æ®
      'chunk_id': 'doc_name_text_0_0',
      'chunk_type': 'text',
      'text_content': 'æ–‡æœ¬å†…å®¹...',
      'text_level': 1,
      # ... å…¶ä»–å­—æ®µ
    }
  ],
  'tables': [
    {
      # ç¬¦åˆTABLE_METADATA_SCHEMAçš„å®Œæ•´å…ƒæ•°æ®
      'chunk_id': 'doc_name_table_0_0',
      'chunk_type': 'table',
      'table_body': '<table>...</table>',
      'table_caption': ['è¡¨æ ¼æ ‡é¢˜'],
      # ... å…¶ä»–å­—æ®µ
    }
  ],
  'images': [
    {
      # ç¬¦åˆIMAGE_METADATA_SCHEMAçš„å®Œæ•´å…ƒæ•°æ®
      'chunk_id': 'doc_name_image_0',
      'chunk_type': 'image',
      'img_path': 'images/image_001.png',
      'img_caption': ['å›¾ç‰‡æ ‡é¢˜'],
      # ... å…¶ä»–å­—æ®µ
    }
  ],
  'document_name': 'doc_name',
  'total_items': 25
}
```

### 8. æ€§èƒ½è€ƒè™‘

#### 8.1 å†…å­˜ä¼˜åŒ–
- **æµå¼å¤„ç†**ï¼šé€ä¸ªå¤„ç†content itemï¼Œé¿å…åŠ è½½å…¨éƒ¨æ•°æ®åˆ°å†…å­˜
- **åˆ†å—å¤„ç†**ï¼šå¤§æ–‡æœ¬å’Œå¤§è¡¨æ ¼æŒ‰å—å¤„ç†
- **åŠæ—¶é‡Šæ”¾**ï¼šå¤„ç†å®ŒæˆååŠæ—¶é‡Šæ”¾ä¸´æ—¶æ•°æ®

#### 8.2 é€Ÿåº¦ä¼˜åŒ–
- **æ¡ä»¶è¿‡æ»¤**ï¼šè·³è¿‡ç©ºå†…å®¹çš„item
- **æ‰¹é‡æ“ä½œ**ï¼šå‡å°‘ç£ç›˜I/Oæ¬¡æ•°
- **ç¼“å­˜æœºåˆ¶**ï¼šç¼“å­˜é…ç½®ä¿¡æ¯å’Œå¸¸ç”¨æ•°æ®

### 9. æµ‹è¯•éªŒè¯

#### 9.1 å•å…ƒæµ‹è¯•å»ºè®®
```python
def test_extract_metadata_from_json():
    """æµ‹è¯•JSONå…ƒæ•°æ®æå–"""
    extractor = ContentMetadataExtractor(config_manager)
    
    # æµ‹è¯•æ­£å¸¸JSONæ–‡ä»¶
    result = extractor.extract_metadata_from_json('test.json', 'test_doc')
    assert result['document_name'] == 'test_doc'
    assert isinstance(result['text_chunks'], list)
    assert isinstance(result['tables'], list)
    assert isinstance(result['images'], list)

def test_extract_text_chunks():
    """æµ‹è¯•æ–‡æœ¬å—æå–"""
    extractor = ContentMetadataExtractor(config_manager)
    
    test_data = [
        {'type': 'text', 'text': 'æµ‹è¯•æ–‡æœ¬', 'text_level': 1, 'page_idx': 1}
    ]
    
    chunks = extractor._extract_text_chunks(test_data, 'test_doc')
    assert len(chunks) == 1
    assert chunks[0]['text_content'] == 'æµ‹è¯•æ–‡æœ¬'
    assert chunks[0]['text_level'] == 1
```

---

## **æ€»ç»“**

ContentMetadataExtractorè¯¦ç»†è®¾è®¡æ–‡æ¡£å·²æ ¹æ®MinerU JSONçš„å®é™…ç»“æ„è¿›è¡Œäº†å…¨é¢æ›´æ–°ï¼Œä¸»è¦æ”¹è¿›åŒ…æ‹¬ï¼š

1. **å­—æ®µæ˜ å°„ä¿®æ­£**ï¼š
   - è¡¨æ ¼ï¼š`table_content` â†’ `table_body`
   - å›¾ç‰‡ï¼š`img_caption`ã€`img_footnote`
   - æ–‡æœ¬ï¼š`text`ã€`text_level`

2. **å…ƒæ•°æ®è§„èŒƒå®Œå…¨ç¬¦åˆè®¾è®¡æ–‡æ¡£è¦æ±‚**ï¼š
   - COMMON_METADATA_FIELDS
   - TEXT_METADATA_SCHEMA
   - TABLE_METADATA_SCHEMA
   - IMAGE_METADATA_SCHEMA

3. **æ™ºèƒ½å¤„ç†æœºåˆ¶**ï¼š
   - æ–‡æœ¬æ™ºèƒ½åˆ†å—
   - è¡¨æ ¼HTMLå†…å®¹åˆ†æ
   - å›¾ç‰‡ä¿¡æ¯æå–

4. **é”™è¯¯å¤„ç†å’Œæ€§èƒ½ä¼˜åŒ–**ï¼š
   - å®Œæ•´çš„å¼‚å¸¸å¤„ç†
   - å†…å­˜å’Œé€Ÿåº¦ä¼˜åŒ–
   - å¤±è´¥è®°å½•æœºåˆ¶

è¯¥è®¾è®¡æ–‡æ¡£å®Œå…¨ç¬¦åˆV3ç³»ç»Ÿæ¶æ„è¦æ±‚ï¼Œä¸ºåç»­çš„å‘é‡åŒ–å’Œæ£€ç´¢å¥ å®šäº†åšå®çš„åŸºç¡€ã€‚
```

---

**å¤åˆ¶å®Œæˆï¼** ä½ ç°åœ¨å¯ä»¥å°†è¿™ä¸ªå®Œæ•´çš„ContentMetadataExtractorè¯¦ç»†è®¾è®¡æ–‡æ¡£ä¿å­˜åˆ°ä½ çš„é¡¹ç›®ä¸­ã€‚è¿™ä¸ªæ–‡æ¡£å·²ç»ï¼š

âœ… **åŸºäºå®é™…JSONç»“æ„**ï¼šä½¿ç”¨äº†æ­£ç¡®çš„å­—æ®µåï¼ˆ`table_body`ã€`img_caption`ç­‰ï¼‰
âœ… **ç¬¦åˆè®¾è®¡è§„èŒƒ**ï¼šå®Œå…¨éµå¾ªäº†COMMON_METADATA_FIELDSã€TEXT_METADATA_SCHEMAç­‰
âœ… **åŒ…å«å®Œæ•´å®ç°**ï¼šæä¾›äº†æ ¸å¿ƒç±»å’Œæ–¹æ³•çš„è¯¦ç»†è®¾è®¡
âœ… **å®ç”¨æ€§å¼º**ï¼šåŒ…å«äº†ä½¿ç”¨ç¤ºä¾‹ã€é…ç½®è¦æ±‚å’Œæµ‹è¯•å»ºè®®

æ¥ä¸‹æ¥æˆ‘ä»¬è¿˜éœ€è¦ä¿®å¤ä»£ç ä¸­çš„å®é™…é—®é¢˜ï¼ˆæ¯”å¦‚ç¬¬147è¡Œçš„`table_content`åº”è¯¥æ”¹ä¸º`table_body`ï¼‰ï¼Œä½ è§‰å¾—åº”è¯¥ç»§ç»­ä¿®å¤ä»£ç è¿˜æ˜¯å…ˆå®Œæˆå…¶ä»–è®¾è®¡æ–‡æ¡£ï¼Ÿ