#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å›¾ç‰‡å¢å¼ºæ–°ç¨‹åº - æŸ¥è¯¢ã€ç¡®è®¤å’Œæ·±åº¦å¤„ç†

åŠŸèƒ½è¯´æ˜ï¼š
1. æŸ¥è¯¢æ•°æ®åº“ä¸­çš„å›¾ç‰‡æ˜¯å¦åšäº†æ·±åº¦å¤„ç†ï¼Œåˆ—å‡ºå“ªäº›æ²¡åš
2. æ ¹æ®ç”¨æˆ·ç¡®è®¤å†³å®šæ˜¯å¦è¡¥åšæ·±åº¦å¤„ç†
3. å¤„ç†æ–¹å¼è¦å’Œä¸»ç¨‹åº image_enhancer.py ä¸€è‡´
4. å­—æ®µå’Œé€»è¾‘ä»¥ç°æœ‰æ•°æ®åº“ç»“æ„å’Œ image_enhancer.py ä¸ºå‡†
5. å¯ä»¥è°ƒç”¨ image_enhancer.py ä¸­çš„ç›¸åº”æ¨¡å—
"""

import os
import sys
import json
import time
import logging
from typing import List, Dict, Any, Optional

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = os.path.dirname(os.path.abspath(__file__))
sys.path.insert(0, project_root)

try:
    from langchain_community.vectorstores import FAISS
    from langchain_community.embeddings import DashScopeEmbeddings
    from config.settings import Settings
    from document_processing.image_enhancer import ImageEnhancer
    from document_processing.vector_generator import VectorGenerator
    from document_processing.image_processor import ImageProcessor
except ImportError as e:
    print(f"âŒ ç¼ºå°‘å¿…è¦çš„ä¾èµ–åŒ…: {e}")
    print("è¯·ç¡®ä¿é¡¹ç›®ä¾èµ–å·²æ­£ç¡®å®‰è£…")
    sys.exit(1)

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class ImageEnhanceNew:
    """å›¾ç‰‡å¢å¼ºæ–°ç¨‹åº - æŸ¥è¯¢ã€ç¡®è®¤å’Œæ·±åº¦å¤„ç†"""
    
    def __init__(self):
        """åˆå§‹åŒ–ç¨‹åº"""
        try:
            # åŠ è½½é…ç½®
            self.config = Settings.load_from_file('config.json')
            self.api_key = self.config.dashscope_api_key
            
            # ä½¿ç”¨ä¸»ç¨‹åºä¸­çš„ImageProcessoræ¥ç®¡ç†é…ç½®å’Œåˆå§‹åŒ–
            self.image_processor = ImageProcessor(self.api_key, self.config.__dict__)
            
            # åˆå§‹åŒ–å›¾åƒå¢å¼ºå™¨ï¼ˆé€šè¿‡ImageProcessorï¼‰
            if self.image_processor.enhancement_enabled:
                self.image_enhancer = self.image_processor.image_enhancer
            else:
                # å¦‚æœImageProcessorä¸­æ²¡æœ‰å¯ç”¨ï¼Œåˆ™æ‰‹åŠ¨åˆå§‹åŒ–
                image_config = {
                    'enable_enhancement': self.config.enable_enhancement,
                    'enhancement_model': self.config.enhancement_model,
                    'enhancement_max_tokens': self.config.enhancement_max_tokens,
                    'enhancement_temperature': self.config.enhancement_temperature,
                    'enhancement_batch_size': self.config.enhancement_batch_size,
                    'enable_progress_logging': self.config.enable_progress_logging
                }
                self.image_enhancer = ImageEnhancer(
                    api_key=self.api_key,
                    config=image_config
                )
            
            # åˆå§‹åŒ–å‘é‡ç”Ÿæˆå™¨ï¼ˆç”¨äºä¿å­˜æ•°æ®åº“ï¼‰
            self.vector_generator = VectorGenerator(self.config.__dict__)
            
            # å‘é‡æ•°æ®åº“è·¯å¾„ - ä½¿ç”¨é…ç½®ç®¡ç†
            self.vector_db_path = self.config.vector_db_dir
            
            logger.info("å›¾ç‰‡å¢å¼ºæ–°ç¨‹åºåˆå§‹åŒ–å®Œæˆ")
            
        except Exception as e:
            logger.error(f"åˆå§‹åŒ–å¤±è´¥: {e}")
            raise
    
    def load_vector_store(self) -> Optional[FAISS]:
        """åŠ è½½å‘é‡æ•°æ®åº“"""
        try:
            # ä½¿ç”¨é…ç½®ä¸­çš„åµŒå…¥æ¨¡å‹ï¼Œå¦‚æœæ²¡æœ‰é…ç½®åˆ™ä½¿ç”¨é»˜è®¤å€¼
            embedding_model = getattr(self.config, 'text_embedding_model', 'text-embedding-v1')
            embeddings = DashScopeEmbeddings(
                dashscope_api_key=self.api_key, 
                model=embedding_model
            )
            # ä½¿ç”¨é…ç½®ä¸­çš„å®‰å…¨è®¾ç½®ï¼Œå¦‚æœæ²¡æœ‰é…ç½®åˆ™ä½¿ç”¨é»˜è®¤å€¼
            allow_dangerous_deserialization = getattr(self.config, 'allow_dangerous_deserialization', True)
            vector_store = FAISS.load_local(
                self.vector_db_path, 
                embeddings, 
                allow_dangerous_deserialization=allow_dangerous_deserialization
            )
            logger.info(f"å‘é‡æ•°æ®åº“åŠ è½½æˆåŠŸï¼ŒåŒ…å« {len(vector_store.docstore._dict)} ä¸ªæ–‡æ¡£")
            return vector_store
            
        except Exception as e:
            logger.error(f"åŠ è½½å‘é‡æ•°æ®åº“å¤±è´¥: {e}")
            return None
    
    def query_image_status(self) -> Dict[str, List[Dict[str, Any]]]:
        """æŸ¥è¯¢æ•°æ®åº“ä¸­å›¾ç‰‡çš„å¤„ç†çŠ¶æ€"""
        print("ğŸ” æ­£åœ¨æŸ¥è¯¢æ•°æ®åº“ä¸­çš„å›¾ç‰‡çŠ¶æ€...")
        
        vector_store = self.load_vector_store()
        if not vector_store:
            return {'processed': [], 'unprocessed': []}
        
        processed_images = []
        unprocessed_images = []
        
        for doc_id, doc in vector_store.docstore._dict.items():
            metadata = doc.metadata if hasattr(doc, 'metadata') and doc.metadata else {}
            
            # æ£€æŸ¥æ˜¯å¦ä¸ºå›¾ç‰‡æ–‡æ¡£
            if metadata.get('chunk_type') == 'image':
                image_path = metadata.get('image_path', '')
                image_type = 'unknown'
                
                # ä½¿ç”¨ä¸»ç¨‹åºä¸­çš„å‡½æ•°æ£€æµ‹å›¾ç‰‡ç±»å‹
                if image_path and os.path.exists(image_path):
                    try:
                        image_type = self._detect_image_type(image_path)
                    except Exception as e:
                        logger.warning(f"æ£€æµ‹å›¾ç‰‡ç±»å‹å¤±è´¥: {e}")
                
                image_info = {
                    'doc_id': doc_id,
                    'image_path': image_path,
                    'document_name': metadata.get('document_name', 'æœªçŸ¥æ–‡æ¡£'),
                    'page_number': metadata.get('page_number', 1),
                    'image_id': metadata.get('image_id', 'unknown'),
                    'image_type': image_type,
                    'enhanced_description': metadata.get('enhanced_description', ''),
                    'has_layered': 'layered_descriptions' in metadata,
                    'has_structured': 'structured_info' in metadata,
                    'has_timestamp': 'enhancement_timestamp' in metadata,
                    'has_enabled': 'enhancement_enabled' in metadata
                }
                
                # åˆ¤æ–­æ˜¯å¦å·²æ·±åº¦å¤„ç†
                if self._is_deep_processed(metadata):
                    processed_images.append(image_info)
                else:
                    unprocessed_images.append(image_info)
        
        print(f"ğŸ“Š æŸ¥è¯¢å®Œæˆ:")
        print(f"   âœ… å·²æ·±åº¦å¤„ç†: {len(processed_images)} å¼ ")
        print(f"   â³ æœªæ·±åº¦å¤„ç†: {len(unprocessed_images)} å¼ ")
        
        return {
            'processed': processed_images,
            'unprocessed': unprocessed_images
        }
    
    def _is_deep_processed(self, metadata: Dict[str, Any]) -> bool:
        """åˆ¤æ–­å›¾ç‰‡æ˜¯å¦å·²æ·±åº¦å¤„ç†"""
        # ä¸»è¦æ£€æŸ¥enhanced_descriptionæ˜¯å¦åŒ…å«æ·±åº¦å¤„ç†æ ‡æ³¨
        enhanced_desc = metadata.get('enhanced_description', '')
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«ä¸»ç¨‹åºæ·»åŠ çš„æ·±åº¦å¤„ç†æ ‡æ³¨ - ä½¿ç”¨é…ç½®ç®¡ç†
        depth_markers = getattr(self.config, 'depth_processing_markers', [
            'åŸºç¡€è§†è§‰æè¿°:', 'å†…å®¹ç†è§£æè¿°:', 'æ•°æ®è¶‹åŠ¿æè¿°:', 'è¯­ä¹‰ç‰¹å¾æè¿°:',
            'chart_type:', 'data_points:', 'trends:', 'key_insights:',
            'enhancement_enabled'
        ])
        
        has_depth_markers = any(marker in enhanced_desc for marker in depth_markers)
        
        # å¦‚æœenhanced_descriptionåŒ…å«æ·±åº¦æ ‡è®°ï¼Œè¯´æ˜å·²æ·±åº¦å¤„ç†
        if has_depth_markers:
            return True
        
        # å¤‡ç”¨æ£€æŸ¥ï¼šå…ƒæ•°æ®å­—æ®µï¼ˆå¦‚æœå­˜åœ¨çš„è¯ï¼‰
        has_layered = 'layered_descriptions' in metadata
        has_structured = 'structured_info' in metadata
        
        if has_layered and has_structured:
            return True
        
        # å¦‚æœéƒ½ä¸æ»¡è¶³ï¼Œè¯´æ˜æœªæ·±åº¦å¤„ç†
        return False
    
    def _detect_image_type(self, image_path: str) -> str:
        """æ£€æµ‹å›¾ç‰‡ç±»å‹ - ä½¿ç”¨ä¸»ç¨‹åºä¸­çš„å‡½æ•°"""
        try:
            return self.image_processor._detect_image_type(image_path)
        except Exception as e:
            logger.warning(f"æ£€æµ‹å›¾ç‰‡ç±»å‹å¤±è´¥: {e}")
            return 'general'
    
    def _extract_semantic_features(self, image_path: str) -> Dict[str, Any]:
        """æå–å›¾ç‰‡è¯­ä¹‰ç‰¹å¾ - ä½¿ç”¨ä¸»ç¨‹åºä¸­çš„å‡½æ•°"""
        try:
            # è¿™é‡Œå¯ä»¥è°ƒç”¨ä¸»ç¨‹åºä¸­çš„è¯­ä¹‰ç‰¹å¾æå–å‡½æ•°
            # å¦‚æœéœ€è¦ç”Ÿæˆembeddingï¼Œå¯ä»¥ä½¿ç”¨ self.image_processor.generate_image_embedding(image_path)
            # ç„¶åè°ƒç”¨è¯­ä¹‰ç‰¹å¾æå–
            return {}
        except Exception as e:
            logger.warning(f"æå–è¯­ä¹‰ç‰¹å¾å¤±è´¥: {e}")
            return {}
    
    def display_image_status(self, image_status: Dict[str, List[Dict[str, Any]]]):
        """æ˜¾ç¤ºå›¾ç‰‡çŠ¶æ€ä¿¡æ¯"""
        print("\n" + "="*80)
        print("ğŸ“Š å›¾ç‰‡å¤„ç†çŠ¶æ€è¯¦æƒ…")
        print("="*80)
        
        # æ˜¾ç¤ºå·²å¤„ç†çš„å›¾ç‰‡
        processed = image_status['processed']
        if processed:
            print(f"\nâœ… å·²æ·±åº¦å¤„ç†çš„å›¾ç‰‡ ({len(processed)} å¼ ):")
            for i, img in enumerate(processed[:5], 1):  # åªæ˜¾ç¤ºå‰5å¼ 
                image_type_info = f" [{img.get('image_type', 'unknown')}]" if img.get('image_type') != 'unknown' else ""
                print(f"   {i}. {img['document_name']} - ç¬¬{img['page_number']}é¡µ - {img['image_id']}{image_type_info}")
            if len(processed) > 5:
                print(f"   ... è¿˜æœ‰ {len(processed) - 5} å¼ å·²å¤„ç†å›¾ç‰‡")
        else:
            print("\nâœ… å·²æ·±åº¦å¤„ç†çš„å›¾ç‰‡: 0 å¼ ")
        
        # æ˜¾ç¤ºæœªå¤„ç†çš„å›¾ç‰‡
        unprocessed = image_status['unprocessed']
        if unprocessed:
            print(f"\nâ³ æœªæ·±åº¦å¤„ç†çš„å›¾ç‰‡ ({len(unprocessed)} å¼ ):")
            for i, img in enumerate(unprocessed[:10], 1):  # æ˜¾ç¤ºå‰10å¼ 
                image_type_info = f" [{img.get('image_type', 'unknown')}]" if img.get('image_type') != 'unknown' else ""
                print(f"   {i}. {img['document_name']} - ç¬¬{img['page_number']}é¡µ - {img['image_id']}{image_type_info}")
            if len(unprocessed) > 10:
                print(f"   ... è¿˜æœ‰ {len(unprocessed) - 10} å¼ æœªå¤„ç†å›¾ç‰‡")
        else:
            print("\nâ³ æœªæ·±åº¦å¤„ç†çš„å›¾ç‰‡: 0 å¼ ")
        
        print("\n" + "="*80)
    
    def get_user_confirmation(self, unprocessed_count: int) -> bool:
        """è·å–ç”¨æˆ·ç¡®è®¤æ˜¯å¦è¿›è¡Œæ·±åº¦å¤„ç†"""
        if unprocessed_count == 0:
            print("ğŸ‰ æ‰€æœ‰å›¾ç‰‡éƒ½å·²æ·±åº¦å¤„ç†å®Œæˆï¼")
            return False
        
        print(f"\nâ“ å‘ç° {unprocessed_count} å¼ å›¾ç‰‡æœªæ·±åº¦å¤„ç†")
        print("è¯·é€‰æ‹©æ“ä½œ:")
        print("   1. è¿›è¡Œæ·±åº¦å¤„ç†")
        print("   2. é€€å‡ºç¨‹åº")
        
        while True:
            try:
                choice = input("\nè¯·è¾“å…¥é€‰æ‹© (1 æˆ– 2): ").strip()
                if choice == '1':
                    return True
                elif choice == '2':
                    return False
                else:
                    print("âŒ æ— æ•ˆé€‰æ‹©ï¼Œè¯·è¾“å…¥ 1 æˆ– 2")
            except KeyboardInterrupt:
                print("\n\nğŸ‘‹ ç¨‹åºå·²é€€å‡º")
                return False
    
    def process_unprocessed_images(self, unprocessed_images: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """å¤„ç†æœªæ·±åº¦å¤„ç†çš„å›¾ç‰‡"""
        print(f"\nğŸ”„ å¼€å§‹æ·±åº¦å¤„ç† {len(unprocessed_images)} å¼ å›¾ç‰‡...")
        
        # åŠ è½½å‘é‡æ•°æ®åº“
        vector_store = self.load_vector_store()
        if not vector_store:
            print("âŒ æ— æ³•åŠ è½½å‘é‡æ•°æ®åº“ï¼Œå¤„ç†ç»ˆæ­¢")
            return []
        
        # å‡†å¤‡æ‰¹é‡å¤„ç†çš„æ•°æ®æ ¼å¼
        image_batch = []
        for img_info in unprocessed_images:
            # æ£€æŸ¥å›¾ç‰‡æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            image_path = img_info['image_path']
            if not os.path.exists(image_path):
                print(f"âš ï¸ å›¾ç‰‡æ–‡ä»¶ä¸å­˜åœ¨: {image_path}")
                continue
            
            # ä½¿ç”¨ä¸»ç¨‹åºä¸­çš„å‡½æ•°æ£€æµ‹å›¾ç‰‡ç±»å‹å’Œç”Ÿæˆå›¾ç‰‡ID
            image_type = self._detect_image_type(image_path)
            if not img_info.get('image_id') or img_info['image_id'] == 'unknown':
                try:
                    generated_image_id = self.image_processor._generate_image_id(image_path)
                    img_info['image_id'] = generated_image_id
                except Exception as e:
                    logger.warning(f"ç”Ÿæˆå›¾ç‰‡IDå¤±è´¥: {e}")
                
            image_batch.append({
                'image_path': image_path,
                'enhanced_description': img_info.get('enhanced_description', ''),
                'doc_id': img_info['doc_id'],
                'document_name': img_info['document_name'],
                'page_number': img_info['page_number'],
                'image_id': img_info['image_id'],
                'image_type': image_type
            })
        
        if not image_batch:
            print("âŒ æ²¡æœ‰æœ‰æ•ˆçš„å›¾ç‰‡æ–‡ä»¶å¯ä»¥å¤„ç†")
            return []
        
        # è°ƒç”¨ä¸»ç¨‹åºä¸­çš„æ‰¹é‡å¤„ç†å‡½æ•°
        print(f"ğŸ“· å‡†å¤‡å¤„ç† {len(image_batch)} å¼ æœ‰æ•ˆå›¾ç‰‡...")
        enhanced_results = self.image_enhancer.enhance_batch_images(image_batch)
        
        # å¤„ç†ç»“æœå¹¶æ›´æ–°æ•°æ®åº“
        results = []
        for i, (img_info, enhanced_info) in enumerate(zip(image_batch, enhanced_results), 1):
            try:
                print(f"\nğŸ“· å¤„ç†è¿›åº¦: {i}/{len(image_batch)}")
                print(f"   æ–‡æ¡£: {img_info['document_name']}")
                print(f"   é¡µç : {img_info['page_number']}")
                print(f"   å›¾ç‰‡ID: {img_info['image_id']}")
                
                # æ›´æ–°å‘é‡æ•°æ®åº“ä¸­çš„å…ƒæ•°æ®
                if enhanced_info and 'enhanced_description' in enhanced_info:
                    try:
                        # è·å–æ–‡æ¡£å¯¹è±¡
                        doc = vector_store.docstore._dict[img_info['doc_id']]
                        
                        # æ›´æ–°å…ƒæ•°æ®
                        updated_metadata = doc.metadata.copy()
                        updated_metadata['enhanced_description'] = enhanced_info['enhanced_description']
                        updated_metadata['enhancement_timestamp'] = int(time.time())
                        updated_metadata['enhancement_enabled'] = True
                        
                        # å¦‚æœæœ‰åˆ†å±‚æè¿°ï¼Œä¹Ÿä¿å­˜
                        if 'layered_descriptions' in enhanced_info:
                            updated_metadata['layered_descriptions'] = enhanced_info['layered_descriptions']
                        
                        # å¦‚æœæœ‰ç»“æ„åŒ–ä¿¡æ¯ï¼Œä¹Ÿä¿å­˜
                        if 'structured_info' in enhanced_info:
                            updated_metadata['structured_info'] = enhanced_info['structured_info']
                        
                        # æ·»åŠ å›¾ç‰‡ç±»å‹ä¿¡æ¯ï¼ˆä½¿ç”¨ä¸»ç¨‹åºä¸­çš„æ£€æµ‹ç»“æœï¼‰
                        if 'image_type' in img_info:
                            updated_metadata['image_type'] = img_info['image_type']
                        
                        # æ›´æ–°æ–‡æ¡£å…ƒæ•°æ®
                        doc.metadata = updated_metadata
                        
                        print(f"   âœ… æ•°æ®åº“æ›´æ–°å®Œæˆ")
                        
                    except Exception as e:
                        print(f"   âš ï¸ æ•°æ®åº“æ›´æ–°å¤±è´¥: {e}")
                        enhanced_info = {'enhanced_description': img_info['enhanced_description']}
                
                # è®°å½•å¤„ç†ç»“æœ
                results.append({
                    'doc_id': img_info['doc_id'],
                    'status': 'success',
                    'enhanced_info': enhanced_info,
                    'image_path': img_info['image_path']
                })
                
                print(f"   âœ… å¤„ç†å®Œæˆ")
                    
            except Exception as e:
                logger.error(f"å¤„ç†å›¾ç‰‡å¤±è´¥ {img_info['image_id']}: {e}")
                results.append({
                    'doc_id': img_info['doc_id'],
                    'status': 'failed',
                    'error': str(e),
                    'image_path': img_info['image_path']
                })
                print(f"   âŒ å¤„ç†å¤±è´¥: {e}")
        
        # ä¿å­˜æ›´æ–°åçš„å‘é‡æ•°æ®åº“
        try:
            print(f"\nğŸ’¾ æ­£åœ¨ä¿å­˜æ›´æ–°åçš„å‘é‡æ•°æ®åº“...")
            # ä½¿ç”¨ä¸»ç¨‹åºä¸­çš„ä¿å­˜å‡½æ•°ï¼Œä¿æŒä¸€è‡´æ€§
            self.vector_generator._save_vector_store_with_metadata(vector_store, self.vector_db_path)
            print(f"âœ… å‘é‡æ•°æ®åº“ä¿å­˜æˆåŠŸ")
        except Exception as e:
            print(f"âŒ ä¿å­˜å‘é‡æ•°æ®åº“å¤±è´¥: {e}")
            logger.error(f"ä¿å­˜å‘é‡æ•°æ®åº“å¤±è´¥: {e}")
        
        print(f"\nâœ… æ·±åº¦å¤„ç†å®Œæˆï¼Œå…±å¤„ç† {len(image_batch)} å¼ å›¾ç‰‡")
        return results
    
    def display_processing_results(self, results: List[Dict[str, Any]]):
        """æ˜¾ç¤ºå¤„ç†ç»“æœ"""
        print("\n" + "="*80)
        print("ğŸ“Š æ·±åº¦å¤„ç†ç»“æœç»Ÿè®¡")
        print("="*80)
        
        success_count = len([r for r in results if r['status'] == 'success'])
        failed_count = len([r for r in results if r['status'] == 'failed'])
        
        print(f"âœ… æˆåŠŸå¤„ç†: {success_count} å¼ ")
        print(f"âŒ å¤„ç†å¤±è´¥: {failed_count} å¼ ")
        print(f"ğŸ“Š æˆåŠŸç‡: {success_count/(success_count+failed_count)*100:.1f}%")
        
        if failed_count > 0:
            print(f"\nâŒ å¤±è´¥è¯¦æƒ…:")
            for result in results:
                if result['status'] == 'failed':
                    print(f"   - {result['image_path']}: {result['error']}")
        
        print("\n" + "="*80)
    
    def run(self):
        """è¿è¡Œä¸»ç¨‹åº"""
        try:
            print("ğŸš€ å›¾ç‰‡å¢å¼ºæ–°ç¨‹åºå¯åŠ¨")
            print("="*50)
            
            # 1. æŸ¥è¯¢å›¾ç‰‡çŠ¶æ€
            image_status = self.query_image_status()
            
            # 2. æ˜¾ç¤ºçŠ¶æ€ä¿¡æ¯
            self.display_image_status(image_status)
            
            # 3. è·å–ç”¨æˆ·ç¡®è®¤
            unprocessed_count = len(image_status['unprocessed'])
            if not self.get_user_confirmation(unprocessed_count):
                print("ğŸ‘‹ ç¨‹åºé€€å‡º")
                return
            
            # 4. è¿›è¡Œæ·±åº¦å¤„ç†
            results = self.process_unprocessed_images(image_status['unprocessed'])
            
            # 5. æ˜¾ç¤ºå¤„ç†ç»“æœ
            self.display_processing_results(results)
            
            print("ğŸ‰ ç¨‹åºæ‰§è¡Œå®Œæˆï¼")
            
        except Exception as e:
            logger.error(f"ç¨‹åºæ‰§è¡Œå¤±è´¥: {e}")
            print(f"âŒ ç¨‹åºæ‰§è¡Œå¤±è´¥: {e}")
            import traceback
            traceback.print_exc()


def main():
    """ä¸»å‡½æ•°"""
    try:
        enhancer = ImageEnhanceNew()
        enhancer.run()
    except Exception as e:
        print(f"âŒ ç¨‹åºå¯åŠ¨å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()
