{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49277df7",
   "metadata": {},
   "source": [
    "## Select by length\n",
    "\n",
    "此示例选择器根据长度选择要使用的示例。当您担心构建的提示会超过上下文窗口的长度时，这非常有用。对于较长的输入，它将选择较少的示例来包含，而对于较短的输入，它将选择更多的示例。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f242efe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import FewShotPromptTemplate, PromptTemplate\n",
    "from langchain.prompts.example_selector import LengthBasedExampleSelector\n",
    "\n",
    "# 创建一个反义词的任务示例\n",
    "examples = [\n",
    "    {\"input\": \"开心\", \"output\": \"伤心\"},\n",
    "    {\"input\": \"高\", \"output\": \"矮\"},\n",
    "    {\"input\": \"精力充沛\", \"output\": \"没精打采\"},\n",
    "    {\"input\": \"粗\", \"output\": \"细\"},\n",
    "]\n",
    "\n",
    "example_prompt = PromptTemplate(\n",
    "    input_variables=[\"input\", \"output\"],\n",
    "    template=\"Input: {input}\\nOutput: {output}\",\n",
    ")\n",
    "example_selector = LengthBasedExampleSelector(\n",
    "    # 可供选择的示例。\n",
    "    examples=examples,\n",
    "    # PromptTemplate 用于格式化示例。\n",
    "    example_prompt=example_prompt,\n",
    "    # 格式化示例的最大长度。\n",
    "    # 长度由下面的 get_text_length 函数测量。\n",
    "    max_length=25,\n",
    "    # 用于获取字符串长度的函数，使用\n",
    "    # 确定要包含哪些示例。被注释掉是因为\n",
    "    # 如果未指定，则将其作为默认值提供。\n",
    "    # get_text_length: Callable[[str], int] = lambda x: len(re.split(\"\\n| \", x))\n",
    ")\n",
    "dynamic_prompt = FewShotPromptTemplate(\n",
    "    # 我们提供了一个ExampleSelector而不是示例。\n",
    "    example_selector=example_selector,\n",
    "    example_prompt=example_prompt,\n",
    "    prefix=\"给出每个输入的反义词\",\n",
    "    suffix=\"Input: {adjective}\\nOutput:\",\n",
    "    input_variables=[\"adjective\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9af99801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "给出每个输入的反义词\n",
      "\n",
      "Input: 开心\n",
      "Output: 伤心\n",
      "\n",
      "Input: 高\n",
      "Output: 矮\n",
      "\n",
      "Input: 精力充沛\n",
      "Output: 没精打采\n",
      "\n",
      "Input: 粗\n",
      "Output: 细\n",
      "\n",
      "Input: big\n",
      "Output:\n"
     ]
    }
   ],
   "source": [
    "#示例输入量较小，因此选择所有示例。\n",
    "print(dynamic_prompt.format(adjective=\"big\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45a1d3de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "给出每个输入的反义词\n",
      "\n",
      "Input: 开心\n",
      "Output: 伤心\n",
      "\n",
      "Input: big and huge and massive and large and gigantic and tall and much much much much much bigger than everything else\n",
      "Output:\n"
     ]
    }
   ],
   "source": [
    "# 示例输入较长，因此仅选择一个示例。\n",
    "long_string = \"big and huge and massive and large and gigantic and tall and much much much much much bigger than everything else\"\n",
    "print(dynamic_prompt.format(adjective=long_string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "337a135a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "给出每个输入的反义词\n",
      "\n",
      "Input: 开心\n",
      "Output: 伤心\n",
      "\n",
      "Input: 高\n",
      "Output: 矮\n",
      "\n",
      "Input: 精力充沛\n",
      "Output: 没精打采\n",
      "\n",
      "Input: 粗\n",
      "Output: 细\n",
      "\n",
      "Input: 胖\n",
      "Output: 瘦\n",
      "\n",
      "Input: 热情\n",
      "Output:\n"
     ]
    }
   ],
   "source": [
    "# 您也可以将示例添加到示例选择器。\n",
    "new_example = {\"input\": \"胖\", \"output\": \"瘦\"}\n",
    "dynamic_prompt.example_selector.add_example(new_example)\n",
    "print(dynamic_prompt.format(adjective=\"热情\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "14a8e4ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "嗯，我现在得帮用户找出输入单词的反义词。让我仔细看看每个例子，然后想想它们各自的反义词。\n",
      "\n",
      "第一个是“开心”变“伤心”，这很简单，当然是“悲伤”。第二个“高”变成“矮”，也是明显的，“矮”。第三个，“精力充沛”到“没精打采”，这说明“精力充沛”意味着有丰富的精力，所以反义词应该是没有力量或者不够活跃的状态。第四个“粗”对应“细”，“粗”是指表面的，而“细”是深入的，所以这明显是一个字面意义上的反义词。\n",
      "\n",
      "接下来第五个，“热烈”变成什么呢？“热烈”通常意味着热情、热闹，那么它的反义词应该是安静或者冷淡的状态。第六个是“慷慨”，这就是指说话或行动的时候语气比较正向，不显得 slackcased，所以它的反义词应该是“慷慨的”就是负面的表达。\n",
      "\n",
      "不过，我得再仔细检查一下每个例子是否正确理解了反义词的关系。比如，“开心”和“悲伤”确实是相反的意思，没有明显的问题。“高”对应“矮”没错，“精力充沛”到“没精打采”，没问题。接下来的是“粗”和“细”，字面意思完全不符合对方，所以是对的。\n",
      "\n",
      "然后是“热烈”和“冷淡”，中间可能有温度或热情的感觉，所以对的上。至于“慷慨”，确实是积极和消极的对立面，所以也是正确的。\n",
      "\n",
      "总结一下，每个输入单词的反义词都正确对应了输出部分，没有问题。我觉得这样应该就解决了用户的需求。\n",
      "</think>\n",
      "\n",
      "开心 → 愉忧  \n",
      "高 → 矮  \n",
      "精力充沛 → 无精打采  \n",
      "粗 → 细  \n",
      "热衷 → 暗示  \n",
      "热烈 → 严肃"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "openai_api_key = \"EMPTY\"\n",
    "openai_api_base = \"http://localhost:11434/v1\"\n",
    "MODEL = \"deepseek-r1:1.5b\"\n",
    "chat = ChatOpenAI(\n",
    "    model= MODEL,\n",
    "    openai_api_key=openai_api_key,\n",
    "    openai_api_base=openai_api_base,\n",
    "    temperature=0.7,\n",
    ")\n",
    "\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "chain = dynamic_prompt | chat | output_parser\n",
    "\n",
    "result=chain.invoke({\"adjective\":\"热情\"})\n",
    "for chunk in result:\n",
    "    print(chunk, end=\"\", flush=True)  # 实时流式打印"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c5d479",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 最大余弦相似度的嵌入示例\n",
    "MaxMarginalRelevanceExampleSelector 根据与输入最相似的示例组合来选择示例，同时还针对多样性进行优化。它通过查找与输入具有最大余弦相似度的嵌入示例来实现这一点，然后迭代地添加它们，同时惩罚它们与已选择示例的接近程度。\n",
    "\n",
    "```\n",
    "pip install sentence-transformers\n",
    "pip install faiss-cpu\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5100039d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: sentence-transformers in c:\\users\\administrator\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (4.1.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in c:\\users\\administrator\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sentence-transformers) (4.50.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\administrator\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\administrator\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sentence-transformers) (2.6.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\administrator\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sentence-transformers) (1.6.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\administrator\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\users\\administrator\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sentence-transformers) (0.30.1)\n",
      "Requirement already satisfied: Pillow in c:\\users\\administrator\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sentence-transformers) (11.1.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in c:\\users\\administrator\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sentence-transformers) (4.13.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\administrator\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\administrator\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.12.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\administrator\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\administrator\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
      "Requirement already satisfied: requests in c:\\users\\administrator\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
      "Requirement already satisfied: networkx in c:\\users\\administrator\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\administrator\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
      "Requirement already satisfied: setuptools in c:\\users\\administrator\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (78.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\administrator\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\administrator\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\administrator\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\administrator\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\administrator\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\administrator\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\administrator\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\administrator\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\administrator\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\administrator\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\administrator\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\administrator\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\administrator\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\administrator\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.1.31)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ab6de5d7-cad0-4719-958f-c50c6756967a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: faiss-cpu in c:\\users\\administrator\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.10.0)\n",
      "Requirement already satisfied: numpy<3.0,>=1.25.0 in c:\\users\\administrator\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from faiss-cpu) (1.26.4)\n",
      "Requirement already satisfied: packaging in c:\\users\\administrator\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from faiss-cpu) (24.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "! pip install faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9bd467aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_22688\\2678929918.py:13: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(model_name=embeddings_path)\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import FewShotPromptTemplate, PromptTemplate\n",
    "from langchain.prompts.example_selector import (\n",
    "    MaxMarginalRelevanceExampleSelector,\n",
    "    SemanticSimilarityExampleSelector,\n",
    ")\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "# embedding在本地\n",
    "\n",
    "\n",
    "embeddings_path = 'D:\\\\AInewModels\\\\BAAI\\\\bge-m3'\n",
    "embeddings = HuggingFaceEmbeddings(model_name=embeddings_path)\n",
    "\n",
    "example_prompt = PromptTemplate(\n",
    "    input_variables=[\"input\", \"output\"],\n",
    "    template=\"Input: {input}\\nOutput: {output}\",\n",
    ")\n",
    "\n",
    "# 创建反义词的假装任务的示例。\n",
    "examples = [\n",
    "    {\"input\": \"高\", \"output\": \"矮\"},\n",
    "    {\"input\": \"精力充沛\", \"output\": \"没精打采\"},\n",
    "    {\"input\": \"粗\", \"output\": \"细\"},\n",
    "    {\"input\": \"快乐\", \"output\": \"悲伤\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fd8d46e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FewShotPromptTemplate(input_variables=['adjective'], input_types={}, partial_variables={}, example_selector=MaxMarginalRelevanceExampleSelector(vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x000001AE009616A0>, k=2, example_keys=None, input_keys=None, vectorstore_kwargs=None, fetch_k=20), example_prompt=PromptTemplate(input_variables=['input', 'output'], input_types={}, partial_variables={}, template='Input: {input}\\nOutput: {output}'), suffix='Input: {adjective}\\nOutput:', prefix='给出每个输入的反义词')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# 作用​：从大量示例中选取 k 个最优示例，兼顾：\n",
    "# ​    相关性​（与输入问题语义相似）\n",
    "# ​    多样性​（避免选出的示例内容重复）\n",
    "# ​算法​：基于 ​最大边际相关性（Maximal Marginal Relevance, MMR）​，在相关性和多样性之间取得平衡。\n",
    "example_selector = MaxMarginalRelevanceExampleSelector.from_examples(\n",
    "    # 可供选择的示例列表。\n",
    "    examples,\n",
    "    # 嵌入类用于生成用于测量语义相似性的嵌入。\n",
    "    embeddings,\n",
    "    # VectorStore 类用于存储嵌入并进行相似性搜索。\n",
    "    FAISS,\n",
    "    # 要生成的示例数量。\n",
    "    k=2,\n",
    ")\n",
    "mmr_prompt = FewShotPromptTemplate(\n",
    "    # 提供一个ExampleSelector而不是示例。\n",
    "    example_selector=example_selector,\n",
    "    example_prompt=example_prompt,\n",
    "    prefix=\"给出每个输入的反义词\",\n",
    "    suffix=\"Input: {adjective}\\nOutput:\",\n",
    "    input_variables=[\"adjective\"],\n",
    ")\n",
    "mmr_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "55a0e0fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "给出每个输入的反义词\n",
      "\n",
      "Input: 快乐\n",
      "Output: 悲伤\n",
      "\n",
      "Input: 高\n",
      "Output: 矮\n",
      "\n",
      "Input: 担心\n",
      "Output:\n"
     ]
    }
   ],
   "source": [
    "# 输入是一种感觉，所以应该选择快乐/悲伤的例子作为第一个\n",
    "print(mmr_prompt.format(adjective=\"担心\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ed086e6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "嗯，用户给了三个例子，让我找出每个单词的反义词。第一个是“快乐”对应“悲伤”，这很简单，因为这两个词都是情感上的相反状态。\n",
      "\n",
      "第二个例子，“高”对应“矮”，这也简单，高就是较大的，矮就是较小的。\n",
      "\n",
      "第三个例子是“担忧”，输出为空。我得想想，“担忧”是什么意思呢？它通常是指担心 something会不好的时候，比如“担忧下雨了”。那它的反义词应该是相对容易的事情或者事情发生的情况嘛，比如“开心”或“轻松”。\n",
      "\n",
      "不过用户并没有给出输出，所以我需要填写反义词。最合适的应该是“开心”，因为它和担忧形成情感上的对比，一个是担心，一个是兴奋。\n",
      "\n",
      "总结一下，每个输入的反义词分别是：\n",
      "1. 快乐 → 悲伤\n",
      "2. 高 → 矮\n",
      "3. 惊心 → 乐观\n",
      "</think>\n",
      "\n",
      "输入： 快乐  \n",
      "输出： 悲伤  \n",
      "\n",
      "输入： 高  \n",
      "输出： 矮  \n",
      "\n",
      "输入： 惊心  \n",
      "输出： 乐观"
     ]
    }
   ],
   "source": [
    "chain = mmr_prompt | chat | output_parser\n",
    "\n",
    "result=chain.invoke({\"adjective\":\"担心\"})\n",
    "for chunk in result:\n",
    "    print(chunk, end=\"\", flush=True)  # 实时流式打印"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e852896",
   "metadata": {},
   "source": [
    "## 通过n-gram重叠选择\n",
    "\n",
    "NGramOverlapExampleSelector 根据 ngram 重叠得分，根据与输入最相似的示例来选择示例并对其进行排序。 ngram 重叠分数是 0.0 到 1.0 之间的浮点数（含 0.0 和 1.0）。\n",
    "\n",
    "选择器允许设置阈值分数。 ngram 重叠分数小于或等于阈值的示例被排除。默认情况下，阈值设置为 -1.0，因此不会排除任何示例，只会对它们重新排序。将阈值设置为 0.0 将排除与输入没有 ngram 重叠的示例。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e4e41470",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import FewShotPromptTemplate, PromptTemplate\n",
    "from langchain.prompts.example_selector.ngram_overlap import NGramOverlapExampleSelector\n",
    "\n",
    "example_prompt = PromptTemplate(\n",
    "    input_variables=[\"input\", \"output\"],\n",
    "    template=\"Input: {input}\\nOutput: {output}\",\n",
    ")\n",
    "\n",
    "# 虚构翻译任务的示例。.\n",
    "examples = [\n",
    "    {\"input\": \"See Spot run.\", \"output\": \"请参阅现场运行。\"},\n",
    "    {\"input\": \"My dog barks.\", \"output\": \"我的狗吠叫。\"},\n",
    "    {\"input\": \"cat can run\", \"output\": \"猫会跑\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bfbe942d",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_selector = NGramOverlapExampleSelector(\n",
    "    # 可供选择的示例。\n",
    "    examples=examples,\n",
    "    # PromptTemplate 用于格式化示例。\n",
    "    example_prompt=example_prompt,\n",
    "    # 选择器停止的阈值。\n",
    "    # 默认设置为-1.0。\n",
    "    threshold=-1.0,\n",
    "    # 对于负阈值：择器按 ngram 重叠分数对示例进行排序，并且不排除任何示例。\n",
    "    # 对于大于 1.0 的阈值：选择器排除所有示例，并返回一个空列表。\n",
    "    # 对于阈值等于 0.0:选择器按 ngram 重叠分数对示例进行排序，并排除那些与输入没有 ngram 重叠的内容。\n",
    ")\n",
    "dynamic_prompt = FewShotPromptTemplate(\n",
    "    # 提供了一个ExampleSelector而不是示例。\n",
    "    example_selector=example_selector,\n",
    "    example_prompt=example_prompt,\n",
    "    prefix=\"为每个输入提供中文翻译\",\n",
    "    suffix=\"Input: {sentence}\\nOutput:\",\n",
    "    input_variables=[\"sentence\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "09d40787",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "为每个输入提供中文翻译\n",
      "\n",
      "Input: cat can run\n",
      "Output: 猫会跑\n",
      "\n",
      "Input: See Spot run.\n",
      "Output: 请参阅现场运行。\n",
      "\n",
      "Input: My dog barks.\n",
      "Output: 我的狗吠叫。\n",
      "\n",
      "Input: cat can run fast.\n",
      "Output:\n"
     ]
    }
   ],
   "source": [
    "# 一个与“cat can run”有大量 ngram 重叠的示例输入。\n",
    "# 并且与“我的狗吠”没有重叠。\n",
    "print(dynamic_prompt.format(sentence=\"cat can run fast.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dd129833",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "为每个输入提供中文翻译\n",
      "\n",
      "Input: cat can run\n",
      "Output: 猫会跑\n",
      "\n",
      "Input: cat can run fast.\n",
      "Output:\n"
     ]
    }
   ],
   "source": [
    "# 您可以设置排除示例的阈值。\n",
    "# 例如，设置阈值等于0.0\n",
    "# 排除与输入没有 ngram 重叠的示例。\n",
    "# 自从“我的狗叫了。” 与“cat can run fast”没有 ngram 重叠。\n",
    "# 它被排除在外。\n",
    "example_selector.threshold = 0.0\n",
    "print(dynamic_prompt.format(sentence=\"cat can run fast.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "016b5fd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "为每个输入提供中文翻译\n",
      "\n",
      "Input: cat can run\n",
      "Output: 猫会跑\n",
      "\n",
      "Input: cat can play fetch.\n",
      "Output:\n"
     ]
    }
   ],
   "source": [
    "# 设置小的非零阈值\n",
    "example_selector.threshold = 0.01\n",
    "print(dynamic_prompt.format(sentence=\"cat can play fetch.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0bb65d99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "嗯，用户给了两个例子，第一个是英文，第二个是中文。看起来他们希望我用中文来翻译后一个句子。先看看用户给的例子：\n",
      "\n",
      "输入1：cat can run\n",
      "输出1：猫会跑\n",
      "\n",
      "那输入2就是“cat can play fetch.”，需要翻译成中文。首先，“cat”是“猫”，“can”是“能”，“play”是“打”，“fetch”是“打窝币”。所以直接翻译应该是“猫能打窝币。”\n",
      "</think>\n",
      "\n",
      "猫能打窝币。"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "openai_api_key = \"EMPTY\"\n",
    "openai_api_base = \"http://localhost:11434/v1\"\n",
    "MODEL = \"deepseek-r1:1.5b\"\n",
    "chat = ChatOpenAI(\n",
    "    model= MODEL,\n",
    "    openai_api_key=openai_api_key,\n",
    "    openai_api_base=openai_api_base,\n",
    "    temperature=0.7,\n",
    ")\n",
    "\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "chain = dynamic_prompt | chat | output_parser\n",
    "\n",
    "result=chain.invoke({\"sentence\":\"cat can play fetch.\"})\n",
    "for chunk in result:\n",
    "    print(chunk, end=\"\", flush=True)  # 实时流式打印\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43554716",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
